Unnamed: 0,title,topic_id,step_id,topological_index,url,text
0,Introduction to Python,333,47352,89,https://hyperskill.org/learn/step/47352,"Let's wrap up what you've learned:

Python Origins: Created by Guido van Rossum in 1991, Python is renowned for its readability and flexibility. Named after the comedy troupe Monty Python, it aims to make coding fun and accessible.

Magic of print(): In Python, the print() function serves as your magic spell for displaying text on the screen.

String Enclosures: Remember, strings must be enclosed in appropriate quotes.

Case Sensitivity: Python is case-sensitive, so watch out for those details!

Indentation: Beware of extra indentation. This will lead to errors.

Call appropriately: Calling functions by the wrong name is a crime in Python.

So, dive in, have fun, and embrace the adventure of learning Python!
"
1,Multi-line programs,335,47555,90,https://hyperskill.org/learn/step/47555,"In our journey through Python's printing magic, we've discovered some cool tricks! Here's what we've been up to:
Printing several lines: The print() function is not just for printing one line – it's a versatile tool for creating multi-line output in our Python programs.Making spaces: Using the print() function without anything inside the parentheses will leave an empty line.Being Quick: Triple quotes or \n can be used to print multiple lines with a single print() function call.Using comments: We can leave little notes in our code using #, kind of like leaving breadcrumbs for others to follow.
With our bag of printing tricks full to bursting, we're ready for the next adventure, eager to explore new lands and conquer even bigger challenges in the world of Python!
"
2,Basic data types,394,47516,91,https://hyperskill.org/learn/step/47516,"Alright, let's summarize what we've covered in this module — the ABCs of Python's basic data types:

Strings (str): Think of these as the MVPs for handling text. They're your go-to when dealing with words and sentences. Plus, you can wrap them up in either single or double quotes for extra flexibility.

Integers (int): These are the plain ol' whole numbers, no decimal points involved. Whether it's -3, 0, or 42, they're your trusty companions for counting and beyond.

Floats (float): Now, these are the numbers with a bit of flair—they come with a decimal point. From 3.14 to -0.5, floats are your go-to for those precise measurements.

And hey, let's not forget about our buddy, the type() function. This little gem helps us figure out what type of data we're dealing with at any given moment.
"
3,Variables,396,47536,92,https://hyperskill.org/learn/step/47536,"Let's summarize our lesson:
Variables: Think of them as labeled storage units for your values. Use the equal sign (=) to assign a value and call the variable by its name to get its stored value. You can change the value of a variable anytime and even assign different types of values to the same variable.
Naming Rules: Variable names should start with a letter or an underscore and can include letters, digits, and underscores. Remember, they're case-sensitive.
Avoid Reserved Keywords: Don’t use Python’s reserved words as variable names.
Descriptive Names: Choose meaningful, concise names for better readability. Avoid overly long or cryptic names.
Following these principles will help you write clean, efficient, and understandable Python code!
"
4,Integer arithmetic: basic operations,398,47564,93,https://hyperskill.org/learn/step/47564,"Let's summarize our lesson:
Arithmetic Operations: Python provides basic arithmetic operations like addition (+), subtraction (-), multiplication (*), and division (/). These operations are essential for various programming tasks and real-life scenarios.
Integer division: In Python, integer division can be performed using the // operator, which returns the quotient as an integer by discarding the fractional part.
With a solid understanding of these principles, you'll be equipped to tackle a wide range of challenges in Python programming!
But wait, there's more. In the upcoming lesson, you'll learn about two additional important operators in Python.
"
5,Taking user's input,404,47680,94,https://hyperskill.org/learn/step/47680,"Finally, let's summarize everything we've learned:
You can process user input with the input() function;
You may include a message for the user with the input prompt;
The input() function has no limit on the length of data entered and will wait until the user hits Enter;
This function treats all entered values as strings;
In the very next lesson, you will learn how to convert the input data to the data type you need later on. So, keep learning!
"
6,Program with numbers,399,47734,95,https://hyperskill.org/learn/step/47734,"Thus, we have shed some light on new details about integer arithmetic and the processing of numerical inputs in Python. The key takeaways are just two:
We can convert the numeric user input with the help of int(input()) or float(input())There are compound assignment operators, such as +=, -=, *=, which make the code shorter and more readable.
You definitely know a lot more on integer arithmetic, however, the learning journey of a developer is never over.
"
7,Invoking functions,400,5891,113,https://hyperskill.org/learn/step/5891,"Even though invoking functions in Python is not about casting a spell or the like, it does sometimes work wonders. Let's start with the concept. A function is a structured fragment of code we may want to use in more than one place and more than one time. What's more, functions allow us to read both our code and that of someone else way better. Haven't they become your favorite yet?
Here is a simple function call:
multiply(1, 7)
Here multiply is the name of the function, and numbers in parentheses (1, 7) are its arguments. What is an argument? Well, it's just a value, that will be used inside the function body. Let's go deeper into it!
Invoking print()
To call, or invoke, a function in your program, simply write its name and add parentheses after it. That's all it takes! Fun fact: if you've ever typed an expression like this print(""Hello, world!""), you already know a little about functions. In this tiny example, however, we see the message ""Hello, world!"" in parentheses after the name of the print function. What does it mean? This string is just an argument. And more often than not, functions do have arguments. As for the print function, we may as well use it with no argument at all or even with multiple arguments:
print(""Hello, world!"")
print()
print(""Bye,"", ""then!"")
And here is the output:
Hello, world!

Bye, then!
So, the first call prints one string, and the second call of print without arguments prints, an empty line, and the last call outputs our two messages as one expression. Are you surprised by these results? Then you may learn how the print function works in more detail from its documentation. The Python documentation contains all sorts of information about the function of your interest, for example, which arguments it expects.
Built-in functions
Functions can make life easier, provided one is aware of their existence. Many algorithms are already written, so there is no need for reinvention, except perhaps for educational purposes. The Python interpreter has several functions and types built into it, so they are always available. Currently, the number of built-in functions amounts to 71 (in the Python 3.13 version). Some of them are used to convert the object type, for example, str() returns a string, int() returns an integer, and float() returns a floating-point number. Others deal with numbers: you can round() them and sum() them, find the minimum min() or the maximum max(). Still, others give us information about the object: its type() or length len(). Let's consider them in action!
In the following example, len() counts the number of characters in the string (the same goes for any sequence, i.e. list, tuple, range, byte sequences, byte arrays).
Then we declare the variables integer and float_number, convert our string to corresponding types, and write their sum into my_sum. By the way, the sum() function deals with iterable objects, that's why we use double parentheses.
The result is a floating-point number, which becomes clear after printing my_sum.
Furthermore, you can see how to find the minimum and maximum values: in this example, the smallest number equals 3 and the largest number 8.4 (the sum of 3 and 5.4) belongs to floats.
There is far more to explore, but let's sum it up.
Conclusion
The beauty of functions is that we can use them without clear insight into their inner structure, and how they manage to perform what we need. If you want to put a function to good use, make sure to check its documentation or try invoking the special help() function with the name of the function in question wrapped in parentheses. It saves the day when the function behaves unexpectedly.
Let's make a summary:
functions are meant to be reusable. You can apply them multiple times with different arguments,to call a function write its name followed by parentheses and place the arguments within,normally, a function has documentation, which sometimes might be of huge help.
"
8,Boolean type and operations. True and false,415,6025,114,https://hyperskill.org/learn/step/6025,"In programming languages, the boolean, or logical, type is a common way to represent something that has only two opposite states like on or off, yes or no, etc. It's a very useful type which you will quickly see for yourself when you start working on your projects or even write small programs. In this topic, we'll look at the boolean type in Python and learn how to use it.

Boolean type
The Boolean type, or simply bool, is a special data type that has only two possible values: True and False. In Python, the names of boolean values start with a capital letter.
If you are writing an application that keeps track of door openings, you'll find it natural to use bool to store the current door state.

Boolean operations
There are three built-in boolean operators in Python: and, or and not. The first two are binary operators which means that they expect two operands. not is a unary operator, it is always applied to a single operand. First, let's look at these operators applied to the boolean values.
and is a binary operator, it takes two arguments and returns True if both arguments are true, otherwise, it returns False.or is a binary operator, it returns True if at least one argument is true, otherwise, it returns False.not is a unary operator, it reverses the boolean value of its argument.
The precedence of boolean operations
Logical operators have a different priority and it affects the order of evaluation. Here are the operators in order of their priorities:
1. not
2. and
3. or
So, not is considered first, then and, finally or. Having this in mind, consider the following expression:
First, the part not False gets evaluated, and after evaluation, we are left with False or True. This results in True, if you recall the previous section.
While dealing solely with the boolean values may seem obvious, the precedence of logical operations will be quite important to remember when you start working with so-called truthy and falsy values.

Truthy and falsy values
Though Python has the boolean data type, we often want to use non-boolean values in a logical context. And Python lets you test almost any object for truthfulness. When used with logical operators, values of non-boolean types, such as integers or strings, are called truthy or falsy. It depends on whether they are interpreted as True or False.
The following values are evaluated to False in Python:
constants defined to be false: None and False,zero of any numeric type: 0, 0.0,empty sequences and containers: """", [], {}.
Anything else generally evaluates to True. Here is a couple of examples:
Generally speaking, and and or could take any arguments that can be tested for a boolean value.
Now we can demonstrate more clearly the difference in operator precedence:
Again, let's break the above expression into parts. Since the operator and has a higher priority than or, we should look at the 5 and 100 part. Both 100 and 5 happen to be truthy values, so this operation will return 100. You have never seen this before, so it's natural to wonder why we have a number instead of the True value here. The explanation is as follows:

The operators or and and return one of their operands, not necessarily of the boolean type (see details below). Nonetheless, not always returns a boolean value.
and returns the first value if it evaluates to False, otherwise it returns the second value.
or returns the first value if it evaluates to True, otherwise it returns the second value.
Coming back to the original expression, you can see that the last part False or 100 does exactly the same thing, returns 100 instead of True.
Another tricky example is below:
A pair of parentheses is a way to specify the order in which the operations are performed. Thus, we evaluate this part of the expression first: False or ''. This operand '' evaluates to False and or returns this empty string. Since the result of the enclosed expression is negated, we get True in the end: not '' is the same as True. Why didn't we get, say, a non-empty string? The not operator creates a new value, which by default has the boolean type. So, as stated earlier, the unary operator always returns a logical value.

Short-circuit evaluation
The last thing to mention is that logical operators in Python are short-circuited. That's why they are also called lazy. That means that the second operand in such an expression is evaluated only if the first one is not sufficient to evaluate the whole expression.
x and y returns x if x is falsy; otherwise, it evaluates and returns y.x or y returns x if x is truthy; otherwise, it evaluates and returns y.
For instance:

Summary
So, in this topic, we've learned about a boolean type in Python, what boolean operations it has (not, and, or) and their priority. We also familiarized ourselves with the concept of truthy and falsy values and why logical operators in Python are called short-circuited. Those were the very basics of boolean values and logical operations in Python. It's definitely good to know them right from the beginning!
"
9,Comparisons,405,5920,115,https://hyperskill.org/learn/step/5920,"Writing code without comparing any values in it will get you only so far. Now, it's time to master this skill.

Comparison operators
Comparison or relation operations let you compare two values and determine the relation between them. There are ten comparison operators in Python:
< strictly less than
<= less than or equal
> strictly greater than
>= greater than or equal
== equal
!= not equal
is object identity
is not negated object identity
in membership
not in negated membership.

The result of applying these operators is always bool. The following sections focus on the first six operators (<, <=, >, >=, ==, !=), but you can find more details about identity and membership testing in the next topics. Also, pay attention to the greater/less than or equal operators, they are supposed to be written in the same order their names are pronounced: <= less than or equal, >= greater than or equal.

Comparing integers
In this topic, we will cover only integer comparison.

Any expression that returns an integer is a valid comparison operand too:

Given the defined variables a, b and c, we basically check if 5 is equal to -10 + 15, which is true.

Comparison chaining
Since comparison operations return boolean values, you can join them using logical operators. In this case, it is important to know their priority, i.e. which one is executed first. All comparison operations have the same priority, and it is lower than that of any arithmetic, shifting, or bitwise operation (the last two are used for operations with bytes).

In Python, there is a fancier way to write complex comparisons. It is called chaining. For example, x < y <= z is almost equivalent to the expression you saw in the last example. The difference is that y is evaluated only once.

Please pay attention to the fact that tools for code quality often recommend chaining comparisons instead of joining them.

Comparison chaining, however, should be used carefully because sometimes expressions might get tricky, so the result would depend on the operators' order and how the parentheses are put.

The first expression is False because it is evaluated the following way: or operator has the lowest priority, so it will be evaluated last. The first argument (b + c <= e) is False. The second argument is the long one: f + g >= e == f == 5, it is going to be evaluated consequently, so let's break it down: this expression is equivalent to (f + g >= e) and (e == f) and (f == 5), which evaluates to False. Finally calculate the value of the whole expression: False or False is False. In the second case, we have True in the left parenthesis and True in the right parenthesis, so True equals True and the final expression is also True.

Logic & arithmetics
Let's look at another interesting case. At the beginning of the topic, we learned that the result of applying comparison operators is always bool. However, if there is a logical and arithmetic part in an expression, we might see unusual behavior due to logical operators in Python being short-circuited, or lazy:

# True and-expressions return the result of the last operation:

# False and-expressions return a boolean False value:

# True or-expressions return the result of the first operation:

# True-False or-expressions return the True part:
It might look confusing at first sight but, if you think about it, every printed value is perfectly legal and complies with common mathematical logic.

Summary
In this topic, we familiarized ourselves with Python comparison operators, learned how to compare integers, and use comparison chaining. These basic operators will definitely be a great help to you in the future!
"
10,If statement,406,5953,116,https://hyperskill.org/learn/step/5953,"There are situations when your program needs to execute some piece of code only if a particular condition is met. It's possible to set that condition in Python and, in this topic, we're gonna learn how!

Simple if statement
So, in Python, a piece of code that should be executed only under some condition should be placed within the body of an if statement. The pattern is the same as in the English language: first comes the keyword if , then a condition, and then a list of expressions to execute. The condition is always a Boolean expression, that is, its value equals either True or False. Here is one example of how the code with a conditional expression should look like:

Note that the condition ends with a colon and a new line starts with an indentation. Usually, 4 spaces are used to designate each level of indentation. A piece of code in which all lines are on the same level of indentation is called a block of code. In Python, only indentation is used to separate different blocks of code, hence, only indentation shows which lines of code are supposed to be executed when the if statement is satisfied, and which ones should be executed independently of the if statement. Check out the following example:

In this example, the line ""It's time for tea!"", as well as ""What tea do you prefer?"", will be printed only if there are 5 or more biscuits. The line ""What about some chocolate?"" will be printed regardless of the number of biscuits.
An if statement is executed only if its condition holds (the Boolean value is True), otherwise, it's skipped.
Boolean values basically make it clear whether a piece of code needs to be executed or not. Since comparisons result in bool, it's always a good idea to use them as a condition.

There is one pitfall, though. You should not confuse the comparison operator for equality == with the assignment operator =. Only the former provides for a proper condition. Try to avoid this common mistake in your code.

Nested if statement
Sometimes a condition happens to be too complicated for a simple if statement. In this case,  you can use so-called nested if statements. The more if statements are nested, the more complex your code gets, which is usually not a good thing. However, this doesn't mean that you need to avoid nested if statements at all costs. Let's take a look at the code below:

The example above illustrates a nested if statement. If the variable my_color is a string that contains the name of a color from the rainbow,  we enter the body of the first if statement. First, we print the message and then check if our color belongs to the warm colors. The membership operator in simply shows whether my_color is a substring of the respective string, rainbow or warm_colors. Just like arithmetic comparisons, it returns a boolean value.
Here is what we will see in our case:
Wow, your color is in the rainbow!
Oh, by the way, it's a warm color.
When it comes to nested if statements, proper indentation is crucial, so do not forget to indent each statement that starts with the if keyword.
Summary
To sum up, in this topic, we've learned how to write and nest conditions in Python with if-statements.
"
11,Else statement,407,5932,117,https://hyperskill.org/learn/step/5932,"Setting conditions is a pretty popular and useful tool in programming. However, sometimes just to check if a condition is true or not might not be enough. Let's say, you don't want a piece of code to execute if your condition is false, but, if that's the case, there is another piece of code you do want to execute. For situations like this Python has another powerful tool about which we're gonna learn in this topic!

Simple if-else
An if-else statement is another type of conditional expression in Python. It differs from an if statement by the presence of the additional keyword else. The block of code that else contains executes when the condition of your if statement does not hold (the Boolean value is False). Since an else statement is an alternative for an if statement, only one block of code can be executed. Also,  else doesn't require any condition:

Note that the 4-space indentation rule applies here too.
As you may soon find out, programmers do like all sorts of shortcuts. For conditional expressions, there's a trick as well – you can write an if-else statement in one line. This is called a ternary operator and it looks like this:

It's a matter of convenience, but remember that the code you create should still be readable.
Nested if-else
It should be mentioned that if-else statements can be nested the same way as if statements. An additional conditional expression may appear after the if section as well as after the else section. Once again, don't forget to indent properly:

Summary
In this topic, we've learned about one more type of conditional expression: if-else statement. Let's go through the main points again:

the keyword else is used to give an alternative;
it will be executed in case if statement isn't;
it doesn't require any condition;
if-else statements can be nested.

That's it! Now you are ready not only to set conditions but also to consider different alternatives. Congratulations!
"
12,List,395,5979,118,https://hyperskill.org/learn/step/5979,"In your programs, you often need to group several elements in order to process them as a single object. For this, you will need to use different collections. One of the most important and useful collections in Python is a list.
Creating and printing lists
Look at a simple list that stores several names of dogs' breeds:
In the first line, we use square brackets to create a list that contains four elements and then assign it to the dog_breeds variable. In the second line, the list is printed through the variable's name. All the elements are printed in the same order as they were stored in the list because lists are ordered.
Here is another list that contains five integers:
Another way to create a list is to invoke the list function. It is used to create a list out of an iterable object: that is, a kind of object where you can get its elements one by one. The concept of iterability will be explained in detail further on, but let's look at the examples below:
So, the list function creates a list containing each element from the given iterable object. For now, remember that a string is an example of an iterable object, and an integer is an example of a non-iterable object. A list itself is also an iterable object.
Let's also note the difference between the list function and creating a list using square brackets:
The square brackets and the list function can also be used to create empty lists that do not have elements at all.
In the following topics, we will consider how to fill empty lists.
Features of lists
Lists can store duplicate values as many times as needed.
Another important thing about lists is that they can contain different types of elements, including other lists. So there are neither restrictions nor fixed list types, and you can add any data you want to your list, as in the following example:
Length of a list
Sometimes you need to know how many elements there are in a list. There is a built-in function called len() that can be applied to any iterable object, and it simply returns the length of that object.
So, when applied to a list, it returns the number of elements in that list:
In the example above, you can see how the len() function works. Again, pay attention to the difference between list() and [] as applied to strings: it may not result in what you expected.
Summary
As a recap, we note that lists are:
*   ordered, i.e. each element has a fixed position in a list;
*   iterable, i.e. you can get their elements one by one;
*   able to store duplicate values;
*   able to store different types of elements;
*   besides being used for creating an empty list, the list() function also can be used to make a list out of an iterable object.

Read more on this topic in Python range function and its methods on Hyperskill Blog.
"
13,Indexes,435,6189,119,https://hyperskill.org/learn/step/6189,"There are several types of collections to store data in Python. Positionally ordered collections of elements are usually called sequences, and both lists and strings belong to them. Each element in a list, as well as each character in a string, has an index that corresponds to its position. Indexes are used to access elements within a sequence. Indexing is zero-based, so if you see a person who counts from zero, you must have met a programmer.
Indexes of elements
To access an element of a list by its index, you need to use square brackets. You add the brackets after the list and, between them, you write the index of an element you want to get.
Don't forget, the indexes start at 0, so the index of the first element is 0. The index of the last element is equal to len(list) - 1.
Strings work in the same way:
Potential pitfalls
When using indexes, it's important to stay within the range of your sequence: you'll get an error (called IndexError) if you try to access an element with a non-existing index!
There is one more obstacle in your way. Imagine that you want to change one of the elements in a list. It can be easily done:
However, when it comes to strings, such reassignment is impossible. Strings, unlike lists, are immutable, so you can't modify their contents with indexes:
Don't worry, after some practice, you will not encounter these errors.
Negative indexes
The easier way to access the elements at the end of a list or a string is to use negative indexes: the minus before the number changes your perspective in a way and you look at the sequence from the end. So, the last element of a list, in this case, has the index equal to -1, and the first element of the list has the index -len(list) (the length of the list).
For example:
As you can see, it works the same for lists and strings.

If you write a non-existing negative index, you'll also get IndexError. Be careful with indexes to avoid off-by-one errors in your code.

The following picture shows the general concept of indexes in a list:

Summary
In this topic, we've learned what positive and negative indexes are in Python, how to find elements in a list by their indexes, and what errors might occur when using them. Since you have learned the concept of indexes, we hope that from now on you will not encounter any difficulties when using them!
"
14,For loop,429,6065,120,https://hyperskill.org/learn/step/6065,"Computers are known for their ability to do things that people consider to be boring and energy-consuming. For example, repeating identical tasks without any errors is one of these things. In this topic, we'll learn what Python tool can help you with that, how to implement it, and what functions you can use along with it.
What is iteration?
In Python, the process of repetitive execution of the same block of code is called an iteration.
There are two types of iteration:
Definite iteration, where the number of repetitions is stated in advance.
Indefinite iteration, where a code block executes as long as the condition stated in advance is true.
After the first iteration, the program comes back to the beginning of the code's body and repeats it, making a so-called loop. The most popular is the for loop, named after the for operator, which provides the code's execution. For loops are usually considered to be definite.
For loop syntax
Here is the scheme of the loop:
where statement is a block of operations executed for each item in iterable, an object used in iteration (e.g., a string or a list). Variable takes the value of the next item from the iterable after each iteration.
Now try to guess what output we'll get if we execute the following piece of code:
During each iteration, the program will take one item from the list and execute the statements on it, so the final output will be:
Atlantic
Pacific
Indian
Southern
Arctic
Strings are also iterable, so you can spell a word, for example:
 Like this:
m
a
g
i
c
Range function
The range() function can be used to specify the number of iterations. It returns a sequence of numbers from 0 (by default) and ends at a specified number. Be careful: the last number won't be in the output since we started from 0.
Let's look at the example below:
What we'll get is this:
0
1
2
3
4
You can change the starting value if you're not satisfied with 0, moreover, you can configure the increment (step) value by adding a third parameter:
According to the parameters included, we've asked to print the numbers from 5 to 45 with an increment value of 10. Be careful again, the last value is not included in the output:
5
15
25
35
If you're not going to use the counter variable in your loop, you can show it by replacing its name with the underscore symbol:
In the example above, we don't need the counter variable in any way, we simply use the loop to repeat the do_smth() function a given number of times.
Input data processing
You can also use the input() function that helps the user to pass a value to some variable and work with it. Thus, you can get the same output as with the previous piece of code:
Oh, look, you can write a piece of code with a practical purpose:
You can, therefore, ask the user to specify the number of iterations to be performed.
Nested loop
In Python, it is easy to put one loop inside another one – a nested loop. The type of the inner and outer loops doesn't matter, the first to execute is the outer loop, then the inner one executes:
The output is shown below:
Rose Miller
Rose Smith
Daniel Miller
Daniel Smith
Check out the Python Tutor visualization for a better understanding of how the code works. Click Next> and follow the arrows. In this example, we use two for loops to create fictional people's names. You can deal with iterable objects of different sizes without too much fuss.
Conclusion
All in all, for loops are an efficient way to automate some repetitive actions. You can add variables and operations to make a nested loop. Moreover, you can control the number of iterations with the help of the range() function. Be careful with the syntax: an extra indent or the lack of a colon can cause an error!
Read more on this topic in Python range function and its methods on Hyperskill Blog.
"
15,Integer arithmetic: special operations,4410,47917,130,https://hyperskill.org/learn/step/47917,"In Python, operators are fundamental tools for performing various operations on data. Two operators that offer unique functionalities are the modulus operator % and the exponentiation operator **.

Modulus Operator (%): This operator calculates the remainder of a division operation. For example, 7 % 3 returns 1, as 7 divided by 3 equals 2 with a remainder of 1.

Exponentiation Operator (**): This operator raises a number to a power. For instance, 2 ** 3 results in 8, as 2 raised to the power of 3 equals 8.

Understanding the precedence of operators is crucial for determining the order in which operations are performed. In Python, the precedence hierarchy is as follows (from highest to lowest precedence):

Parentheses > Exponentiation > Multiplication = Division = Integer Division = Modulo > Addition = Subtraction

Parentheses can be used to override the default precedence and force operations to occur in a specific order.

By mastering the usage and precedence of these operators, you gain the ability to manipulate data effectively and efficiently in Python.
"
16,PEP 8: Coding style guide,402,47499,131,https://hyperskill.org/learn/step/47499,Error extracting text: 429 Resource has been exhausted (e.g. check quota).
17,Comments,403,6081,132,https://hyperskill.org/learn/step/6081,"Sometimes you need to explain what particular parts of your code are for. Luckily, Python allows you to fulfill your needs. You can leave special notes called comments. They are especially useful for beginners. Throughout this course, we will often use comments to explain our examples.

What is a comment?

Python comments start with a hash, #. Everything after the hash up to the end of the line is regarded as a comment and will be ignored when running the code.

In the example above, you can see what PEP 8 calls an inline comment. It's a comment written on the same line as the code.

A comment can also refer to the block of code that follows it:

We intend to use comments primarily for learning purposes. Now, it's time to find out how to comment code properly.

Formatting comments

Although it is easy to write a comment, let's discuss how to do so according to the best practices.

To begin with, there should be one space after a hash mark. For inline comments, there should be two spaces between the end of the code and the hash sign. Putting more than two spaces between the end of the code and the hash mark is acceptable, but most commonly, there are exactly two spaces.

Indent your comment to the same level as the statement it explains. E.g., the following example is wrong:

A comment is not a Python command: it should not be too long. Following PEP-8, the comment length should be limited to 72 characters. It's better to split a long comment into several lines. You can do so by adding a hash mark at the beginning of each new line:

Comments that span multiple lines are called multi-line or block comments. In Python, there is no special way to indicate them.

You may come across multi-line comments enclosed in triple quotes: """"""..."""""". Nonetheless, we recommend that you use several lines starting with hash marks for this purpose. Then, your code will comply with the official style guide. Triple quotes are reserved for documentation strings, docstrings for short. They are also informative, but their use is limited to functions, methods and several other cases.

We hope our comments will help you understand our code examples better!

Summary

In this topic, we learned what comments are and what they're used for. The main points are:

Comments are used to explain what particular parts of your code are for.
Comments start with a hash, #.
Comments are ignored during the execution of the code.
Comments might be above a piece of code, inline, or form a block.

There are specific comment formatting rules you should follow according to PEP 8:

There should be one space after a hash mark.
For inline comments, there should be two spaces between the end of the code and the hash mark.
The comment length should be limited to 72 characters. You can split a long comment into several lines forming a block.
Indent your comment to the same level as the statement it explains.
"
18,Declaring functions,401,5900,133,https://hyperskill.org/learn/step/5900,Error extracting text: 429 Resource has been exhausted (e.g. check quota).
19,Importing modules,414,6019,134,https://hyperskill.org/learn/step/6019,Error extracting text: 429 Resource has been exhausted (e.g. check quota).
20,Creating modules,421,6057,135,https://hyperskill.org/learn/step/6057,Error extracting text: 429 Resource has been exhausted (e.g. check quota).
21,Multiple modules. Package,466,6384,136,https://hyperskill.org/learn/step/6384,"The process of building web applications has been greatly simplified in today's world. One of the factors that has made this possible is the ability to reuse code. Can you imagine having to write your own function that generates a random number? While it is possible to write it, given that such functionality is already built out, you would rather spend more time on the unknown aspects of your application. Packages are an effective method that has contributed greatly to enabling code reusability.
In this topic, we will focus on learning and understanding what packages are and how they can be created and used.
What is a package and how to get one?
Each package is a collection of typically related modules and sub-packages stored under the same directory that contains an __init__.py file. The purpose of the __init__.py file is to mark the directory as a package. Packages are extremely handy as they enhance code organization in a hierarchical manner, promote code reuse, distribution, and encapsulation.
Below is a toy example of a laptop package: it contains 2 modules (dell.py and hp.py) and the Apple subpackage with its 2 modules (macbookair.py and macbookpro.py):

The standard package manager for Python is called pip. It is used for installing, upgrading, and generally managing Python packages from the Python Package Index (PyPI). PyPI is the software repository for the Python programming language where all Python packages are shared, you can think of it as of a central storage place.
With current Python versions, pip is usually included by default. You can use the following command to verify whether pip is installed in your system:

You can use the following command to install:

To install a package using pip use the following command:

For example, to install the numpy package you would use:

Using an installed package: import
In order to incorporate an installed package into your program, you need to import it. Assuming we have installed the numpy package, we can use the import keyword to include it like so:

This avails all the modules and sub-modules in the numpy package, as well as all the functions and declarations.
As a means to improve readability import is commonly used with aliases to give programmers a chance to write more descriptive code suited to their needs, or to replace excessively long package names. Alias can be declared using the askeyword, as shown below:

This way you can use all those aliases inside your code. It is important to note that, while using import the last attribute should be a module or a subpackage, consequently, functions and class names cannot be used directly with import.
After imports with aliases you can then use them in your code as such:


Using an installed package: from … import
Packages can also be imported using from keyword combined with import: it allows to import specific modules or subpackages without clogging up the namespace with unnecessary declarations. If we already know which functions or classes we'll need for our program, we can explicitly import only those, without importing any other declarations from the same module or subpackage. Let's consider our example from the previous section and import only the specific functions and classes we'll definitely use:

Now our program will look as such:


Note how we can only use explicitly imported declarations. It is also important to mention that now the last attribute should be a module, a subpackage or a function/class, as shown above.
If you want to import all entities from a package or a subpackage, you can do so with the following syntax and then use them as such:


Such imports are called wildcard imports. It is really handy in terms of writing code, since you no longer need to specify the package name to which an entity belongs. However, it could make debugging quite difficult since pinpointing the specific function with the error is a hassle.
Relative imports
Relative imports allow you to import modules or packages that are located in the same directory and depend on the current location of the module or package to be imported. They make use of the dot notation: a single dot means the module or package being imported is in the same directory as the current directory, while two dots would mean it is in the parent directory of the current location.
From our laptop example, for us to import the dell.py module into the hp.py module we would use

since they are located in the same directory. At the same time, in order to import the dell.py file into the macbookpro.py file, we would use

It is important to note that relative imports are mostly useful when developing larger projects and therefore they may not work when using them in standalone scripts.
PEP Time!
Please note that, according to PEP 8, using wildcard imports is considered bad practice, as they make it unclear which names are present in the namespace, confusing both readers and automated tools. Absolute imports are recommended, as they are usually more readable. They also give better error messages if something goes wrong.


Explicit relative imports are also acceptable, especially when dealing with complex package layouts where using absolute imports would be unnecessarily verbose:


Standard library code should avoid complex package layouts and always use absolute imports.
Multiple packages and Virtual environment
When you check the Python Package Index (PyPI), you will notice that most packages have different versions. This is due to constant upgrades made to the packages to improve their functionality. It is therefore a good convention to make use of the virtual environment when using multiple packages. A virtual environment gives you the ability to separate packages for your different Python projects, as well as isolate them from the global Python environment. Let's say you have two different projects that use the numpy package. Project 1 uses numpy 1.24, while Project 2 uses numpy 1.19. A virtual environment makes it possible to have these two different versions of the same package coexist without conflicts. It acts like a barrier that isolates one version from the other.
Conclusion
In this topic, we learned what a package is and what is its purpose. We went ahead and saw how to create a package and different ways of importing packages. We also explored why it is important to use the virtual environment when using multiple packages. Packages are an essential part of programming and we must understand how they work, and how we can use them to make our programs more efficient.
"
22,What is object-oriented programming,117,3614,141,https://hyperskill.org/learn/step/3614,"Fundamentals

Object-oriented programming (OOP) is a programming paradigm based on the concept of objects that interact with each other to perform program functions. Each object can be characterized by a state and behavior. An object’s current state is represented by its fields, and an object’s behavior is represented by its methods.

Basic principles of OOP

There are four basic principles of OOP. They are encapsulation, abstraction, inheritance, and polymorphism.

Encapsulation ensures bundling (=encapsulating) of data and the methods operating on that data into a single unit. It also refers to the ability of an object to hide the internal structure of its properties and methods.

Data abstraction means that objects should provide a simplified, abstract version of their implementations. The details of their internal work usually aren't necessary for the user, so there's no need to represent them. Abstraction also means that only the most relevant features of the object will be presented.

Inheritance is a mechanism for defining parent-child relationships between classes. Often objects are very similar, so inheritance allows programmers to reuse common logic and at the same time introduce unique concepts into the classes.

Polymorphism literally means ""having many forms"" and is a concept related to inheritance. It allows programmers to define different implementations for the same method. Thus, the name (or interface) remains the same, but the actions performed may differ. For example, imagine a website that posts three main types of text: news, announcements, and articles. They are somewhat similar in that they all have a headline, some text, and a date. In other ways, they are different: articles have authors, news bulletins have sources, and announcements have a date after which they become irrelevant. It is convenient to write an abstract class with general information for all publications to avoid copying it every time and store what is different in the appropriate derived classes.

These are the key concepts of OOP. Each object-oriented language implements these principles in its own way, but the essence stays the same from language to language.

Objects

The key notion of OOP is, naturally, an object. There are a lot of real-world objects around you: pets, buildings, cars, computers, planes, you name it. Even a computer program may be considered as an object.

It's possible to identify some important characteristics of real-world objects. For instance, for a building, we can consider the number of floors, the year of construction, and the total area. Another example is a plane, which can accommodate a certain number of passengers and transfer you from one city to another. These characteristics constitute the object's attributes and methods. Attributes characterize the states or data of an object, and methods characterize its behavior.

Classes

Often, many individual objects have similar characteristics. We can say these objects belong to the same type or class.

A class is another important notion of OOP. A class describes a common structure of similar objects: their fields and methods. It may be considered a template or a blueprint for similar objects. An object is an individual instance of a class.

In accordance with the principle of encapsulation mentioned above, any class should be considered as a black box, that is, the user of the class should see and use only the interface part of the class, namely, the list of declared properties and methods, and should not delve into the internal implementation.

Let's look at some examples below.

Example 1. The building class
An abstract building for describing buildings as a type of object (class)

Each building has the same attributes:
Number of floors (an integer number);
Area (a floating-point number, square meters);
Year of construction (an integer number).

Each object of the building type has the same attributes but different values.

For instance:
Building 1: number of floors = 4, area = 2400.16, year of construction = 1966;
Building 2: number of floors = 6, area = 3200.54, year of construction = 2001.

It's quite difficult to determine the behavior of a building, but this example demonstrates attributes pretty well.

Example 2. The plane class

Unlike with a building, it is easy to define the behavior of a plane: it can fly and transfer you between two points on the planet.
An abstract plane for describing all planes as a type of object (class)

Each plane has the following attributes:
Name (a string, for example, ""Airbus A320"" or ""Boeing 777"");
Passenger capacity (an integer number);
Standard speed (an integer number);
Current coordinates (they are needed to navigate).

Also, it has a behavior (a method): transferring passengers from one geographical point to another. This behavior changes the state of a plane, namely, its current coordinates.

Objects and classes

In OOP, everything can be viewed as an object; a class, for example, is also an object. Programs are made up of different objects that interact with each other. Object state and behavior are usually combined, but this is not always the case. Sometimes we see objects without a state or methods. This, of course, depends on the purpose of the program and the nature of the object.

For example, there is such a thing as an interface. Not a user interface, but a class that only serves to be inherited from in order to guarantee an interface to its descendant classes. It is a stateless class. Structures exist in C++ for historical reasons. Now a structure in C++ is also a class, but once upon a time, a structure had only properties and did not have any methods – a type for storing data and nothing else. These are special cases, and they are sometimes useful.

Conclusion

Object-oriented programming is akin to the work of an architect. As an architect, you create templates called classes and build individual instances of these classes, known as objects. Similar to the inhabitants of a building, users of a class interact solely with its fields and methods, without needing to delve into the internal implementation details. This principle is commonly known as encapsulation.

OOP is a key part of many programming languages, including C++, C#, Java, Kotlin, Python, and Ruby. Mastery of OOP enables you to write tidy, easily updatable code, an essential skill for every coder. So, it's time to start practicing!
"
23,Operating systems,872,9704,175,https://hyperskill.org/learn/step/9704,Error extracting text: 429 Resource has been exhausted (e.g. check quota).
24,Command line overview,480,8977,176,https://hyperskill.org/learn/step/8977,Error extracting text: 429 Resource has been exhausted (e.g. check quota).
25,Parameters and options,876,9746,177,https://hyperskill.org/learn/step/9746,"We hope that you already know how to open the command-line interpreter and run some basic commands. Now, let's take a step further and learn how to expand the functionality of the commands and how to get more information about them.
Commands with parameters
Sometimes, using just one command is not enough. Let's take a look at the command mkdir, which is used to create a new folder in the current directory. If you try to use it as it is, you will get an error. The terminal needs to know how to name a new folder! That's where parameters come in handy. A parameter is some additional information that you give to the command. Simply put, parameters are variables that commands can take.
Now, type the command mkdir with a parameter papers. We use this command to create a folder named papers:
Although the current directory stays the same, if you follow this path, you will see that the new folder papers was created in the student directory.
All examples in this topic are for Windows OS, but the listed commands are relevant for Linux and macOS too. Note that the path separator on Windows is a backslash, but in Linux/macOS it's a forward slash.
Now let's change our location and go to the folder you've just created! Use the cd command with the path to the papers folder as a parameter.
Another useful parameter of the cd command is ... It allows you to go to the parent directory, the directory one level above the current one.
You can also go back to the root folder, a top-level directory in the file system. To go back to the root directory, you can use the/parameter:
Thanks to commands and parameters, it seems like we are back to the roots! Actually, without parameters, most commands would be useless.
Options
If you google anything about commands and a terminal, you'll encounter the term options. Don't be afraid of it! Let's briefly explore what it means.
Options, as the name suggests, are usually optional and are used to somehow change the common behavior of the command. If you use Windows and are already sick and tired of exploring the current drive, you can change it by adding the /d option to cd. Don't forget to set the path you want to follow as the parameter, for example, F:\Codepen snippets:
Now you see that with options and parameters, you can transform a simple command into something complicated.
To sum up: what are options and parameters? Both of them are just two particular types of arguments. While an option changes the behavior of a command, a parameter is used to assign information to either a command or one of its options. One of the key differences between them is that the number of possible values in options is limited and locked in the code, while with parameters users have more freedom as they don't have such limitations.
Help Manual
No one can remember all the existing commands, options, and parameters. Don't worry about that. The help command is there for you. Type it in Windows, and you will get a list of commands available to you.
For Linux and macOS, the way to get information about the commands depends on the shell you use. The simplest way for Linux is the --help flag. There is also the man command, short for manual. You can use the man command in Linux similar to the help command in Windows: help mkdir.
That's not all. The help command can take any command as a parameter and return all the available options. Let's try. We will use the simplest command we've learned so far, the cd command.

Displays the name of or changes the current directory.

CD [/D] [drive:][path]
CD [..]

.. Specifies that you want to change to the parent directory.

Type CD drive: to display the current directory in the specified drive.
Type CD without parameters to display the current drive and directory.

Use the /D switch to change the current drive in addition to changing the current directory for a drive.

As you can see, these are all the details you need to know about the cd command. We call this description the help manual.
Let's discuss what the help manual includes. First, it states what the command is supposed to do. For the cd command, it reads, ""Displays the name of or changes the current directory"". Then it returns all the combinations of that command along with all possible parameters that you can use. You can also notice that on Windows, commands are case-insensitive, unlike on Linux and macOS. Let's look at the example from the manual:
CD [/D] [drive:][path]
So, the above command has three parts. CD is the command name. [/D] is an option, and [drive:][path] a parameter. You might wonder what these [] brackets mean. Well, they are just notations, which means that the parameters are optional to the commands. You shouldn't add these brackets when you use commands.
You can read this article for Windows or the manual for the cat command on Linux/macOS to learn more about the command-line syntax and look through the examples.
Conclusion
Let's summarize what you've learned so far:

You can use options and parameters to extend the functionality of commands.

You can pass different values with the parameters.

You can get a full list of commands using the help and man commands.

You can open a help manual for a command by typing help [command_name] or man [command_name]. This manual explains how to use a command properly and what options and parameters it has, if any.

Although you may feel that using these commands would slow down developers' work and that they are less efficient, we would still urge you to try them out. You have to get used to these commands as early as possible. Once you get accustomed to working with them, you will find that using them is much easier than resorting to the GUI on many occasions.
"
26,Installing packages with pip,444,6230,178,https://hyperskill.org/learn/step/6230,"One astonishing fact about Python is that it has a huge and diverse community of contributors. Essentially, that means that there are plenty of solutions to a vast range of problems in open access. This fact comes in handy, especially when you are working on your own projects. It's highly likely that you'll be able to find a proper task-specific package and use it effectively to meet your needs. Now we are going to learn about standard tools for package management in Python.

What is pip?

By this time you've probably familiarized yourself with the Python standard library. It contains a lot of useful built-in modules and should be preinstalled with your Python distribution. In fact, one more thing that is preinstalled (starting with Python 3.4) is the standard package manager called pip (the acronym is commonly expanded as ""Pip Installs Packages"").

Pip is designed both to extend the functionality of the standard library by installing the additional packages on your computer and to help you share your own projects and thereby contribute to the development of Python.

Now let's make sure that you have pip installed. All you need to do is to open a command prompt/terminal and run this line on Windows:

On Unix the command is a little different:

The output should report your current pip version. For example, now, in January 2022, the latest version is:

In case it's not installed (or you want to upgrade it), please follow these installation instructions specifically for your operating system.

If your terminal cannot find the pip command, try to use pip3 instead.

Pip capabilities

Since pip is the recommended installer for Python, the most obvious and crucial command to begin with is install. Have a look at the following line:

The installation is really that simple. However, if you are interested in a certain version of the package, you need to specify it after the package name like this:

Or, at least, define a minimal suitable version:

Note that the last expression should be enclosed within double quotes for the comparison operator to be interpreted without any problem.

Another useful thing is the show command. It shows information about installed packages, for instance, their version, author, license, location or requirements. Here is a general example:

Also, the list command might be of use. It lists all the packages you've installed on your computer in alphabetical order:

If you print the list command with the option --outdated, or just -o, you'll get the list of outdated packages coupled with both the current and latest versions available.

or with a bit shorter variant:

After executing one of the mentioned lines, you will see a similar output:

Having discovered outdated packages, you might want to update them to the newest available version:

To remove a package from your computer run the uninstall command:

When developing your project, it may be advantageous to keep a list of packages to be installed, i.e. dependencies, in a special file (see Requirements File Format). It is convenient because you can install the packages directly from it:

Of course, you are not supposed to write this file yourself listing all the necessary packages. It will be enough to run the code below in order to obtain it:

Let's examine the line above in detail. freeze is a command used to get all installed packages in the format of requirements. So all the packages you had installed before the execution of the command and presumably had used in some projects would be listed in the file named ""requirements.txt"". Furthermore, their exact versions would be specified (see Requirement Specifiers).

Consider an example output of the freeze command:

What's important is that freeze actually lists all the installed libraries, which is rarely necessary and might be considered a bad practice. For this reason, we recommend that you take a more conscious approach and revise the obtained requirements file by yourself.

Summary

Overall, we've learned the basics for package installation through pip:
how to install packages (either a specific version or non-specific one),how to create a requirements file and use it for installation,how to obtain information about installed packages,and, finally, how to uninstall packages.

For further details, try consulting the documentation or running the command help.

Now let's get to practice so that you can use all this information in the future!

Read more on this topic in Jupyter Notebook — a complete how-to tutorial on Hyperskill Blog.
"
27,Virtual Environment,1448,13923,179,https://hyperskill.org/learn/step/13923,"Introduction

If you spend a lot of time programming, the chances are that you work with different Python versions quite often. That's why you need to install additional packages and modules outside the standard library. Most packages are updated regularly, and there are many versions, older and newer. It can present an issue if you need to maintain an outdated project of yours, as you cannot have two versions of one package at the same time. Another example would be when you want to deploy your code to another machine. How can you make sure that the program will work as planned? The solution is to create a virtual environment. With its help, you can manage different versions of packages and modules, recreate your environment on another machine or create an environment with required settings on your own machine to develop and test your code.
Roughly speaking, a virtual environment is a directory that contains a particular Python version and packages. You can create a separate virtual environment for every project that requires something that comes in conflict with what you use habitually. Very convenient, isn't it?

Creating virtual environment
In this topic, we'll refer to a tool from the standard Python library. It is venv. You can interact with it through the command line. To create a virtual environment, you can type either:

The Python command defines the Python version you'd like to use. The -m flag stands for the module-name.
We have created the new_project directory that contains a bunch of other directories along with the Python interpreter, the standard library, and various supporting files. Let's change our current directory for convenience:

To start working with our virtual environment, we need to activate it.
On Windows, you can run:

On Unix or macOS, run:

After this, you'll see the virtual environment in your shell:

Working with packages
You can do many things with pip in your virtual environment:

you can install, upgrade, and remove packages with pip install, pip install --upgrade and pip uninstall respectively:

pip install package_name==package_version specifies a particular version of a package:

pip show package_name shows the detailed information about a package, including the version, summary, author, location, and so on:

pip list displays the installed packages:

pip freeze displays the installed packages in the requirements format. To create a requirements.txt file, type pip freeze > requirements.txt:

When you're done with the virtual environment, deactivate it:

Once you've created an environment, it will be stored on your machine. You can activate and deactivate it at any time. If you don't need the environment, delete the directory. For example, for Unix or macOS run:

for Windows:

Tip: Before deleting a directory, deactivate the environment first.

Other libraries
As you already know, venv is a part of the standard Python library, but there are quite a few external packages for the same purpose. Each has its own peculiarities and additional tools. We will try to cover them briefly:

virtualenv is probably the most popular external library for working with virtual environments. Since recently, the subset has been integrated under the venv module. Virtualenv addresses several issues of venv, such as slower performance, upgradability, inability to create separate environments for arbitrary Python versions, and several others.
pyenv is another external library for managing virtual environments. It makes working with many different Python versions easier and is ideal for testing across versions.

Summary
In this topic, we've learned what a virtual environment is and how to work with it using the venv module from the standard Python library. Now you know how to create, activate, manage, and deactivate packages in the environment. We have also touched upon other options that can help you manage virtual environments.
"
28,Global vs local. Scopes,455,6322,223,https://hyperskill.org/learn/step/6322,"A scope is a part of the program where a certain variable can be reached by its name. The scope is a very important concept in programming because it defines the visibility of a name within the code block.
Global vs. Local
When you define a variable, it becomes either global or local. A variable is considered global if it's defined at the top level of a module. This means you can refer to this variable from any part of your program. Global variables can be useful when you need to share state information or configuration between different functions. For example, you can store the name of the current user in a global variable and then use it where needed. This approach makes your code easier to modify: to set a new username, you only need to change a single variable.
Local variables are created when you define them within the body of a function. Their names can only be resolved inside the current function's scope. This localization helps you avoid issues with side effects that may occur when using global variables.
Thus, a global variable can be accessed both from the top level of the module and from within function bodies. On the other hand, a local variable is only visible inside its nearest scope and cannot be accessed from outside that scope.
LEGB rule
Variable resolution in Python follows the LEGB rule. This means that the interpreter looks for a name in the following order:
Locals: Variables defined within the function body and not declared global.Enclosing: Names in the local scope of all enclosing functions, from inner to outer.Globals: Names defined at the top level of a module or declared global with the global keyword.Built-in: Any built-in name in Python.
Don't forget about LEGB rule if you plan on using enclosing functions.
Keywords ""nonlocal"" and ""global""
We have already mentioned one way to assign a global variable: define it at the top level of a module. However, there is also a special keyword global that allows us to declare a variable as global inside a function's body.
You can't change the value of a global variable inside a function without using the global keyword:
The error is raised because, to execute print(x) on the 8th line, the interpreter tries to resolve x and finds it in the local scope – the local x is declared on the next line (9th), i.e., after its use on line 8, so the interpreter raises the error. However, even if we removed line 8, the same error would occur. In that case, to execute x = x + 1, the interpreter would need to compute the expression x + 1 and resolve the variable x in it. However, x is declared in the same line (remember, the interpreter checks the local scope first). Since its value would be needed before it had actually been computed, the interpreter would raise the same error:
UnboundLocalError: local variable 'x' referenced before assignment
To fix this error, we need to declare x as global:
When x is global you can increment its value inside the function.
nonlocal keyword lets us assign to variables in the outer (but not global) scope:
Though global and nonlocal are present in the language, they are not often used in practice, because these keywords make programs less predictable and harder to understand.
Why do we need scopes?
Python distinguishes between global and local scopes to enhance code organisation. Global scope allows retaining information between function calls, aiding data transfer and communication in complex processes like multithreading. However, if all the declarations were stored in a global scope, the namespace would be extremely clogged up and hard to navigate, which may lead to confusion and bugs. Therefore Python saves you the trouble by allowing you to ""isolate"" some variables from the rest of the code when you split it into functions.
Summary
In this topic, we've found out the difference between global and local variables and ""nonlocal"" and ""global"" keywords, learned the LEGB rule, and how scopes can be helpful in practice. Hope you'll find this new knowledge useful!
"
29,Identity testing,626,8077,224,https://hyperskill.org/learn/step/8077,"By now, you know how to work with values in Python. For example, you know how to perform arithmetic operations with numbers. But what is a value in Python? It can't be an abstract thing, like in math, because a computer should be able to work with it. In this topic, you will get some understanding of values in Python.
Many copies of equal values
Equal values in Python can exist in many copies. Consider the following code:
It looks like all these variables are the same. But they aren't in some sense. To see it let's modify the list a.
The reason is that we created two copies of [1, 2, 3]. Variables a and c refer to the first copy, and b refers to the second copy. Changing one of them doesn't affect the other one.
We call these copies as objects. An object is stored in memory and contains information about an abstract value it represents. So there can be several objects that represent the same value. You can treat such objects as twins. At first glance, they look identical, but actually, they are different people.
Let's see how to distinguish twins in Python.
Id function
Each object in Python has an associated integer called identity. You can get this integer by passing the object to the function id. Numbers, strings and other primitive types are also objects and they have an identity too. Identity never changes during the life of the object. Different objects in memory have different identities.
Using it we can distinguish two objects in Python that contain the same value. It is similar to distinguishing twins by looking at their identity documents.

 Python generates id on the fly, running the pieces of code above will give you other integer values. Moreover, new objects can have smaller ids than the objects created earlier. 

But if two variables refer to the same object, then the id function will return the same value.
As you can see, the variables a and c share the identity, which means they refer to the same object.
Identity testing
You can check if two variables refer to the same object by comparing the results of the id function. But there is a better way to do it. Python has an identity operator is that checks if two objects have the same identity. The result is a boolean value: True or False. You should not confuse it with the equality operator == which tests whether two objects contain the same value.
The is not operator is the negation of the is operator. It returns True if its operands refer to different objects.
Use the identity operator carefully
Using the identity operator instead of the equality operator might lead to lots of mistakes. The example below shows the danger of the is operator.
The reason for such weird behavior is that Python optimizes the use of small integers between -5 and 256. They are commonly used, so Python doesn't create a new object every time, but gives a reference to an existing number. The same thing happens to short strings.
However, the case of large numbers depends on the implementation. You may get True for the following expression:
When to use the identity operator
The proper case to use the is operator is to test if something is None. None is a special keyword in Python that is used to define no value.
It is safe to use is  in this case, because None is a singleton. This means that None object is created only once and then used whenever you refer to None in your code.
It is common to use None as a default value for optional arguments in functions.
True and False are also singletons, so you can use is with them too.
Summary
In this topic, we've learned a little about objects in Python and how to test objects for identity. In order not to make mistakes in your code pay attention to the following points:

There can be many objects containing the same value. They are equal but not identical.
The identity operator does not compare values, but it checks if its operands refer to the same object.
Don't use the identity operator with primitive types.
Use the identity operator to test if something is None.
"
30,The Jupyter Notebook,1303,12623,251,https://hyperskill.org/learn/step/12623,"So far, we have been interacting with Python through the console, PyCharm, or other IDEs. In this topic, we are going to cover another coding environment called Jupyter Notebook. It is a powerful tool for data science projects. The Jupyter name comes from the main supported languages: Julia, Python, and R. It is an app that allows you to make programs in your browser. Jupyter runs either locally on your computer (no Internet connection is required) or on a remote server. It lets you execute the code in small chunks, which is really good for debugging and for showing your results to others. You can even add text to explain what your code does! That's why so many data scientists and programmers use it to share their work with colleagues. In this topic, we will learn how to set up Jupyter Notebook on your local machine and how you can use it in your projects.

Installation
You can install Jupyter Notebook in two ways:
Or through Anaconda that conveniently installs Python, Jupyter Notebook, Orange, and other commonly used tools for data science. To do it with Anaconda, please, follow these steps:
Download and install Anaconda, following the instructions on the download page.
Run it. You will see this page:
Find Jupyter Notebook and install it.
Off we go!

First steps
If you used pip, type jupyter notebook in the Terminal or in the Command prompt. If you installed it with Anaconda, click on the program shortcut. You will see the following lines.

It creates a local web server, and after that, all you need to do is copy and paste the URL to your browser to access the app. You will see the main page. By default, you will see the folder where the Jupyter Notebook application is installed. However, if you first type cd path/to/a/folder and only then – jupyter notebook, you can start it from any other directory as well.

To create a new notebook, select 'New' > 'Python 3'. You can find the 'New' button in the upper-right part of the page. Under the 'Notebook' tab, you can see available kernels. Every notebook has a kernel, an execution environment associated with it. The kernel runs the code in a specific programming language (R, Python, etc.). It also provides access to various libraries, performs the computation, and produces the results. In our case, we would need only one kernel — Python 3 — as we work only with this version of the programming language.
This kernel is a part of the global IPython kernel. IPython (Interactive Python) is a shell that provides additional command syntax, code highlighting, and auto-completion for Python. You can also use notebooks for many other languages to install additional kernels: IRkernel, IJulia, etc.

Interface
Let's take a look at the Jupyter Notebook interface. In this case, a notebook is a document that contains pieces of code as well as various text elements (paragraphs, links, and so on).

We highlighted the main parts of the interface. Let's have a closer look at them.
The main building unit of a notebook is a cell. That's where we can write our code or add any text information. Each cell can be executed independently.
By default, a notebook bears the 'Untitled' name, but you can easily change it by clicking on it.
The File button allows you to copy, save, rename or download your file. Mind that there are a lot of extensions that can save your notebook. We will focus on two of them: .py and .ipynb. The first one is a standard extension of Python files that can be run with the Python console. The second extension, .ipynb, stands for IPython Notebook; it is a default notebook extension.
The Floppy disk symbol allows you to save the notebook.
The Plus symbol adds cells.
The next three buttons allow you to remove, copy, or insert a cell.
The Up and Down arrows move a cell.
By pressing the next set of buttons, you can run a cell, interrupt the kernel, or restart the kernel. For running a cell, you can also use Shift+Enter . You can find more information about shortcuts in the Documentation. Interrupting the kernel is useful in case there's an infinite loop. Restarting allows you to clear all variables.
You can also change the type of the cell by clicking on the Code button. There are four types: code, markdown, raw NBConvert, and heading. If you need to change the title of your notebook, use heading. The markdown cell is used for writing a text and transforming it with the special markdown syntax. You can read about it in the Markdown Guide. The Raw NBConvert type is used for unmodified content.
Once your code is ready, press the Logout button in the upper-right corner of the page. Your session will be stopped.
Of course, it's only the basics. You can also format strings (change colors, for instance), add themes for the whole notebook, visualize your results, and so on. That's why more and more scientists are moving to Jupyter notebook.

Example program
Let's discuss the programming pipeline in more detail. Suppose, we need to write a basic calculator and sum up two integers. Below is an example of this program (screenshots were cropped for readability purposes):

The results are printed right after the cell. Of course, you can write everything in one cell as well.
By the way, have you noticed the numbers in the square brackets to the left of the cells? They show the order in which the cells were executed. This order is pivotal in Jupyter Notebook. Let's say you run the middle cell first. What is going to happen in this case?

It will produce an error since we haven't set our variables! Please, pay attention to the execution order.
We can also install libraries with Jupyter Notebook. You can execute terminal commands directly in your Jupyter Notebook. To do so, put an exclamation mark ! at the beginning of the command. This will tell the app that it is not a Python command. Wonderful, isn't it?

So, we have installed and imported a library, and now we can work with it as usual.

Summary
What have we learned about Jupyter Notebook so far?
The Jupyter working environment is known as a notebook; a notebook consists of code and text cells.
It can be installed in several ways — using pip or with Anaconda.
Now you have a basic understanding of the interface and know how to run cells and install libraries. If you are interested in more information, you can always read the official Documentation.
Read more on this topic in Jupyter Notebook — a complete how-to tutorial on Hyperskill Blog.
"
31,Google Colab,1304,12631,256,https://hyperskill.org/learn/step/12631,"You already know the basics of Jupyter Notebook. Now imagine that your laptop lacks computing power, but you need to train a huge model. This is where Google Colab comes in handy. This is an online service provided by Google. With Colab, you can write and execute programs, save and share your results, and have access to powerful computing resources in your browser. In this topic, we will show the main advantages and disadvantages of the service and describe how to work with it.

Google Colab vs. Jupyter Notebook

Before we turn to Google Colab, let's have a closer look at the main features of Google Colab and Jupyter Notebook.

Google ColabJupyter NotebookInitiates online sessions to work with your team.Doesn't allow instant teamwork. A researcher has to wait until another one finishes their part of the code and sends it for further editing.Uses Google computing power.Uses the power of your computer only.Most of the ML libraries are on-board.You need to install the libraries on your machine first.Every line of code can be saved on Google Drive.Sometimes, it is hard to get through various notebooks in different local folders.

Google Colab has some minor cons, too, as it cannot be run offline. You can also lose your code if you close the environment without downloading the results. Nevertheless, we see that it still has a lot of benefits over the Jupyter Notebook.

First steps

Here we go! This is how we can write our first program in Google Colab:

Sign in to your Google account.Go to Google Colab.If you are a new user, you are going to see the following page:You can skip this page and proceed to create your own Colab notebook. To do it, press the File button in the upper-left corner and choose New Notebook.If you have already visited Google Colab, you can choose one of the existing notebooks from the list. Have a look at the example below.Choose the New Notebook button at the bottom of the page.Hooray! You have created a new notebook!

Interface

Let's have a look at the interface of your environment. As you can see, it resembles the interface of Jupyter Notebook.

At the top of the page, you can see the name of your notebook. By default, it has the ""UntitledXX.ipynb"" name where ""XX"" is a number of your notebook.The File button allows you to do the main operations: save your notebook, download it both .py and .ipynb extensions, save a copy on your Drive, and so on.The Connect button connects you to Google servers. Once connected, you can start working with your code.The highlighted buttons at the top allow you to modify a cell — move it up or down, comment, or delete it.The Play button allows you to run your code. An error message will appear on the screen under the cell in case something is wrong.The + Code and + Text buttons can add one more cell, a piece of code, or any text information. You can also do it by pressing the buttons that can be found near the Connect button.The Folder button provides access to files that are used by the notebook.

By default, there are no files, but one folder. By pressing the button that is highlighted in the picture above, you can upload your own datasets for further processing.

Now let's describe code examples in Colab.

Programs in Colab

In this section, we will discuss several programs and show some features of Colab.

The simplest example. First of all, let's analyze an easy example. Imagine we want to count the average number of likes for three posts. You can see how similar it is to Jupyter Notebook. We have created two cells. In the first one, we have defined three variables, in the second one we have calculated the average number of likes. After that, we can run each cell in the given order and get the results shown in the picture above.Uploading a file. Let's imagine we need to process a text file named names.txt. We have put down the names of our friends and relatives, one per line. We want to print their names, and we need to upload the file in advance for that. You can do it in two different ways:Use the buttons described in the previous section.Use the following snippet.After that, you will see a button for uploading a file. You can press it and choose the file you need.And then open it. Now, we can carry out other operations and print all the names.Downloading a file. Sometimes you need to download a file with data. Imagine you have a CSV file with information on passengers. There are two ways to download it.Press the Folder button on the left side, choose your file, press the button with three dots, and download your file.Use the following snippet to download the file.

Working with libraries

Libraries are vital for every Python developer. Google Colab allows us to use various external libraries. Suppose, we are going to work with a pre-installed library. Let's use NumPy for this purpose.

The first cell is used for importing NumPy, the second one allows us to create an array from the list. Of course, NumPy is not the only installed library. You can import other libraries like NLTK, Keras, Scipy, TensorFlow, etc. The installed libraries can be displayed by inputting pip list.

Use the following pip command to install a library:
pip install ...
 Let's try to install the pymorphy2 library that is used for morphological analysis of Russian words.
The library is installed successfully. You can use it for your own experiments. Unfortunately, the libraries you install cannot be saved, so you have to install them on your virtual machine each time you start a new session in Colab.

Conclusion

So, let's summarize what we learned about Google Colab:

You can run it in the cloud;You can work in Google Colab with your team;Most of the libraries for machine learning are already installed, so you can easily import them;You can upload your files to work with them in the environment and download them afterward.

Of course, it is just the beginning. Welcome to Colaboratory page contains more information about this environment. But for now, let's work on solving some practical tasks.

Read more on this topic in Jupyter Notebook — a complete how-to tutorial on Hyperskill Blog.
"
32,Computer algorithms,266,16547,263,https://hyperskill.org/learn/step/16547,"You have probably heard something about algorithms in real life. Simply put, an algorithm is a step-by-step sequence of actions you need to perform to achieve the desired result. It can be an algorithm for cooking a sandwich described by a recipe or an algorithm for getting dressed according to today's weather and your mood.

Among all algorithms, there is one special group called computer algorithms. They are usually created for and utilized by computers. In this topic, we will discuss in detail what computer algorithms are, as well as explain why it is important to learn them.
Computer algorithms
Computer algorithms are everywhere around us. Your smartphone is able to guide you through a city from one point to another using a certain algorithm. Other algorithms can control the behavior of your enemies in a computer game. Services like Google or Yahoo apply sophisticated algorithms to provide you with the most relevant results when you use them to search for information on the Web. Algorithms are also used to calculate the trajectory of rockets. And they even help doctors to determine diagnoses correctly!

An important difference between real-life and computer algorithms is that a computer cannot guess what we intend to do. If something goes wrong or an algorithm is not clear, a human can adjust the algorithm based on their experience. Computers cannot do the same. Let's get back to our sandwich algorithm. If we realize that we are out of bread, a human would think of going to the store and buying some more. On the other hand, a computer would report the absence of such an ingredient or proceed with its work without even noticing that, which would result in incorrect output. Thus, it is our responsibility to describe a computer algorithm precisely and unambiguously.
Programs and algorithms
As you may know, a program is a sequence of instructions to perform some tasks on a computer. The difference between programs and algorithms is that programs are written using a specific programming language while algorithms are usually described at a higher level than programming language statements. In other words, an algorithm is like an abstract schema, and a program can be its implementation.
All this also means that algorithms are language-agnostic: you can implement one algorithm using different programming languages. For example, you may use Java, Python, Kotlin, or other languages to implement the same algorithm.
Programming languages usually contain implementations of some basic algorithms for solving typical problems. These algorithms are provided in standard libraries, and software developers can reuse them instead of implementing a new one each time. However, to be able to use such algorithms correctly and efficiently and to understand how other developers use them, it is essential to learn these basic algorithms and get familiar with how they work under the hood. Moreover, the methods and tricks used in these approaches may come in handy while building your own algorithms as well. It is similar to solving exercises at school: these here are the examples you solve with your teacher during the class, and at home you have to solve other tasks using the methods discussed during the lesson.

Algorithms from standard libraries cannot cover all possible problems developers can encounter, so you will usually have to construct and implement your own algorithms for your problems. Classic algorithms serve as nice examples for learning the basic principles of algorithm construction.
Furthermore, there are so many well-known problems and their efficient solutions that standard libraries typically implement only the most prominent ones. Thus, sometimes you will need to implement a classic solution for a problem yourself, from scratch. This is yet another reason why it is essential to learn algorithms: you need to know which one and when to apply and how to implement it efficiently.
Summary
An algorithm is a sequence of actions you need to perform to achieve a certain result. An important group of algorithms is computer algorithms: the ones created for computers and utilized by them. There are several reasons why it is essential to learn computer algorithms:

Software developers often encounter tasks of the same type while working on different projects. For such typical tasks, programming languages provide ready-to-use algorithms in standard libraries. To utilize these algorithms efficiently, you need to understand how they work under the hood;

There are numerous well-known algorithms that cannot be found as ready-to-use functions from libraries. Sometimes you may even encounter problems that are impossible to solve using only well-known algorithms. In both cases, you need to implement a suitable algorithm yourself. To be able to do that, you need to know basic algorithmic approaches, their pros and cons, and which one to apply in a particular case;

Often you need not only to write the code yourself, but also to read the code written by other developers. If you want to understand the algorithms they might use, you need to know basic algorithms and algorithmic approaches as well;

Implementing algorithms will help you improve your programming skills.

We believe that there are other reasons why learning algorithms is worth it. If you have some ideas, don't hesitate to write them in the comments.
Good luck with learning algorithms!
Read more on this topic in Demystifying Data Science: Exploring the Top Languages on Hyperskill Blog.
"
33,World Wide Web,485,6633,264,https://hyperskill.org/learn/step/6633,"What is the Web?

Have you ever wondered what images will appear in the heads of future generations when it comes to the era in which we live now? It is likely that the 21st century will spark associations with the advent of the Internet and the World Wide Web. Their creation caused major changes not only in the military and science structures but also in the lives of ordinary people, giving us opportunities that previously could only be imagined.

You so often hear phrases like ""The World Wide Web has engulfed our planet"", that the definition of the Web is naturally pre-assumed and taken for granted. But really, what is this Web and why is it so global?

The World Wide Web is a collection of information resources scattered around the world and linked together by reference. Sometimes this term is shortened to WWW, W3 or simply Web.

The Web is also sometimes ironically called Wild Wild Web by analogy with the movie title Wild Wild West: come to think of it, the resemblance is undeniable.

A unit of hypertext data on the W3 is called a web page. A web page may contain text, media files, graphics and links to other pages.

A group of Web pages that share a common content theme, design and links to each other is called a website. Special programs — browsers — are used to download and browse these websites. Most popular browsers: Firefox, Chrome, Edge, Safari.

Often when you visit sites, you can see ""www"" in the address bar of the browser: This prefix indicates that the address of the website belongs to the Internet space of the World Wide Web and is not mandatory.

The history of the Web

The World Wide Web was created at the European Organization for Nuclear Energy (CERN). The development of the internal computer network was carried out by the scientist Tim Berners-Lee. In 1989, he was the first to suggest the idea of an information management system that used links to consolidate documents across the network. He and his colleagues created a prototype project and released it for presentation. The first few years of the web pages were purely text-based until the first NCSA Mosaic graphics browser was introduced in 1993. The event allowed the World Wide Web to transform itself from scientific research into a media outlet. Initially, the Internet only allowed users to search and read information. This period is referred to as Web 1.0 (~1991-1999) to provide a general presentation of the ever-changing Internet environment.

Soon people were able to interact with each other and share their content. This period is unofficially called Web 2.0 (~1999-2007).

The development of the World Wide Web continues to this day and we will be able to see what changes Web 3.0 (~2007- ...) will bring. Currently, Web 3.0 aims to improve content analysis and provide faster and more relevant search results using artificial intelligence.

Internet vs WWW

Most people use the terms ""Internet"" and ""WWW"" interchangeably, but in fact, these are two separate notions. The Internet is a global computer network, i.e., a technical infrastructure that connects millions of computers around the world. While W3 is used to distribute data that contains links to other data, the Internet connects computers to each other to provide access to the information.

It is worth noting that the W3 is just a part of all information that the internet provides access to. Also, there are services such as E-Mail, telephony, FTP, SSH, and other data transfer protocols that are not parts of the Web.

Conclusion

Simply put, the WWW is a way of obtaining information over the Internet, yet the Internet is also used to access information that is not a part of the Web. Hypertext documents - web pages are the units of the WWW. They may include different content and are usually joined by a shared topic and links to websites. Specific programs called browsers can download websites, so we can explore them.

Now you understand that the World Wide Web and the Internet actually mean different things. More importantly, now you can demonstrate your knowledge and explain this difference to your friends.
"
34,HTTP: HyperText Transfer Protocol,479,6569,265,https://hyperskill.org/learn/step/6569,"What is HTTP

Whenever you decide to check out your friends' pictures on social networks or leave them a message, watch a funny video with kittens, or find the meaning of an unknown term in the search engine, the device (client) from which you surf the Internet sends a request to the server and receives a response from it.

A client is a customer of a service, and a server is a computer that serves users or other computers. It can be located remotely, tens of thousands of kilometers away from you. The technology in which the network load is distributed between servers and service customers is called Client-Server Architecture.

Data exchange between the client and the server takes place due to the HTTP. HTTP stands for HyperText Transfer Protocol. A protocol is a set of rules and conventions that define a uniform way to exchange data between different programs and handle errors. Like a waiter in a restaurant, it accepts your requests, takes them to the server for processing, and then comes back to you with a response.

Short HTTP History

HTTP was developed by a scientist and CERN employee Tim Berners-Lee, the inventor of the World Wide Web.

Work on the protocol continued for two years, and in March 1991, HTTP was used as a technology to help access documents on the Internet and facilitate hypertext navigation. This was Protocol version 0.9. It was designed to optimize communication(request-response) between the client and the server on the network.

Currently, the most recent version of the Protocol is HTTP/3.0, but the most common version is still HTTP/2.0, released in 2015. Prior to that, HTTP/1.1 (released in 1999) was used for as long as sixteen years. This standard satisfied everyone for many years because of its innovations: with the advent of HTTP/1.1, the transfer of requests from client to server was greatly accelerated.

Not all sites have switched to HTTP/2 yet, but browsers support both new and old standards.

What is HTTPS

Despite the great functionality and popularity of HTTP, there is one drawback: data is transmitted in an unsecured form. This flaw can be critical when it comes to paying for purchases over the Internet or sending passport data: no user wants their confidential information to leak.

To make the Internet space safer, the programmers decided to develop an add-on over HTTP, which helps to avoid data interception by encryption. The HTTP extension is called HTTPS and stands for HyperText Transfer Protocol Secure.

HTTPS provides a secure connection between the user's browser and the web server. Often, the browser window displays a green address bar or lock indicating encrypted data transfer. You can also check the address bar of your web browser to see if you have a secure connection. It should start with ""https://"".

Conclusion

This protocol acts as a translator between your device and a server, enabling data exchange. The most common version is HTTP/2.0, though HTTP/1.1 is still in use. You can already apply the basics of HTTP! While browsing the web, notice whether you're using HTTP or HTTPS, the latter being more secure. It encrypts your data during transfer. You'll need to delve deeper into HTTP, if you plan to build apps or websites.

So, let's engage in some practice exercises to reinforce this foundational knowledge!
"
35,Web development,1449,13931,270,https://hyperskill.org/learn/step/13931,"Web development is the process of creating web applications and websites that power the digital world. It enables businesses, communities, and individuals to share information, conduct transactions, and interact online. Developers often separate a web application's logic into server-side and client-side components, each requiring specialized skills. Understanding both frontend and backend development is essential for building robust, user-friendly, and scalable web applications. Let's delve deeper into these components and explore their roles in the web development ecosystem.

Frontend and backend development
It is customary to divide web development into two parts: frontend and backend. Frontend development, also known as client-side programming, involves creating the user interface and writing the interaction logic with users. In essence, frontend development handles everything users see and interact with on a web page. Backend development, also called server-side programming, focuses on developing the internal server side of the web application and implementing its logic. Backend development includes everything users do not see, such as server management, database interactions, and application logic.

Developers
In web development, specialists focus on different aspects of creating web applications. These specialists include frontend developers, backend developers, and full-stack developers, each playing a key role in bringing a project to life. Frontend developers are responsible for interpreting designs into functional web pages. They ensure websites look great and function correctly across various browsers and devices. Typical tasks for frontend developers include creating responsive layouts, building interactive elements like sliders and forms, and optimizing user interfaces for performance and accessibility. Backend developers focus on the server-side logic and infrastructure of web applications. They write core business logic, process user data, manage databases, and ensure data security and application scalability. Tasks handled by backend developers include developing APIs, integrating third-party services, and implementing authentication and authorization systems. Full-stack developers handle both frontend and backend development. They work on all phases of web application development, from creating the user interface to implementing server-side functionality. Full-stack developers are often involved in building complete applications, managing end-to-end development processes, and integrating various technologies.

Separation of client and server parts
In web development, ""client-side"" and ""server-side"" describe where the application code is executed. But why do we separate the client and server components? Why do we need the user interface representation and the server logic separated from each other? There are several reasons for this:

You can independently update the frontend and backend logic, thus reducing errors. For instance, you can alter the site's appearance without modifying the common processes.
You need a server to store and structure data.
Data on the client's side may become outdated, but the server's responses are usually up to date.
It's easier to manage data flows and orchestrate processes on a few servers than on millions of clients.
Some tasks run faster locally without needing a server update.

How do frontend and backend communicate
To ensure a web service functions properly, the client and server parts must interact. This interaction occurs through HTTP requests. At its core, the communication between frontend and backend happens as follows:

The client sends a request to the server to retrieve or modify data using the HTTP protocol.
The backend processes this request and returns a response via HTTP.
The frontend receives the response, processes it, and displays the result to the user.

JSON stands as the most popular format for exchanging data between client and server, though other formats exist. Markup languages, like HTML and XML, help display server responses in a user-friendly manner.

Conclusion
In this topic, you've explored the organization of the web development process, the reasons for dividing it into server and client parts, and how these parts interact with each other. Typically, backend and frontend developers handle the server and client parts, respectively. However, full-stack developers work with both frontend and backend development.
"
36,Libraries,671,8504,276,https://hyperskill.org/learn/step/8504,"If you are already familiar with at least one programming language, you know that any programming language has a human-readable design. Most of them use Latin-script symbols to represent functions, keywords, and operators. However, it's not the language that the machine can understand, that's why we use interpreters, compilers, and assemblers. So, to make the process of creating machine code easier, we need a high-level interface that allows us to operate with verbal commands, which would be transformed into 'zeros and ones' by the program itself.The same idea can be applied when you want to reuse existing code that provides you with high-level functions and methods, rather than write it by yourself once more. We are here not to talk about tedious copy-paste but the usefulness of programming libraries. High-level means that each function you're calling orchestrates the low-level work for you. For example, some imaginary function WRITE_DATA under the hood opens a file, writes data to it, and finally closes the file. What is a libraryA programming library is a collection of reusable and redistributable code that has a well-defined interface to use.A library provides you with high-level functions and methods. We can expect that a library has documentation to get familiar with the behavior of the inner implementation. You should treat a library as a black box: you have the documentation of its interface, but you don't need to know an implementation. Just like programming languages isolate you from working with machine code, libraries isolate you from working with low-level operations.So, what do you think: can a big pile of incoherent functions be a library? Of course, but it's unlikely that someone will use it! Let's try to highlight the main features that we find important in terms of usability. A good library:belongs to one domain of knowledge, for example reading and writing to files, nothing moreprovides the documentationhas a clear interface, where the name of each object reflects its functiondoes not have malicious code in ithas testsfollows programming language's code styleNow you know how to understand whether a library you've chosen is a well-written one. How exactly can we use it?Standard and third-party librariesThere are several types of libraries, but where can you find them?Programming language implementations are the usual software that you can install on your computer, and most implementations come with standard libraries. The standard library is a stable and standardized collection of modules for the essential needs of the development process. Usually, standard libraries consist of common utilities like working with the file system, making network connections, or parsing JSON files, and are a part of the programming language specification.The standard library can hardly cover all your needs. For example, you may want to make a desktop application or a web crawler, but the standard library doesn't give you handy tools for that. In this case, you can search through the internet to find a third-party library on sites like Github. A third-party library is a collection of high-level modules, apart from the standard library of a programming language. Those libraries are often open source.To include a library in your program, you should use a keyword and its name. If you use third-party tools, you should look through the documentation and find out how you can install it on your computer first; the authors of a library provide this information in the README file.So, now you could feel like you've learned all the basics about using libraries. Perhaps you still have a question though: is it more efficient than just writing code by yourself? The answer is: in many cases, yes. Why use librariesLibraries are not a silver bullet for all programming problems. Not all libraries are mature enough to be used in code production, and some of them are buggy. If the problem is too narrow, it's hard to find a library to solve it even if it exists.Let's suppose that a library for your problem exists. We cannot cover all the cases, but we can give you several reasons to use it:It reduces the time to develop an end product. We can focus on implementing the logic of the application, not on making auxiliary software.The development of a library is community-driven. It means many people support a library, and you can join them if a library is open source, if you want.If a library is popular, many companies and programmers use it. It means that the library has been tested and utilized by different people, and a new developer in your team will likely know this library too.Libraries have documentation. You can just read a tutorial and start using a library without learning about the inner implementation.The main goal of libraries is to prevent people from doing the same work twice. You can follow this rule and make your software without getting distracted by any other issues. If your code uses a library, you can always replace a library function with your own without breaking the program. You are in control of what you want to use. ConclusionLet's summarize what we've learned so far. In essence, the library is a compilation of code with an understandable interface made for specific situations. Libraries can be standard and third-party. The use of third-party libraries instead of writing your own code can be reasonable in many cases simply because it saves time and effort. Moreover, popular libraries are usually well-tested, and if they are open-source, you can even join the community of their supporters.
"
37,Concept of design patterns,157,3611,292,https://hyperskill.org/learn/step/3611,"Code design
If you are reading this, you must be really interested in programming. It doesn't matter whether you are an experienced developer, just starting your career, or still working on the basics; what really matters is that you are curious, so welcome.
To begin with, let's talk about code design. In general, the design of your code is about expressing your ideas clearly to your teammates, colleagues, and clients. We can compare code to text: if you put the lines in the right order and make the structure clear, it will be much easier to explain and understand the text later. From an engineering point of view, your code is well-designed if you can agree with the following statements:
1) When you make a small change, it does not produce a ripple effect elsewhere in the code.
2) Your code is easy to reuse.
3) It is easy to maintain your code after release.
Design patterns
In application development, the design of code has to match the problem and be general enough in order to fit all the requirements that may arise in the future. Everyone tries to find more elegant, suitable and flexible solutions that can also be reused. Here is where design patterns come into play: these are repeatable solutions to common problems that developers face. Design patterns even have names! For example, if you want to confine yourself to just one instance of a class, Singleton pattern is going to be the best choice; if you see family relations between objects and you want to encapsulate creational processes, you should use AbstractFactory, etc.
As a rule, examples of well-structured object-oriented architecture make use of patterns a lot. When a suitable pattern is used, it tells us that the developer has really paid attention to typical interactions between elements in the system. As a result, the architecture of an application becomes easier to understand.
Being so useful, design patterns have made it onto many programmers' bookshelves: one of the most famous examples is the book Design Patterns: Elements of Reusable Object-Oriented Software. You probably heard about its authors, ""Gang of Four"", which is frequently abbreviated as ""GoF"". Today it is considered one of the classic books on software design and programming. You may check it out to deepen your understanding or proceed directly to practical learning here. 
Note that in this topic we will only consider object-oriented design patterns.
 

Software design patterns and related concepts
A great thing about patterns is that they help you not to waste your time reinventing the wheel so you can spend it on developing cool features instead. The structure of design patterns is strict: describe the problem, the solution, when to apply the solution, and its consequences. Theoretically, you can combine a few patterns and create your own monster pattern that contains, for example, Builder, Abstract Factory and Decorator simultaneously. However, as you will see from the following topics, it's better to avoid such monsters because patterns have already been well-grouped for you. In other words, don't get too excited, it's really better to use them one at a time.
Using patterns does not require any specific programming language skills or striking imagination. Patterns are also language-independent: even though they can be implemented differently in different languages, the general idea of each pattern is common for all of them. That means that it's possible for you to speak the language of architecture with your colleagues even if they work with different technologies.
Why should I know design patterns?
Here is a list of quite convincing reasons to get familiar with design patterns:

Patterns provide tested and commonly used solution templates for design problems; you don't have to invent anything!
Patterns improve flexibility and maintainability of object-oriented systems, which makes it easier to react to changing requirements.
Patterns can speed up the development process.
Patterns are a universal vocabulary that allows developers to describe a program design using a set of well-known identifiable concepts.
Patterns are often used in standard libraries and frameworks.
You can find patterns in the source codes of many applications and quickly understand how they work, instead of reading thousands of lines of code.

Caveats
In order to achieve flexibility, design patterns usually introduce additional levels of indirectness, which in some cases may complicate the resulting designs and hurt application performance. In other words, even though patterns are supposed to make things easier for you, they may also become an unnecessary complication if applied unwisely. Beginner developers may try to apply patterns everywhere, even in situations where a simpler code would do just fine. Look how design patterns can complicate even the simplest ""Hello, World"" program.
To avoid misusing the patterns, you should apply them wisely and be able to correctly adapt them to your problem and language.
Conclusion
When you master the principles of working with patterns so that after successfully applying them you scream ""Eureka!"" without any doubt in your thoughts, your perception of object-oriented programming will probably change once and for all. In the following topics, you will learn about Creational, Structural, and Behavioral design patterns. Be concentrated and attentive: these matters are quite advanced. Happy coding!
"
38,PyCharm basics,438,6193,302,https://hyperskill.org/learn/step/6193,"When you start programming, an Integrated Development Environment (IDE) can help with the main developer workflows allowing you to keep focusing on the language specifics. We encourage you to use PyCharm for your Python projects. PyCharm is a dedicated Python IDE that provides a variety of useful features like code completion, code inspections, project navigation, and refactorings.

Overview
PyCharm is available in two editions: Community and Professional. The Community edition is free and open-sourced. It comes with everything you need for smart and intelligent Python development, including code assistance, refactorings, visual debugging, and version control integration. PyCharm Professional is a paid version of PyCharm that is aimed at professional Python, web, and data science development. With PyCharm Professional, you can create web framework applications, develop remotely, analyze big data, and work with Jupyter notebooks. See more details about each edition on the PyCharm product page.

Install and run PyCharm
Before you start, check the requirements for memory and operating systems in the PyCharm System Requirements.

Install Python
PyCharm is a Python-specific IDE, so you need some Python to start your work. Download it from python.org, then install it according to your operating system requirements.

Download and install PyCharm

Download PyCharm Community from https://www.jetbrains.com/pycharm/download.

Run the installer and follow the wizard steps. See more details in the PyCharm Installation Guide.

Note that you can opt for a standalone installation or Toolbox App that is helpful when you need to install several JetBrains IDEs or handle multiple versions of PyCharm.

Launch PyCharm
To launch PyCharm, perform the following action depending on your operating system:

Windows: Run PyCharm using the Windows Start menu or the desktop shortcut

macOS: Run the PyCharm app from the Applications directory

Linux: Run the pycharm.sh shell script in the installation directory under bin

Welcome screen
Once you launch PyCharm, you will see the Welcome screen:

On the Welcome screen, you can find all options and settings to start your work in PyCharm. The quickest way is to create a new project from scratch or open an existing project from a local drive or a repository.
The start page also contains a link to the PyCharm onboarding tour that will help you get acquainted with the main developer's workflow in just 7 minutes. Take the tour to make your start even smoother.

Quick start
You can begin your work in the IDE without setting anything beforehand because PyCharm provides almost all features out-of-the-box. Nevertheless, whatever you do in PyCharm, you do in the context of a project. A project is an organizational unit that serves as a basis for coding assistance, bulk refactoring, and coding style consistency. So, you need to start with a project setup. You have the following options:

Create a new project — create a new project in your file system and configure a Python environment using your Python installation.

Open an existing project — open an existing PyCharm project. You can also open any folder in your file system, and PyCharm will detect any previously configured Python environment.

Get a project from a version control system — clone a project from a Git, Mercurial, or Subversion repository.

Customized start
On the Welcome screen, you can adjust the IDE default settings. Click Customize and select another color theme or select the Sync with OS checkbox to use your system's default theme. Here you can also configure accessibility settings or select another keymap.

You can also click All settings to open the settings dialog. The settings that you modify at this moment will become the new default configuration for your projects and the IDE.
Although PyCharm Community comes with the all main features, you can extend them by installing plugins. Click Plugins in the left-hand pane of the Welcome screen, then download and install the required plugins from the PyCharm plugins repository.

With this, you're ready to create your first Python application.

Create a Python project in PyCharm
To create a new Python project, perform the following steps:

On the Welcome screen, select New Project:

In the New Project dialog, PyCharm fills all the required fields for you. The IDE will create a Python virtual environment and the Python built-in package manager, which allows you to install external libraries. The Base interpreter list indicates the path to the actual Python, which you download and install on your computer.

So, at this point, you can select one type of environment: Virtual Environment (default), Conda, Pipenv, or Poetry, and create it using one of the Python interpreters installed in your system. Refer to Creating Python Projects for more details about other project options.

Mind the Create a main.py welcome script checkbox. It is selected by default. With this option enabled, PyCharm creates a Python file with some basic code that can be a good starting point for your application.

Click Create to complete the task.

When the project is created, the main.py file is opened in the editor. This file shows the basic script and provides useful hints so that you can start editing code in PyCharm. For the time being, remember one of the most helpful shortcuts Shift + Shift. It opens a dialog where you can find any command, setting, code construct, or project file. Refer to Working with Source Code in PyCharm for more detail on available coding assistance.
You can add more files of various types to your project, as well as directories and Python packages. They are all listed in the Project tool window. Refer to the following PyCharm web help topic for more details about adding files and directories to a project: Populating PyCharm Projects.
You already learned about the PyCharm editor and Project tool window. Let's look at the entire PyCharm user interface:

The main elements of the IDE UI are:

Main menu. Its position is OS-specific;

The navigation bar and main toolbar;

Project tool window;

Editor;

Tool windows that include the Python Console and Python Packages windows;

Python interpreter selector. It shows the environment that is currently configured for the project.

After doing this, you have created a PyCharm project and configured a Python interpreter for it. You can create more Python interpreters if you need various environments to run your scripts (for example, when you want to execute them on different Python versions).

Create Python interpreters
The easiest way to open the Python interpreter settings is to click the Python Interpreter selector located in the lowest part of the PyCharm window, on its Status Bar.

Click the interpreter selector. You should be able to see all the interpreters that have been configured to be used by all projects.

Select Add New Interpreter > Add Local Interpreter from the menu.

You can see various types of interpreters in the Add Interpreter dialog:

You can create a new interpreter or continue to use an existing one.
For a new interpreter, select Base interpreter from the list, or click ""..."" and find a Python executable in your file system. For an existing interpreter, select Interpreter, or, similarly, click ""..."" to discover a Python executable.

If PyCharm is not able to detect Python on your machine, it provides two options: download the latest Python versions from python.org or specify a path to the Python executable (in case of non-standard installation). See more information and related procedures in Configure a Python Interpreter in PyCharm.
When you save the changes, the newly created interpreter is set for the current project.
The key point for creating different isolated environments is to keep different sets of Python packages. So, let's learn how to install packages in PyCharm.

Install Python packages
The Python Packages tool window provides the quickest and neat way to preview and install packages for the currently selected Python interpreter.

To install a package from the default repository:

Type the package name in the Search field of the Python Packages tool window.

Locate the package in the list of the default repository

Click the Install button in the upper-right corner of the tool window

For more details about installing Python packages, see Install, Uninstall, and Upgrade Packages in PyCharm.
Read more on this topic in Testing Python Code 101 with PyTest and PyCharm on Hyperskill Blog.

Conclusion
To sum up:

PyCharm is a Python-specific IDE. It has two editions: Community (free) and Professional (30-day free trial).

To install PyCharm, download an installer from https://www.jetbrains.com/pycharm/download

The Welcome screen provides a quick way to create, open, or clone a Python project.

You can customize your IDE with PyCharm settings.

To start your way in PyCharm, you need to create a project, configure a Python virtual environment (Python interpreter), and add your Python code to the main.py file or to other Python files.

PyCharm allows you to configure various Python interpreters depending on your operating system and edition of PyCharm.

With the Python Packages tools window, you can quickly install packages on the selected Python interpreter.

Find more details and specific procedures in the PyCharm Web Help.
"
39,Immutability,608,7929,306,https://hyperskill.org/learn/step/7929,"In philosophy, there is a thought experiment called ""Ship of Theseus"". It is one of the oldest concepts in Western philosophy and it goes like this.
The famous ship of the hero Theseus has been kept as a museum piece in a harbor. Over the years, the wooden parts have rotted and been replaced. A hundred years later, all of the wooden parts of the ship have been replaced. The question is: is it still the same ship?

There are many ways to answer this question and you can check them out on Wikipedia. What is of interest to us is that this question of identity can be applied to programming as well. One of the most important concepts in programming, the one directly connected to change and identity, is the concept of (im)mutability.
In this topic, you will read about the general idea of immutability, and in the following topics, you will explore the means of ensuring immutability in the programming language you have chosen to study.
Mutability and immutability
Mutability literally means ""the quality of being changeable"" and, in programming, it refers to the idea of changing the state of the object after it has been created.
Along this line, we can distinguish between mutable and immutable objects. To put it simply, mutable objects can be altered once they've been created and immutable cannot. This is the key difference between mutable and immutable objects.
What does this mean in practice? Immutable objects always represent the same value: if you want to have a different value, you need to create a completely new object. With mutable objects, things are much easier and we can change the values they contain without creating a new object.
Returning to the ship of Theseus, if we were to consider it an immutable object, then the answer to the question of identity would be no. Once you change something, you have a different object. In other words, the ship of Theseus is no longer the ship of Theseus even though it has the same name!
Alternatively, if we regard the ship as a mutable object, then, yes, it is still the same ship. The changes that we made did not affect its identity.
Depending on the programming language you're using, different types of objects may be immutable. For instance, strings are immutable in Python and Java, but Java also has StringBuilder and StringBuffer classes which are mutable. In Ruby and PHP strings are mutable. When writing a program in your favorite language, you need to take into account which objects are mutable and which are immutable in that particular language.
Custom objects and immutability
In general, objects of custom classes are mutable. However, there are cases when we would want to make them immutable: immutable objects are thread-safe, easier to test, and may be more secure.

Immutable objects can be shared between different threads without additional protection. The state of mutable objects is hard to follow as long as they can be changed by any of the working threads. 

In the context of custom objects, we can also talk about weak immutability and strong immutability. Weak immutability is when some fields of an object are immutable and others are mutable. Strong immutability is when all fields of an object are immutable.
Specific instructions on how to make a custom class immutable depend on the language, but we can give general guidelines. Basically, you need to forbid changing the value of the field once it has been created or forbid reassigning the value. This can be done, for example, by making the field read-only or a constant. Another option is to modify the methods that set attribute values so that they throw exceptions. You can also work with access modifiers: make the fields unattainable from the outside of the class.
Summary
To sum up, the difference between mutable and immutable objects lies in the fact that mutable objects can change their states after creation and immutable objects cannot. Languages have their own division into mutable and immutable objects. Custom classes are usually mutable but can be made immutable using language-specific tools and techniques if necessary.
"
40,What are bugs,348,5504,318,https://hyperskill.org/learn/step/5504,"A software bug is a problem that causes a program to crash or produce invalid output. There are many reasons for software bugs; the most common of them are human mistakes in software design, coding, or understanding of the requirements.
A program is usually called stable if it doesn't have a lot of obvious bugs. If the program has a large number of bugs that affect the functionality and cause incorrect results, it is considered buggy or unstable. The user cannot successfully interact with such software. It is important to find bugs before users start interacting with your program.
Bug etymology
You've probably already heard the term ""bug"" and can imagine what it means. Here is a little story about this.
The first computer bug was discovered by Grace Murray at Harvard University in 1947, while she was working on the Mark II computer. During the investigation of an issue, an actual moth was found between the contact of the relays. The moth was removed and added to the logbook, which now is located at the Smithsonian Institution's National Museum of American History in Washington, D.C.
So, computer errors are often called bugs. This term is used to describe any incorrect program behavior until the specific nature of the error is determined.

Some Internet sources give a different story of this term. You can google it if you are interested. Let us know if you find a story most credible to you.
 
Why do programs have bugs?
Developers often say that a program without bugs doesn't exist. There are some common reasons for bugs in software:

communication issues in the team;
misunderstanding of the requirements;
software complexity;
programming errors (programmers, like anyone else, can make mistakes);
time pressure;
use of unfamiliar technologies;
an error in a third-party library (yes, that happens too).

During this course, you will mainly encounter bugs caused by misunderstanding of the given requirements or programming errors.
Avoiding bugs
It is almost impossible to avoid all bugs in a large program, but it is possible to reduce their number. Here we give you five steps that can help to do that in both educational courses and industrial programming.

Make sure you know what to do. As a programmer, you need to understand the requirements of a program that you are going to work on. If you have doubts, you can always find some help on the Internet or among fellow developers.
Decompose a program into small units that are easy to look through and understand. A good architecture reduces software complexity, and, as a consequence, the number of errors.
Write easy-to-read-code and follow all the standards of the language. It will also allow you to make fewer errors.
Run the program with boundary input values. Do not forget to consider different cases: 0 or a huge number as an input value, 0 or 1 element as an input sequence. Such cases often reveal bugs.
Write automated tests that will check the program at the build time.

We will not discuss automated tests in this topic, but we will return to that later. At this moment, you can simply create a set of input values and run the program manually (as it was described in step 4).
Debugging
Suppose you know that your program does not work correctly for some input values. To fix this bug, you need to find it in the code and then make some changes.
To locate a buggy place, you can:

read the code and try to understand what it does for the input values;
start the debugger and see the current values of variables and the control flow of the program;
print the current state of the program in critical parts of the code (logging) and then analyze it.

The combination of the approaches above will allow you to find most of the bugs in your program.
Conclusion
Let's sum this topic up. A bug is the incorrect behavior of a program. However, there are ways to reduce the number of bugs. For example, understanding the requirements of the program, following the standards of the language, building a clear-cut architecture of the program, checking the program with boundary values, and using automated tests.
If you still happen to have a bug, first of all, you need to locate it in the code. For that, you can use a debugger or logging, or try to understand what the code does with input values by reading it. Use these tips, and, most likely, you will avoid writing buggy programs and spending time debugging them.
"
41,Functional testing,1400,13438,321,https://hyperskill.org/learn/step/13438,"Imagine that you and your development team have made a new product, for example, a mobile application. Before you upload your product to some download service, you need to make sure that everything works as intended. To do this, you may conduct functional testing. It will help you verify that the application performs the desired tasks in the appropriate context. Let's take a closer look at what kind of testing it is, how it works, and what types it has.

What is functional testing

Functional testing checks if the output satisfies some specific requirements or not. Its main task is to confirm that the functionality of an application or system behaves as expected.

There should be something that defines what is acceptable and what is not. Usually, it's written in a specification. It is a document that describes the expected behavior of a program. Additionally, sometimes specifications also include the actual business scenarios to be validated.

So, now you know what functional testing is. The next step is to describe different types of functional tests.

Test pyramid

The key concept that represents different kinds of tests is the test pyramid. This is a great visual aid that shows different test levels. It also shows the extent of the tests at each level. At the lower levels, there are more tests and they go faster, as they are small and aimed at testing individual functions or features. At the higher level, there are fewer tests, since they are more complex and voluminous, they require more effort and time. Let's look at the pyramid from the bottom up.

Unit testing

The most basic type of testing is unit testing. It requires writing tests for every non-trivial function or method. With it, you can quickly check whether the latest change in the code has led to some new errors in the already tested parts of the program; it also facilitates the detection and elimination of such errors. The goal of unit testing is to isolate individual parts of a program and show that each of these parts work.

Unit testing is performed at the earliest stages of the development process, and in many cases, it is executed by the developers themselves before handing the software over to the testing team.

The advantage of detecting errors in the software at an early stage is in minimizing software development risks, as well as time and money wasted on going back and fixing fundamental problems in the program when it is almost ready.

Integration testing

All complex applications are integrated with some other parts, such as databases, file systems, etc. Thus, it turns out that developers also need to test how these parts will all work together. This is what integration tests are for.

They take the already tested units as input, group them into larger sets, run the tests defined in the test plan for these sets, and present them as outputs and inputs for subsequent system testing. The goal is to check the integration of the application with all the outside components.

So, during such testing, one needs to run not only the application itself but also the components that will be integrated. For example, If you want to check integration with a database, then you should run the database when executing the tests.

End-to-end testing

After integration tests, one can check the entire system from start to end. This is called end-to-end testing.

End-to-end testing is a software testing methodology to entirely test an application flow. The purpose of end-to-end testing is to simulate the real user scenario and validate the system that is being tested, as well as its components, for integration and data integrity.

It is performed under real-world scenarios like communication of the application with hardware, network, database, and other applications.

End-to-end tests are very useful, but they're expensive to perform and can be hard to maintain when they're automated. It is recommended to have a few key end-to-end tests and rely more on lower-level types of testing (unit and integration tests) to be able to quickly identify new errors.

UI testing

UI testing stands for User Interface testing. The idea is that the QA engineers simulate user actions, i.e. clicks on buttons and links, and other actions of a similar type. The point is to check the interactions between the components. If you, say, made a new site, then during UI testing you will check, for example, how the search works, whether users can log in and out, how sections are opened, and so on.

UI testing can be performed not only by the developers but also by the users. This functional testing type is called Beta testing.

Beta or Acceptance testing is carried out at the very end when the raw or beta version of the product is ready. Beta testing is the intensive use of a near-finished version of a product in order to identify as many bugs as possible before the product is finally released to the market. It does not require developers like in all previous testing methods, but volunteers who will use the product for a while and point out its shortcomings.

Okay, we've reached the top of the pyramid, but there are still a couple of tests we need to mention: smoke and regression.

Smoke and Regression

Smoke testing is a testing technique that is inspired by hardware testing, which checks for the smoke from the hardware components once the hardware's power is switched on. Smoke Testing means a minimal set of tests to find some obvious errors. Smoke testing is executed to verify that critical functional parts are performing as expected and the whole system is stable. It makes no sense to send a program that has not passed this test for deeper testing.

Regression testing is often done after a smoke test and some code changes. Its goal is to confirm that these changes have not negatively impacted the existing functionality/feature set. Regression test cases can be obtained from functional requirements or specifications, user manuals, and are carried out regardless of what the developers have fixed.

These two test types can be implemented at any level because the developers can make changes at any level. This means that every time they change anything they need to check again if the system is stable and if everything is working correctly.

Conclusion

In this topic we've looked at functional testing and its types. To sum up, functional testing helps developers make sure their product performs as intended. Different types of functional testing help check the product both in separate parts or units and as a whole, to identify minor flaws and serious system bugs.
"
42,Unit testing,572,7545,322,https://hyperskill.org/learn/step/7545,"What is Unit Testing?

There are different types of testing in software engineering, all serving different purposes. We will consider one that is performed by developers: unit testing. This is probably the most popular methodology: it implies testing the behavior of a unit of an application. A unit is a portion of code that does exactly one task, so it's the smallest testable part of an application.

Unit testing is usually done by the author of the tested unit to confirm that the unit does its work well. In object-oriented programming, a unit can be a class or a function. In procedural programming, a unit is a function or a procedure.

Steps to test a unit

The main idea of unit testing is to isolate a specific unit and check that it works properly.

Generally, each unit behaves in a similar way: it consumes input data, performs some action on it and produces output data. We can use this behavior to verify the code. The test goes through the following stages:

We create two datasets: the input and the expected output;
We define acceptance criteria: some conditions determining if the unit works as expected (usually, the acceptance criterion is a comparison of the actual output with the expected one);
We pass the created input dataset to the tested unit;
The input invokes code of the tested unit;
The code produces an output;
The produced output is checked by the acceptance criteria, which compares the actual output with the expected one;
Acceptance criteria return the result: pass or fail.

Note: there is no step called ""we thoroughly examine the code"".

In unit testing, we know nothing about what the unit actually does with input arguments, but we know exactly what result is expected for each set of input arguments.

Manual Vs Automated

All these steps can be carried out manually or automated. It is in fact very uncommon to opt for manual unit testing, and there are a couple of sound reasons for that. First, testing is a really repetitive process: every time you make a small change in your code, you have to retest it. Doing this manually would be daunting. Second, unit testing can be easily automated, so there is simply no reason to do it manually.

Automated test cases are reusable. Suppose you add a new feature to your program; you can execute existing test cases to check whether the new feature has affected the application.

Benefits

First, unit testing allows developers to find bugs at the early stages of development – as you hopefully remember, unit testing is done during the development process, unlike many other testing types. The sooner you find a bug, the less effort you spend on fixing it. It means we can save some time and money!

Secondly, unit testing protects your code from further incorrect changes. Like a butterfly may cause a tornado, even the smallest changes can drastically affect the behavior of your application. In that case, unit testing is a part of regression testing, where we re-run tests to ensure that code still works as expected after it has been changed.

Finally, unit testing makes the integration process easier. The correctness of the whole program depends on each unit and the interaction between them. Since correctness of individual units is approved by unit tests, developers can focus on building interaction between them.

Example: Add two numbers

Suppose we're developing a calculator that has several basic functions: add, subtract, multiply and divide. The application can be divided into 4 units according to these functions. Let’s try to apply unit testing to the add function which takes two parameters, x and y.

The pseudocode consists of three parts. First of all, we initialize the test data. Then, we invoke our test subject: the add function. In the end, we compare the actual result with the expected result. If the add function returns 4, your test case passed; otherwise, it failed. Easy as that!

As you can see, unit testing does not depend on the implementation of the unit. There is no need to look under the hood unless our unit tests fail.

Conclusion

We have covered quite a major topic – unit testing. It is a kind of testing that checks the behavior of the smallest testable pieces of code. Unit testing considers a unit as a black box; it only checks the result of a unit without internal details. It can be automated easily, so it is often used to confirm that the unit still works properly after code has been changed.

Unit testing is an essential part of a developer's daily work. Even though it is quite time-consuming, it protects your code from bugs and saves you a lot of energy at the end of the day.
"
43,Pseudocode,1579,15090,334,https://hyperskill.org/learn/step/15090,"Different people use different programming languages, and that often becomes a problem. If you implement an algorithm you've written in one particular language, developers who don't know that language would hardly be able to understand it. To solve this problem, you can use pseudocode, a special artificial language that stands somewhere in between ""human"" language and code. Let's find out what it is and why we need it at all.

What is pseudocode?

Despite the variety of programming languages, they all share some common features. These include variables, loops, if-else blocks, and so on. In fact, if we remove all language-specific features from a program, we are left with its ""logical core"", which is the essence of any algorithm. By isolating this core, we are inevitably forced to resort to high-level constructs like ""Do A until B happens"", where both A and B can be quite complex operations. So, this essence of an algorithm may be called pseudocode.

If we decide to use pseudocode, we lose the opportunity to ""explain"" our instructions to a computer, which requires a significantly lower-level input. On the other hand, we gain a lot in the brevity of our solution and its comprehensibility to people, which is exactly what we strive for when we create pseudocode. 

Why do we need pseudocode?

But why should we use an abstract language, not an existing one? Of course, we can use a popular and simple language like Python, and many programmers can understand this code. The main problem here is that in real code you need to work with memory, include libraries, solve some problems with visibility, variable types, and so on. Why do we need to think about this stuff if we want to understand the algorithm? An abstract language better describes the idea of an algorithm without complications.

Another obvious solution to the problem of universal description of an algorithm is to simply describe it in human language. However, this is also a bad idea. In this case, you have to read a lot of text and take some time to figure out what the code will look like. With pseudocode, you don't need to clarify the description, and it's easy to see the structure of the code.

Pseudocode example

Let's solve a standard task and find the maximum value in an array of positive numbers. The array is just an ordered bunch of numbers if you're not already familiar with the term.

We emphasize that in our pseudocode indexing starts with 1.

It looks pretty straightforward and gives a sense of the algorithm's internal logic.

As you can see, with pseudocode we can omit reading and storing values. We can focus on describing only the algorithm's logic.

Pseudocode has a lot of variations and dialects. In this course, we will use a specific version of pseudocode. This dialect will be clear for almost any developer, but if you don't feel confident enough, feel free to read our topics with the examples of variables, relations and conditions, and complex code chunks. The most important thing for you to know is the following: you should know how to read and understand pseudocode, not how to write it correctly.

Conclusion

Pseudocode is widely used to communicate the essence of an algorithm to others while ignoring the details of its implementation. With pseudocode, you can easily communicate ideas and concepts to other developers, no matter what language they write in. Pseudocode has many dialects, but in this course we will use a specific version, which we'll discuss later.
"
44,Data structures,3822,40371,336,https://hyperskill.org/learn/step/40371,"Let's face it: you can't ignore algorithms if you're hoping to write an innovative and efficient program. However, algorithms are not the only thing you need: besides the question of processing, there's also the question of data storage, including how much space your program takes. Here data structures come in handy, so let's learn some essential information about them.
What data structures are
Data structures are a way of organizing data and providing convenient access to it. Rather abstract? Okay, let's look at a more specific example.
Imagine that we have a variety of soda cans and bottles that we would like to organize. We could put them all in a random bag or build a can tower, but this way, it won't be easy to fish out a specific type of soda or even count the items. After a bit of pondering, we decided to put them in a vending machine. This vending machine will be a structure of beverages: it has a specific order, and you can easily observe the tins and bottles, count them, access one or another, as well as understand the capacity of the machine and perform many other operations.

Now let's return to the formal definition and try again: the term data structure refers to a collection of elements containing data, as well as relationships between them and data operations. As a rule, data structures have two types of operations: internal, supporting data organization, and external, available to users for storing, retrieving, or modifying data. There are several common data structures: an array, a linked list, a hash table, and a whole variety of trees (binary search tree, heap, red-black tree, B-tree, etc.). You can read about all of them in detail on our platform, but don't hurry: let's get to know the basics first.
The role of data structures
Now, why is it so important to have all these kinds of data structures? We've mentioned that organizing soda cans in a vending machine instead of a can tower is much more efficient, as it is far easier for us to perform any actions on these cans. What does this mean formally? We are already familiar with Big O and the time complexity. In a nutshell, different data structures have different time complexities for performing the same external operations in a set of data. This is why it is essential to consider all the possible structures and choose the most efficient among them. Let's illustrate what we've said above in an example.

Later on, you will learn about an important shortest path algorithm: Dijkstra's algorithm. It has two main implementations: using an array or a heap as a data structure. In the first case, Dijkstra's algorithm time complexity will be \(O(n^2+m)\), whereas if we use the second type of data structure, our algorithm will work on \(O((n+m)\log n)\). Just for now, we suggest ignoring the names and the unfamiliar terms — the idea is to simply illustrate how using different data structures can lead to different time complexities of the same algorithm. There is a famous book entitled Algorithms + Data Structures = Programs, written by the Swiss scientist Niklaus Wirth in 1976. This book covers some of the fundamental topics of computer programming; its title shows quite clearly just how essential it is for a programmer to understand data structures.
Common principles
There are several key principles of data structures. Data structures:

provide a systematic way to organize and structure data, ensuring efficient storage and retrieval.
are designed to optimize operations such as searching, insertion, deletion, and so on, ensuring efficient algorithmic performance.
provide scalability and flexibility, allowing systems to handle growing or changing datasets without sacrificing performance.
optimize memory usage and manage memory allocation and deallocation efficiently.
promote code reusability by encapsulating data and operations into reusable modules, enhancing software development productivity and maintainability.

Conclusion
To sum up, let's revisit the key points covered in this topic:

Data structures are tools for organizing data and providing efficient access to it. They encompass a wide range of types and implementations.
Data structures have two types of operations: internal operations, which facilitate data organization, and external operations, which allow users to store, retrieve, or modify data.
Different data structures come with varying time complexities for the same external operations. Selecting the most efficient data structure is crucial for optimizing program performance.

In conclusion, understanding data structures and their role in computer science is essential. In the following topic you will study data structures deeper, by learning some more formal definitions and concepts, and after this you will have the chance to explore many of the data structures used in practice by professionals.
"
45,Abstract and concrete data structures,267,16927,337,https://hyperskill.org/learn/step/16927,"After getting familiar with the concept of data structures and its importance, it is time to know some other fundamental details about them. That is to say, we will learn about abstract and concrete data structures, as well as the difference between them. This enables programmers to select the right data structure, design efficient algorithms, manage memory effectively, develop modular and reusable code, and facilitate collaboration and communication within a development team.

Abstractness of vending machines

There is another term: abstract data type (ADT), which is sometimes used as a synonym for data structures, though this is not entirely correct. Let's try to figure out what ADT is by considering yet another example.

We hope you don't doubt that this above is a vending machine. The thing is that you can't see what exactly it contains on the inside. Now, you probably know how to interact with vending machines: you insert a coin and get your drink. If you are just thirsty, this information is more than enough. It doesn't matter to you how the machine works from the inside, how it organizes the payment, the beverages, or how many beverages there are; you only need to know how to get your soda. Hence, this is an abstract vending machine for you.

Abstract data types

For those who would like a formal explanation of this concept, we should say that in programming, such techniques of ""covering vending machines"" are known as:

Abstraction — a concept in object-oriented programming; it ""shows"" only essential attributes and ""hides"" unnecessary information, a.k.a. abstract classes or interfaces;
Encapsulation — is a method of making a complex system easier to handle for end users. Formally speaking, encapsulation is the process of combining data and code, operating this data into a single entity. The user needn't worry about the internal details and complexities of the system.

In general, an Abstract Data Type is a mathematical concept, a simpler and more abstract way to view the data structure as a whole. It is a data type that is defined by a set of values (elements/items) and a set of possible external operations (behavior) from the user's point of view. There are some common ADTs that every trained programmer should know: stack, queue, and so on. As a rule, modern programming languages like Java, Python, and C++ provide these ADTs in standard libraries so that we can use them in our programs.

How do they vend

Let's get back to our vending machine parable once again to realize the difference between data structures (sometimes referred to as CDTs – concrete data types) and ADTs. There are different ways to create a simple vending machine that performs a single function of exchanging a coin for a drink. We can keep the soda in a huge bottle; we can put it in different bottles in a heap inside the storage; we can organize the bottles and tins in one big row or ten different rows. All these arrangements can be called the implementations of a simple abstract vending machine. Nevertheless, they are still vending machines that exchange a coin for a drink.

If you want to create a more complicated mechanism with several functions, for example, ""choose a type of soda, then insert a coin"" or ""choose a drink or an ice cream"", the previous implementations won't work. In this case, we will have not only a new CDT, but also a new ADT: a vending machine that does much more than just exchange a coin for a drink.

CDT vs ADT

So, data structures (CDTs) are exact representations of data, but ADTs are different: they reflect the point of view of a user, not an implementer. A data structure (CDT) is an implementation of an ADT's functions, a way to look more closely at some specific operations and components of the structure. Recall from the previous section, that a stack is an abstract data type. It may define operations like push, pop, and peek, regardless of whether it is implemented using an array or a linked list. On the other hand, each one of these possible implementations defines a concrete data structure. For those who are familiar with OOP, java.util.Map, for example, plays the role of an ADT, whereas HashMap or LinkedHashMap can be interpreted as data structures. In some sense, an ADT defines the logical form of the data type, while a data structure (CDT) compels the physical form of it.

Conclusion

To sum up, let's revisit the key points covered in this topic:

Abstract data type (ADT): ADTs represent a higher-level perspective of data structures, focusing on their functions and overall behavior rather than implementation details.
Comparison of data structures and ADTs: Data structures are precise representations of data, while ADTs define the logical form and behavior of a data type.

It is okay if you don't understand the formal definition of an ADT or a CDT yet in every detail. You will get a chance to get back to it later. So, are you hungry for more? Dozens of topics on specific data structures are waiting for you on our platform.
"
46,Stack,318,5252,340,https://hyperskill.org/learn/step/5252,"Stack essentials
A stack is an abstract data type where elements are inserted and removed according to the last-in-first-out (LIFO) principle. The push operation inserts an item at the top of the stack, the pop operation removes the top item from the stack. Access to arbitrary elements is restricted. As a rule, a stack also supports the peek operation that just returns the current top element. In some cases, it may also be useful to check whether the stack is empty or what its size is, so these operations should also be supported.
The following image demonstrates the basic mechanism:

Here, element 1 was added first and will be removed last, while element 5 was added last and it's the first to be removed.
The underlying data structure to implement a stack can be an array or a linked list with restricted access to its elements.
Stacks in real-life and programming
The simplest real-life example is a stack of books. Only a book placed at the top can be removed, and a new book is always added to the top of the stack.
 

You can also imagine it as a stack of plates or a pistol magazine. Also, you might have seen the Stack Overflow logo before.
In programming, stacks are used to:


evaluate arithmetic expressions;


store arguments of functions and results of the functions' calls;


reverse the order of elements.


The efficiency of stacks
If you use a linked list or a classic array (non-resizable) as an internal structure, both push and pop operations always take constant O(1) time. It does not depend on how many elements there are in the stack, so the operations are very quick.
"
47,Fixed-size array,537,20078,344,https://hyperskill.org/learn/step/20078,"In programs, data is represented in the form of numbers, characters, strings, or other more complex objects. Often, some of these objects can be naturally grouped together. For example, assume that you conducted an experiment and got some measurements. They might correspond to temperature, distance, time, or something else. In such a case, it would be convenient not to store each measurement as a separate variable, but to process all of them together as a single unit. This will neatly organize our experimental observations, allowing us to analyze them quickly.
To efficiently deal with such cases, most programming languages provide a structure called a fixed-size array. The structure allows us to sequentially store a collection of elements of the same type and process them as a single unit. In this topic, we will look at this structure in more detail and learn some basic operations used for arrays.
Fixed-size array
A fixed-size array is a structure for storing a collection of elements of the same type. As you can guess from its name, the size of such an array is a constant: once an array is created, you can't change its size. While creating a fixed-size array, we declare its size. The computer then reserves necessary memory resources for the array. After that, the elements of a fixed-size array are stored sequentially into those memory addresses. Given below is an example of a fixed-size array that stores five floating-point numbers:

An array isn't limited to storing numeric values only. We can also store a list of strings in it. Like this one containing some flower names:

Arrays have some technical characteristics. To begin with, the size of an array indicates how many elements the array contains. It is also referred to as the length of an array. The length of both of our previous arrays is 5.
The index of an element is a number that tells us where the element resides within the array. For most programming languages, the counting starts at 0. The first element of the first array is 10.8 and its index is 0, the second one is 14.3 with the index of 1. The last element is 9.7 with the index of 4. The same rules apply to the second array.
Using pseudocode, we can represent the first array as follows:
measurements = [10.8, 14.3, 13.5, 12.1, 9.7]
A variable named measurements combines the numbers in a single unit.
Accessing elements
Programming languages provide a set of standard methods for array processing. There is one of them used most frequently. It is a method for accessing an element by its index. Let's try and access the third element of the measurements array and store it in a new variable value.

The value now contains 13.5.
Take notice that we can not only read, but also modify elements of an array:
measurements[2] = 3.7
Now, the array looks like this:

Both reading and modifying operations require O(1) time complexity. It's so efficient, because by knowing the index number, the computer can jump directly to the required memory address and fetch or modify the data.
Inserting and deleting elements
In short, inserting an element into a fixed-size array or deleting an element from the array is not possible. This is mainly because those operations would change the length of the array and it would no longer be a fixed-size array.
Still, you may want to add one more flower named Daisy to the array of flowers mentioned earlier. There's a way to do so! After inserting, the length of our new array will be 6. Thus, you need to create another array with the length 6, and copy all the five elements from the first array to the new array. There will be a spot left in your new array. Fill it up with the new flower name. You can use the same trick for deleting an element as well.

This operation requires O(n) time complexity, where n is the number of elements of the array, since we have to copy all n elements to our new array. In terms of performance, inserting and deleting are very slow operations for a fixed-size array. To overcome this limitation, programmers have introduced dynamic arrays, which you will learn about later.
On the flip side, the inability to modify the size is a strong characteristic of a fixed-size array. Nothing can affect our array's length. In the example above, we've added a new flower name to the array, but still, our old array remains the same. Thus, it is wise to use a fixed-size array when changing the array length may negatively affect your program.
Along with these operations, there are some other more sophisticated methods for array processing, such as sorting, reversing, searching elements, and others. When you use a particular programming language, check the documentation of the standard library to see what methods the language provides.
Example
Let's consider a simple example of how to process arrays. Given an array of numbers, our task will be to calculate the mean value of the elements in the array. The mean of the array elements is the sum of all array elements divided by their number. We will consider how it can be done for our array of measurements:
measurements = [10.8, 14.3, 13.5, 12.1, 9.7]
The procedure is the following:
We initialize the variable sum with the value 0. Then, we sequentially read the elements of the measurements array using the index numbers from zero up to the array length minus one, which is the index of the last element, and add them to the sum variable. After that, we divide the obtained sum by the length of the array and thus get the mean value for the elements. The length of the array of measurements is known in advance.
Here is the pseudocode of the process:
sum = 0

for i in (1, len(measurements)):
    sum = sum + measurements[i]

mean = sum / len(measurements) # 12.08
Here, len(measurements) will return the length of the measurements array.
Conclusion
Let's now summarize the main points considered in this topic.
The array data structure is widely used in programming. A fixed-size array allows us to store a collection of elements of the same type. The most frequently used method of array processing is accessing an element by its index. Not all array methods are efficient for a fixed-size array, but still, we can use them to our advantage. Since an array is a collection of data of the same type, processing it is easy and intuitive. Without this data structure, we would have to declare a new variable for every value in a list, which would result in a complex program and require much more storage.
To get information about other array methods, check the standard library of a programming language you use. Use a fixed-size array if you need to process a collection of data of a similar type and you know the number of values in advance.
"
48,Dynamic array,346,5357,345,https://hyperskill.org/learn/step/5357,"Introduction
Many programs need to store and process sequences of elements of the same type like numbers, strings, or even more complex objects. An array is a widely used structure to represent such data sequences since an element can be accessed in constant time by index. However, regular arrays have a significant limitation  – they have a fixed size. This does not allow one to create an array if the number of elements is unknown in advance. In such cases, using a dynamic array is a possible solution.
Essentials
A dynamic array is a linear data structure that is able to grow and, in some implementations, shrink when its size changes. As a rule, it has an internal regular array that actually stores data under the hood and provides some additional operations on top of it.
A dynamic array has two important properties:

size – the number of elements already stored in it;
capacity – a possible number of elements to be stored that corresponds to the size of the internal regular array.  

Usually, there are two paths: either to specify a capacity for a new dynamic array or to set a constant default value (e.g. 10). In contrast to basic arrays, dynamic arrays have operations for adding/removing elements to or from any position. This way, we can add and remove elements one by one after a dynamic array has been created.
The picture below demonstrates a dynamic array to which we added four numbers. The actual size is 4 and the capacity is 10 (initial):

Scaling factor
If the number of elements exceeds the capacity, all elements will be copied to a new internal array of a bigger size. There are a number of different scaling strategies for the size of it. The most common ones are the multiplication of the initial capacity by 1.5 (Java) or 2 (C++, the GCC STL implementation). There are also more unique cases like the Golang dynamic array (""slice""), which doubles the size until 1024 elements (after that the ratio is 5/4).
It is a trade-off between time and space complexities. With a bigger growth factor, we have more insertions before we would have to extend an array, thus decreasing time complexity.
But what is the best scaling factor? That is, what value will have both optimal time and space complexities? It turns out, that the value must be equal to the golden ratio, \(1.61803\). As you may notice, \(1.5\) is as close to it as it can get. If you're interested, you can read more about it  here.
It may also be necessary to support the shrinking of the internal array when removing elements to reduce the required size.
Common operations
Add an element to the end of the array. As discussed above, in the base case scenario where we just add an element to an array without specifying the index, we'll have these complexities:

\(O(1)\) – in average cases, since we just insert an element to already allocated memory (less than capacity);
\(O(n)\) – in the worst case, where we ran out of space and need to allocate a new array and copy every element into it.

The average estimate for adding an element to the end of the array is called amortized. Since it is rather difficult to tell from the first glance that it is \(O(1)\), we have to use a special analysis for that. If you're interested, you can read more about it here.
Add an element at the specified index. This operation is used when we want to add an element between some already placed elements. Its complexities (both average and worst) would be \(O(n)\) since on each insertion we must move an element at the index we want and then move each next element one index to the right.

Update value at the specified index. This operation replaces the element at the specified index with another element. All this is done in constant time since it is just like the assignment in the basic array, so the complexities are both \(O(1)\).
Remove an element by value/index. These methods either remove the first occurrence of an element specified or an element at the index specified. Both are similar to adding an element at the specified index in the sense that we would have to move some (or all) of the remaining elements one index to the left; therefore their complexities would also be \(O(n)\).


Clear. Here we just want to remove every element from the array. Since insertion is done via computation on the current array size, we can just reset the size to zero and override the old elements during the following inserts. That would leave the elements hanging out in memory (so the garbage collector won't be able to collect them) until they are overridden. The simplest form would have complexities of \(O(1)\), but the right one would have \(O(n)\).
Get element by index. Since a dynamic array is basically just a normal array, we can access elements by their index in constant time, so complexities are \(O(1)\).
Conclusion
A dynamic array is just like a regular array, but the number of stored elements can be changed. If adding operations run out of space to store elements, a new bigger array is allocated, and every element of the old array is copied to the new one. The scaling factor is a trade-off between time (speed) and space. With a bigger factor we have fewer allocations and less copying, but higher chances of running out of memory. The most common factors are 1.5 and 2. In some implementations, a dynamic array can support shrinking to reduce the used memory after removing elements.
"
49,Objects in Python,790,9262,377,https://hyperskill.org/learn/step/9262,"Knowing how different types of objects work in Python will help you understand some of the following topics more deeply, as well as the structure of the language in general.

Reference to an object
In Python, all values are stored in objects. You can think of an object as a box that contains information about some value and also stores some additional data such as its identity. When you assign a value to a variable, e.g. string = ""hello"", Python creates a new object, places this value (the string ""hello"" in our case) inside the new object and then creates a reference from the variable name string to the object.

Then, if we assign one variable to another, e.g. new_string = string, Python will create a reference from the new variable new_string to the same object.

As a result, you can access the object using any of the two variable names. You can also assign a new value to one of these variables and this will not affect the other one.

Note that the identity has changed along with the value.

However, the situation is a bit more complex when we deal with mutable objects, e.g. some of the containers.
Mutable objects and references
Let's take a list as an example. The thing is, a list doesn't store its values inside itself. Instead, it stores references to objects that store values. For example, when you write lst = [2, 3, 9], Python creates the following structure:

Now, if we assign our list to a new variable and then try to alter the first object, this will also affect the new list:

This is so because both lists refer to the same object: when it is modified, all variables continue to refer to this very object. In the next topic, you will learn how to alter a list without changing its copies.
Summary

Variables in Python do not store values themselves, they store references to objects that store values.
When we assign one variable to another, they refer to the same object.
After modifying mutable objects, other variables referring to it will also change.
"
50,Elif statement,408,5926,391,https://hyperskill.org/learn/step/5926,"Since you are familiar with basic conditional statements, such as if statement and if-else statement, it’s time for the more advanced elif statement. Buckle up!
Elf? Elif!
An elif statement is used when we want to specify several conditions in our code. How does it differ from if-else statements? Well, it's simple. Here we add the elif keyword for our additional conditions. It is mostly used with both if and else operators and the basic syntax looks like this:
The condition is followed by a colon, just like with the if-else statements, the desired action is placed within the elif body and don't forget about an indentation, i.e., 4 spaces at the beginning of a new line. Here we first check the condition1 in the if statement and if it holds (the value of the Boolean expression is True), action1 is performed. If it is False, we skip action1 and then check the condition2 in the elif statement. Again, if condition2 is True, action2 is performed, otherwise, we skip it and go to the else part of the code.
Let's take a look at the example below:
To buy or not to buy? To answer the question we first check if the price is higher than 5000. If ‘price > 5000’ is True, we print that it’s too expensive and set off, looking for something cheaper. But what if the price was less than or equal to 5000? In this case, we check the next condition ‘price > 500’, and again, if it is True, we print out that we can afford that, and if it is False, we go to the else block and print that it's too cheap. So “I can afford it!” will be printed if the price is less than or equal to 5000 but more than 500, and “That’s too cheap” if the price is lower than or equal to 500.
Elif statement differs from else in one key aspect: it represents another specific option while else fits all cases that don't fall into the condition given in the if statement. That's why sometimes you may encounter conditional statements without else:
In this example, it's possible to add an else statement to slightly expand the perspective, but it's not necessary if we are only interested in dogs and cats.
Why elif and not if?
The last example probably made you wonder: why did we use an elif statement instead of just two ifstatements? Wouldn't two if statements be easier?
 In this particular case, the result would be the same as with elif. But this wouldn't work as needed for the first example of this topic:
See? We got two contradicting messages instead of one that we originally intended to output. The difference between the above examples is that in the example with pets, the cases described by conditional statements are mutually exclusive, that is, there's no string that would be equal both to 'dog' and 'cat' at the same time. In the other example, the cases aren't mutually exclusive, and there are values for price that can satisfy both conditions.
So, an elif statement is a better alternative than two if statements when you want to show that only one of the conditions is supposed to be satisfied. A chain of if statements implies that the conditions stated in them are totally unrelated and can be satisfied independently of each other, like in the following example:
With this distinction in mind, you'll be able to make your code more clear and less error-prone. Now, let's get back to studying elif functionality.
Multiple elifs and a decision tree
There can be as many elif statements as you need, so your conditions can be very detailed. No matter how many elif statements you have, the syntax is always the same. The only difference is that we add more elifs:
The code inside the else block is executed only if all conditions before it are False. See the following example:
In this program, the message from the else block is printed for the light of any color except green, yellow and red for which we’ve written special messages.
Conditionals with multiple branches make a decision tree, in which a node is a Boolean expression and branches are marked with either True or False. The branch marked as True leads to the action that has to be executed, and the False branch leads to the next condition. The picture below shows such a decision tree of our example with traffic lights.

Nested elif statements
Elif statements can also be nested, just like if-else statements. We can rewrite our example of traffic lights with nested conditionals:
Summary
In this topic, we familiarized ourselves with elif-statement and learned when it might be helpful, how to use and nest it or make a decision tree with it. Since you have mastered the topic of conditionals, from now on you can make your program do what you want when you want it!
"
51,"Function, arguments and parameters",534,7248,399,https://hyperskill.org/learn/step/7248,"By now, you are on good terms with functions, since you know how to invoke and declare them. Let's deepen your knowledge a bit and discover some new features of functions.
First, a line should be drawn between the terms ""argument"" and ""parameter"". Parameters represent what a function accepts, it's those names that appear in the function definition. Meanwhile, arguments are the values we pass to a function when calling it. We'll cover both arguments and parameters further.
Positional arguments
There are different ways to assign arguments to a function. First of all, you can do it simply by position. In this case, values will associate with parameters in the order in which you passed them into your function from left to right. Such arguments are called positional, or non-keyword.
When we swapped the numbers in the second function call, we got a different result. Thus, you can see that the order determines how arguments are assigned.
Named arguments
Another way to assign arguments is by name. Sometimes you might want to control the order of passed values. That's where named, or keyword, arguments come into play.
The order doesn't matter here since parameters are matched by name. However, keyword arguments are always written after non-keyword arguments when you call a function:
Make sure to mention each parameter once. To understand why this is important, let's think about what happens every time we call a function. In fact, arguments are initialized so that all operations with the values in this function start from scratch. You cannot initialize an argument twice, so if a value has already been passed and associated with some parameter, attempts to assign another value to this name will fail.
As shown in the example, multiple values for the same name cause an error.
Names are important
We have covered the main errors that you can face. Of course, there can be more parameters in a function:
Note that when we use keyword arguments, names are important, not positions. Thus, the following example will work correctly:
However, if we call the function with the same order of names, but without named arguments, then the output will be wrong, with mixed responsibilities:
This way, Python knows the names of the arguments that our function takes. We can ask Python to remind us about them using the built-in help() function.
PEP time
Look at the declared function and function calls shown in this topic one more time: greet(name=""Willy"", surname=""Wonka""). Have you noticed missing spaces around the equality sign? Their absence is not accidental. By PEP 8 convention, you should not put spaces around = when indicating a keyword argument.
Summary
Now that we've discussed some advanced features of functions, let's sum it up:
There's a distinction between parameters and arguments.You can pass arguments to a function by position and by name.The order of declared parameters is important, as well as the order of arguments passed into a function.The help() function can tell you the function arguments by name.
"
52,Operations with list,416,6031,400,https://hyperskill.org/learn/step/6031,"You already know how to create lists (even empty ones), so, no wonder, that you may want to change your lists somehow. There are lots of things to do with a list, you can read about them in the Python Data Structures documentation. In this topic, we will discuss only the basic operations.
Adding one element
The list is a dynamic collection, which means you can add and remove elements. To take a closer look, let's create an empty list of dragons.
What is next? The first thing that comes to mind is, of course, to add new elements to the list.
To add a new element to the end of an existing list, you need to use the list.append(element) method. It takes only a single argument, so this way you can add only one element to the list at a time.
Now you have three dragons, and they are ordered the way you added them:
Adding several elements
There is the list.extend(another_list) operation that adds all the elements from another iterable to the end of a list.
Be careful — if you use list.append(another_list) instead of list.extend(another_list), it adds the entire list as an element:
Alternatively, to merge two lists, you can just add one to another:
If you need a list with repeating elements, you can create a list with the repeating pattern, and then just multiply it by any number. This is particularly useful when you want to create a list of a specific length with the same value:
Removing elements
The opposite of adding elements — deleting them — can be done in three ways. Let's have a look at them.
First, we can use the list.remove(element) operation.
If the element we want to delete occurs several times in the list, only the first instance of that element is removed.
The other two ways remove elements by their indexes rather than the values themselves. The del keyword deletes any kind of objects in Python, so it can be used to remove specific elements in a list:
Finally, there is the list.pop() method. If used without arguments, it removes and returns the last element in the list.
Alternatively, we can specify the index of the element we want to remove and return:
Our discussion of the basic operations with lists has come to an end. If you need more information, check out the Python Data Structures documentation.
Summary
Summing up, in this topic we've learned to:

add an element with append();
add several elements with extend();
remove elements with remove();

We also know now that since the list is a dynamic collection, it can be changed. There is no need to constantly create new lists,  which benefits the memory and performance of your program.
"
53,Default arguments,949,10295,401,https://hyperskill.org/learn/step/10295,"In addition to several ways that you can use to pass arguments into functions, Python also has special syntax for accepting these values from a function call. So, while in earlier topics we have learned how to work with arguments, now we will focus on parameters, the ones with default values in particular, and look into them in more detail.

Defaults
In Python, functions can have parameters with default values. Default parameters are specified in the function definition and contain default values for arguments in case they are not provided with a function call.

Here we have two parameters, place and planet. The first one has no default value, so we should always specify it when calling the function. The second one, in contrast, can be omitted, in which case the function will simply take the default value.

Parameters with default values, such as planet, are optional in some way. You can easily call a function without them and rely on preset values. As in the example above, most of the places we might want to find are most likely on Earth. However, new values can be assigned to them either by name or by position.

When you declare this function, place non-default parameters first and then those with default values. If you try doing the opposite, SyntaxError will crop up:

In this case, you will not be able to use the default value at all. As the second parameter still requires a value, we would always have to write both values in a call, which does not make much sense. So, when you declare a function, pay attention to the order of the parameters.

Mutable objects as defaults
When it comes to mutable objects, things are getting trickier. Let's set a list as a default value and see how it works:

As you can see, the function simply adds a new player to a team. First, we will give both arguments to it:

Everything looks fine. However, when we call it relying on the default value, the function's behavior would differ from what you might have expected:

Instead of two separate lists for teams, surprisingly, you got just one. With every subsequent call, the function will append a new item to this list. Why so? It turns out that default parameter values are evaluated once.

After you have declared a function, a new object for a default value is created. It will be used from this point on. This means that if the function modifies this object in some way, the default value in the mutable will change too. For this reason, you should use mutable default values carefully.

Here is a common workaround to fix the function from our earlier example:

Setting the default value to None and explicitly reassigning the value of the team parameter allows you to create a new list each time this function is called.

PEP time
Look at the declared functions shown in this topic one more time, for example, def locate(place, planet=""Earth""): .... Have you noticed missing spaces around the equals sign? Their absence is not accidental. By PEP 8 convention, you should not put spaces around = when indicating a keyword argument. This holds true for parameters with default values.

Summary
Let's go over the main points we have discussed:
Python Functions can be quite flexible, you can use them passing fewer arguments in a call (thanks to default values).You should pay close attention to the order of parameters when you declare functions. Place non-default parameters first and those with default values afterward.Mutable defaults may work contrary to your intentions, as their values are created once at the runtime. If so, a common way to avoid trouble is by using None by default and changing the parameter's value in the function's body.
"
54,Tuple,564,7462,403,https://hyperskill.org/learn/step/7462,"By now, you definitely know how to handle a list, the most popular collection in Python. Now let's discover an equally useful data type — tuples. You should remember that they are almost identical to lists. What sets them apart is their immutability.
Define a tuple
Since tuples cannot be changed, tuple creation is similar to opening a box of a fixed size, then putting several values into this box and sealing it. Once the box has been sealed, you cannot modify its size or content.
Use a pair of parentheses to define a tuple:
Empty tuples are easy to create. Then what went wrong in the following example?
As you can see, the variable we created stores a string. It's actually a comma that makes a tuple, not parentheses. Let's fix this piece of code:
So, always use a comma when defining a singleton tuple. In fact, even if your tuple contains more than one element, separating items with commas will be enough:
The built-in function tuple() turns strings, lists and other iterables into a tuple. With this function, you can create an empty tuple as well.

What can we do with tuples?
First, let's examine what characteristics lists and tuples have in common.
Both lists and tuples are ordered, that is, when passing elements to these containers, you can expect that their order will remain the same. Tuples are also indifferent to the nature of data stored in them, so you can duplicate values or mix different data types:
Just like lists, tuples support indexing. Be careful with indexes though, if you want to get along without IndexErrors.
And here the first distinctive feature of tuples comes into play. What they don't support is item assignment. While you can change an element in a list referring to this element by its index, it's not the case for tuples:
In the example above, we tried to update the tuple and it didn't end well. You can't add an item to a tuple or remove it from there (unless you delete the entire tuple). However, immutability has a positive side. We'll discuss it in the next section.
Immutability and its advantages
By this time, one question might have come to your mind: why use tuples when we have lists? Predictably, all answers conduce to immutability. Let's dwell on its upsides:

Tuples are faster and more memory-efficient than lists. Whenever you need to work with large amounts of data, you should give it a thought. If you are not going to modify your data, perhaps you should decide on tuples.
A tuple can be used as a dictionary key, whereas lists as keys will result in TypeError.
Last but not least, it's impossible to change by accident the data stored in a tuple. It may prove a safe and robust solution to some tasks.

Summary
Those were the very basics of tuples in Python. Just like lists, tuples are ordered and iterable. Unlike lists, they are immutable. You'll learn more of tuple features in the next topics, now it's time to write your first programs with them!
"
55,Args,685,8560,404,https://hyperskill.org/learn/step/8560,"Functions have a flexible syntax in Python. We will find out what allows functions to accept a varying number of arguments and how to unpack iterable objects when calling a function.
Multiple positional arguments
You might be surprised by the fact that everything we've done before with functions limited us in some way. For example, if we don't specify the defaults for arguments, we will always have to pass the exact number of values into such a function. However, sometimes it's more convenient when the number of arguments varies. For example, if you are declaring a function that should find the sum of all values passed into it, you never know how many arguments a user might want to use. Let's start with a simple case and define a function with two parameters. It can be done as follows:
This function makes us pass only two values, we can't just do add(1, 2, 3). Well, what we can do is to set a default value for the third parameter and then call this function with either two or three values. But this hardly solves the problem for more complex cases.
If you are not sure about the number of arguments that your function might take, or if you don't want to limit them, use the following syntax to define a function with *args:
This allows you to work with the variable args, which is a tuple of remaining positional arguments. Its length may vary:
The function add() now requires two arguments, but if you pass additional values they will be collected in a tuple and get added to the total.
As you might have guessed, args is short for ""arguments"". You don't have to use this conventional name all the time, though:
The output for this function call will be as follows:
Will Daenerys Targaryen survive?
Will Arya Stark survive?
Will Brienne of Tarth survive?
This works for any variable name as long as there is a single asterisk * right before it.
Normally, *args comes after specific parameters:
Once all required arguments have been passed, the remaining values are packed into the tuple.
The parameters that come after *args are keyword-only. It means that they can only be used as keywords rather than positional arguments.
Unpacking in function calls
The Python syntax enables us to pass all items from a sequence as individual positional arguments using *. A single asterisk operator unpacks an iterable. Let's invoke the print() function and see how it works:
This code will be equivalent to a call where elements are listed one by one: print(""f"", ""u"", ""n"") and print(5, 10, 15) respectively. Unpacking just takes less of your time.
Combined with *args in our slightly modified function add(), unpacking takes away the concern for the number of values both in the function's body and upcoming calls.
This is a really powerful feature, as it allows you to conveniently handle an arbitrary number of values in your function.
Summary
Let's sum up what we discussed in the topic:

A function with *args can accept a changing number of positional arguments.
The variable name args is arbitrary, you can always choose another one.
*args provides access to a tuple of remaining values.
The order of parameters in the function definition is important, as well as the order of passed arguments.
In function calls, you can use the unpacking operator  * for iterable objects.
"
56,Quotes and multi-line strings,393,5814,433,https://hyperskill.org/learn/step/5814,"You are already familiar with strings, which are extremely common and useful in programming. Let's take a look at some features of Python strings related to quotes and multi-line strings.

Quotes
As you know, a string literal is surrounded by a pair of single or double quotes. There is basically no difference between the two, but there are some common conventions concerning their use:

Use double quotes if your string contains single quotes, for example, ""You're doing great!"".
Use single quotes if your string contains double quotes, for example, 'Have you read ""Hamlet""?'.
Do not mix two styles in one literal! For example, something like ""string!' is not correct.
Most importantly, be consistent in your use!

There is a way to include any quotes in your string, regardless of the style of the outer quotes, and that is to use the backslash symbol (\) before the quotes inside of the string. The backslash will basically tell Python that the quote symbol that follows it is a part of the string rather than its end or beginning. It is called escaping, and you'll learn about it in detail in the next topics.
In the examples below, both ways of writing strings are correct and will produce the same result:

However, it's considered best practice to avoid backslashes inside the strings – even though it works. You'll learn more about the style conventions in following topics.
Multiline strings
Strings can represent a long text, a single character, or even no characters, like in the case of an empty string. One thing has so far been true about all of them: all our strings were single line, no matter how long they were. However, you can also write multi-line strings in Python! To do that, you need to use triple quotes on each side of the string literal. Again, the choice of single or double quotes is up to you as both work fine in Python.
Multi-line string in double quotes:

Multi-line string in single quotes:

Both examples print the same result:
This
is
a
multi-line
string
Summary
In this topic, we've covered some basic information about using quotes in strings and saw how to write multi-line strings. This is by far not all you can do with strings in Python: there is a lot more to learn and, very importantly, to practice!
"
57,String formatting,417,6037,434,https://hyperskill.org/learn/step/6037,"Sometimes, you might need to insert variable values into text. Python has a helpful feature known as string formatting to assist with this. Let's look at what it is and how it helps.

Imagine you need to print a welcome message:

Hi, my name is , I am years old!

Your immediate thought might be to use string concatenation like this:

This strategy works, but it's not perfect. To address such tasks, Python offers you three methods of string formatting.

The % operator

This built-in operator comes from C-language. Let's use it for our welcome message:

You see how we created placeholders for the string name (%s) and for the integer age (%i) then substituted the variables into the string using the % operator.

With the % character, we can also control the number of decimal places, for example, reduce their number to 3 or 2:

However, this approach is quite old-fashioned and we do not encourage you to write code like this; in the past, it needed certainty in specifiers, length modifiers, and conversion types. The vast number of extra operators often caused common errors. That's why more user-friendly operators were introduced.

str.format()

One of them is the built-in str.format() method. Let's see how it can help us deliver the same welcome message:

The curly braces in the string are placeholders where the format method inserts the corresponding variables. Notice how we used the age variable as it is, without converting it to str.

With empty placeholders, variables were substituted in the same order they were passed to the format() method. But, we can change the order and the number of occurrences by specifying the corresponding position inside curly braces:

Remember, if you passed more variables to the format() method than needed, the extra ones would be ignored. On the other hand, if you provided fewer variables, you would get an IndexError.

The format() method is very flexible, letting you use keywords inside placeholders, like this:

This improves your code readability. You can also arrange the keywords in any order, and place them after positional arguments:

Formatted string literals

Another method to format strings in Python is f-strings. To create one, you need to put an 'f' before the string. Look at our welcome message from earlier:

As you see, f-strings let you use the format() method's functionality, but the code turns out to be shorter and cleaner.

You can also round decimals with f-strings by specifying the number of decimal places like this:

Conclusion

What are the key points to remember from this topic? Here are two essential takeaways:

The str.format() method lets you customize string formatting;
Formatted string literals, or f-strings, excel in being brief and clear.

Read more on this topic in Working with Python Strings on Hyperskill Blog.
"
58,Class,488,6661,435,https://hyperskill.org/learn/step/6661,"As you already know, object-oriented programming (OOP) is a programming paradigm that is based on the concept of objects. Objects interact with each other and that is how the program functions. Objects have states and behaviors. Many objects can have similar characteristics and if you need to work with them in your program it may be easier to create a class for similar objects. Classes represent the common structure of similar objects: their data and their behavior.

Declaring classes
Classes are declared with the keyword class and the name of the class:

Generally, a class name starts with a capital letter and it is usually a noun or a noun phrase. The names of the classes follow the CapWords convention: meaning that if it's a phrase, all words in the phrase are capitalized and written without underscores between them.

Classes allow you to define the data and the behaviors of similar objects. The behavior is described by methods. A method is similar to a function in that it is a block of code that has a name and performs a certain action. Methods, however, are not independent since they are defined within a class. Data within classes are stored in the attributes (variables) and there are two kinds of them: class attributes and instance attributes. The difference between those two will be explained below.

Class attribute
A class attribute is an attribute shared by all instances of the class. Let's consider the class Book as an example:

This class has a string variable material with the value ""paper"", a string variable cover with the value ""paperback"" and an empty list as an attribute all_books. All those variables are class attributes and they can be accessed using the dot notation with the name of the class:

Class attributes are defined within the class but outside of any methods. Their value is the same for all instances of that class so you could consider them as the sort of ""default"" values for all objects.
As for the instance variables, they store the data unique to each object of the class. They are defined within the class methods, notably, within the __init__ method. In this topic, we'll deal with the class attributes, but don't worry – you'll have plenty of time to learn more about instance attributes.

Class instance
Now, let's create an instance of a Book class. For that we would need to execute this code:

Here we not only created an instance of a Book class but also assigned it to the variable my_book. The syntax of instantiating a class object resembles a function call: after the class name, we write parentheses.
Our my_book object has access to the contents of the class Book: its attributes and methods.

Conclusion
Well, those were the very basics of classes in Python. Classes represent the common structure of similar objects, their attributes, and their methods. There are class attributes and instance attributes. Class attributes are common to all instances of the class.
All in all, classes are an extremely useful tool that can help you optimize your code and organize the program in a logical and readable way. We hope you'll make use of them!
"
59,Class instances,489,6669,436,https://hyperskill.org/learn/step/6669,"By now, you already know what classes are and how they're created and used in Python. Now let's get into the details about class instances.
A class instance is an object of the class. If, for example, there was a class River, we could create such instances as Volga, Seine, and Nile. They would all have the same structure and share all class attributes defined within the class River.
However, initially, all instances of the class would be identical to one another. Most of the time that is not what we want. To customize the initial state of an instance, the __init__ method is used.
The __init__ method is a constructor. Constructors are a concept from the object-oriented programming. A class can have one and only one constructor. If __init__ is defined within a class, it is automatically invoked when we create a new class instance. Take our class River as an example:

We created three instances (or objects) of the class River: volga, seine, and nile. Since we defined name and length parameters for the __init__, they must be explicitly passed when creating new instances. So something like volga = River() would cause an error. Look at this visualization of the code to see how it works almost in real-time!
The __init__ method specifies what attributes we want the instances of our class to have from the very beginning. In our example, they are name and length.
self
You may have noticed that our __init__ method had another argument besides name and length: self. The self argument represents a particular instance of the class and allows us to access its attributes and methods. In the example with __init__, we basically create attributes for the particular instance and assign the values of method arguments to them. It is important to use the self parameter inside the method if we want to save the values of the instance for later use.
Most of the time we also need to write the self parameter in other methods because when the method is called the first argument that is passed to the method is the object itself. Let's add a method to our River class and see how it works. The syntax of the methods is not of importance at the moment, just pay attention to the use of the self:

Now if we call this method with the objects we've created we will get this:

As you can see, for each object the get_info() method printed its particular values and that was possible because we used the self keyword in the method.
Note that when we actually call an object's method we don't write the self argument in the brackets. The self parameter (that represents a particular instance of the class) is passed to the instance method implicitly when it is called. So there are actually two ways to call an instance method: self.method() or class.method(self). In our example it would look like this:

Instance attributes
Classes in Python have two types of attributes: class attributes and instance attributes. You should already know what class attributes are, so here we'll focus on the instance attributes instead. Instance attributes are defined within methods and they store instance-specific information.
In the class River, the attributes name and length are instance attributes since they are defined within a method (__init__) and have self before them. Usually, instance attributes are created within the __init__ method since it's the constructor, but you can define instance attributes in other methods as well. However, it's not recommended so we advise you to stick to the __init__.
Instance attributes are available only from the scope of the object which is why this code will produce a mistake:

Instance attributes, naturally, are used to distinguish objects: their values are different for different instances.

So when deciding which attributes to choose in your program, you should first decide whether you want it to store values unique to each object of the class or, on the contrary, the ones shared by all instances.
Summary
In this topic, you've learned about class instances.
If classes are an abstraction, a template for similar objects, a class instance is a sort of example of that class, a particular object that follows the structure outlined in the class. In your program, you can create as many objects of your class as you need.
To create objects with different initial states, classes have a constructor __init__ that allows us to define necessary parameters. Reference to a particular instance within methods is done through the self keyword. Within the __init__ method, we define instance attributes that are different for all instances.
Most of the time, we'll deal in our programs not with classes as such but rather with their instances, so knowing how to create them and work with them is very important!
"
60,Methods,508,6931,437,https://hyperskill.org/learn/step/6931,"If attributes define the data that the objects of a particular class have, the methods define their behavior. Python has several types of methods that you can create within a class but, in this topic, we will focus on the instance methods.

Method syntax

Methods define the functionality of the objects that belong to the particular class. The basic syntax looks like this:

You can see that declaring a method resembles declaring a function: we have the keyword def followed by the name of the method. The parameters of the method are written inside the parentheses.

The first parameter of the method should always be self. You may remember that self represents the particular instance of the class. When it comes to instance methods, the first parameter that is passed to the method is the instance that called it. Let's create an instance of MyClass and see how this works:

In this example, the my_object instance is passed implicitly so we do not write the parameter in the code. We can, however, pass the instance explicitly:

These examples clearly illustrate why self has to be the first argument of the instance methods. If you want your method to have other parameters, just write them after the self keyword!

Methods vs functions

Though they are quite similar, Python does make a distinction between methods and functions. To quote the official documentation, ""a method is a function that 'belongs to' an object."" Since we're interested in OOP, we'll specifically be looking at methods associated with class instances.

Let's consider an example:

What is of interest to us here is the method .sail() of the class Ship() and the function sail_function(). Let's call them:

The way that we've defined them, both our method and our function produce the same results but in different ways. A method is connected to an object of the class; it is not independent the way a function is. Sure, they are both called by their names, but to call a method, we need to invoke the object to which this method belongs.

Return

So far, the method hasn't returned any values since we only used the print() function. Obviously, just as with functions, we can define what type of data the method can return with the return statement. For example, let's create a method that calculates how many kilograms of cargo the ship has (initially, the weight of the cargo is given in tonnes):

The method is simple: it converts the tonnes into kilograms (by multiplying it by 1000) and then returns the calculated value. If we were to call it, we wouldn't get any messages unless we explicitly printed the result of the function:

Since we haven't changed the default value of the cargo attribute, the method would return 0 multiplied by 1000, which is also 0.

Conclusion

Methods within classes specify the behavior of a class or its objects. They are similar to functions with the exception that they are strongly connected to the class and cannot be called independently from it or its instances.

The first parameter of instance methods is the keyword self that represents the particular instance of the class. That particular instance of the class is the first argument that is passed to the method. Methods can return values or simply print messages (i.e. return nothing).

Methods allow you to add any functionality to your classes. This is how you can manipulate your objects and create complex programs, so we encourage you to explore methods in your projects!
"
61,Methods and attributes,511,6981,438,https://hyperskill.org/learn/step/6981,"Now that you've learned how to create instance methods let's go even further and learn to use the methods for creating and modifying attributes.

Creating attributes with methods
Instance attributes are the ones defined within methods so by definition we can create new attributes inside our custom methods. Let's take the class Ship as an example.

Every ship needs a captain so let's define a method called name_captain for those purposes:

When called for the first time, the name_captain method creates a new attribute called captain and prints the corresponding message. When used next, it just changes the value of the self.captain attribute (and prints the message as well).
To see how it would work, let's create the ship ""Black Pearl"":

If we tried to print the value of the captain attribute now, we would get an error:

This is because this attribute is only created within the name_captain method. If we call it, we will be able to access the attribute captain:

Note that only those instances that have called this method will have the captain attribute. It's an important thing to remember! You may get an error if you try to use the attribute and the method hasn't been called yet.
To avoid these problems, it is recommended to define all possible attributes in the __init__. This can not only help you avoid AttributeError, but also gives a good understanding of the class and its objects from the get-go. If you do want to create the value for the attribute in a special instance method, then list it in the __init__ as None:

Then, in the specific method, you simply modify the default value which is what we'll consider in the next section.

Modifying attributes with methods
Methods can also be used to modify the instance attributes. Take the methods load_cargo and unload_cargo for example:

Both these methods are supposed to change the value of the attribute cargo if those changes are possible. The load_cargo method first checks that the loading of a particular weight will not exceed the capacity of the ship and the unload_cargo checks that the unloading will not make the weight of the cargo negative. Then they both make the changes or print a message that those changes are impossible.

If we wanted to print out the value of cargo after all these manipulations, we would see that it would equal 200 (tons). Because of the restrictions that we placed, only the first callings of load_cargo and unload_cargo made changes to the attribute cargo.
So far our methods haven't been returning any values since we only used the print() function, but we can make our methods return any type of value that we want. For example, let's create a method that calculates how much more cargo our ship can load.

If we were to call this method on our Black Pearl we wouldn't get any messages, because the method doesn't print anything. But instead, we could use the value it returns in our further calculations. We could, for instance, rewrite the load_cargo method by using thefree_space method:

In this example, we called a method inside another method and used the values in our calculations. Again, we used self to make sure that we only deal with the particular instance of the class Ship and that all calculations concern this instance.
Summary
In this topic, we focused on more advanced uses of instance methods in Python.
Methods can be used for creating new attributes and modifying existing ones. You can call methods inside other methods, use the results for calculations or just output messages. Knowing how methods and attributes interact can help you expand the functionality of your classes and make your programs very efficient.
We hope that you'll experiment with instance methods and use them in your projects!
"
62,Magic methods,530,7139,439,https://hyperskill.org/learn/step/7139,"There are different ways to enrich the functionality of your classes in Python. One of them is creating custom methods which you've already learned about. Another way, the one that we'll cover in this topic, is using ""magic"" methods.
What are ""magic"" methods?
Magic methods are special methods that make using your objects much easier. They are recognizable in the code of the class definitions because they are enclosed in double underscores: for example, __init__ is one of those ""magic"" methods in Python. Since they are characterized by double underscores they are often called dunders. 
Dunders are not meant to be invoked directly by you or the user of your class, it happens internally on a certain action. For example, we do not explicitly call the __init__ method when we create a new object of the class, but instead, this method is invoked internally. All we need to do is to define the method inside the class in a way that makes sense for our project.
There are many different dunders that you can use, but in this topic, we will focus on the most helpful ones.
__new__ vs __init__
So far we've been calling __init__ the constructor of the class, but in reality, it is its initializer. New objects of the class are in fact created by the __new__ method that in its turn calls the __init__ method. 
The first argument of the __new__ method is cls. It represents the class itself, similar to how self represents an instance of the class. This also makes __new__ a different kind of method since it doesn't require an instance of the class. This makes sense since it is supposed to create those instances. The method returns a new instance of the class which is then passed to the __init__ method.
Usually, there is no need to define a special __new__ method, but it can be useful if we want to return instances of other classes or restrict the number of objects in our class. 
Imagine, for example, that we want to create a class Sun and make sure that we create only one object of this class. We would need to define a class variable that would track the number of instances in the class and forbid the creation of new ones if the limit has been reached.
The code above may be a bit unexpected so let's analyze it. We first check that the class variable n has a value of zero. If it does, it means that no instances of the class have been created and we can do that. We then update the class variable and call __new__ method of object class which allows us to create a new instance.
If we now try to create 2 objects of this class we will not succeed:

__str__ vs __repr__
Printing out information and data is very important when programming. You can print the results of calculations for yourself or the user of your program, find the mistakes in the code or print out messages.
For example, let's consider the class Transaction: 
If we create a transaction and try to print it out we will not get what we want:
Instead of the values that we would like to see, we get information about the object itself. This can be altered if we deal with __str__ or __repr__ methods.
As the names suggest, __str__ defines the behavior of the str() function and __repr__ defines the repr() function. A general rule with the __str__ and __repr__ methods is that the output of the __str__ should be highly readable and the output of the __repr__ should be unambiguous. In other words, __str__ creates a representation for users and __repr__ creates a representation for developers and debuggers. If possible, __repr__ should return Python code that could be used to create this object or, at least, a comprehensive description.

Both __repr__ and __str__ should return a string object!

A good rule is to always define the __repr__ method first since it is the method used by developers in debugging. It is also a fallback method for __str__which means that if the __str__ method isn't defined, in the situations where it's needed, the __repr__ will be called instead. This is, for example, the case with print().
In our example here, let's create the __repr__ method that would create an unambiguous representation of the transaction and all its attributes.
Now if we try to print any transaction we will get a standard readable string:
You can see that we've called print and got the representation from __repr__. Now let's add __str__ and see if things change.
Now that we have __str__, when we call print, we get the representation defined there. To see the ""official"" representation we need to directly call the repr function.
Read more on this topic in Exploring Python Magic Method Operators on Hyperskill Blog.
Summary
Magic methods are said to add ""magic"" to your classes and that is somewhat true. Dunders really make working with classes much easier and far more efficient. 
In this topic, we've covered only a couple of these magic methods. We highly encourage you to look them up (for example, in ""A Guide to Python's Magic Methods"" by Rafe Kettler) and try them out in your projects. As for the magic methods for arithmetics and comparisons, we'll look into them in another topic!
"
63,While loop,409,5940,440,https://hyperskill.org/learn/step/5940,"Sometimes one iteration (=execution) of a statement is not enough to get the result you need. That is why Python offers a special statement that will execute a block of code several times. Meet the loop command and one of the universal loops — the while loop.
People generally don't choose Python to write fast code. The main advantages of Python are readability and simplicity. As the while loop requires the introduction of extra variables, iteration takes up more time. Thus, the while loop is quite slow and not that popular. It resembles a conditional operator: using the while loop, we can execute a set of statements as long as the condition is true.
The condition itself (2) is written before the body of the loop (some call it the conditional code) and is checked before the body is executed. If the condition is true (3a), the iterations continue. If the condition is false (3b), the loop execution is terminated and the program control moves further to the next operation.

Visualization
The variable number plays here the role of a counter – a variable that changes its value after each iteration. In this case, the iterations continue until the number is equal to 5 (note that the program outputs the value of the number before increasing it). When the value of a counter reaches 5, the program control moves to the next operation and prints the message. Here you can see the output of this code:

The infinite loop
If you delete a part of the conditional code where you increase the value of a counter, you will bump into the infinite loop. What does it mean? Since you don’t increase your variable, a condition never becomes false and can work forever. Usually, it is a logical fallacy, and you'll have to stop the loop using special statements or finishing the loop manually.
Sometimes the infinite loop can be useful, e.g. in querying a client when the loop works continuously to provide the constant exchange of information with a user. You can implement it by writing True as a condition after the while header.

Conclusion
Now you are familiar with the while loop and its usage. Don’t forget about the role of a counter, otherwise, you’ll have to deal with the infinite loop. After you’ve written the code, try to ""run"" it as if you were a Python program. That’ll help you understand how the loop works.
Programming is all about simplification, so the code should be readable, short, and clear. Don’t forget about comments and syntax. In the beginning, it may seem that the while loop is not that easy to implement, but after a couple of times, you’ll see that it’s a very useful tool.
"
64,"Loop control: break, continue, pass",453,6302,441,https://hyperskill.org/learn/step/6302,"Loop control statements are nested inside loops and designed to change their typical behavior. In this topic, we'll find out how they work and what they are used for.

Break
The break statement is used to terminate a loop of any type (i. e. for and while loops). It may be said that break ""jumps out"" of the loop where it was placed. Let’s examine a tiny example:

We wanted to stop the loop before it iterated for the last time. For that purpose, we introduced a condition when the loop should be stopped. The output is as follows:

Be careful where you put print(). If you put it at the loop’s end, the output will return only the first value – ‘dog’. This happens because break exits from the loop immediately.

Often enough, break is used to stop endless while loops like this one:

Let's consider how break works in for...else or while...else statements. else statements will be executed if no break is encountered during the execution of the loop. Look how it works in the examples below!

In this case, the body of the else statement is executed because no break was met. Let's change the number list.

break was met, so the print() command after else wasn't executed.

Continue
The continue operator is commonly used, too. You can stop the iteration if your condition is true and return to the beginning of the loop (that is, jump to the loop's top and continue execution with the next value). Look at the following example:

The output will contain all values except the first one ('dog') since it fulfills the condition:

Thus, the loop just skips one value and goes on running.

One nuance is worth mentioning: the continue operator should be used moderately. Sometimes you can shorten the code by simply using an if statement with the reversed condition:

In this case, the output will remain the same:

Pass
When no action is required (e.g. some condition is met, you need to take it into account in a loop, but do nothing if that's the case), in Python, you can use pass statement which does exactly what you need – nothing. Here the program is just waiting to be manually interrupted:

Summary
To sum up, loop control statements represent a useful tool to alter the way a loop works. You can introduce extra conditions using the break, continue, and pass operators. In addition, they allow you to skip a beforehand selected set of values, terminate an endless loop, or even do nothing. Use them wisely and they'll work wonders.
"
65,"Synchronous, asynchronous, parallel",800,9332,442,https://hyperskill.org/learn/step/9332,"When we are considering some complex process, let's call it workflow, various parts of it may run differently. Sometimes actions go one by one, sometimes they go in random order overlapping each other, and sometimes things go simultaneously and in parallel. The workflow can evolve differently. There are three sorts of workflow executions sequence: synchronous, asynchronous, and parallel.

Many terms related to computer program processing are not just technical ones. They describe a wide variety of real-world phenomena. In some sense, the processes taking place inside a computer are not that different from those in real life. Moreover, on some level of abstraction, they are practically identical. So, let's try to use them and explore their base concepts using real-life examples.

An appropriate example of a complex process is customer service. Let's use it to study some basic types of workflow from the point of view of the sequence of execution.

Synchronous workflow

There are many models to manage customer flows. The simplest approach is one shop with one seller. The seller deals with each client from the beginning to the end of each sale and performs all the roles from storekeeper to cashier.

When there are many customers at the same time, this approach is very far from perfect as the seller can deal only with one client per time, while others have to wait in line. They serve each client separately one by one which means starting to serve the next client only after finishing with the current. We name this type of action a synchronous one.

Synchronous workflows are very common. Most of the activities should go synchronously if their goal is to achieve some specific results. The number of examples is enormous. Scenes in a movie plot, car assembling, words in a sentence, cooking, you name it.

Asynchronous workflow

Let's imagine our old shop becomes fancier, this is a pizza shop now. After the first client has ordered their pizza, they need to wait for it to be cooked. At this point, the seller leaves the first customer alone for a while, and now the second one can make their order, then the third, and so on.

When the first client's pizza is ready, the seller returns to them to complete the sale. That's how this story will repeat again and again.

Our old friend seller can serve several customers simultaneously in overlapping periods. We call such behavior asynchronous.

Operations of this kind often emerge when there is a need for waiting. Imagine you are reading on an aircraft while flying, or you do the dishes while something is cooking; those pairs of activities are asynchronous.

Parallel processing

As the pizza shop sales are growing, now one worker is not enough for the whole business. So, we should hire several. If each seller has a separate compact oven for preparing exactly one pizza at a time, then we can divide the queue of buyers among the sellers.

Now each of them works independently, and this is a case of parallel processing. Each task in parallel processing is running in a continuous period as a whole unit process. Parallel execution is possible only if there is more than one executor. Cashiers in a supermarket are an example of parallel processing in everyday life, as well as highways.

Conclusion

So, there are three types of workflow processing. The first is synchronous, the second is asynchronous, and the third is parallel.

Synchronous: one task at a time, the next starts when the current is done.

Asynchronous: multiple tasks at the same time in overlapping periods, executed by little parts.

Parallel: multiple or one task split into parts, being executed continuously by different executors in parallel.
"
66,Processes and threads,812,9420,444,https://hyperskill.org/learn/step/9420,"Imagine that you come to a food court during lunchtime, and you see a line of pizza shops there. Each shop's mission is to sell pizza and each of them has several workers to accomplish this. So, each worker's purpose is to sell pizza, but they can't sell it by themselves without the equipment provided by the shop. Likewise, any pizza shop can't sell anything without its workers. That is, there has to be at least one worker in a pizza shop to do the job. Meaning, the workers rely on the shop's equipment to do their jobs, just as the shop depends on these workers to function.

It's similar to how a computer runs applications and manages multitasking and parallel execution. To delve deeper and understand it better, let's explore the concepts such as processes and threads, drawing parallels between these computer science concepts and the dynamics of a pizza shop.

Process

A process is a self-contained unit of execution that includes everything necessary to complete its tasks. In short, a process is the container for its threads, encompassing all necessities for their operation and their shared resources. It's cheaper to arrange access to shared resources once than to do so each time a new thread is spawned. Every process must have at least one thread, as they perform all the work. There is no such thing as a thread without its process or a process without at least one thread.

If we look at the pizza business, a single pizza shop would serve as an analogy for the process. It provides all the environment and equipment required for a worker to perform their job. Equipment is expensive, so it's cheaper and more efficient when workers share it. There is no need for each worker to acquire personal equipment. On the other hand, a shop cannot function without its workers; it is crucial to have at least one worker, as, without them, all the equipment would remain idle. Together, these elements constitute the process of making and selling pizza.

Thread

In computer science, a thread of execution is a sequence of instructions within a process that can be scheduled and run independently. Each thread has its own executor, which can manage only one thread at a time. Multiple threads within the same process can operate concurrently (switching between tasks) or in parallel (simultaneously, if multiple executors are available), depending on how they are scheduled and the resources available.

To understand what the term thread means, think of employees in a pizza shop. They perform various tasks according to their job descriptions, following the rules set by the shop and utilizing shared resources provided by the shop.

In this analogy, workers in a pizza shop represent thread executors, and the tasks they perform are the threads within the pizza shop ""process"".

Concurrency and parallelism

Concurrency and parallelism are key concepts in computing that describe different methods for handling multiple tasks efficiently.

Concurrency: Imagine a chef in a kitchen preparing two dishes simultaneously. The chef starts by chopping vegetables for a salad, then while those vegetables are chilling, begins grilling chicken for another dish. The chef isn't working on both dishes at the exact same moment but switches between tasks, advancing both dishes without completing one before starting the other. This is concurrency, which involves managing multiple tasks by alternating between them to maximize efficiency.

Parallelism: Now picture a large kitchen where two chefs are working at the same time, one grilling chicken and the other preparing a salad. Each chef works independently on their dish, and both dishes are being prepared at the same time. This scenario exemplifies parallelism, where multiple tasks are truly happening simultaneously, each handled by separate resources.

This should help clarify the distinction between concurrency, which involves switching between tasks to give the appearance of simultaneous progress; and parallelism, where tasks genuinely occur at the same time, utilizing multiple resources. Both concepts aim to optimize the execution time and resource utilization in multitasking environments, but they achieve this in different ways. Concurrency is about dealing with many tasks through quick switching, while parallelism is about doing many tasks exactly at the same time.

Internal or lightweight concurrency

In some cases, workers (threads) can perform multiple roles within the same pizza shop (process). For instance, a worker might serve as both a cashier and a cook at different times. This kind of concurrency isn't about multiple workers doing tasks simultaneously, but about a single worker switching between roles efficiently. These roles typically involve tasks that are quick and do not demand significant time or shared resources, classifying them as lightweight.

If tasks are lightweight and require minimal shared resources except the executor's time and attention, there is no need to run them in separate threads. It is more efficient to manage their concurrent execution through time-slicing within a single thread, where the executor switches between tasks quickly enough that they appear to be happening simultaneously. This form of concurrency is often referred to as internal or lightweight due to the minimal nature of the tasks involved.

Conclusion

Processes are like pizza shops. They serve as containers for worker's threads, shared resources, and parameters necessary for completing tasks. Every process must have at least one thread.

Threads are independent units of execution within a process; they can operate concurrently or in parallel with one another.

Concurrent tasks that compete only for the executor's time and don't require a lot of resources can run concurrently within the same thread. These tasks are called lightweight, and this type of concurrency is known as internal or lightweight concurrency. This is more resource-efficient than creating new threads for each task. Execution within threads can be synchronous or asynchronous but never parallel.

By understanding these concepts through the pizza shop analogy, you can better grasp how processes and threads work together in computer systems.
"
67,Files,512,13025,488,https://hyperskill.org/learn/step/13025,"Introduction
Data is stored on disks under certain addresses. For a computer, such addresses are numbers. It uses them to find the corresponding information. However, humans are not that good at memorizing sets of numbers. It's much easier for us to name our data, for example, family photo, November report, and so on. Therefore, the concept of a file was invented: in a file, one can store some information under a user-friendly name. Let's take a closer look at what files are.

What is a file
A file is associated with a piece of data. However, there are some restrictions on naming a file. For example, filenames must contain only those characters that are supported by a specific file system. There are different types of contents of the files: text, photo, music, video, etc. The type of information stored in a file defines the file format. In order for the computer to be able to distinguish what format a certain file has, file extensions were invented.

File extensions
Finding out the format of a file right away is pretty useful. One way to do it involves filename extensions. The end of a filename informs users or programs about the file format. The file format designation usually goes after a period, so you get a name ending with ""."". As for more specific examples, here are some of the most common extensions: text files will have the .txt extension, for example, november_report.txt; files with photos may have the .jpg extension, like my_photo.jpg; for videos, the most usual is the .mp4 extension and for music files, it is .mp3. Operating systems use filename extensions to remember which program to use to open files with a certain extension. Filename extensions aren’t strictly necessary, though: they just eliminate the need to guess the format of a file.

Now you know that a file extension is the service information used by a computer. Let's find out what other information a file has that helps computers understand what properties it has. This information is called file metadata.

File metadata
Metadata stands for ""data about data"". One of the most common pieces of such data is the filename as we've discussed above. Other examples are the file size, creation time, the last access time, etc.

Also, metadata consists of file attributes. Each attribute has two possible states: set (toggled on) or cleared (toggled off). File attributes tell the file system or operating system if a file should get some special treatment. For example, if a file has a read-only attribute set, its contents can be read, but all attempts to modify them will be prevented by the file system until this attribute gets cleared. If a file has a hidden attribute set, it won’t show up in a graphical user interface unless the user explicitly tells the operating system to show all hidden files. Attributes can also be used to restrict file access to specific groups of users.

Absolute and relative paths
In order to find a file, we need to know the path to it. The path is a character set indicating the location of a file in the system. The file path can be seen in the file manager (Explorer in Windows). There are two types of paths: an absolute or a relative path.

A path to a file that starts with a root directory is called an absolute path and serves as the file’s unique identifier. If you try to create another file named ""my_file"" in the same subdirectory, the file system won’t allow you to do that. If both files have the same identifier, how will the system tell them apart? Creating a file named ""my_file"" in the root directory, however, would be okay: ""root_directory/sub_directory/my_file"" and ""root_directory/my_file"" are different identifiers.

There is a catch with absolute paths though. When you write a program that will be installed on different computers, you know your own program’s directory, but you don’t know where other users of this program will install it. Your program’s directory can end up in any parent directory on a user’s computer, so you can't use an absolute path in your program to point to its directory.

This is where relative paths come into play. Each process that runs on a computer is associated with a working directory on this computer; it is tracked and managed by the operating system. This basically means that the operating systems of other users will be focused on your program’s directory when they run it. Your program can address the working directory by using a special character . instead of the directory’s actual name, so you can use a path like ""./my_file"" without specifying the whole path from a root. You just let the user’s operating system figure it out! You can also use .. to address a parent directory of the working directory.

Summary
To sum up, in this topic you've learned that

information on computers is stored in files
the files are named in accordance with the system's instructions
depending on the type of data in the file, the file will have a specific extension so that the computer can distinguish one format from another
the detailed information about a file is called the file metadata
to find the file you need to look at its path in the file explorer
a path can be absolute or relative
"
68,os module,1047,11119,491,https://hyperskill.org/learn/step/11119,"Sometimes, you may need to interact with the current operating system and access its features when working on your programs. You may need to know whether it would be easy to run it on other systems. If you need to get the list of files and folders in the current working directory, you may know that there are different commands for this on Linux/macOS and Windows.
It is useful to have the tools that would work on any OS so that you wouldn't need to handle all possible outcomes manually. Python provides a built-in module: os for working with files and directories.
You can access os by loading the module as:
In the topic, we will discuss the basics of os module.
Current working directory
Suppose we have a very simple program divide.py that writes the result of the division of two input numbers to a separate text file:
If we store divide.py in a separate PyCharm project, it may be located as /home/user/PycharmProjects/project/divide.py. However, depending on your operating system (especially on Windows), the path can look different.
In the example above, we did not specify the directory where we want to create the file, so when we open the project folder from the PyCharm IDE and launch divide.py, the program will write the text file with the result to the same project directory. It happens because we execute divide.py from the project folder, so it becomes the current working directory. We can check the current working directory using the os.getcwd() function. The result is returned as a string:
Now, assume that we want to launch the program from the command-line interpreter by typing the following statement:
The text file will be created in the directory of the Python command-line interpreter. So, it is the home directory. We can similarly check the current working directory from CLI:
The resulting file will be created in different places, depending on the current working directory, the directory where the program is executed. If you don't know it, it can cause problems, so, please, bear it in mind.
Changing the working directory
We can change the working directory manually to avoid confusion. The os.chdir() function can be used for this. It takes the absolute or a relative path as an argument that is basically our desired directory. In the following example, we pass the (absolute) home directory path as a string:
Once we passed the path to chdir(), we can call getcwd() again to make sure that the working directory was changed correctly:
The OSError exception (or its subclass) will tell us that the path or filename is not correct.

Creating directories
We may want to create a new directory when working on a piece of code. There are two functions to create new directories — os.mkdir() and os.makedirs().

os.mkdir() is used to create a single directory. To do so, we should pass the name of the new folder or the full path to it — so that it will be created in the working directory or in another specified directory, respectively. An example below illustrates the former, we just pass the string some_new_project to mkdir():
os.makedirs() allows us to create nested directories in the specified path. Similarly, we can indicate the full path or the names of directories. This function is applied in the following example when creating course, students, and year; year is created within the students directory and students in its turn is created within course.

If a defined directory already exists, FileExistsError will be raised.

Folder content
When working with directories in os, it is very easy to learn about their contents or even change it. We have two functions for that, os.listdir() and os.rename().

os.listdir() returns a list of names of all files and folders in the given directory. If not specified, the function will return the list of names for the current working directory.
It is a very important function. It can be used when you need to process all files in a folder. Note, however, that it returns both file names and folder names, so to get a proper list of files, you'll need to choose only those that end with "".txt"" in our example.

os.rename() renames the file or the directory to the given name. Its first argument is the path to the text file, the name of which we want to change, and the second argument is the very same path, but with the new name, list_of_students.txt in our example.

Conclusion
In this topic, we covered the functions of the os module. The functionality of it is, of course, much larger and you can find the entire list of provided functions in the os module documentation.
Let's briefly sum up the functions we have discussed in the os module:

os.getcwd() to learn the current working directory and os.chdir() to change it.
os.mkdir() to create a single directory and os.makedirs() to create multiple nested folders.
os.listdir() to get the listing of the directory's content and os.rename() to change the name of files and folders.

Now, it's time to practice your new knowledge!
"
69,What are databases,670,8497,496,https://hyperskill.org/learn/step/8497,"The world today is overloaded with information, and so are we. How do you keep important information safe and sorted? You may simply hope you neither forget nor confuse anything, but it's better to write it down or save it on your device. So you have it on your computer or phone, and the program keeps the information safe. While the program is active, it ""remembers"" everything. However, quitting the program may result in losing all that information. That's why it's better to store the data using more sophisticated tools. The challenge is to navigate a huge and complex web of information and ensure everything important is safe and organized: a task that databases handle well.

A database is a collection of data that is specifically organized for rapid search and retrieval processed by a computer.

The difference between a database and a usual file is that a file may be structured or not, but a database must have a specific structure. For example, you can create a file with a to-do list:

Obviously, we'd say that this file has some kind of structure, but from a computer's perspective, it's still a plain file, until you write a program that manages data in it. Usually, the information in databases is compressed and stored as binaries rather than plain text, so it's clear that this kind of structure is meant for computers, not humans.

Unlike us, computers can easily understand the binary format of data, but what allows them to read and write it correctly? It is a program called Database Management System, which controls the data in a database.

A Database Management System (DBMS) is a type of software that allows users to define, create, and control data.

A DBMS can optimize queries and retrieve data from а database in an optimal way. It is a mediator between the user and the database, which means that users can work with it through the interface of a DBMS. In addition, it can also help isolate data from the users.

Another goal of this software is to help people work with different types of databases without exposing their actual differences.

Most database management systems have pretty good descriptions and tutorials on their websites. There are also specific languages like SQL that you need to learn to start working with them, but if you know some programming languages, you can work with a database with their tools instead. For example, there are many libraries in Python and Java that can work with DBMS.  Although it sounds like all databases have different syntaxes, most of them actually implement common standards. Almost all relational databases use the SQL standard, so you can apply the same commands in different DBMSs.

Access to data

At this stage, you may still have many questions about how to use databases. You have to learn a new language to update and select the data, which can be time-consuming. Why not use plain files instead?

Of course, you can store the files locally, but as they grow in number, you won't be able to find information quickly. Databases provide schemas and metadata that allow for a quick search of the data needed.

A schema describes how you organize the data. Metadata holds structural and statistical information.

If you want to access your data from multiple devices, most systems provide a convenient way to work with them online.

To provide restricted access to another person, some management systems use simple login/password authentication, while some provide more powerful instruments. With their help, you can grant access to a limited amount of data for each user.

If you still are not convinced how great DBMSs are, let's look at what else they can do for you.

Data consistency

One of the best features of databases is their ability to keep and restore data correctly. It doesn't mean that a DBMS knows how to be correct, but once you define the rules with the configuration or schema, you can be sure that nothing will break these rules. A DBMS can provide you with formats for your data. You can also set up all the tests and constraints that you want to have.

If several people have simultaneous access to the same data, there may be a problem. Updates in files usually follow the ""last save wins"" rule, which leads to a conflict of updates. For example, if someone decides to contribute to your to-do list, then following the “last changes saved” file update rule, you may lose the notification you just created and miss the football game you have scheduled for tomorrow night. Meanwhile, databases isolate different users and can be configured to resolve conflicts between their updates. There's another good thing about databases. When some file becomes corrupted and cannot be opened, you've lost your data forever. Using a DBMS instead, you can make backups and then restore the data and continue your work.

Of course, you can emulate all of these operations and develop your own DBMS, but first, try to work with the existing solutions.

Conclusion

There is a lot to do before you start working with databases. No pain, no gain, and here you can actually gain a lot.

With databases you can:

Store, retrieve and update data;
Get metadata;
Access a database remotely;
Restrict access to data;
Make concurrent updates;
Recover to some point in time;
Check the rules for data consistency automatically.

In a data-driven world, this kind of functionality is golden. Welcome to the world of new opportunities and good luck with exploring databases!

Read more on this topic in Database Design 101 on Hyperskill Blog.
"
70,Documentation,1157,12069,498,https://hyperskill.org/learn/step/12069,"Introduction
Imagine you've just finished your program and are ready to share it with users and fellow programmers. While working on it, you probably mostly focused on writing code, so a machine would understand what needs to be done and the final program would be executed correctly. However, how will other people know the way your program works, what it can and cannot do, what tasks it's supposed to solve? Most importantly, will you yourself be able to answer all these questions after some time passes? One way to make sure you and others can make use of the program regardless of time and place is to document your code. Let's find out what ways of documenting code are there.

Strategies for documenting code
Documentation is any kind of written or illustrated information that accompanies the source code or is embedded into it and aims at explaining how the code works or how to use it depending on whom it's written for (users or developers).

Let's look at some ways to document your code:

*   writing explanatory comments (and other types of annotation provided by a particular language) to help understand what a particular piece of code is for (e.g. ""This function takes the name of a book, its author and prints a list of stores in the area close to you where you can buy it right now"".);
*   providing images, block schemes, diagrams, and other illustrative data that graphically shows what's going on (e.g. a diagram that shows the implemented neural network architecture);
*   writing README file containing all the necessary information about code utilization (e.g. README to Kotlin);
*   providing additional information in the form of PDF or HTML files, guides, handbooks, etc.
*   creating a wiki for managing your documentation (e. g. wiki for Python);
*   writing release notes/changelogs (e.g. Slack release notes)

To get started and get more information on this, check this beginner's guide to writing documentation from, as stated, ""a global community of people who care about documentation"".

Now let's take a closer look at some of the strategies listed above.

README
README is usually a plain text file (if it's called README.md though, it's using markdown markup like the provided example) which serves as an introduction to a project explaining what it does and why. There is no strict content policy for a README file, which, to some extent, will also depend on whom you're writing it for (users or developers). However, you may notice some commonly-used sections like:

*   Name
*   Description
*   Installation
*   Usage
*   FAQ
*   Support
*   Contributing
*   Contact information
*   License
*   Acknowledgment

Section names are quite self-explanatory, but you can read more instructions on how to write README files. When the file is ready, put it in the same directory as your project.

Wiki
Wiki is basically a website that can be edited by multiple users, so it's especially convenient for team projects. Writing a whole wiki is not gonna be easy, so you'll need some tools and recommendations on how to do it. One of the most popular software used for this type of work is MediaWiki. It's a free and open documentation platform that helps you organize the information about your project in a customizable way. Obviously, this format of documentation gives you much more freedom in design and functionality than a simple README file, so you can create a complete and clickable table of contents, add media files, embed code snippets with correct indentation, etc.

Release notes/changelogs
Release notes and changelogs are specific types of documentation used for informing and keeping track of updates, so it's particularly useful for version control. When something's been changed in the project, you write a release note to inform users and colleagues how exactly this new version differs from the previous one: what's new, what's been fixed, what's deprecated, etc. By writing release notes you will always know at what moment something went wrong or broke, and ask for feedback. Even if you're not planning on publishing these files, it's good practice just to keep these notes for yourself.

Auto-generated documentation
There are also external tools that have different functionality that at their core are aimed at helping you with generating documentation for your code. It's important to notice that, for the most part, these tools do not automatically write documentation for you. Since their work is mostly based on the comments embedded in the source code in the first place, they simply convert what's already been written into a more structured and readable form. For example, Doxygen supports many languages and can generate HTML files from source code. Sphinx was originally developed for Python documentation and is ready to help you with building tables, defining document trees, etc. Dr. Explain is a tool for frontend developers, it analyzes the user interface of an application and generates documentation in a fast and user-friendly manner. This list is by no means complete, so you can find something for yourself.

Pros and cons
Documenting your code one way or another is quite an important skill to master on your journey to becoming a good programmer (which is our goal!). So let's one more time summarize why it's important and what pitfalls might be there:

Pros:

*   helps to refresh your memory
*   guides you through the code
*   explains how the code works and how to use it
*   helps to fix bugs
*   allows for version control

Cons:

*   takes a lot of time
*   takes practice to make it structured and clear
*   easily becomes outdated, so needs to be updated all the time
*   it's a common practice to write documentation in English which might be a foreign language for you
*   constant feedback is needed to make it genuinely good

Summary
In this topic, we've learned about software documentation, its types, ways to write it, and its pros and cons. Now we know that this important information helps us use different types of software, and understand/explain how it works. We also looked at some helpful documentation generators. All in all, it's a very powerful tool everyone benefits from. However, it may also take some time and effort to be able to use it proficiently.
"
71,Inheritance,887,9844,514,https://hyperskill.org/learn/step/9844,"Software development is strongly associated with real-world entities. However, we should consider not only the entities themselves but also the interactions between them. One of the ways it is presented in object-oriented programming is inheritance.
In this topic, we will talk about this technique and see how it can be useful in your code.
What is inheritance?
We start making our program with basic objects and methods. Imagine a messenger application. The main objects in messengers are chats, so we start ours with the CHAT class. Then, we decide to break it into three categories:

direct messages;
group chat;
saved messages only for yourself.

If we want to make more types of chats, do we need to write the code from scratch for each one? The answer is no! With the help of inheritance, we can reuse the code we already have.
Inheritance is a relation between entities that we interpret as ""is a"" or ""is a kind of"" relation. In the case of programming methods and attributes, it means that a child entity has every feature of the parent entity. However, we can also change inherited features or define new ones for child classes.
Here are some examples of inheritance:

A swan is a bird. A swan can do everything that a typical bird can do, but it has an additional feature: it can swim.

A Python developer is a programmer. They, like all programmers, develop algorithms and computer programs based on special mathematical models, but they do it using a specific language, namely Python.

A laptop is a computer. It has processor units, memory, a keyboard, and all the stuff computers typically have, but it is also portable.

Inheritance modeling
Let's stick to the example with a chat and see how we can model the classes of our program. 
We can start by moving all the shared methods and attributes to the base CHAT class. For the sake of simplicity, we define only one attribute and only one method:

To make our base class more useful, we can add some more features like SEND_FILE, EDIT_MESSAGE, POSTPONE_MESSAGE, and others.

Next, we draw child classes and methods that need to work properly:

Let's take a closer look at the diagram and figure out what benefits inheritance gives us. First, we don't need to implement any other methods to make a new class SAVED_MESSAGE: we add only one participant there, and it can work right out of the box! For the other two classes, we implement only some new methods like FETCH_MESSAGES to get updates from other participants and ADD_PARTICIPANT to add a new person to a group chat.

You may notice that we can even inherit the GROUP_CHAT from the DIRECT_MESSAGES to reuse its methods. It makes sense because there is not much difference if two, three, or a hundred persons communicate in a chat, but the hierarchy is fine, too. 

Conclusion
Inheritance is a very flexible and useful mechanism in software development. It allows us to simplify and speed up the development process by reusing the code we've already written. As you have learned, it also reflects the dependency between the parent and child classes that we can express as ""a kind of"" relation.
"
72,Inheritance in Python,533,7235,517,https://hyperskill.org/learn/step/7235,"One of the main principles of object-oriented programming is inheritance. In this topic, we'll focus on inheritance in Python: what it means and how it's done.

What is inheritance?
Inheritance is a mechanism that allows classes to inherit methods or properties from other classes. Or, in other words, inheritance is a mechanism of deriving new classes from existing ones.

The purpose of inheritance is to reuse existing code. Often, objects of one class may resemble objects of another class, so instead of rewriting the same methods and attributes, we can make one class inherit those methods and attributes from another class.

When we talk about inheritance, the terminology resembles biological inheritance: we have child classes (or subclasses, derived classes) that inherit methods or variables from parent classes (or base classes, superclasses). Child classes can also redefine methods of the parent class if necessary.

Class object
Inheritance is very easy to implement in your programs. Any class can be a parent class, so all we need to do is to write the name of the parent class in parentheses after the child class:

The definition of the parent class should precede the definition of the child class, otherwise, you'll get a NameError! If a class has several subclasses, its definition should precede them all. The ""sibling"" classes can be defined in any order.

When we don't define a parent for our class, it doesn't mean that it doesn't have any! By default, all classes have the class object as their parent. In Python 3.x we don't need to explicitly indicate that, so the definitions below are equivalent:

Subclasses of object inherit its methods and attributes. So, all standard methods like __init__ or __repr__ are inherited from the class object. If we don't redefine those methods for our custom classes, we end up using their implementations defined for the object class.

Single inheritance
Unlike some other programming languages, Python supports two forms of inheritance: single and multiple. Single inheritance is when a child class inherits from one parent class. Multiple inheritance is when a child class inherits from multiple parent classes. In this topic, we'll cover only single inheritance. Don't worry, though, you'll have a chance to learn about multiple inheritance in the next topics!

Let's consider an example of single inheritance.

Here we have a base class Animal with the __init__ method and a subclass Dog that inherits from the base class. The keyword pass allows us not to write anything in the definition of the child class.

Now that we've defined classes, we can create objects:

We haven't defined the __init__ for the class Dog but since it's a child of Animal, it inherited its __init__. So if we tried to declare an instance of the class Dog in a different way, we would get an error:

type() vs isinstance()
There are two main ways to check the type of an object: type() or isinstance() functions.

The type() function takes one argument, an object, and returns its type. The isinstance() function takes two arguments: an object and a class. It checks if the given object is an instance of the given class and returns a boolean value.

For built-in types, they work the same, but when inheritance is involved, their results are different. Let's check it out!

First, let's look at the type() function:

As you can see, this allows us to check for the immediate type of the object. Now, isinstance() works differently:

With this, we get True not only with the immediate type but also with the parent type and it would work even with the parent of the parent type! This distinction is important to remember for future projects!

issubclass()
While isinstance() checks the type of an instance of a class, another built-in function asks whether a given class is a subclass of another class:

As shown, the issubclass() function returns True if the first class inherits from the second class, and False otherwise. Each class is considered a subclass of itself. Notice that the function can't work with instances of a class, both its arguments should be classes. However, you can use a tuple of classes to check if your class inherits from any of the several classes in the tuple.

The case with several classes might be somewhat misleading, though. The thing is that the function checks whether any element of the tuple is a parent. Say, we have defined a new class Robot:

Then issubclass() will return the following:

Even though Dog has nothing to do with Robot, in the last case, we got True. So keep this detail in mind when calling this function!

Conclusion
As one of the pillars of OOP, inheritance is very important! In Python, declaring parent classes is quite simple and straightforward. In this topic, we've covered the basics of the inheritance in Python: how it's done, what is class object, how to define a single parent for the class, and then check the type of an object or a class without any mistakes.

Inheritance is what really makes classes so powerful and useful. It also allows programmers to stick to the DRY (Don't Repeat Yourself) principle and pushes them to think about the effectiveness and clarity of their classes.
"
73,SQL: structured query language,519,7054,522,https://hyperskill.org/learn/step/7054,"SQL (Structured Query Language) is a domain-specific programming language designed to handle data in tables. It was developed in the 1970s. To this day, SQL-like interfaces are very popular in various data management systems, not only the ones based on tables!
Understanding such a popular language is likely to be very useful. If you are a software engineer, it's good to learn it because many systems store and process business data via services that support SQL. For example, the backend of an insurance company's information system may use SQL to extract and update data about their clients.
We will begin by looking at a practical example of how you can use SQL to calculate statistics. Then we will examine what the letters in the name SQL stand for.

Calculating statistics
SQL makes aggregating data and calculating statistics easier. Suppose you need to evaluate changes in the popularity of the name Jessie between 1920 and 2000 (inclusive) based on census data. Using SQL, you can complete this task with only 11 lines of code! You might not know the exact definition of each keyword of SQL yet, so try to read it as a sentence written in English. It selects records about individuals named 'Jessie' who were born BETWEEN 1920 and 2000. It groups them by year and gender, counts the number of records in each group via COUNT(*), and generates a table with columns named year, gender, and cnt. It also sorts the table by year and gender in descending order.

SQL is the standard data manipulation language used by data-driven companies around the world. There is a lot to gain from understanding it and plenty to learn. The best place to start is with the basics, so let's now look at what each letter in the name SQL means to find out what exactly we're dealing with! 
S is for Structured
SQL is a language used to extract and update data structured as tables. This kind of data appears in various application areas, such as Excel spreadsheets containing accounting data, or census statistics in Google BigQuery. Another example is an online store that utilizes a special software system to store and access tables, known as a Relational Database Management System (RDBMS). These can help to process the information on goods, orders, and customers.
SQL is intended for use with tables that have a particular structure:

The tables contain rows and columns. Each row is an object or entity that has a set of properties or attributes. For instance, the third row contains data about Willie, a man born in 1985.
Data is often organized into a set of tables, known as a database. Then it's possible to access these tables using their individual names. For example, in an online store's database, a table called Customers would probably contain general information about the company's customers: their names and contact details. The Orders table would store information about the specific orders they place: customer names, goods, and payment details.
Q is for Query
SQL is a programming language with a large set of data processing features. It is declarative, meaning that a statement written in SQL can be a query that tells the system what should be done or evaluated but doesn't specify how.
In the next example, a query extracts all rows and columns from the table Census:
SELECT * FROM Census;
The * symbol is used to select all the columns from the table.
It's necessary to end each SQL statement with a semicolon, also known as a statement terminator. Else, there will be an error. A semicolon may be omitted only if you make one query at a time, but it is a good practice to always put it at the end of your query.
Keywords such as SELECT are not case sensitive in the SQL language. They can be in any letter case but are often written in all caps to make them more visible.
L is for Language
You can read the simple query in the above example as ""select everything from the census."" SQL was designed to be as similar as possible to a natural language. Its declarative nature helps to hide the operation's complexities, letting the user define what is required in a relatively straightforward way. The system then analyzes the query, chooses the control flow, and executes it.
SQL was originally adopted as a standard by the American National Standards Institute (ANSI) in the 1980s. There are many dialects implemented by software vendors that support it. Dialects are based on the ANSI standard but have some technical differences. For example, they might process dates or strings differently. This means that SQL queries written in different dialects are not compatible. However, once you know the SQL basics, it's possible to adapt to dialects fairly easily, like with written American and British English.
MySQL syntax has been used in this topic and elsewhere on this website, so the examples may not be compatible with other SQL dialects.
Conclusion
SQL is a domain-specific, declarative language used when working with structured data.
You have learned that with data organized in tables, you can write SQL queries to select rows and columns according to various criteria, create groups of entities, calculate statistics, and much more!
Read more on this topic in Database Design 101 on Hyperskill Blog.
"
74,Polymorphism,910,10027,523,https://hyperskill.org/learn/step/10027,"With the object-oriented paradigm, it's as if we are working with real-life objects in our code. We choose simple names for classes and methods, so anyone who speaks English can catch up with what's actually happening in the code. Sometimes methods just slightly differ from one another but do we have to create myriads of specializations for our objects with methods DO_SMTH_WITH_OBJECT_A, DO_SMTH_WITH_OBJECT_B, etc...? Of course, we should distinguish them, but with the help of polymorphism, we can do it rather smoothly.

Polymorphism is the ability of an object or its methods to take on many forms depending on its type and the parameters of this or that method. This definition may seem a little vague, so let's look closer at what polymorphism is in practice.

Assume you're programming robots that move boxes in a smart warehouse. For now, we only have two types of boxes: USUAL_BOX and FRAGILE_BOX but it doesn't mean that there won't be other different types of boxes in the future. To make working with robots easier, we create only one method MOVE: Not all languages support this kind of polymorphism. For example, you can define such methods in Java, Kotlin, or Scala, but not in Python or JavaScript. Now, when we order a robot to move something, it checks the type of a box and adjusts its actions accordingly. It slows down when moving something fragile compared to a regular box and maybe it places this fragile box onto the designated spot for fragile boxes. The mechanism of defining several methods with the same name but with different parameters is known as overloading.

You can see that depending on the type of a box a robot can perform different tasks. We can call it a polymorphic method. Let's go a step further and look at how we can create polymorphic classes.

Subtyping

Our warehouse may have high ceilings, so it's possible to make a big rack with boxes on it. Robots can reach a certain height, but we cannot expect them to reach the highest shelves. For this kind of task we can create the DRONE subclass of robots.

Basically, these drones do the same thing as the robots that run on the ground: they MOVE all kinds of boxes. However, we know that they do it differently by moving in the air. We can say that our robots take various forms, so we have a polymorphic object that may be a usual robot, or a drone, and how they perform the task depends on their type.

The technique to redefine methods of the parent class in its subclasses is called overriding. We override methods to extend or change their execution flow. In our example, we change the navigation method of robots to correctly control the drones.

Duck typing

Another way to make polymorphic objects is called duck typing. Duck typing term comes from the duck test reasoning ""If it looks like a duck, swims like a duck, and quacks like a duck, then it probably is a duck.""

In programming, if an object A has the same methods or attributes as an object B, we can say that the object A is a form of B. In our example if we encounter an object with the method MOVE, we can use it to move boxes in a warehouse. Although this form of polymorphism is weak because all we know is that an object has a method with the same signature.

For example, let's consider two objects: CAR and BUS. Both of them have the following methods: MOVE, STOP, and HONK. Basically, these two objects perform the same actions. In other words, both of these objects implement the same interface.

Or imagine that we make two new kinds of robots HEAVYLIFTER and SCAVENGER with the method MOVE. We can use a HEAVYLIFTER as a usual robot, its behavior doesn't differ much. However, a SCAVENGER has an algorithm that moves boxes only to the waste container, so if we try to use it, we shouldn't be surprised to find our boxes in the garbage. No one is safe from such mistakes, so don't forget to check the work of your code with tests, if you prefer to use duck typing. We can use duck typing in languages like Python or JavaScript, but not in Java.

Conclusion

We can use polymorphism to define how we want our objects to behave depending on their type or the parameters of their methods. We can:

*   overload methods with different parameters;
*   override methods in subclasses;
*   use duck typing.

Not all of these techniques are possible to use in your programming language, so you should check the information about it in other topics or refer to the documentation.
"
75,Method overriding,566,7629,540,https://hyperskill.org/learn/step/7629,"One important concept of object-oriented programming is overriding. Overriding is the ability of a class to change the implementation of the methods inherited from its ancestor classes.
This feature is extremely useful as it allows us to explore inheritance to its full potential. Not only can we reuse existing code and method implementations, but also upgrade and advance them if needed.
Overriding is a concept applicable only to class hierarchies: without inheritance, we cannot talk about method overriding. Let's consider an example of a class hierarchy:

Here, the method do_something is overridden in the class Child. If we hadn't overridden it, the method would have the same implementation as in the class Parent. The code child.do_something() would then print Did something.

super()
Python has a special function for calling the method of the parent class inside the methods of the child class: the super() function. It returns a proxy, a temporary object of the parent class, and allows us to call a method of the parent class using this proxy. Let's take a look at the following example:

We've overridden the __init__() method in the child class but inside it we've called the __init__() of the parent class. If we create an object of the class Child, we will get the following output:

In Python 3 the method super() doesn't have any required parameters. In earlier versions, however, you had to specify the class from which the method would search for a superclass. In our example, instead of super().__init__(name) we would write super(Child, self).__init__(name). Both lines of code mean the same thing: that we want to find the superclass of the class Child and then call its __init__ method. In Python 3 these are equivalent, so you don't have to explicitly write the type. However, it may be useful if you want to access the method of the ""grandparent"" class: the parent class of the parent class.

super() with single inheritance
The method super() is mostly used in cases of multiple inheritance: when a class inherits from two or more classes. There it is most convenient and useful but you'll have a chance to learn about that in the next topics. This method can also be of use with single inheritance which is what we'll cover now.
Suppose we have the following classes:

In the subclass Cat, we've overridden the __init__() method. Now the objects of the class Cat do not have the species attribute. We would like for objects of the Cat class to have this attribute, but adding it as a parameter of the __init__ seems a bit excessive. We could, of course, simply create this attribute inside the initializer, but there is a more elegant (and more Pythonic) solution. This solution, as expected, is the super() method:

Let's create a cat and see how this has worked:

Both __init__() methods have done their job and our cat has both the species and the name attributes.
You may wonder why we had to do it this way. Why did we have to call the parent implementation of the method when we could manage without it? Well, the example above is a very simple one. In real-life projects, classes, their methods and the relationships between them are much more sophisticated.
Overriding does provide us with an opportunity to enhance the methods of the parent class but it doesn't mean that we should discard the original implementations. Sometimes, you may not have full access to the original implementation and you may not know everything that happens there. If you just override it, there may be unexpected consequences. So, it is recommended to always call the parent implementation. This way, you get the best of both worlds: you have the original implementation and your enhancements.
Just be careful and thoughtful when overriding methods and using the super() function and you'll do great!
Summary
Thus, in this topic, we've covered the concept of overriding in object-oriented programming, learned about a special super() function that can call the parent class method inside of child class methods and how to use it in case of single inheritance. Hopefully, you'll find this information useful in your future projects!
"
76,Working with strings: basic methods,501,6842,556,https://hyperskill.org/learn/step/6842,"As you already know, the string is one of the most important data types in Python. To make working with strings easier, Python has many special built-in string methods. We are about to learn some of them.
An important thing to remember, however, is that the string is an immutable data type! This means that you cannot just change the string in-place, so most string methods return a copy of the string (with several exceptions). To save the changes made to the string for later use, you need to create a new variable for the copy that you made or assign the same name to the copy. So, what to do with the output of the methods depends on whether you are going to use the original string or its copy later.
""Changing"" a string
The first group of string methods consists of those that ""modify"" the string in a specific way. These methods return a new copy of the string with the specified changes, while leaving the original string unchanged.
The syntax for calling a method is as follows:
string.method_name(arguments)
or
variable_name.method_name(arguments)
Where string is the actual string, variable_name is a variable holding a string, method_name is the name of the method being called, and arguments are any additional parameters the method may require.
Here's a list of common string methods in this category:
str.replace(old, new, count) replaces all occurrences of the old string with the new one. The count parameter is optional, and if specified, only the first count occurrences are replaced in the given string.str.upper() converts all characters of the string to upper case.str.lower() converts all characters of the string to lower case.str.title() converts the first character of each string to upper case.str.swapcase() converts upper case to lower case and vice versa.str.capitalize() changes the first character of the string to upper case and the rest to lower case.
And here's an example of how these methods are used (note that we don't save the result of every method):
Removing characters from a string
When reading a string from a source (such as a file or user input), you often need to edit it to retain only the necessary information. For example, the input string may contain excessive whitespace or unwanted characters at the beginning or end. Three useful ""editing"" methods to help clean up such strings are:
str.lstrip([chars]) removes the leading characters (i.e. characters from the left side). If the argument chars isn’t specified, leading whitespaces are removed.str.rstrip([chars]) removes the trailing characters (i.e. characters from the right side). The default for the argument chars is also whitespace.str.strip([chars]) removes both the leading and the trailing characters. The default is whitespace.
The chars argument, when specified, is a string containing characters that should be removed from either the beginning or end of the string (depending on the method you're using). Here's how it works:
Keep in mind that the methods strip(), lstrip(), and rstrip() get rid of all possible combinations of specified characters:
Use them carefully, or you may end up with an empty string.
Summary
To sum up, we have considered the main methods for strings. Here is a brief recap:
While working with strings, you have to remember that strings are immutable, thus all the methods that ""change"" them only return the copy of a string with necessary changes.If you want to save the result of a method call for later use, you need to assign this result to a variable (either the same or the one with a different name).If you want to use this result only once, for example, in comparisons or just to print the formatted string, you are free to use the result on the spot, as we did within print().
Read more on this topic in Working with Python Strings on Hyperskill Blog.
"
77,Function decorators,918,10103,557,https://hyperskill.org/learn/step/10103,"Decorator is a structural design pattern that allows programmers to extend and modify the behavior of a function, a method, or a class without changing their code. The main idea is that we place those callable objects, the functionality of which we need to change, inside other objects with new behavior. So, decorators are just wrappers around the initial objects. Most frequently, we use them to pass a function as an argument to a decorator to call this function later and perform some actions before and after the call.

Syntax
In Python, the standard syntax for decorators is the @ sign preceding the name of a decorator, and then the object we want to decorate on the next line with the same indentation. Decorators are called immediately before the body of a function, the behavior of which we would like to change. Here is a small example of what the general structure should look like:

Now, to better understand how it works, let's see how to make a simple decorator.

Here we define the function our_decorator , it takes another function as its argument and contains a wrapper that prints the message and calls the function that we have passed to our_decorator. Then, we return this wrapper function that contains our modified one.
Now, we define a function greet using our_decorator:

Then, if we call greet, we will see the following output:

However, you do not always need to write decorators, sometimes you can use decorators from the Python standard library.
Why use decorators?
The reason why you may want to use decorators is that they provide means for making your code more readable and clean. Imagine that we have a set of functions. We want to measure, for instance, how long it takes for each of them to perform the algorithms, so we add timers in each code block:

However, once it is done, the two following problems may arise:

Particular lines would appear and be repeated in each function: the ones with start and end in our case;
These lines would be redundant to the actual functionality and the initial code.

These issues can be solved with a separate reusable pattern that may be further applied to any other function. In our case, we can make it like this:

In the example above, we have written a function decorator timer() that takes any function as an argument, it notes the time then invokes the function, notes the time again, and prints how much time it took. As a result, we can use this decorator for any function later on, and there will be no need to modify the code of the functions itself.
Summary
Now, let's go over the main points we have learned in this topic:

Decorators allow us to change the behavior of the object without changing its source code;
They are introduced with the @ symbol right before the function, the functionality of which we want to modify;
To create custom decorators, we need to specify a decorator function that will return a wrapper over the given function.
"
78,Running Python applications in PyCharm,2080,19153,561,https://hyperskill.org/learn/step/19153,"When you have created your project in PyCharm and added some Python scripts, it is time to execute it. PyCharm provides several methods to execute code including the ability to execute the entire file or code selection. You can use the Python console to run code fragments and stand-alone commands. You can also use Run/Debug configurations to customize the way you're executing the code.
Run a Python script
Open your Python file in the editor. Then you have the following options to run it:

Right-click anywhere in the editor and select Run <filename>.

Alternatively, press Ctrl+Shift+F10 (Windows and Linux) or Ctrl+Shift+R (macOS).

If your code contains the main clause, click the run icon in the gutter, and then select Run <filename>.

The output of each Python script is displayed in its tab of the Run tool window. If you re-run an application, the new output overwrites the contents of the tab. To preserve the output of an application, even if you re-run it, pin the output tab.

That was the simplest way to run your Python code in PyCharm. However, in some cases, you may need to customize the way you execute your code. Moreover, you may need to run different Python applications using the same set of configuration options. Try Run/Debug configurations!
Use run/debug configurations
PyCharm uses run/debug configurations to run, debug, and test your code. Each configuration is a named set of startup properties that define what to execute and what parameters and environment should be used.
You can create a run configuration manually, or you can execute a Python file, and PyCharm will create a temporary configuration for that file with the default parameters. Later, you can modify and save it.
Look at PyCharm after you have executed your Python script:

The configuration for the Championship script appears in the list of the available run/debug configurations. You can modify it by clicking the Modify Run Configuration icon in the Run tool window.
You can open and edit the configuration by expanding the list of run/debug configurations and selecting Edit Configurations.

You should see a Python script run/debug configuration with the default parameters. You can alter them and fill in some optional parameters.

See the following reference in the official documents for more details: Python Run/Debug Configuration Parameters.
Read–Evaluate–Print–Loop (REPL)
If you have some experience with Python and know how to execute commands line by line, you can do it in PyCharm, too. The main reason for using the Python console from PyCharm is to benefit from the main IDE features, such as code completion, code analysis, and quick fixes. The console is always available in the lower group of tool windows.

Click  on the console toolbar to preview the variables as you're executing Python commands. Also, you can click  to add a new Python console. You can rename each console to come up with meaningful names.
See Using a Python Console part of the official documentation for more details.
Read more on this topic in Testing Python Code 101 with PyTest and PyCharm on Hyperskill Blog.
Conclusion
To sum up:

You can execute your Python script using a context menu, pressing a shortcut, and clicking the icon next to the main clause.

Once you've executed a script, PyCharm creates a run/debug configuration. You can use it for the next runs, or to modify and customize the way you want to execute your script.

You can use the Python console to run commands and execute scripts.
"
79,Debugging Python applications in PyCharm,2081,19163,562,https://hyperskill.org/learn/step/19163,"You already know how to execute your code in PyCharm. Unfortunately, working on your code may get frustrating at some point, and pretty often, you will encounter difficult situations. In this topic, we're going to discuss what if something goes wrong and you get execution errors. PyCharm has a special tool to help you solve these issues – a visual debugger. With it, you can detect the problematic line, preview the variable values at a breakpoint, and breeze through the suspended script.

Breakpoints
One of the most common tools to detect undesirable behavior in code is breakpoints. If you add a breakpoint to a line, this is going to be a line where your code stops executing. Let's consider a typical workflow:
1. Click the gutter at the executable line of code where you want to set the breakpoint.
2. Right-click your Python script in the editor and select Debug <script name>
3. Review the debugging process in the Debug tool window.

As you can see, PyCharm initiates code execution and stops at the breakpoint. You can check the variable and special values. Use the Debug tool window toolbar to proceed with the execution or restart it.
One of the tabs in the tool window is the Debug Console. Like the Python Console, it is interactive, so you can use it to type commands, execute them, and review results:

Line-by-line execution
If you want to see what your code does line-by-line, there's no need to put a breakpoint on every line, you can step through your code. There is the toolbar with the stepping actions:

Step over steps over the current line of code and takes you to the next line even if the highlighted line has method calls in it. The implementation of the methods is skipped, and you move straight to the next line of the caller method;

Step into steps into the method to show what happens inside it. Use this option when you are not sure the method is returning the correct result.

Step into my code prevents the debugger from stepping into library classes.

Step out steps out of the current method and takes you to the caller method.

For more actions available during the debugging process refer to Stepping through the program in the official docs.
Expression evaluation at runtime
While debugging your code, you can evaluate expressions to obtain additional details about the program state or try different scenarios at runtime. Just start typing the variable or method in the dedicated field and specify the expression for this code element:

You can try various expressions including arbitrary expressions. Learn more about available methods in the Evaluating expressions part of the official PyCharm docs.
Read more on this topic in Testing Python Code 101 with PyTest and PyCharm on Hyperskill Blog.
Conclusion
Let's sum up:

The visual debugger provides handy methods to discover problematic code in your Python script.

To stop execution at a certain line, you can use breakpoints.

During the debugging process, you can step through the suspended program executing code line by line.

The debugger allows you to evaluate expressions at runtime.
"
80,HTML Basics,4352,47192,564,https://hyperskill.org/learn/step/47192,"HTML is where every web page begins, allowing you to shape digital content into a visible form for the world to see. HTML is not just for static pages; it's the foundation for dynamic applications, interactive forms, and visually engaging websites that capture attention. HTML is the core of the web, providing the structure and substance of every site you visit.

What is HTML?

Imagine you're an architect, creating a blueprint for a house. Before laying the foundation or erecting the walls, you need a plan that outlines the structure, designates rooms, and defines the flow from one space to another. In the digital world, HTML (HyperText Markup Language) serves as this blueprint for building websites. Hypertext refers to text connected to other texts via links, creating an interconnected web of pages. The markup language helps browsers recognize and present this text in a user-friendly format.

HTML provides the skeleton that gives structure to web content, defining elements such as headings, paragraphs, links, and images in a way that browsers can interpret and display. Think of HTML as the building blocks of websites, allowing you to present your content on the Internet.

A glimpse into history

HTML is not merely a set of tags and attributes; it's a living language with a rich history and a promising future. Did you know that HTML is the reason we can navigate from page to page via hyperlinks?

The first website, created by Tim Berners-Lee at CERN, introduced HTML (HyperText Markup Language) and sparked a revolution that led to the modern Internet. Today, HTML has become the universal language for creating web content, accessible by billions of devices worldwide.

Your first handshake with the web

Begin your journey into web development with a simple yet significant step: creating your first HTML page. This initial creation is more than a ritual; it's a gateway to endless possibilities. The following code snippet is your first encounter with HTML:

This snippet represents the blueprint of your first web page. Let's start with what <!DOCTYPE html> is. This declaration at the beginning of the document tells the browser that this is an HTML5 document, ensuring it is rendered correctly.

To confirm that HTML provides the structure for the page, you can view the source code by right-clicking on the page and selecting View Page Source, or by pressing CTRL+U (or Option+Command+U on Mac). You'll see something like this:

The road ahead

Learning HTML is more than just creating web pages; it's about gaining a fundamental skill set that opens doors to numerous opportunities. By mastering HTML, you'll be able to communicate effectively in the digital world, whether you're building a personal blog, developing an e-commerce platform, or designing a modern web application. Understanding HTML is like learning the alphabet—it's the foundation upon which you can build a universe of digital experiences.

As you explore HTML further, you'll learn how to structure content, design user-friendly interfaces, and optimize websites for search engines. This knowledge will enable you to bring your creative visions to life and connect with audiences globally. HTML is not just a language; it's a gateway to a dynamic and innovative field that encourages creativity.

Advantages of HTML

HTML has become widely popular due to its clear advantages:

It is easy to learn and use.
It is supported by all common browsers.
It can be integrated with programming languages.

Conclusion

Today, you've taken your first step into web development. You've glimpsed the potential of HTML and started to understand its role as the backbone of the web. As you continue to build your knowledge, you'll transform these fundamental concepts into complex, interactive, and engaging web pages. The journey of a thousand sites begins with a single tag, and you've just placed yours.
"
81,Escape sequences,529,7130,565,https://hyperskill.org/learn/step/7130,"Let's recall the problems that you may encounter using the print() function.
Nobody likes to write long forms of words, so here comes apostrophe. Be careful, though, when using an apostrophe in strings in Python, you might get an error message. Let's take a look at the example below:
The sentence seems to look fine, but Python will show you an error message «EOL while scanning string literal». Why did that error occur? The abbreviation ""EOL"" stands for ""End-of-line"" and it means that Python went through the text and didn't find the end of the string. The sentence was divided into two parts. The first one is ""That"" and the second one is ""s my car"".
What is an escape sequence?
To avoid the described problem you could use escape sequences.
All escape sequences start with a backslash \, which is interpreted as an escape character. A backslash indicates that one or more characters must be handled in a special way or that the next character after it has a different meaning.
Add an escape character to our example and see that the quote is now interpreted as the literal symbol of a single quote without any errors.

Don't forget that single quotes and an apostrophe in the same sentence are a bad style! According to PEP8, it is better to use double quotes in these cases.

A backslash can be used in a combination with another symbol to do some particular things. For example, if you use \b in the middle of the string and then try to print it, you won't see the character before \b. The combination \b means a backspace character:
Take a look at some other escape sequences:
\n – newline\t – horizontal tabulation\r – moves all characters after \r to the beginning of the line, overwriting as many characters as moved.
The use of escape sequences in a string is always the same. Nevertheless, we will give more examples in the next section.
So, what if you need to print the backslash itself?
The error happens because Python expects an escape sequence that is not there. In this case, we must use a double backslash \\
You add an extra \ to tell Python that the next \ should not be interpreted as the start of an escape sequence.
Now if you want to print text that contains \, you can double it. For example, this is useful when you need to print literally \n, because print('\n') will only output a new blank line. Double backslash will help you in such situations!
And you can also write:
Why is everything correct in such a case? Our string with \ printed correctly, because \m is not an escape expression. Therefore, no formatting has occurred. One more example:
The function repr() returns a printable representation of this string, thus, escape sequences are visible.
When we want to know the length of a string, escape sequences and quotes are also taken into account:
Other examples
Let's consider an example with the escape sequence \n:
The \n combination starts a new line, so you will see the following output:
Hello
World!
The next example shows the escape sequence \t. As it was said above, \t is used for tabulation. If you put it in the middle of a string, the two parts of the string will be divided by some blank space that is called tabulation. It is quite useful when you work with a text.
Another escape sequence that can be useful while you are working with text is \r. The common name for this escape sequence is a carriage return. It moves characters after \r to the beginning of the line, replacing the exact number of old characters. That is, if the length of the string is longer before this escape sequence, then only the required number of characters is rewritten.
Please note that the string length remains the same!

Mind that \r might work in a little bit different way if you use a specific Python environment or operating system. Be careful when you use it!

Escape sequences are simple to use, aren't they? Let's talk more about the length of strings. For example:
After calling the len() function, we can see that the length of the string with an escape sequence (in this case \n) is greater.
Be careful while working with strings because the function print() doesn't show escape sequences.
Summary
Thus, in this topic, we have introduced basic escape sequences, their features, and considered several examples of how to use them, so now you can work with them in Python strings!
"
82,Splitting strings and joining lists,510,6972,566,https://hyperskill.org/learn/step/6972,"In Python, strings and lists are quite similar. Firstly, they both pertain to sequences, although strings are limited to characters while lists can store data of different types. In addition, you can iterate both over strings and lists. However, sometimes you need to turn a string into a list or vice versa. Python has these kinds of tools. The methods that will help you to accomplish this task are split(), join(), and splitlines().

Split a string
The split() method divides a string into substrings by a separator. If the separator isn't given, whitespace is used as a default. The method returns a list of all the substrings and, notably, the separator itself is not included in any of the substrings.

You can also specify how many times the split is going to be done with the maxsplit argument that comes after the separator. The number of elements in the resulting list will be equal to maxsplit + 1.
If the argument isn't specified, all possible splits are made.

If the separator doesn't occur in the string, then the result of the method is a list with the original string as its only element:

Thus, in all cases split() allows us to convert a string into a list.
It may also be useful to read input directly into several variables with split():

It's pretty efficient when you know the exact number of input values. In case you don't, it's likely to result in ValueError with a message telling you either that there are too many values to unpack or not enough of them. So keep that in mind!

Join a list
The join() method is used to create a string out of a collection of strings. However, its use has a number of limitations. First, the argument of the method must be an iterable object with strings as its elements. And second, the method must be applied to a separator: a string that will separate the elements in a resulting string object. See below the examples of that:

Note that this method only works if the elements in the iterable object are strings. If, for example, you want to create a string of integers, it will not work. In this case, you need to convert the integers into strings explicitly or just work with strings right from the outset.

Split multiple lines
The splitlines() method is similar to split(), but it is used specifically to split the string by the line boundaries. There are many escape sequences that signify the end of the line, but the split() method can only take one separator. So this is where the splitlines() method comes in handy:

The method has an optional argument keepends that has a True or False value. If keepends = True linebreaks are included in the resulting list:

You can also use several string methods at once. It is called chaining, and it works because most of the string methods return a string:

But do not get carried away, because the length of a line should be no more than 79 characters, and we definitely do not want to break PEP 8! Also, note that order of methods in chaining matters. sent.split().lower() will throw an error because the method split() returns a list, and applying lower() to a list is not supported.

Summary
We have learned how to convert strings to lists via the split() and splitlines() methods, and how to get strings back from lists via the join() method. As a recap, consider the following:
Splitting and joining methods do not change the original string.
If you need to use the ""changed"" string several times, you need to assign the result of the respective method to a variable.
If you need to use this result only once, you can work with it on spot, for example, print() it.
There are a lot of parameters in string methods. You can check the documentation if you need to fine-tune your program.
"
83,Docstrings,1131,11869,575,https://hyperskill.org/learn/step/11869,"You already know that comments are very useful to explain the inner logic of your code and clarify implicit steps. Comments are intended for other people working on your program. However, there can also be people who will just use your program and they won't need to look through the code and understand all the implementation details. They will need to learn how to use a certain function, a module, etc. So, to briefly describe the object's functionality and how to use it, you can provide a general description via a docstring, the main unit of documenting in Python.
In this topic, we will take a look at what is considered documentation in Python. Moreover, docstrings have several Python Enhancement Proposals dedicated to them, so we will also sum up the conventions of PEP 257 and PEP 287.
What is a docstring?
Docstring (documentation string) is a string literal. It is written as the first statement in the definition of a module, a class, a method, a function, etc., and briefly describes its behavior and how you can use it, what parameters you should pass to the function.
This docstring contains a description of what the function does and its expected behavior towards the values passed to it. Note that triple-double quotes are the conventional punctuation signs to indicate a docstring in Python, and the annotation should start with a capital letter and end with a period, as recommended by PEP 257. What is more, just like a comment, each line in a docstring should be no longer than 72 characters.
We can access docstrings without reading the source code: for example, by using the __doc__ attribute:

Alternatively, we can call the help() function on the object:

The help() function also allows you to access a docstring for the object without importing it. To do so, you just need to pass its name in quotes: for example, help('statistics.median').

Now let's move further and learn more about docstrings.
Types of docstrings
The two main types of documentation strings in Python are one-liners and multi-liners. In the previous example, the docstring for the median() function is a multi-line docstring. However, the very first line of it can be regarded as a one-liner itself:
One-line docstrings are a sort of quick summary for your object, it is the shortest description. Ideally, they are easy to understand for any person who uses something in your program for the first time. Generally, it is better to provide a multi-line description, but in some obvious cases that don't require further explanation, one-liners can be acceptable.
Naturally, multi-line docstrings should contain a more detailed description. For example, the median docstring includes the function outline and two cases of implementation. The structure of multi-line docstrings can be summed up as:
A brief one-line description of the object's purpose;A more elaborate explanation of the functionality, for instance, a list of classes a module has or usage examples.
Now, let's try to write a docstring!
One-line docstrings for functions and methods
First, let's create a small example with a one-line string. Below, we declare the count_factorial() function and specify what it does in triple double-quotes right after the declaration:
Under PEP 257, you should follow the next conventions for docstrings for functions and methods:
The opening and the closing quotes should be on the same line.There should be no empty strings either before or after the docstring.Your description should be imperative, that's why we need the wordings like """"""Return the factorial."""""" or """"""Return the number."""""" instead of """"""Returns the number."""""" or """"""It returns the number."""""".The description is not a scheme that repeats the object's parameters and return values, like """"""count_factorial(num) -> int."""""".
As in the example with median(), we can access the annotation via __doc__.

If you have backslashes in your docstring, you should also wrap it with the r prefix, for example, as in r""""""A \new example with \triple double-quotes."""""". Otherwise, the combination of a backslash and a letter will be handled as an escape sequence.

Multi-line docstrings for functions and methods
Now, let's create a bit more elaborate description of the function's behavior. Following the general structure above, we start by leaving the first line unchanged: it continues to be the main summary of our function. Next, the multi-line docstring for a method or a function should include the information about the arguments, return values, and other points concerning it. In the example below, we indicate the right argument type for num, what value the function returns, and what this return value denotes:
As for style conventions, it is worth noting the following three things:
The summary is separated from the detailed description using a single blank line. The docstring in the example starts right after the triple-double quotes. However, it is also possible to specify them on the next line after the opening quotes:def count_factorial(num):      
      """"""
      Return the factorial of the number.
      
      The rest of the doctsring.  
      """"""The detailed description starts at the same position as the first quote of the first docstring line — there's no indent.
Classes and modules
Now, we will turn to class and module docstrings. PEP 257 proposes the following conventions:
Module docstrings should also provide a brief one-line description. After that, it is recommended to specify all classes, methods, functions, or any other of the module's objects.In class docstrings, apart from the general purpose of the class, you should indicate the information about methods, instance variables, attributes, and so forth. Nevertheless, all these individual objects should still have their own docstrings, with more thorough information given.
To practice this, let's create an example summing up both cases. Below, we briefly visualize the docstrings of the Person class.

First of all, note that the class constructor should be documented in the __init__ method. Also, according to PEP 257, we should insert a blank line after a class docstring to separate the class documentation and the first method.
In the given example, we don't give a comprehensive annotation for the module and for the class, even though it is recommended. Why so? Imagine that you list all the objects that the information.py module contains in the docstring, and then, in its turn, every object that the Person class contains in the docstring. In this case, your annotation may get redundant: for example, you would have to repeat what the calculate_age() function does three times: in the module's annotation, in the class' one, and, finally, in the function's annotation. This is done so that just by looking at the docstring for the object we can get a deeper understanding of what it contains. However, when we use some documentation generating tools or the help() function and call them on the class, we are likely to get the outline of all its methods even without specifying them in the class docstring.
The help() function
Perhaps, you came across the help() function previously: it is used to access the documentation of the object. If you type this command without any arguments, it will start an interactive help utility. To get the documentation of a particular module (a class, a method, etc.) you simply need to pass it as the argument to this function. Take a look at the example below — there we learn the documentation for the Person class, defined in the information.py module.

As you can see, here we obtain the docstrings not only for the class but also for all of its objects.
Summary
In this topic, we covered recommendations concerning the style of writing docstrings with respect to PEP 257. Although this is the prevalent style of designing docstrings, other style guides also exist. For example, you can check out Google-format docstrings.
Generally, docstrings can be used to describe the behavior of modules, classes, functions, and so forth. Python uses triple-double quotes """""" """""" for them. The two main types of docstrings are one-liners and multi-liners.
You can find the object's docstring in its source code. To access it without looking through the source code, use the help() function or the __doc__ attribute.
Now, let's practice!
Read more on this topic in Commenting the Right Way in Python Code on Hyperskill Blog.
"
84,Functional decomposition,857,9571,579,https://hyperskill.org/learn/step/9571,"At this point, you already know how to declare functions in Python. This is a very useful skill, no doubt about that, but to make the most of it, we need to know when to declare them. In this topic, we'll see how to decompose the solution of a particular problem into functions.
Real-life example
Before we go to the actual decomposing, let's figure out what it is that we want to decompose.
Suppose, we are writing a program that simulates an ATM. How do real-life ATMs work? Well, usually a client inserts the card, enters the pin, and, if the pin is correct, performs some operations, for example, withdraws money or deposits money to an account. We can reimagine these actions as parts of a computer program. This is how the algorithm can be described in general:

Parse the input data (card and entered pin);
Check that the pin is correct;
Ask the client what they want to do;
If the operation is supported, perform it.

Before we program this algorithm, let's settle a few things. Obviously, a real bank has a database that stores all necessary data, like the encrypted correct pin or the current card balance. Here we are creating a very simple version of an ATM, so we're not going to include database checkups. Instead, we will define variables card_pin and card_balance. These variables will represent the correct pin and card balance that we would've gotten from a database.
We also need to determine which operations we'll allow. Let's settle on three: displaying the card balance, adding money to the account and withdrawing money from the account.
Now let's see the code:
As you can see, a lot is going on and it's a bit hard to follow. The main logic is the same we've described above. This code works perfectly fine for our problem and we could leave it like that.
However, what if we want this script to work for many users and not just one? What if we want to process other cases and perform other actions, for instance, check if the card is in the database or change the pin? Some parts of this code will be useful, other parts we'll have to comment or delete. We would also need to track all places where we're introducing changes to make sure that everything runs smoothly. Now it starts to sound like we may have a problem with our code. The solution, as you may have guessed, is decomposition.
Functional decomposition
Functional decomposition is simply a process of decomposing the problem into several functions. Each function does a particular task and we can perform these functions in a row to get the results we need.
When we look at a problem, we need to think about which actions we may want to repeat multiple times or, alternatively, perform separately. This is how we can get the desired functions. Let's look at our ATM simulation again and figure out which steps can be turned into separate functions.
First, an action that we do frequently is reading the input with a particular message displayed. Second, we perform a certain sequence of actions when the pin is correct, specifically we ask what we should do next. Third, depending on the answer from the client, we either perform certain actions to deposit the sum to the account or withdraw them from the account. And lastly, whatever the action, we always print out the current balance.
Some of these actions can be converted to separate functions to make the program simpler.
Let's go over them step by step. First, let's separate our main operations into functions.
You may have noticed that in the original program we print the current balance regardless of what we've done before. This means that we can also create a separate function that would log everything.
This function is going to be called after we've done something and will display information about the current balance and the changes that have been made.
Next, it makes sense to create a function that would manage these operations:
You can see that this function returns the card balance that we get after our manipulations. This is helpful because, as we've seen before, we always want to know how much money we end up with. The main purpose of this function, however, is to simplify the process of revising the functionality of our program. If we want to add some other action, we just add another option to the if - else statement and specify the function that would carry out this task. Removing is similar.
One important part that we haven't covered yet is getting the information about the money we'll be moving somewhere. We know that we don't need this information for display, but it is necessary for other operations.
At this moment, we only have bits and pieces of our final program. Another important step is creating a function that would put it all together.
This is when the main logic takes place. We have a single entry point that determines the order of operations and calls necessary functions.
The result
Now, let's rewrite the program above using these functions:
That's it! Sure, together with the functions, the code is much bigger, but this provides us with more advantages than disadvantages. We can understand the general direction of the program and can easily introduce changes if needed. Now, for example, if we want to add another action, we just need to define its function and modify the move_money function. We can also easily test separate components since they are determined in separate functions. All in all, our program now is a real functioning program that won't fall apart when we decide to change it a bit.
Summary
In this topic, we've covered the concept of functional decomposition, dividing the process into several functions.
Among other things, decomposing allows us to:

structure code better;
see the general logic of the program;
introduce changes easily;
test separate functions.

Obviously, functional decomposition is not a universal solution. However, if you can think of your problem in terms of a sequence of some functions, it can be of great help to you!
"
85,Set,487,6643,582,https://hyperskill.org/learn/step/6643,"When you need to get rid of duplicates in a sequence or intend to perform some mathematical operations, you may use a set object. A set is an unordered container of hashable objects. You will learn more about hashable objects later, for now, remember that only immutable data types can be elements of a set. Due to their form, sets do NOT record element position or order of insertion, so you cannot retrieve an element by its index.

Creating sets
First things first, we create a set by listing its elements in curly braces. The only exception would be an empty set that can be formed with the help of the set() function:

If you pass a string or a list into set(), the function will return a set consisting of all the elements of this string/list:

Each element is considered a part of a set only once, so double letters are counted as one element:

Moreover, using sets can help you avoid repetitions:

Have a look: as the order of naming the elements doesn't play any role, the following two sets will be equal.

Working with a set’s elements
You can:
get the number of a set's elements with the help of len() function.go through all the elements using for loop.check whether an element belongs to a specific set or not (in / not in operators), you get the boolean value.

add a new element to the set with add() method or update() it with another collection

When updating a set with a list, the individual elements of the list are added to the set, not the list itself as a whole.

delete an element from a specific set using discard/remove methods. The only difference between them operating is a situation when the element to be removed is absent from this set. In this case, discard does nothing and remove generates a KeyError exception.

remove one random element using pop() method. As it's going to be random, you don't need to choose an argument.

delete all elements from the set with clear() method.
When to use sets?
One important feature of sets (and all unordered collections in general) is that they allow you to run membership tests much faster than lists. In real life, if you have a list and you try to check by hand whether a particular item is present there, the only way to do this is to look through the entire list until you find this item. Python does the same thing: it looks for the needed item starting from the beginning of a list, because it has no idea where it may be placed. If the item is located at the end or there is no such item at all, Python will iterate over the majority of items in the list by the time it discovers this fact. So, in case your program is looking for items in a large list many times, it will be slow.
And that's where sets come to help us! In sets membership testing works almost instantly, since they use a different way of storing and arranging values. So, depending on the situation, you need to decide what is more important to you: preserving the order of items in your collection or testing for membership in a faster way. In the first case, it's reasonable to store your items in the list, in the second it's better to use set.
Frozenset
The only difference between set and frozenset is that set is a mutable data type, but frozenset is not. To create a frozenset, we use the frozenset() function.

We can also create a frozenset from a list, string or set:

As mentioned above, a frozenset is immutable. This means that while the elements of a set can change, in a frozenset they remain unchanged after creation. You can not add or remove items.

So why do we need frozenset exactly? Since a set is mutable, we can't make it an element of another set.

But with a frozenset, such problems will not appear. It can be an element of another set or an element of another frozenset due to its hashability and immutability.

Also, these properties of frozensets allow them to be keys in a Python dictionary, but you will learn more about this later.
Summary
All things considered, now you know how to work with sets:
you know how to create a new set and what can be stored in a set (immutable data types only).you understand the difference between the set and other Python objects.you can work with a set's elements: add new elements or delete them, differentiate discard and remove methods, etc.you know when to use sets (this really can save your time!).you know that frozenset is an immutable alternative of set.
"
86,HTTP URL,494,6740,611,https://hyperskill.org/learn/step/6740,"What is a URL?

Imagine all files on the Internet are located in a megalopolis, each of them lucky to be living in their own home. Given the scale of the Internet, in the resulting settlement, there will be an unimaginable number of blocks and streets. For example, you have an interesting article that you want to share with your friend who lives in one of the houses in the megalopolis. How do you explain where exactly to find the article? That's right, you need to come up with a single standard by which you could name all the addresses in the city, and then give your friend the street name and house number, just like in a real city!

All documents on the Internet have a personal address. For example, the URL of the JetBrains website looks like this:

Web pages, images, videos, and other documents that can be stored on your computer also have addresses. To make them look the same on the Internet, in 1990 the creators of the World Wide Web developed a special standard that defines what addresses should look like. That standard is called a URL, which stands for Uniform Resource Locator. It represents the standardized way of recording file addresses on the Internet.

The standard has one specific feature: not all characters can be used in URLs. The list of allowed characters includes:

Latin alphabet (or English alphabet symbols);
An Internationalized Resource Identifier (IRI), a form of URL that includes Unicode characters;
Numbers;
Reserved characters with special meaning !#$&'()*+,/:;=?@[] ;
Unreserved characters: -_.~.

Basic URL Structure

Here is an example of a URL address:

URL address has a certain structure based on the following template:

Now let's look at this template in more detail:

 is a way of exchanging data with a resource. You are probably most familiar with http and https URL schemes, but there are others;
 and  are prefixes that transmit authentication data for some protocols, if necessary;
 is the domain name or IP address where the site is located. Domain is the name of the site, IP is its address in a network;
 is required for connection within the specified host. The official default port for HTTP connections is 80, and the alternative is 8080, but it is possible to use any other ports too. The default setting for HTTPS is 443;
 indicates the exact address of a particular file or page within a domain;
 are parameters transmitted to the server. Depending on request parameters, the site may slightly change its display. For example, it is possible to sort the items of a list in a different order;
 allows you to connect to a specific part of a web page or document.

This is the general structure of most URLs. Most often, when accessing web pages and documents located on a web server, most of the parameters are not mandatory and are set automatically.

When you just want to see a particular page on the Internet with your browser, the URL template looks a lot easier:



For example, it can be recorded in a form:

https://www.google.com

This simplification was created to make life easier for ordinary Internet users, but most programmers need to know the complete template, and now you do.

Absolute and relative URLs

As we know, a URL consists of several parts, and when you're browsing through the same site, some elements of it stay the same. Whichever IDE you want to read about on JetBrains, the scheme and host parts of a URL always match https://www.jetbrains.com. For example, let's look at these links:

https://www.jetbrains.com/pycharm/ about PyCharm
https://www.jetbrains.com/go/ about GoLand
https://www.jetbrains.com/idea/ about IntelliJ IDEA

The new information in each link is its . There exists another way to locate resources on the same site by only ?# . The complete web address is called an absolute URL, while its shorter version is called a relative URL. These terms are shown in the picture below.

You should remember that it would work only on the same site, while you cannot refer to another site by a relative path. We know that by absolute URLs we can easily find the resource through the Internet, but why do we need relative paths? Here are the main reasons for that:

They are short, and coding is more accessible with them.
We can easily move the site to another host because relative paths do not depend on a particular domain.
They are a little bit faster to retrieve by a browser.

Conclusion

Let's sum up what you have learned about URLs in this topic:

We can locate any resources on the Internet through a URL.
Each URL consists of several parts, but some of them are optional.
We can retrieve resources by an absolute URL and then browse them through relative paths.
"
87,Tags and Attributes,550,7536,613,https://hyperskill.org/learn/step/7536,"Imagine building a house from scratch. You have bricks, windows, doors, and various decorations at your disposal. Each of these components plays a specific role in the construction and design of your home. Similarly, when building a webpage, HTML tags are your bricks and decorations, and learning to use them effectively is the first step in creating your website.

When a browser receives a HTML document, it analyzes the tags and uses them to form elements that we can see and interact with. The current HTML specification includes about 100 tags. Take a look at the complete list of all existing tags by MDN.

Tag syntax is very simple. The name of an element is written between the < and > symbols. Tag names are case-insensitive, but it is considered good practice to write them in lowercase.

All tags in HTML are divided into two main types: paired and unpaired. Let's consider them both in more detail.

Paired tags

Paired HTML tags consist of two instructions — an opening tag (also called a starting tag) that marks the beginning of a block, and a closing tag that looks the same but with an additional slash /.

As an example, let us consider the <p> tag. It represents a text paragraph:

Here, <p> is a starting tag, Hello, World! is the content, and </p> is a closing tag.

The tags are basically containers where we can put (enclose) something. Paired HTML tags usually contain either other tags or some information, for instance, text.

Lets try it out. Open CodePen and type in the following: <p>Hello, World!</p> in the HTML section.

Unpaired tags

Unpaired tags, also known as self-closing tags, have no content inside. They form graphic HTML elements or symbols on a page. So, unpaired HTML tags have only an opening tag.

Here is an example of an unpaired tag:

A browser will draw a horizontal line once it detects this tag. Another example of an unpaired tag is <br> that defines a single line break.

Nested tags

Tags can be nested within each other to combine formatting and structure:

Here, <b> is used to bold a word.

Copy the above nested tags snippet and paste it in the CodePen. The HTML line is rendered as:

A nested tag is only complete when it's properly closed within its parent tag.

The outer tag is called a parent element, and the inner tag is a child element.

HTML attributes

To extend the capabilities of individual tags and manage them easier, you can use attributes. Attributes are clarifications for the browser on how to display a tag.

Each HTML attribute consists of names and values. The following example shows the syntax of attributes:

The <a> tag means a link, href is the name of an attribute, and ""https://hyperskill.org"" is the value. The attribute is assigned to a value with an equals sign =. HTML allows you to specify attribute values without quotes if they consist of one word. However, using quotes is a good practice. The value of an attribute can be enclosed in double or single quotes ("""" or '').

Another important feature of the HTML attribute syntax is that an attribute must be written in the angle brackets:

In this example, an image is added to a web page with the unpaired <img> tag. A link to the file is specified in the src attribute. The value of the attribute is the reference to the desired image.

There are many attributes out there. It can be worth you checking them out.

Conclusion

In this topic, we have covered several useful tags and some attributes. Tags provide information to the browser about the structure of a web page. Remember that the name of a tag is enclosed between < and > in lowercase. They are subdivided into opening and closing, paired and unpaired. Each subtype has its own purpose. Tag attributes also play a vital role. They refine tags and provide additional information about tags and help your browser. HTML comprises a good number of tags and attributes; some are common, some are not. But remember — practice makes perfect!
"
88,HTML page structure,476,6491,614,https://hyperskill.org/learn/step/6491,"Programming is not as mechanical and alien as it may seem: in many respects, it is similar to the human world. This is very easy to notice if you look at the structure of HTML pages, which contains elements like <head> and <body>. Making a site is thus a process of creation, and as a creator, you need to be familiar with all the necessary building blocks. This topic aims to explain the structure of an HTML document, ensuring you can confidently craft the skeleton of a web page.

Basic tags in HTML

In the realm of HTML, certain tags are foundational to the architecture of a webpage. These tags orchestrate the content and structure, providing a framework for web browsers to interpret and display the data. A typical HTML document is segmented into three core sections: <html>, <head>, and <body>.

Upon saving this snippet as an .html file and viewing it through a web browser, the page will look like this:

This looks quite basic, but with HTML you can do much more: customize the structure of the text, manage its visual presentation, and display paragraphs, forms, pictures, titles, and tables. HyperText Markup Language allows you to format texts, which makes them friendlier to Internet users. It is much more convenient to read text with clear and logical markup rather than plow through unstructured text.

Let's get back to the code from the previous example and consider the listed tags in more detail.

The <!DOCTYPE> declaration is crucial as it informs the browser of the HTML version being used, ensuring the document adheres to the appropriate HTML standards. Unlike most HTML tags, it does not require a closing tag.

The <meta charset=""utf-8""> tag specifies the character encoding for the document. Omitting this can lead to incorrect character rendering in some browsers, especially for non-ASCII characters.

The <html> tag encapsulates the entire HTML document, essentially declaring the start and end of the HTML content.

The <head> tag acts as a container for metadata, which includes information used by browsers and search engines, such as CSS links and scripts.

Within <head>, the <title> tag defines the title of the document, which appears on the browser tab or title bar. It's a small but vital element for SEO and user experience.

The <body> tag defines the page content area. It wraps the content displayed in the main browser window;

The <h1> tag is typically used for the main heading of a page, and it's important for both SEO and accessibility. Similarly, the <p> tag is used to define paragraphs of text.

Basic HTML Page Structure

Here is a visualization of the basic HTML page structure:

As you can see, this structure bears a resemblance to our anatomy. Hopefully, this analogy will help you understand HTML better.

Conclusion

Just as humans have more complex systems beyond the basic anatomy, web pages can also contain different elements and tags within the <body> that make them unique and functional. However, no matter how complex a web page gets, its fundamental structure remains consistent. Understanding this foundation is the first step in creating any web page and will serve as a guide as you learn more about HTML and web development.
"
89,Block-level elements,539,7271,619,https://hyperskill.org/learn/step/7271,"When crafting web pages, understanding different HTML elements is like knowing the building materials for your digital structure. Among these essential materials, block-level elements form the core sections of your web pages. They create the framework that holds everything together. This topic will guide you through the concept of block-level elements, how they function, and why they are indispensable when creating well-structured and visually appealing web pages.

Understanding HTML elements
As you know, HTML files can be opened in browsers. After receiving an HTML document, the browser reads the tags in it and uses them to create a HTML page that users see on their monitor screens. All you see on the page in your browser viewer are HTML elements.
There are two main types of page elements: block-level elements and inline elements.

Block-level Elements
Block-level elements start on a new line and stretch out to fill the available width of their parent container, thereby creating distinct sections or blocks within the page. This characteristic makes them essential for organizing content and creating well-structured layouts.

Key Characteristics of Block-Level Elements are:
New Line Start: Each block-level element begins on a new line, separating it from other content. This behavior ensures that each block-level element stands out as a distinct section within the web page.
Full-Width: By default, these elements extend to take up the entire width of their parent container. This full-width behavior allows them to create large, easily distinguishable sections. To verify it, open the developer tools by pressing Ctrl+Shift+I or Cmd+Opt+I keys on a web page and point the mouse cursor at some object. In the browser, rectangles of different height and widths will be highlighted in color. This is the area occupied by the elements you select:
Contain Other Elements: Block-level elements can contain other block-level elements or inline elements, enabling the creation of complex and nested layouts. This feature allows for greater flexibility and control over web page design.
Semantic Meaning: Many block-level elements carry semantic meaning, indicating the type of content they contain (e.g., <header> for page headers, <article> for self-contained content).

Common Examples of Block-Level Elements include:
<div> is used to group similar HTML elements. Whenever you want to divide the sections on the webpage you can use the div element.

 defines a text paragraph:
 This is how it looks in the browser:
<h1> - <h6> are header tags that define headings, with <h1> being the highest level and <h6> the lowest.

The result will be displayed in the browser as follows:
 defines an unordered list.
 defines an ordered list.
 defines a list item (used within  or ).
 defines a table.
 defines a section of content.
 represents a self-contained composition.
 represents introductory content or a set of navigational links.
 represents footer content for its nearest sectioning content or sectioning root element.
 creates a horizontal line:
Now let's see how it's displayed in the browser:

Structured Web Pages with Block-Level elements
Using block-level elements effectively can transform a basic HTML document into a well-structured web page. For instance,  elements can be used to create distinct sections such as headers, footers, navigation bars, and content areas. By nesting block-level elements, you can build detailed and responsive layouts.
Example of a structured web page using block-level elements:
In this example, each section of the web page is clearly defined using block-level elements, making the HTML more readable and easier to maintain. This is how it looks in the browser:

Conclusion
Block-level elements are indispensable for creating well-structured and organized web pages. They provide a clear separation of content, making your web pages more readable and maintainable. By mastering block-level elements, you will be better equipped to design and develop professional and user-friendly websites. Keep experimenting with different block-level elements to understand their behavior and enhance your web development skills.
"
90,Inline elements,556,7518,620,https://hyperskill.org/learn/step/7518,"For many beginners, HTML structure can pose a challenge. Web page elements and their properties may be very confusing. To get things straight, it is enough to know the exact type of a particular web page element.

In HTML 4.01 or earlier, there are two main types of page elements: block-level and inline. In HTML5, however, the elements are not just divided into block-level and inline types, they are also grouped by their meaning and purpose, representing content categories. This concept will be considered at length in the topics to come. For now, try to understand the ins and outs of inline elements.

Inline elements are elements of a document that constitute an integral part of a line. They emphasize a part of a text and give it a certain function or meaning. They usually contain one or more words.

Let's now take a look at six examples of inline elements.

The <a> tag
The <a> tag is probably one of the most important HTML elements. It's designed to create links. This tag is often used with the href attribute that indicates the path to a file/webpage. Consider a code snippet that takes us to the JetBrains website:
This is what we get in the browser:
The text wrapped in the <a> tag is highlighted and underlined. When you click on it, the link takes you to the address specified in the href attribute.

The <span> tag
You can wrap a text or a part of it in the <span> tag:
This tag does not affect the text representation:
You may want to ask a question why do we need this tag? The <span> tag is used when you need to change the appearance of a text using CSS. CSS is the language that describes the web page's appearance.

The <button> tag
To create a clickable button, use the <button> tag. You can wrap something in this paired tag, and the text will be displayed inside the button:

The <b> tag
This paired tag makes any text bold. The limits of the text are indicated by the <p> tag. In the example below, we have changed the outline of the person name and surname:
Now look at the result in the browser:
As you can see, this tag is very convenient and easy to use when you want to highlight an important part of the text.

The <sub> tag
Use this tag to create a subscript text. The text inside this paired tag is scaled down and reduced in size. Let's see how it works:
The result is the following:
This tag comes in handy when you need to write a chemical formula.

The <sup> tag
This tag creates a superscript text. It is similar to the previous tag we've covered, except that the text enclosed in this tag is scaled up:
This is the result we see in a browser:
With <sup>, you can display mathematical equations and formulas on your web page.

This is by far not a complete list of inline elements, as there is definitely more to know.

Inline elements features
The following features are characteristic of all inline elements:

Inline elements can be nested within block-level elements or other inline elements. However, they cannot contain block-level elements. For example, you can place an <em> tag inside a <p> tag, but not a <div> tag inside an <em> tag.
A browser doesn't make a line break before and after a tag. Take a look at the behavior of inline elements and compare it with that of block-level elements:
Inline elements work only when they are enclosed in tags.
Inline elements do not respect the width and height properties in the same way block elements do. Their dimensions are determined by their content and the surrounding context. For example, a <span> element will expand or contract to fit the text it contains.

Conclusion
Inline elements are essential for fine-tuning the presentation of content within a web page. By understanding how inline elements behave and how they can be used, you can create more visually appealing and well-structured web pages. Whether you are styling specific parts of text, embedding images, or creating hyperlinks, mastering inline elements will enhance your ability to control the layout and appearance of your web content.
"
91,HTTP messages,495,6752,621,https://hyperskill.org/learn/step/6752,"The HTTP relies on the ""client-server"" architecture that is built on the basis of messaging. HTTP messages are a way to exchange data between clients and servers on the Web. There are two types of messages: requests and responses. A request is an operation that a client wants to perform on the server, and a response is an answer from the server to an incoming request. Usually, programmers do not need to worry about creating HTTP messages since they are produced by browsers, applications, and web servers.

The format of messages
In the HTTP protocol, all messages consist of text strings. Both requests and responses have roughly the same standardized format:

Start line which may vary:
for requests, it indicates the type of request (method) and the URL where to send it (target);
for responses, it contains a status code to determine the success of the operation.
Headers that describe the message and convey various parameters.
Body in which the message data is located.
The start line and the header are required attributes, so the other parts may be empty.

The full format can be quite complicated for beginners, so we have considered only its part which is the most important for understanding the general principles.

The simplified HTTP interaction
Here is a simplified HTTP interaction between a browser client and a server. The client and the server interact through requests and responses which follow the studied format: Note that there are other possible types of client programs, not just a browser. You can even write your own HTTP client and interact with servers. The only requirement is that such a program should always follow the message format.

Methods
HTTP defines a set of request methods that specify what the desired action will be for a given resource. Despite the fact that their names can be nouns, these query methods are sometimes referred to as HTTP verbs.

Let's look at the most commonly used query methods:

GET method is only used to retrieve data from the server;
POST method is used to send data to the server;
HEAD requests data from the server in the same way as the GET method, but without a response body.

Every time you click on a link, you basically communicate to your browser that you want to GET this page. When you want to log in to your favorite site, you POST your login and password to receive access to it.

There are more available verbs to learn. You don't need to memorize them all right now.

Status codes
For normal operation of computer programs and web pages that work via HTTP, besides the content of the page, the server returns a three-digit code, which specifies the response for the request. With the help of this code, it is possible to redirect the client to another site or to indicate the change of the page, as well as detect an error in the data processing.

Currently, the standards define five classes of status codes:

1xx: Informational
Codes beginning with ""1"" are called information codes. They report on how client requests are processed.
2xx: Success
Messages of this class inform that the action requested by the client has been successfully accepted for processing.
3xx: Redirection
It means further action must be taken in order to complete the request.
4xx: Client Error
It reports errors on the client's side.
5xx: Server Error
The code indicates that the operation was unsuccessful due to the fault of the server.

As an example, if you have successfully loaded a website, the response you received has code 200. You can check this by opening the developer tools of your browser, and clicking on the Networking tab. Then try reloading the web page and you will see the status codes. The combination of keys to open the developer tools can vary. To give you an example, this might be Ctrl + Shift + I or F12 on Windows and Linux, or Cmd + Opt + I on macOS.

You have also probably been in a situation where your browser displays the ""404 Not Found"" message when you input the address of a page that does not exist. This is how these failure messages usually look:

Browsers display error messages so that users can understand that something has gone wrong, rather than continuing to look at the blank page while waiting for the content to be downloaded.

Conclusion
Let's highlight the main points we've just discussed here:

HTTP messages can be of two types: requests and responses.
They are composed of the start line, headers, and body. The start line in requests includes method and target, while in responses it includes status code.
The commonly used methods in request messages are GET, POST, and HEAD.
Status code indicates the response from the server as a three-digit number. It can be one of 5 classes: Informational, Success, Redirection, Client Error, and Server Error.

Now, when you've finished reading the topic, you can visit various sites in a browser and try to guess what your actions look like from a technical point of view.
"
92,List comprehension,454,6315,646,https://hyperskill.org/learn/step/6315,"List comprehension is a way of making new lists. It allows you to create a list from any iterable object in a concise and efficient manner. See the basic syntax below:

Here you can see that list comprehension is specified by square brackets (just like the list itself) inside which you have a for loop over some iterable object. In our example, new_list will simply consist of all elements from some_iterable object. The code above is completely equivalent to the one below, however, it takes less space and works a little bit faster!

You may wonder why there is a need for list comprehensions at all since we have a list() function. Obviously, list comprehensions are used not just for copying elements from some iterable into a list, but mainly for modifying them in some way to create a specific new list. In this case, in the first place of the list comprehension, we write some function of our variable. For example, the code below shows how to create a list of squared numbers.

Also, we can use list comprehensions to convert elements of a list from one data type to another:

List comprehension with if
Another way to modify the original iterable object is by introducing the if statement into the list comprehension. The basic syntax is this:

The conditional statement allows you to filter the elements of the original collection and work only with the elements you need. The if statement works here as a part of a comprehension syntax. The filtering condition is not an obligatory part, but it can be very useful. For instance, here it is used to create a list of odd numbers from another list:

You can also modify the condition by using standard methods. For instance, if you want to create a list of words that end in -tion, you can do it like this:

Finally, we can introduce the else statement in list comprehension. The syntax here differs a bit: [x if condition else y for x in some_iterable]. Using this, we can, for example, get 0 in a new list for each negative number in the old list:

Conclusion
In general, list comprehension should be used with caution: where it gains in efficiency it loses in readability. Nevertheless, it is a very useful tool and we hope you'll use it in your programs!
"
93,Algorithms in Python,546,7316,647,https://hyperskill.org/learn/step/7316,"As you know, algorithms are language-independent, meaning that the same algorithm can be implemented in different programming languages. Since your goal is to learn Python, we will consider how to implement basic algorithms using this language and its features. 
Implementing algorithms in Python
Python has many libraries that provide ready-to-use functions for various problems. Algorithms are not an exception. You can find most of the widely-used algorithms in the Python standard library or in the external packages. Usually, an algorithm is a standalone function that may either be implemented directly in Python or represent a wrapper that calls a function written in another programming language.
Python standard library contains such functions as sorted, min, max, which represent algorithms for sorting and finding the minimum/maximum values in a collection of elements. There are also modules that unite the algorithms of one subject area, for example:

math is a module with mathematical algorithms. For example, math.sqrt is an algorithm that calculates the square root of a number. 
collections is a module that extends and improves the functionality of standard collections such as list or tuple. An example is collections.deque, an efficient implementation of a double-ended queue data structure.

Although most standard algorithms are already present in libraries and packages, we will learn to implement some of them ourselves. This will help you practice your Python skills and understand how these algorithms work under the hood.
A particular example
Let's implement a simple algorithm in Python and consider some typical problems that arise during the process. Below is an algorithm that finds the index of the maximum element in a list of numbers: 

The indexof_max function takes a list of numbers as an input and returns the index of the maximum element in this list. The algorithm works as follows:

First, we initialize the variable index with zero indicating that the element with this index is a candidate to be the maximum.
Then, we start iterating through the list, compare the current element with the maximum element, and update the index if necessary.
Finally, we return the index of the maximum element.

Invoking the function
The function above can be invoked as follows:

Here, we create a list of integers and apply the described function. The maximum element is equal to $5$ and its index is $2$.
Let's try to use lists of other sizes:

Here, the list numbers consist of three elements. The index of the maximum element is $1$. Below is how the function works for a list consisting of a single element:

Considering corner cases
Looks like the function works well for the above lists. Now, let's try to answer the following questions:

What will happen if a list contains several elements equal to the maximum value?
What will happen if a list is empty?
What will happen if a list contains not only numbers but also strings?

Let's go through these questions one by one.
First, the function finds the index of the first maximum element in a list:

This is because we use greater than (>) operator and not greater than or equal (>=). In some cases, you may need to find the last index of the maximum element. You can easily modify the provided function to do that.
Secondly, if a list is empty, the function returns $0$:

This happens because at the very start we define the index as $0$. Such behavior is ambiguous: it doesn't allow us to distinguish between the case when the element with the index $0$ is the maximum and the case when the input list is empty.
To fix the issue, let's return a special value of $-1$ when the input list is empty. The function should be modified in the following way:

Now it works as follows:

The last question is a bit trickier to answer. What will be the result of the code below?

After invoking the code, we will get the TypeError exception with the following error message:
'>' not supported between instances of 'str' and 'int'
The problem is that the interpreter doesn't know how to compare a string with an integer. This issue may also be fixed, but we will discuss it in another topic.
Summary
Python has a wide range of resources that we can use to work with algorithms: from standard library features to special libraries and modules. In the following topics, we will learn about some basic algorithms and implement them ourselves to improve our Python skills and understand the internal logic of these algorithms. While implementing algorithms, it's important to take into account all kinds of situations, so always think about corner cases!
"
94,Stack in Python,731,8915,656,https://hyperskill.org/learn/step/8915,"A stack is a data structure that stores data in the last-in-first-out (LIFO) fashion, meaning that the last element added to a stack will be the first to be removed from it. The simplest example of a stack in real life is a stack of plates — the most recent are on top, and they are also the first you'll remove. Another illustration of a stack is the Tower of Hanoi, a toy that became the inspiration for a famous game. The rings at the very top are the last ones added, but also the first that can be taken away:

Stack implements two basic operations: push that adds an element to the stack, and pop that returns its top element and removes it from the stack. Sometimes, there is also a third operation, peek. It returns the current top element without removing it from the stack.
In Python, there is no conventional stack implementation. However, you can use several data structures as one. In this topic, you will learn about some of them.
Using lists as stack
Built-in Python lists implement all the necessary stack functionality. Indeed, append() adds the elements to the list (the analog of the push operator), while pop() removes its last element. Note that the top of the stack is at the end of the list. Let's take a look at the example:

Despite the simplicity, using lists as stacks isn't a good idea, as it can lead to memory issues. The way lists are implemented in the Python source code increases the time complexity of some operations. When the list grows bigger, Python might need to find a large block of memory to relocate it to, which can slow down some append() calls.
Collections.deque() as a stack
The problem described above can be avoided by using deque.
Deque is a linear data structure that supports adding and removing elements from both sides. In Python, you can find deque implementation in the collections module. The essential methods are append(element) and appendleft(element) that add a new element to the right or left side of the deque respectively. It is similar to pop() and popleft() that remove the first element from the corresponding side of deque.
Since deque is implemented as a doubly linked list; you don't need to store its elements next to each other in memory. By contrast, only smaller chunks of elements are stored together, and each such chunk stores the references to the previous and the next chunk. This enables faster append operations.
You can use deque as a stack in your program. Let's take a look at the example:

If you call pop() one more time, you will get an exception because there are no more elements in the stack for the pop operation:

To avoid this, you can always check if the queue is non-empty before trying to get the next element. This can be done with the help of len():

Conclusion

Stack is a LIFO data structure;
You can use Python lists as stacks, but it might lead to memory issues;
Collections.deque() implements deque as a doubly linked list;
Using deque as a stack in your program enables faster append operations.
"
95,Conversion to boolean,952,10327,657,https://hyperskill.org/learn/step/10327,"You already know that all objects in Python can be interpreted as boolean values. Objects that are evaluated to True are called truthy, objects that are evaluated to False are called falsy. The following values are falsy:

some constants: None and False,
zero: 0, 0.0, 0j,
empty containers such as a string """", a list [], and others.

All other objects are evaluated to True.
This allows us to use objects of any type in boolean expressions. In this topic, we are going to learn when it can be useful and when you should explicitly convert objects into boolean values.
Truthy test
Since there are few objects in Python that are evaluated to False, there are not many cases when non-boolean values are used in logical expressions. The most common one is checking whether the given container is empty or not. Let's write a function that prints a list if it is not empty and the string ""empty list"" if it is the opposite.

According to PEP8, writing if lst instead of if len(lst) > 0 is preferable, but you should understand well which objects could be passed to your function. In this example, if the passed argument lst turns out to be None, this function prints ""empty list"".
 

Here and later in this topic, all examples use lists but this all can be applied to other containers in the same way.
 
There is a more compact way to implement the same function but it requires a deep understanding of how the and and or operators work with non-boolean values.
Logical operations with non-boolean values
You already know that given two boolean values, and returns True if both operands equal True while or returns True if at least one operand equals True. When the operands are of the arbitrary type, Python can apply and and or operators to them, but the result will be one of the operands rather than the boolean values True or False.
The tables below show what and , or and not operators return depending on whether their operands are truthy or falsy.
The and operator.



a
b
a and b


truthy
truthy
b


truthy
falsy
b


falsy
truthy
a


falsy
falsy
a



The or operator.



a
b
a or b


truthy
truthy
a


truthy
falsy
a


falsy
truthy
b


falsy
falsy
b



The not operator.



a
not a


truthy
False


falsy
True



Now we can implement the print_list() function in one line:

According to the second table, when lst is not empty, so it is truthy, the or operator returns the first operand (the list itself); when lst is empty, so it is falsy, the or operator returns the second operand (the string in our case).
Another thing to note is that when the first operand uniquely determines the result of the operation, which happens when the first operand in the and operation is falsy or when the first operand in the or operation is truthy, Python does not look at the second operand at all. For example, when we want to check if the given list lst is not empty and its first element is positive, we may write the following:
if lst and lst[0] > 0:
    ...
If lst is empty, the lst[0] > 0 expression is invalid but it does not cause an exception because it never gets evaluated.
bool() function
Although we can use any objects in boolean expressions, there are cases when we should explicitly convert objects into real boolean values. This can be done with the bool() function. The bool() function returns True if the passed argument is truthy, and False if it is falsy.

This function is not very common, but there are special cases when it can be useful.
When to use the bool() function?
Sometimes you need to store the result of a logical expression or even write it to a file. In this case, you would want to get True or False, not a truthy or falsy object.
Let's look at the example. You have a list of lists with integer values. You want to check if this list is not empty and its first element is not zero for each inner list. The solution is the following code:

Although 5 is a truthy value and 0 and [] are falsy values, most likely you would prefer to get a list consisting of real boolean values:result = [True, False, False]. So you should explicitly convert the result of the function into a boolean value.

 

When you do not have to store the result of a logical expression, there is no need to enclose the expression in the bool() function. For example, if lst is more readable than if bool(lst).
 
Summary

All objects in Python can be interpreted as boolean values.
Some boolean operators, such as and and or, return one of the operands as a result; not, on the contrary, always returns a boolean value.
It is fine to use the test for truthiness when checking if the container is empty but do it carefully.
When you want to store the result of a logical operation, not just check if it is true or false, you should explicitly convert it to a boolean value using the bool() function.
"
96,Abstract classes,919,10111,660,https://hyperskill.org/learn/step/10111,"Suppose, you want to create a role-playing game. You have come up with a bunch of different character classes and you want to define their actions. You want your characters to explore the world, interact with each other, fight, cast spells, sing songs. All characters should be able to do all these things, but the exact way they do it should depend on the type of the character.
In practice, this means that you need to create a class for each character and define the corresponding methods. To make the process easier and more structured, you should use abstract classes.
In this topic, we will discuss what abstract classes are, and why they are perfect for these tasks.
What are abstract classes?
Generally speaking, an abstract class is a template that can be used to create other classes. Once we have a template, we do not work with it directly, we create other objects based on this template and work with them instead. Abstract classes operate in a similar manner.
So, what makes a class abstract?
Well, for one, we cannot create instances of abstract classes. Since an abstract class is some kind of a blueprint, it would make no sense to create such an instance. Another feature of abstract classes is that they have abstract methods. Abstract methods are methods that generally do not have any implementation and they are declared with the @abstractmethod decorator.
You may wonder what is the purpose of these abstract classes since there are no objects and no functionality. Well, their value lies in the fact that they define the structure and functionality for other classes. Abstract classes are used as parent or base classes. All abstract methods defined in the abstract class should be overridden in a child class.

Note that even though abstract methods generally do not have any implementation, they can be implemented. You would still need to override this method in the child class, though. So, implementing an abstract method doesn't make a lot of sense.

Take our RPG as an example. We can use abstract classes to create our characters: we would need to create an abstract player class, list all possible actions as methods, and then create child classes for specific character roles.
How to create an abstract class?
To create an abstract class in Python, we need to use the abc module (which we first have to import). abc is a module for abstract base classes, that is why we have the name.
The first step to make a class abstract is to declare it with a parent class ABC from the abc module.

As we start to create our player classes, we take the class Player as our template. However, this is not enough. This class is not abstract yet, as it does not have any abstract methods. So, you could create an instance of this class, but it is not what we want.
Now we need to define methods, they represent the actions that our players will be able to do.

Now, this is a proper abstract class — it inherits from ABC and has abstract methods.

Note that not all methods in the abstract class need to be abstract. With the abstract class, only ""mandatory"" methods should be abstract because they will need to be overridden in the child class to work properly.

If we attempt to create an object of this class now, we will get a TypeError:

Subclasses
Now we have a proper template, which means we are ready to create actual player classes. Let's start with the class Warrior.

We have already mentioned that abstract methods need to be overridden in the subclasses of an abstract class. What happens if they remain the way they are? Well, as you can see, with the class Warrior above, we have not overridden anything. This is what happens when we try to create an object of this class:

We have an error because we have not overridden abstract methods do_spell and fight. Note that nothing is said about the sing_song method since it is not abstract.
Now, let's implement this class properly:

No exceptions now! Here, you can see that the sing_song method was inherited ""as is"" from the Player class. Since it is a regular instance method, we do not have to override it in the child class. But we could do it just in case.
Take another character class, Bard, as an example. Bards do need to sing, so we could override this method:

Now our bards can sing a song!
Summary
To sum up:

Abstract classes serve as a template for other classes.
Abstract classes inherit from the class ABC from abc module and have abstract methods.
Abstract methods have no implementation. They are preceded by @abstractmethod decorator.
Abstract methods should be overridden in child classes.
"
97,Multiple inheritance,584,7657,662,https://hyperskill.org/learn/step/7657,"By now, you are familiar with the mechanism of inheritance. Now it's time to go deeper and gain insight into multiple inheritance. Multiple inheritance is when a class has two or more parent classes. We will see how it is implemented, what benefits it gives us, and what problems may arise.

Multiple inheritance
In code, multiple inheritance looks similar to single inheritance. Only now, in brackets after the child class, you need to write all parent classes instead of just one:

 Let's have a look at a particular class hierarchy. In the scheme, arrows point from the child class to the parent class.

Class hierarchy with multiple inheritance.
As you can see, there are a basic parent class Person and classes Student and Programmer that inherit from it. The class StudentProgrammer, in its turn, inherits from both Student and Programmer classes, which makes it a case of multiple inheritance. This way, we can say that StudentProgrammer has two parent classes, Student and Programmer, while Person can be regarded as a ""grandparent"" class.
Here's how the basic code for this hierarchy looks:

The diamond problem
As you remember, classes inherit methods and attributes from their parents. If inheritance is simple, everything is clear and straightforward. However, when we deal with multiple inheritance, things are bound to get a little bit more complicated.
One of the most famous ""complications"" is called the diamond problem (or, rather dramatically, ""Deadly Diamond of Death""). The diamond problem is an ambiguity that arises in the case of multiple inheritance. The class hierarchy we've described above is a perfect example of the structure that may cause this problem.
So, we have a class hierarchy with one superclass, two classes that inherit from it, and a class that has those child classes as parents. As you can see from the hierarchy scheme above, the whole structure is shaped like a diamond, which is where the name of the issue comes from (not the Rihanna song, unfortunately).
Let's add some methods to classes to see where the problems lie.

The class Person has a method print_message, which classes Student and Programmer override to print their own messages. The class StudentProgrammer doesn't override this method.
The question is, then: if we create an instance of the class StudentProgrammer and call the print_message method, which message will be printed?
This is the crux of the diamond problem: how to choose an implementation when we have several alternatives.
MRO
Different programming languages use different techniques for dealing with the diamond problem. Basically, what we need to do is to somehow transform the diamond shape (or any complicated hierarchy) into a single line so that we know in which order to look for the necessary method. Python uses the C3 Linearization algorithm that calculates the Method Resolution Order (MRO). 
MRO tells us how the particular class hierarchy looks in a linear form and how we should navigate this hierarchy. Two basic rules are that child classes precede parent classes and parent classes are placed in the order they were listed in.
Each class has a __mro__ attribute (inherited from object) that contains the parent classes in the MRO. Let's print this attribute of the StudentProgrammer class and see what we'll get:
You can see that according to MRO, the immediate parent of the class StudentProgrammer is Student. It means that if we call print_method, the version from the class Student will be implemented.
Note that the MRO looks like this because, in the definition of the class StudentProgrammer, the class Student precedes Programmer. If the situation was reversed, the output of the code snippet above would be Message from Programmer.
super() with multiple inheritance
By now, you already know how the super() function is used in single inheritance. However, it truly shines when we have to deal with multiple inheritance, especially the diamond problem. The super() function uses MRO to call the method and get an attribute of the immediate parent class. You don't need to analyze the hierarchy and figure out the parent class yourself, the super() function will do it for you.
Let's modify our classes by adding the super() calls to the print_message methods.

Each class (except Person) now calls the method of the parent class after printing its own message. Now if we call this method for StudentProgrammer class we'll see the following:
The messages were printed in the MRO of the class StudentProgrammer without any repetitions. This is the beauty and the benefit of the super() function: if you've designed your classes well, you don't need to worry about the order.
Summary
In this topic, we've looked at multiple inheritance in Python: a situation when a class has more than one parent. While it can be very useful, multiple inheritance can also lead to some problems, for example, the diamond problem.
Python uses method resolution order, MRO, to deal with ambiguity. Every class has an attribute that contains its MRO. The super() function, which is used for accessing methods and attributes of the parent class, makes use of the MRO to determine which implementation to call.
We encourage you to experiment with different class hierarchies and the super() function. This will allow you to get the hang of multiple inheritance, deal with hidden dangers and learn how to construct complex hierarchies in an efficient way.
"
98,Basic data types,528,7123,668,https://hyperskill.org/learn/step/7123,"As you already know, SQL is a language used for working with different types of data organized into a table. Usually, data values from the same column in a table have the same meaning and type. For example, a table Car may look like this:

We see that values in the manufacture year column are integer numbers, values in price are decimal, and values in electricity are boolean. SQL databases usually require that each column in a database table has a name and a data type. The column data type restricts the set of values that can be stored in the column and defines a set of possible operations on them. ANSI standard defines a pretty complex set of data types. Besides, database vendors usually add their non-standard data options. In this topic, we will consider a very basic subset of data types: INTEGER, FLOAT, DECIMAL, VARCHAR, and BOOLEAN.

Numerical data types

INTEGER is a numeric data type that represents some range of mathematical integers (usually from -2147483648 to +2147483647). INTEGER type is good for counters, numeric identifiers, and any integer business value you can imagine that fits the scale range.

In everyday life, we usually face decimal numbers quite a lot: for example, when measuring body temperature (36.6 degrees Celsius) or counting our precious finances ($103050.79). SQL supports a special data type for such values – DECIMAL(precision, scale). This type has two parameters: precision and scale. Scale is the count of digits to the right of the decimal point. Precision is the total count of digits in the number. The FLOAT data type is an approximate numeric data type used for floating-point numbers. With the FLOAT data type, we can store very large or very small numbers. Also, it is used for calculations that require fast processing. The FLOAT data type has an optional parameter n that specifies the precision and storage size (from 1 to 53).

By the way, sometimes in SQL, you can encounter the REAL data type. And so REAL is FLOAT(24), or FLOAT of certain accuracy.

Text

Of course, you may want to process something other than numeric data, and SQL supports a family of data types designed to represent text data. Let's consider one of them, quite universal and basic – VARCHAR(n). This type represents a string of symbols of varying lengths not longer than n. For example, one can insert the strings apple, plum, and peach into a column with the type VARCHAR(5). The strings orange and banana will exceed the length restriction and the system will either truncate them or generate an error if one tries to insert such long values.

Boolean

The BOOLEAN type represents boolean logic values: either TRUE or FALSE. This simple data type can be utilized for any attributes with flag semantics, for example, whether a client has visited a competitor's site.

Who defines types and how?

As a database user, you should just know the types of table columns you utilize to be able to process them correctly. However, as a software engineer, you should also know how to create a table and define the column types.

Conclusion

Data may be very diverse, and SQL supports an extensive set of data types to represent this diversity. We have discussed a basic subset of data types just to start with, yet there is more to the topic: type casting, compound types, special types for numeric data, text, timestamps, and so on.

Read more on this topic in Relational vs. Non-relational Showdown on Hyperskill Blog.
"
99,Literals,557,7400,669,https://hyperskill.org/learn/step/7400,"In almost any program or data analysis script, you need to operate constant values called literals. For example, if you're analyzing census data and need to extract census rows according to specific criteria, you often have to use literals. In this topic, we'll discuss three basic types of literals: numeric, string, and boolean. To apply this newly acquired knowledge right away, we'll write a ""Hello world!"" program.

String literals
A string constant in SQL is a sequence of characters surrounded by single (') or double ("") quotes, for example, 'Hyperskill', 'Hello world!', and ""SQL (Structured Query Language)"". To include a single-quote character within a string literal wrapped in single quotes, type two adjacent single quotes, for example, 'Jessie''s birthday'. Alternatively, wrap the literal in double quotes so that a single quote will be treated as a regular symbol. For example, ""Sophie's choice"".

Numeric literals
Numeric literals can be either positive or negative numbers specified as an integer (for example, 1, +9000, -256), decimal (for example, 2.3, +876.234, -1024.0), or real values in exponential notation (for example, 0.4e3, +7.192834e+10, -4.0e-5). If you do not specify the sign, then a positive number is assumed by default. Numeric literals may be INTEGER, REAL, or DECIMAL. The data management system automatically defines a literal's type based on the context. For example, if you specify a numeric value without a decimal point, which fits the INTEGER range of values, the system will treat it as INTEGER, and otherwise as DECIMAL. Numeric values specified in exponential notation are treated as REAL data.

Boolean literals
Boolean literals are boolean logic truth values: TRUE and FALSE. No matter how you specify the value (TRUE or true), these values are identical boolean literals. The same applies to the FALSE values.

Hello, World
Now, we are ready to write a traditional ""Hello, World!"" program.

The query evaluation result is the following. Its actual representation may be different depending on the environment you run it in:
Hello, World!
Actually, the query declaratively states that we want to select this string as a result. The statement consists of three parts: the keyword SELECT (case insensitive), the literal that we want to receive, and a semicolon that defines the end of the query.

Summarizing, a simple SQL query that extracts any literal, whether it's a string, numeric, or boolean, looks as follows. You may replace literal with any correctly specified constant you want:

Conclusion
In this topic, you learned about constant values in SQL, or, in other words, literals. Numeric literals can be specified as positive or negative numbers. Also, they can be specified as integers, decimals, or real values in exponential notation. String literals are characters surrounded by single or double quotes. Boolean literals are boolean logic truth values: TRUE and FALSE. Having studied this topic, you now know how to define numeric, string, and boolean constant values and say ""Hello, Data!"" – and even more – in SQL. Let's move on to practice.
"
100,Arithmetic expressions,558,7409,670,https://hyperskill.org/learn/step/7409,"You already know quite a bit about data types and literals in SQL. It's time to dig deeper and discuss arithmetic and logic expressions. As a cool bonus, we'll teach you how to make a simple calculator with this knowledge!

Arithmetic
If you remember a bit of school math, arithmetic expressions in SQL will look familiar to you. We can also perform mathematical calculations on our data.
The basic set of arithmetic operators supported in SQL is the following:

- unary minus that changes the sign of a value;

* multiplication;
/ division;
% modulo that returns the remainder of integer division;

+ addition;
- subtraction.

SQL supports the common rules of operator precedence. In the list above operators are sorted in descending priority. SQL also supports brackets to make an operator take priority over any other operation.
You can also utilize brackets to improve code readability even if you do not need them to correctly evaluate an expression. Compare these: -2+2*2-2/2 and (-2)+(2*2)-(2/2). The second one is much easier to read!

Calculator
After reading this topic, you can now use SQL when you do not have a calculator at hand! This sounds like quite a lifehack. Moreover, now you know how to process strings. Very impressive!
In SQL you can select not only a literal but an arithmetic expression, as well. Let's provide a template for a simple SQL query that extracts an expression:
SELECT expression;
The statement consists of three parts: the keyword SELECT, the expression we want to evaluate, and a semicolon that defines the end of the query.
For example, the code below evaluates the expression (2+2)*15.

The query evaluation result is 60.

Summary
As you can see, with SQL you can handle arithmetic expressions. SQL allows you to work with operators such as +, -, *, /, %. Thanks to this, you can even write a calculator! 
Well, this covers a lot. Let's now move on to the practical tasks?
"
101,Basic CREATE statement,768,9084,671,https://hyperskill.org/learn/step/9084,"SQL is a language that works with data organized in tables and databases. Yes, you know this already. What you probably don't know yet, is how to create and delete databases and tables. In this topic, we'll teach you that. Let's get creative!

CREATE statement

Let's store information about university students in a new database. We can use the CREATE DATABASE statement for this. Our database will be named students:

This simple SQL query will create the database. In addition to that, we will need a few tables to organize the data.

Creating a new table

To create a table, use the CREATE TABLE statement.

Let's keep working with our students database and create a table students_info that will contain four columns: student_id, name, surname and age.

The column student_id will hold the unique student identifier of the INT type. The columns name and surname will have VARCHAR(30) data. The age column will hold INT values.

As a result, we have an empty table students_info:

student_idnamesurnameage

The query above illustrates the main idea of CREATE statement implementation. The table created this way will be very simple. Soon you will learn how to make more complex tables.

Drop a database

Now you know how to create a database or a table, so let's find out how to delete them. To delete a database, you can use the DROP DATABASE statement.

The following SQL query drops the existing database students:

Keep in mind that if you drop the database, you will lose all the tables stored in it.

Drop a table

As we've mentioned above, DROP DATABASE will delete all the tables in the database and the database itself. If you want to delete only a specific table, use the DROP TABLE statement.

Let's delete our students_info table with a simple SQL query:

While the DROP DATABASE statement deletes all the tables inside the database, DROP TABLE statement deletes the table itself and all information stored in it.

Conclusion

To create a new database, you can use this query template:

The following template is used to drop the database:

To create a new table, follow this general template:

To delete a table, use this statement:

Now you know how to create and delete databases and tables. Let's practice!
"
102,Basic SELECT statement,559,7392,672,https://hyperskill.org/learn/step/7392,"Introduction
You've already written your first simple SQL queries, for example:

Both of these queries are examples of basic SELECT statements. In this topic, we'll further discuss this first building block for the majority of SQL queries. Yes, you can select more data!

Tuple
In a SELECT statement, you can specify more than one value separated by a comma. For example, the query below selects a string literal, a numeric literal, and an arithmetic expression:

Such a set of values (or attributes, fields) is called a tuple (record, row). Actually, the result of the Hello World query is also a row with a single attribute.

Alias
In a query, you may specify a name (alias) for each attribute of a tuple. To do so, you should use the keyword AS followed by a name for the value. If the attribute alias consists of several words or matches an SQL keyword, it should be stated in double-quotes. The query below illustrates the application of aliases:

The query evaluation result is a tuple with three attributes: ""name"", ""height_in_centimeters"", and ""height in inches"". It's a good idea to specify human-readable aliases; alternatively, your data management system can generate some for you.

As you remember, SQL is designed to process data organized in tables. Actually, the result of the example query is also a table with column names specified in aliases and consisting of only one row.

Code readability
SQL is case insensitive (keywords may be written in any case), so SELECT, select, SeLeCt, and seLEct are all valid. However, it is most common to type keywords in uppercase to emphasize them and improve code readability.

We also recommend using indentation, which leaves a bit of free space to visually separate the line. There are different code style guides: use your intuition and follow your team's preferences.

Compare the following formatting options of the same query. Which one would you prefer to read?

The third version is much better: you can easily see the number of attributes, their values, and their names. The version in the middle is intermediate in terms of code readability but easier to edit than the third one (manual indentation by blanks gets broken each time one changes the code). Of course, in practice, you can choose the code formatting style that your team prefers.

Conclusion
Here is a template for a basic SELECT statement: the SELECT keyword, a list of values to extract with optional aliases for them, and a semicolon to indicate the end of the statement:

Congratulations! Now you know how to select a row with several named attributes of different types. Let's practice, shall we?
"
103,SELECT FROM statement,692,8611,673,https://hyperskill.org/learn/step/8611,"You already know that SQL is designed to handle data structured as tables, which comes in handy in various application areas. You also know that to extract all the data from a table called ""table_name"", you should use the following query:
In this topic, we'll learn more about the SELECT statement and how to extract preprocessed data from the table.

Projection
Assume you have a table weather that stores information about the weather in London for the past 5 days.

As you can see, there are a lot of attributes for every hour. Do we need all of them? Let's write a query that selects only the basic info to be displayed on a mobile phone screen, for example, day, hour, weather phenomena, temperature, feels like, and wind speed.

After the SELECT keyword, we list the columns that we want to select and specify aliases where needed. The query evaluation results in the following table:

The type of data extraction when you select a subset of table columns is called projection.

Here's a general schema for such queries: keyword SELECT, list of column names with optional aliases, keyword FROM, table name, and a semicolon to mark the end of the statement:

Expressions
Now, let's imagine that for some reason we need to have different results based on the same data, for example, add columns that state the place, show the temperature in Fahrenheit, and estimate whether it feels colder than that.

The query below does this easily:

We specified the corresponding expressions for attributes place, temperature in Fahrenheit, and feels colder based on literals and column names. Yes, you can use column names in expressions as well! When the data management system executes your query, it will substitute the column names with the corresponding attribute value for each processed row.

Logical table
A data management system hides the way your data is physically stored behind an abstract concept of a logical table. All you need to know to be able to run a query is the database schema—table names, column names and types—and appropriate access permissions. Internally, the query processor maps table and column references from queries to physical data such as files, network connections, and even the results of executing other queries.

Conclusion
Let's take a final look at the overall template for statements that extract data from a table and evaluate expressions in it: keyword SELECT, list of expressions with optional aliases, keyword FROM, table name, and a semicolon to mark the end of the statement.
"
104,Logic and comparison expressions,693,8619,674,https://hyperskill.org/learn/step/8619,"In our previous topics we have already figured out that SQL language uses different expressions, such as arithmetic, logic, and comparisons to extract required data from tables. Those expressions make queries specific. This time let's get into details of logic expressions and comparisons in order to understand how they work.
Imagine that you are responsible for a book store database. You already know how to select preprocessed info about all entities from a table ""books"". There are so many rows in each selection, and you need to filter them according to certain criteria, for example, by author, language, some attribute or even expression requested by the client. The selection of a subset of rows from a table is called filtering. 
Filtering by a criteria
In most cases when we proceed with a query, we want to extract only those records that comply with certain criteria. In order to filter the selection, there is a special operator WHERE in SQL.
The syntax for this operator is as follows:
In the conditions field we can insert any parameters we want our extracted data to be consistent with. However, in order to define those specific selection conditions, we need to apply them to expressions.
Let's imagine that your first client wants to buy a book by Charles Dickens. Let's write a query that selects books that meet the criteria:
At the end of the SELECT statement, we added a keyword WHERE followed by the logical expression that specifies the filters author = 'Charles Dickens'. The SELECT clause doesn't have to contain the columns or expressions listed in the WHERE clause. For example, we didn't have to output author in the query above even though there is a corresponding condition in WHERE. 
Filtering with Comparisons
This is a full list of comparisons operations that can be used in the WHERE operator.
=equality check
<, >less, greater
<=, >=less or equal, greater or equal
!<, !>not less than, not greater than
<>, !=not equal
Usually, we apply comparisons to numerical values. In case we want to make a selection by string literals or dates, we should put those in quotation marks ("" "").
Below are some examples of data extraction from the table products using comparisons.
Let's say, we want to know which products in our table cost more than 250. This time we use the > operator. The query looks like this:
Below we can see what our table with the requested items looks like:
Pretty simple, isn't it?
If we want to select items that cost more than or equal to 250, we should use >= instead. The same principle works for comparisons < and <=. Let's study one more example to make sure we are clear about it.
This time, we want to select all products from the table that are related to the vegetables category. Our SQL query will look like this:
Note, that quotation marks are essential when we make a selection by a string literal. If you forget them, the query won't work.
The result of our selection seems to be correct:
Logical expressions
We are convinced that expressions with comparisons are easy for you to handle. Next, we are going to deal with logical expressions that help us form more complex SQL queries. Here are the three operators from boolean algebra that you are already familiar with:
NOT returns True if argument equals to False and vice versa.
AND compares operands and returns True only if all of them are True. Alternatively, returns False.
OR returns True if at least one of the operands is True. Otherwise, returns False.
Please note the order of operators given above, as they are sorted according to their priority (meaning that if we have all three operands in the expression, first we proceed with NOT, then comes AND, and finally OR).
The picture below shows the logic of the operands mentioned above:
Now let's study several more examples.
Below we have a table named staff containing info on programmers working in our company. Imagine we want to make a selection of those fitting for our next project.
In order to hire the right person for the project, we need a candidate to meet two requirements: be a Middle or a Senior and know SQL.
Our query should look like this:
Please note the parentheses that we use with the OR operand. It's an important tool for prioritizing the OR condition over AND. If we do not use it, SQL would first process the AND operand and only then OR, making the query request irrelevant.
We can arrange the same criteria selection by using the NOT operand instead of OR:
Our selection of candidates for the project will look as follows:
Now we can send proposals to those three lucky ones, and you should continue mastering your SQL skills in order to become one of them.
Conclusion
Today we've moved one step further in writing SQL queries. Let us sum up what we've learned from this topic:
We've discovered how to write SQL queries with conditions using WHERE operator.
We've figured out how to use comparisons in order to extract information from tables.
We've applied logic expressions for more complex queries and studied priorities of logical operands.
It's time to apply the new skills. Let's move on to the practical part?
"
105,Dictionary,475,6481,678,https://hyperskill.org/learn/step/6481,"Imagine that you're a birdwatcher sitting in the park and counting birds that you see. You've observed a dozen pigeons, 5 sparrows, and even one red crossbill! Now, suppose that you want to store these observations for later use. You need to remember exactly how many birds of each kind you've seen. So, a simple list with numbers won't do because you won't be able to tell which number refers to which bird. You need a data type that can associate one thing with another: in our case, the name of the bird with the number of observations.
Luckily, Python has such a type — dictionary (dict). You can picture a real dictionary — a large book with definitions for a lot of words. The definition contains two parts: the word itself (let's call it a key) and the definition for it (a value). In our birdwatcher example, the keys are names of the birds (""pigeon"", ""sparrow"", and ""red crossbill"") and the values are how many birds of that kind we've seen (12, 5 and 1, respectively).
In programming, dictionaries work in a similar way: if we want to store an object, we need to select some key for it and put our object as a value for that key into our dictionary.
Dictionary creation
A dictionary consists of a collection of key-value pairs. Each key-value pair maps the key to its associated value. If you already know the values needed, then the easiest way to create a dictionary is to use the curly braces with a comma-separated list of key: value pairs. If you want to create an empty dictionary, you can do so with the help of curly braces as well. Note that values in a dictionary can be of different types.
Another way to create a dictionary is to use the dict constructor.
When creating a non-empty dictionary, a dict constructor can take a dictionary as an argument, and / or future dictionary keys as arguments with assigned values, as in the example:
When we give the dict constructor dictionary keys with assigned values, as dict(americano=8.0), the left part of the expression is treated as a variable. In contrast to the use of curly braces, in which you can use integers as keys, keys in the dict constructor can't be an integer, a string in quotes, a list, a multiword expression, etc. That is, the following lines will give you an error:
Overall, the curly braces and the dict constructor are interchangeable, just mind the feature given above.
Finally, you can create a nested dictionary. It's a collection of dictionaries inside one single dictionary.
Accessing the items
The syntax for accessing an item is quite simple — dictionary name followed by a key in square brackets []. This approach works both for adding objects to a dictionary and for reading them from there:
When working with a nested dictionary, getting the right value may be a little harder. As in our example, there are different levels and you need to stop at the right depth.
Choosing the keys
You can save objects of any type in a dictionary, but not all of them qualify as a key. You need a good, unique key for each object in your collection. Still, this is not the only restriction on dictionary keys and we will cover them later. For now, safely use numbers and strings.
If a key has already been added to your dictionary, its old value will be overwritten:
In Python 3.7 and up, dictionaries do maintain the insertion order for values they store, but in previous versions it is not necessarily so:
Conclusion
In this topic we've covered some basics for the dictionary data type in Python:

how to create a dictionary,
what is a nested dictionary,
how to manage dictionary items: keys and values.

In the following lesson you'll get acquainted with basic operations on dictionaries, but first, let's practice some tasks, so you would feel confident using this data type!
"
106,Dictionary methods,751,9008,679,https://hyperskill.org/learn/step/9008,"You already know how to create a dictionary and access its items. In this topic, you are going to learn about other features of dictionaries.

Alternative dictionary creation
You know that there are two ways to create a dictionary. Using curly braces with a comma-separated list of key: value pairs or the dict constructor. We will learn about the fromkeys method that creates a new dictionary with specified keys and values. This is the syntax for this method:
dict.fromkeys(keys, value)
The keys parameter is a sequence of elements that will become the keys of a new dictionary. The value parameter is optional and defaults to None, but the user can specify a value for all keys in the dictionary. Look at the example below:
The word was added successfully! But now we want to create a dictionary that would store the names of the satellites for those planets. Some planets have several satellites, and some do not have them at all, so it is more convenient to use a list as a value.

Let's add the items from the satellites list to the corresponding planets. Look, this is what happened to our dictionary:
We see that all the elements of the satellites list have been assigned to all planets in our dictionary. This happened because the fromkeys method assigns the same object to all keys. While referring to different keys of the planets_dict dictionary, we are still referring to the same list. The difference from the previous example is that if we use mutable objects (a list, a dictionary) as values, all changes will also apply to our dictionary. The solution is to use the dictionary comprehension:
More details on this operation will be provided in another topic on dictionary operations.
Adding items
Suppose we want to add items to an existing dictionary. You know one way to do it — define a new key and a new value: existing_dict['new key'] = 'new value'. But there is another way — use the update method. The method updates the dictionary with new elements from another dictionary or an iterable of key-value pairs.
Let's create a dictionary and define months as keys, and the average temperature for this month as values. So we have the following testable dictionary:
If the specified key already exists in the dictionary, the method will update the key with the new value:
With Python 3.10, you can use the union operator (|) to merge two dictionaries. If a key appears in both operands, the value from the right-hand operand prevails, overwriting any previous value associated with that key.
Summary
What have we learned in this topic?
a new fromkeys method for alternative dictionary creation; we also found out its peculiarities,discovered how to add new items to the dictionary with the update method,
If you want to see more information on dictionaries, don't forget to check out the Python documentation.
"
107,Operations with dictionary,1046,11096,680,https://hyperskill.org/learn/step/11096,"You have learned about basic methods that are used to work with dictionaries. Let's talk about other operations. They will help you discover new features of dictionaries.
Membership testing in a dictionary
Sometimes you need to check whether a specific item is present in your dictionary. For example, you have a furniture catalog where products (keys) are listed along with prices (values), and you want to find out if it has a blue sofa in it or not. In this case, you can use operators in and not in for this purpose. The syntax is quite simple: key in dictionary returns True if key exists in dictionary and False otherwise. The not in operator does the opposite, it returns True if key does not exist in the dictionary:

Note that the membership operator looks for keys, not values:
Iterating over keys
You already know that the for loop allows us to iterate over elements of an object. So what does iteration over a dictionary give us? Let's take a look at the following example:

We see the keys of the dictionary in the output:
a
b
c

A similar way to iterate over keys is to use the keys method, which creates a special iterable object — a collection of dictionary keys:
Now let's try to write our loop using the keys method and check whether the output remains the same:
# a
# b
# c
Including values in iteration
What if we want to get more than just the dictionary keys when iterating?
Thevalues method is quite similar to the previous one, the only difference is that you get the values, not the keys. It provides a collection of values, without any information about keys that are used to get these values from the dictionary:
# 1
# 2
# 3

Finally, the items method provides complete iteration in case you need both keys and values. It returns the collection of (key, value) pairs (tuples):
# ('a', 1)
# ('b', 2)
# ('c', 3)

Dictionary comprehension
Dictionary comprehension is a very convenient and concise way to create a new dictionary with one line of code. The minimal template looks like this:
dictionary = {key: value for element in iterable}
Let's take a closer look. The expression is grouped in curly brackets — {}. What happens inside? The for loop goes over the elements of an iterable object (list, another dictionary, etc.). To create a dictionary, we need to specify the key, which, if we want to create several elements at once, should be bound with an iterable object, and then the value, which can be arbitrary:
However, the value is usually also associated with the iterable:
In the example above, we retrieve keys and values by performing operations on elements in the iterable object.
However, dictionary comprehension is used more often to create a new dictionary by changing values in another dictionary. Imagine that we have a dictionary that contains the names of the planets and their diameters in kilometers. You need to create a new dictionary where the diameters are in miles. Without the dictionary comprehension, it would be like this:
planets_diameter_km = {'Earth': 12742, 'Mars': 6779}

# correct but long way
planets_diameter_mile = {}
for key, value in planets_diameter_km.items():
    planets_diameter_mile[key] = round(value / 1.60934, 2)
    
print(planets_diameter_mile)  # {'Earth': 7917.53, 'Mars': 4212.29}
Now let's wrap the same operation with the dictionary comprehension; we will convert the values from kilometers into miles:
# convenient and short!
planets_diameter_mile = {key: round(value / 1.60934, 2) for (key, value) in 
                         planets_diameter_km.items()}
print(planets_diameter_mile)  # {'Earth': 7917.53, 'Mars': 4212.29}
We can devise some conditions in our expression. For now, we want to include only the planets that are bigger than 10000 km in the new dictionary:
planets_diameter_mile = {key: round(value / 1.60934, 2) for (key, value) in
                         planets_diameter_km.items() if value > 10000}
print(planets_diameter_mile)  # {'Earth': 7917.53}
So, the dictionary comprehension streamlines the process of creating a dictionary, and the logic of the process is understandable. However, be careful not to make your code hard to read.
You can find more information about dictionary comprehension on the official Python website.
Sorting the dictionary
As with any collection, you can sort a dictionary. Since it consists of (key, value) pairs, you can sort it either by keys or values. This can be achieved with the help of the built-in sorted function. However, we will not sort the dictionary, but rather create a new sorted dictionary from our original one.
Let's take the furniture catalog dictionary as the basis.
catalog = {'green table': 5000, 'brown chair': 1500, 'blue sofa': 15000, 'wardrobe': 10000}
First, let's sort it by keys. In our case, those will be furniture names, so we will be sorting them by alphabet. Here's how that is done.
import operator

catalog_sorted_by_key = dict(sorted(catalog.items(), key=operator.itemgetter(0)))
# {'blue sofa': 15000, 'brown chair': 1500, 'green table': 5000, 'wardrobe': 10000}
Let's go over the code. The sorted function takes an iterable as an argument and returns a sorted list. We use catalog.items() because we want to keep the connection between keys and values in the sorted dictionary. So, sorted will return a sorted list of key-value pairs, so to get a sorted dictionary we need to turn it back into a dictionary.
The key parameter determines the logic which is used to compare elements in the input iterable. Here we're using another built-in function that returns the item by its index. We sort by key, so we use the item with the index of 0.
To sort a dictionary by value, we just need to choose the item with index 1 as the key.
catalog_sorted_by_value = dict(sorted(catalog.items(), key=operator.itemgetter(1)))
# {'brown chair': 1500, 'green table': 5000, 'wardrobe': 10000, 'blue sofa': 15000}
So far, we've been sorting in direct order, but if we wanted to sort in reverse order, we could do that by setting the parameter reverse=True for the sorted function. 
catalog_sorted_by_value_reverse = dict(sorted(catalog.items(), key=operator.itemgetter(1), reverse=True))
# {'blue sofa': 15000, 'wardrobe': 10000, 'green table': 5000, 'brown chair': 1500}
Summary
In this topic, you've learned some tricks about dictionaries:
in and not in operators allow to test for membership in a dictionary, though, they look for keys only;the for loop can iterate through the keys of a dictionary;keys and values methods give you access to the keys and values of a dictionary and the items method — to both at the same time.the dictionary comprehension is a quick and easy way to create a dictionary.a dictionary can be sorted by keys or values using the sorted method.
"
108,Kwargs,853,9544,681,https://hyperskill.org/learn/step/9544,"With *args you can create more flexible functions that accept a varying number of positional arguments. You may now wonder how to do the same with named arguments. Fortunately, in Python, you can work with keyword arguments in a similar way.

Multiple keyword arguments
Let's get acquainted with the ** operator used to pass a varying number of keyword arguments into a function. **kwargs collects all possible extra values in a dictionary with keywords as keys.

By convention, people use special names for this kind of arguments: *args for positional arguments and **kwargs for keyword arguments, but you can call them whatever you want. The main thing is that a single asterisk * matches a value by position and a double asterisk ** associates a value with a name, or keyword. So, **kwargs differs from *args in that you will need to assign keywords.

Once the function has been invoked, these 4 lines will be printed:
Ottawa is the capital city of Canada
Tallinn is the capital city of Estonia
Caracas is the capital city of Venezuela
Helsinki is the capital city of Finland
So, everything works just fine! And again, the number of arguments we pass may differ in the next call.

Note that the names in a call are without quotes. That is not a mistake. Moreover, the names should be valid, for example, you cannot start a keyword with a number. Follow the same naming rules as for variables.

It is also possible to combine *args and **kwargs in one function definition:

The order is crucial here. Just as non-keyword arguments precede keyword arguments, *args must come before **kwargs in this case. Otherwise, both when creating and calling a function with *args and **kwargs in the wrong order, a SyntaxError will appear:

Unpacking in function calls
There are two unpacking operators in Python: a single asterisk * unpacks elements of an iterable object and a double asterisk ** works with dictionaries. Let's try to get key-value pairs from a dictionary and pass them as keyword arguments using a double asterisk **:

By default, you iterate over keys in a dictionary, so be careful with this. You might need this type of unpacking when setting specific parameters of a function. Saving values in a dictionary and then unpacking them in this way might be much easier than listing them in each call manually. Also, it will save time when you choose to fine-tune these parameters.
Summary
Let's go over the main points discussed in the topic:

If you want to work with a varying number of keyword arguments, make use of **kwargs.
The variable name kwargs is conventional, you can always choose another one.
Notice the difference: *args provides access to a tuple of remaining values, while **kwargs collects remaining key-value pairs in a dictionary.
The order of parameters in the function definition is important, as well as the order of passed arguments.
In function calls, now you can use both unpacking operators: a single asterisk * for iterable objects and a double asterisk ** for dictionaries.
"
109,Function annotations,1673,15664,682,https://hyperskill.org/learn/step/15664,"You already know about docstrings and the role of function inputs and outputs in code clarity. Is there an easier and more concise way to add a document to your code? The answer is positive. This is where function annotations come in handy.

Introduced in PEP-3107, the function annotations are a Python 3 feature that lets you add arbitrary metadata to function arguments and a return value. According to the PEP, the function annotations are arbitrary Python expressions that can be associated with various function parts. Python does not attach any meaning to these annotations by itself.

Importance of annotations
Function annotations require minimal effort, but they can have a huge impact on your code:
They improve the way you write your code — it becomes more concise;
They encourage you to think outside the box;
By normalizing the documentation of inputs and outputs, they help you and other people understand the code easier;
They help you identify type-related issues.
Enough said, let's see what the annotations are!

Syntax of annotations
First of all, we'll discuss the main syntactic structures of annotations. Mind the structures below:

We will often use the word ""expression"" in the examples. In function annotations, an expression is any valid Python expression from a string (Bob drives a nice car.) to object types (str, int, dict, etc.) and mathematic expressions (5 + 2).

Annotations for simple parameters. An argument is followed by : and an expression. The annotation syntax runs like this:The default arguments are specified after the annotation expression.Annotations for excess parameters. The excess parameters like *args and **kwargs allow passing an arbitrary number of arguments in the function call. The syntax is very similar to the one with simple parameters:Annotations for the return type. Annotation of the return type is quite different from argument annotation. The return value is annotated with -> followed by an annotation expression. Mind the example below:

With Python 3, the feature: Nested parameters, where a tuple is passed in a function call and automatically unpacked, is removed.

It's important to understand that annotations are completely optional, and Python doesn't provide any semantic significance for annotations. It only provides nice syntactic support for associating metadata and an easy way to access it. We've discussed the first part, the syntax, so let's talk about accessing annotations.

Accessing annotations
All annotations are stored in a dictionary named __annotations__ that is an attribute of the function:

As you can understand, annotations are not typed declarations. They are just arbitrary expressions that allow arbitrary values to be stored in the __annotations__ dictionary.

Case studies
As we recall from PEP-3107, annotations have no standard meaning or semantics. However, there're certain cases that we will discuss in more depth.
One of the biggest advantages of function annotations is that you can move an argument and a return value from a docstring. Let's take a look at the two functions below. The first one employs a docstring, while the second one is annotated according to PEP-3107. As you can see, the second option is more concise and easy to read:
There are several other benefits of annotations over docstrings. First of all, when an argument is renamed, the docstring may remain out of date, so don't forget to update them. It is also much easier to see whether an argument is documented or not. Finally, the __annotations__ attribute provides a direct, standard mechanism to access metadata.
Another benefit of annotations over docstring is that you can specify different types of metadata, such as tuples or dictionaries, without any special parsing methods or external modules. Let's say you want to annotate arguments and a return value with both type and a description string. You can do that by annotating with a dict that has two keys: type and description:

Another case where function annotations can be helpful is optional typing. Even though Python is dynamically typed, and any object can be passed as a function argument, there are many cases when functions require arguments of a specific type. With annotations, you can specify the type right next to the argument in a very natural way:
Remember that solely specifying the type is not going to enforce it. For example, there will be no errors if the function is called with incorrect argument types. But still, even specifying the type in annotations can make the intent more readable than specifying the type in the docstring. It can help users understand how to call the function.

Conclusion
In this topic, we have found out what function annotations are, how to write them, and how to access them. Let's briefly go through the main points we have discussed:
Python doesn't provide any semantics with annotations.
They are stored in a dictionary and can be accessed by calling the __annotations__ method.
Annotations are completely optional, but they have various use cases.
"
110,Requests: retrieving data,691,8603,683,https://hyperskill.org/learn/step/8603,"This topic is an introduction to requests, an elegant and simple HTTP library for Python.
Hypertext Transfer Protocol (HTTP) is arguably the most popular application protocol used on the Internet. It allows for communication between HTTP clients (e.g., web browsers) and HTTP servers (web servers) by sending text messages: the client sends a request message to the server which, in turn, returns a response message.
Python requests allows you to send all kinds of requests and get the responses to them in an easy and intuitive way. Don't forget that it's not in the standard library, and therefore you might need to install it by typing pip install requests in your command line.
To start using requests in your code, import the library:
Making a GET request
The GET request is used to retrieve information from the given server using a URL. For example, whenever you enter a URL in the address box of your browser, it translates it into a GET request message and sends it to the server.
Imagine we need to get the main page of the official website of the requests library. We can do so with the help of requests.get(url) as follows:
This returns a response object r containing all the necessary information about the response of the server. Note that 200 is a standard HTTP code indicating that the request succeeded, while code 404 means that the resource you were looking for was not found. You can explicitly access the response code in the status_code attribute of the response object:
If you use a response object in an if statement, it will evaluate to True if the status code starts with the digits 2 (request was accepted) or 3 (redirection), and False otherwise:
To read the content of the server’s response, look at the text property:
Note that requests automatically decodes the content of the response from the server. You can find out what encoding is being used and change it, if necessary,  using the encoding property:
Other useful information, e.g., content type,  is stored in the response headers. To view them, access .headers:
A dictionary-like object is returned, so you can access the header value you need by its key. Note that the headers are case-insensitive, meaning you don't have to worry about their capitalization:
Query parameters
A query string is a convention for appending key-value pairs to a URL. It's separated from the standard URL with a question mark sign ? and contains key-value pairs. Each key is separated from the value by an equality sign =, while the pairs are separated by an ampersand &.
Query strings can include fields added to a base URL by the browser or other client applications. How these parameters are used is up to the server-side application. For example, https://www.python.org/search/ is a search page of the official Python website. If you search for 'requests' there, the results will be displayed on the page with the URL https://www.python.org/search/?q=requests.
When using requests, there’s no need to manually add query strings to your URLs. The library allows you to provide these arguments as a dictionary of strings using the params keyword argument when making a request:
If you need to send similar requests multiple times in your project, it makes sense to define a special function for that. For example,  google_search(query, num) returns a URL to the page containing num Google search results for a given  query :
Unfortunately, a lot of requests to Google can lead to banning. Try to be attentive when sending multiple requests!

Summary

requests is a Python library for making HTTP requests.
GET request requests.get() is used to retrieve the data from the server.
To provide additional parameters to the server with your GET request, use a query string.
A query string can be passed to requests.get() as a dictionary of key-value pairs.
"
111,Requests: manipulating data,700,8681,684,https://hyperskill.org/learn/step/8681,"Most often we browse the web fetching some data, but when we log in to a social network, add an item to the cart in some online store or delete a picture posted earlier, we send information to the server to change its state. For this purpose we use such HTTP methods as POST, PUT and DELETE. In this topic, you'll learn how to send these common types of requests in Python.

Setting up
First, you might need to install requests, a Python library for making HTTP requests:

To start using requests in your code, import the library. It will allow you to send different kinds of requests and get the responses to them from the server in a special response object.

requests.post()
A POST request allows you to send some additional data to the server. Unlike GET requests, where you could specify additional parameters in the query string, POST requests pass additional data in the body of the message (request).

With the requests library, you can make a POST request using requests.post, specifying additional data with the data parameter, e.g. as a dictionary.

Imagine you want to add a new blog post to your personal blog. Then you would write something like this:

requests.put()
PUT method replaces the resource at the given URL with the resource specified within the request. If there is originally no resource to replace on the server, PUT will create one.

So if you need to update a specific post you published earlier, you will send a PUT request similar to this one:

requests.delete()
You might also want to remove a post from your blog. In order to do so, you'll need to send a DELETE request, which deletes the resource identified by the request URL. This is straightforward with requests.delete():

Idempotency
An important property of some HTTP requests is idempotency. A request is called idempotent if sending the same request more than once doesn't introduce additional changes to the state of the server. Can you say which of the requests mentioned in this topic have this property?

Obviously, GET is idempotent because it just collects data from the server without introducing any changes to it. PUT is idempotent as well since if you PUT the same object multiple times, it will have no effect comparing to sending a PUT request just once. And, of course, if you DELETE a resource once, the state of the server will not change any further when you send the same request more times, meaning that DELETE is idempotent.

However, note that POST isn't idempotent, because a POST request may add new data to the server (e.g., a new record to a database), and doing so multiple times is different from adding it just once.

Summary
Let's highlight the main points:

POST is the most common request method used to send data to the server.
To make a POST request with requests, use requests.post(url, data).
PUT requests are used to update the resource on the server. They can be sent withrequests.put(url, data).
DELETE request requests.delete(url) removes a resource at the given URL from the server.
An HTTP request is idempotent if sending several identical requests has the same result as sending just a single one.
GET, PUT and DELETE are idempotent, while POST isn't.
"
112,BeautifulSoup: working with HTML,935,10209,685,https://hyperskill.org/learn/step/10209,"Imagine you are a student who is eager to study regional press news. If you collect every news piece manually, it will take plenty of time. Luckily for us, Python has some tools to offer to automate this process. beautifulsoup is a library that helps you analyze the HTML and the XML syntax, create parse trees and extract necessary information. It also provides web scraping, a simple technique of getting data for further analysis. So, by combining basic operations in Python, requests, and beautifulsoup libraries, you can get all the texts and save precious time. Although it is possible to work with XML using the library, in this topic, we will focus on HTML.

Installation
To install beautifulsoup, you need a Python package manager pip. 
Also, you need the requests library to send HTTP requests. It can also be installed using pip.
Do not forget to import these libraries before starting your work.

Getting started with web scraping
First, we need to create a variable that will store the content of the page. To do so, use requests.get() with a link as an attribute.
To check whether the page was downloaded successfully, you can use status_code. If the returned code is 200, there are no errors. If your code is 400 or 500, there are some difficulties with getting the page.
Then we use BeautifulSoup() class to create a parse tree of our page.
There are two parameters: r.content is the data of the page, and html.parser is a parser included in the standard Python library. You can install additional parsers like lxml via pip and use them instead of the html.parser. The lxml parser is used for swift processing.
The result of the procedure is a tree. You can use the prettify() method to turn your tree into a nicely formatted string.

Searching for tags
As far as you can see, the content stored in the variable soup is hard to follow, plus it contains a lot of unnecessary information that we do not need. Important data like texts or titles are often stored with particular tags. So, once you have decided which tags you need, there are two useful methods for finding these tags in your tree.

find() method returns the first occurrence of the tag in the tree. This method is suitable if you are sure that your document has only one specific tag you need.

find_all() method returns the list of all the results with the tag you are searching for.

If the specified tags have not been found, the find() method returns None and find_all() returns an empty list.
We can also specify our tag using supplementary attributes: class, style, and so on... The typical structure of such specification is shown below.
We have changed our variable a little bit by adding the second parameter, a dictionary specifying the text style of elements. The keys of this dictionary are attributes of tags.
Another method connected with tag searching is soup.<tag> where <tag> is any tag you may need to find. This structure returns all the content between an opening tag and a closing tag. In the next example, the result is the content between <head> and </head>:
If there are several tags with the same name, the method will return only the first occurrence.
Text and link extraction
Now we know some basics of HTML and beautifulsoup, it is time to extract all the necessary data. Earlier, we have learned to create a variable with lists of <p> tags.
Now, to process all tags in this list, you can use a for loop for iteration and the text method helps to get text data.
Each p.text returns a text paragraph from the page.
There is another helpful method that can be used to get tag attributes. Let's get hyperlinks while working with link tags. After collecting hyperlinks, we can use them for further requests and collecting related data. The developers of beautifulsoup also allow users to extract links using the get() method. Just write down a quoted attribute of the tag you need to extract in round brackets.
Summary
In this topic, we have learned the main operations with beautifulsoup:

How to create a parse tree,
How to search for tags,
How to extract texts and links.

We have also got acquainted with the basics of HTML. beautifulsoup seems to be elaborate at first, but after some practicing, you will get used to this library and soon you will be able to collect rich varieties of data. Find more onbeautifulsoup in the official Beautiful Soup Documentation.
"
113,Comments in HTML,554,7502,686,https://hyperskill.org/learn/step/7502,"In HTML files, you can write a special text which the browser will ignore when opening the file. Such text is called a comment. Why write it if in the end it is simply and deliberately ignored? Actually, it makes a lot of sense to use comments during the development process, as they can greatly improve the readability of your code. A comment in the HTML code can be generally defined as follows: Any text placed between  and  will be considered a comment. The text of the comment can be placed either in a single line or several lines. Now let's take a closer look at some specific examples of how comments are used and what purpose they serve. Single-line comments Comments that occupy one line are called single-line comments. Take a careful look at the syntactic features of single-line comments: The result in the browser will look as follows: As you can see, the comment text is not displayed in the browser window. It is invisible for visitors of web pages but can be very useful for developers. With these notes you can easily remember later why some particular code fragment is needed. Comments can also serve as hints for other developers who will work with your code later on. Multi-line comments Comments that take up several lines are called multi-line comments. Take a look at their syntactic features: In the browser it will look like this: Such comments, as suggested by their name, occupy several lines. This may be useful for explaining some particularly complex sections or disabling large parts of the code. Disabling code fragments With comments you can make the browser hide specific parts of the code. Take a careful look at this example: Here is how it would look in your browser: Some tags aren't displayed in the browser window, but they can be made ""visible"" by deleting the characters  and . This process is called uncommenting. Temporarily disabling the code is a good strategy when you need to find a bug. It's quite inconvenient to just remove the code because you may need to restore it, so comment/uncomment is a great solution. Code editors often have special key combinations (shortcuts) to quickly comment and uncomment. You can find them in the documentation for the code editor that you're using, but usually it's CTRL + /.
"
114,Basic INSERT statement,765,9059,687,https://hyperskill.org/learn/step/9059,"You are getting more and more familiar with databases. Let's take it a step further! To use a database, you should know how to insert new records into a database table. In this topic, we'll show you how this can be done in SQL.

Basic INSERT statement
You can insert a new record into a table with a simple query using INSERT INTO statement.

For example, let's add a record about a new customer into the table customers with columns name (VARCHAR(20)), surname (VARCHAR(20)), zip_code (INT) and city (VARCHAR(10)).

Our new customer's name is Bobby, his surname is Ray, his ZIP code is 60601, and he lives in Chicago. The query below will insert this information into the table:

As you can see, what you should do is write a list of values to be inserted after the keyword VALUES.

Once we have executed this query, our table customers will have a new row:

If you know the exact order of the columns in the table, you can use the shorter version of INSERT INTO query without specifying the column names.

In this case, our previous SQL query can be rewritten like this:

Insert multiple rows
If you want to insert multiple rows, you don't have to add them one by one: you can add multiple rows simultaneously.

Let's add two more rows to the table customers:

In this example, we wrote two comma-separated lists of values instead of just one.

Insert into specified columns
Sometimes you have to insert a record with some missing values. Assume we have an empty table cats with columns name (VARCHAR(20)), age (INT) and owner (VARCHAR(40)). None of these columns have a default value.

We want to add information about a three-year-old homeless cat Felix. Since Felix doesn't have an owner, we can skip this column in our INSERT INTO query.

As a result, the table cats will have one row:

The owner column value for the first row will be NULL since we didn't specify it.

If a column has a default value and you skip this column during the insertion, its value will be set to default.

Conclusion
Here is a template for a basic INSERT INTO statement:

This notation means that one tuple of values is always necessary, others are optional.

When you know the order of columns and want to insert values into all the columns, you can follow the shorter INSERT INTO statement template:
"
115,Basic DELETE statement,767,9075,688,https://hyperskill.org/learn/step/9075,"You already know how to insert data into tables. However, in real life we don't just collect records, sometimes we want to get rid of them. Let's find out how we can delete rows from a table with SQL queries.

DELETE statement

To delete all the data from the table but not the table itself, use a query with a DELETE FROM statement.

For example, let's delete all the information from the following table titled books:

We can do that with a very simple query:

As a result of the query execution we still have the table books, but it is empty now.

Delete selected rows

You can also use DELETE FROM statement to delete only selected rows from a table.

Let's assume that we have added a few new rows in our table books:

As you can see, some books from the table are unavailable (their quantity equals zero). We can delete records about these books with an SQL query with a WHERE clause:

This query will delete all the rows from the table books where the logical expressionquantity = 0is true.

After we execute the query, our table books will look like this:

Conclusion

The following query can be used to delete all the rows without deleting the table:

If you want to delete only selected rows, you can use this template:
"
116,Introduction to logging,360,5538,689,https://hyperskill.org/learn/step/5538,"Introduction

Imagine you are investigating a robbery and are trying to figure out what happened. You have witnesses whose testimonies are very vague, but there is no evidence. It will be very difficult to unravel such a mess. If only there were recordings from surveillance cameras to restore the chronology of the events...

So now, let's say you are investigating a bug, but what 'surveillance cameras' do you have in that case? Obviously, we need records of everything that happened with the program before the incident. Also, it would be nice to know during which operation it happened. All such records are usually kept in a log. So what is a log?

Log

Logging refers to the act of recording during the execution of an application. Logs are records that give us information about the events in a software application. This record could be a message that is enough to understand the event that happened, it may include a timestamp, a description, and a severity level. These events could be user-generated or system-generated. We use either a log file or, sometimes, the standard output to make these records.

We need logging for several reasons. Firstly, it will save a lot of time when we are troubleshooting our application at a later stage. If the program, for example, broke or something went wrong in it, then we can find the exact moment at which the error occurred in the log. This makes the debugging process a lot easier. Secondly, it is also possible to trace who used the program with the log. If it is, say, a site, one can find out who sent the requests. Also, logs help to monitor the operation of a particular system, which makes verification and reporting a whole lot easier. This way, we are always aware of how our programs work and how well they perform.

There are several things to consider when logging: when do we log? what do we log? how do we log? Let’s find out the answers to these questions.

When, What, and How

As we've mentioned above, there are several common reasons to generate logs:

*   troubleshooting
*   auditing
*   profiling
*   statistics

What we log usually depends on the application. In any case, we should be able to understand the execution path of a program through the logs. It is important to avoid excessive logging as it is costly. For example, there's no need to log the start and the end of every method, their arguments, since they are easy to track. Logs are meant to cover server issues, database issues, networking issues, errors from unanticipated user inputs, states of dynamically created objects, configuration values.

Providing contextual information in your log messages is very important as well. Often, the success or the failure of a program depends on the user inputs. So, you need to put them in your log messages if necessary. For example, when authenticating a user, log the username that is inputted. Context is also important when your program runs in a concurrent environment. In such a case the thread name can be added to the log message.

Log levels

We said earlier that a lot of important information can be added to the log file. But what kind of information is it? There are different types that correspond to the accepted logging levels: Debug, Info, Warn, Error, Fatal (from the least critical level to the most critical one).

Let’s see what those log levels are for.

Debug logs are used to diagnose applications. Debugging messages inform us about what the program is doing at a certain step and what it gets as a result of these actions. For example, a message can contain information about the output of some function, so that we can see if it should be fixed.

Info is used to log important information about an application. It is used to log service start, service stop, configurations, assumptions. For example, the information about the user who has just registered on the website.

Warn logs are considered to be the first level of application failure. They are usually applied to log repeated attempts to access a resource, missing secondary data, or switching from a primary server to a back-up server. For instance, there can be a message about a possible disconnection with the server. However, it does not affect the user at this point.

Error log level is used for more critical problems. These kinds of issues usually affect the result of the operation but do not terminate the program. Errors are considered to be the second level of application failures. For example, there can be a message that a user could not log in because the database was temporarily unavailable.

Fatal is the third level of application failures. It is used to indicate a much more serious error that causes the termination of the program. Such a message may say that the program totally failed and depending on the time and conditions of this failure the developers can find out how to fix the problem.

Great, now we know what bugs are usually written into the log file. Now we need to display the log. But what should be displayed? In order to make the log readable and understandable, there is a special recording format. Let's find out more about it below.

Log Format

To investigate a bug, we need to know when it happened, how serious it was, and who came across it. Thus, the log format generally looks like this:

\[date time]\[log level]\[message]

So, it starts with the date and time of when the error occurred. Then comes the log level, and the last thing is the message with the explanation of what exactly happened. More specifically, if we, for example, want to monitor who registers on our site, we need the corresponding logs with Info log level. Then every time a user sends data to the site, we will log a message about this event. For example, on February 2, 2021, a user with the nickname 'demo' registered on the site at 3 pm. Then the log will look like this:

\[2021-02-02 15:00:00] \[INFO] User 'demo' has registered

And if some user named 'alex98' cannot log in because of some technical issues, we will receive an Error message:

\[2021-02-02 01:00:10] \[ERROR] User 'alex98' cannot log in because the database is temporarily unavailable

Thus, we will know that user 'alex98' failed to log in due to our database being temporarily unavailable. We have localized the problem and know exactly what we need to do: check the database and fix it. There is also a more complex version of this format called The Common Log Format.

Conclusion

So, we've figured out what logs are and what they are for. We've also learned what types of logs there are and how we can issue a log message. Now you can start using logs to monitor the operation of your system at any given time.
"
117,Introduction to SQLite,1176,12165,699,https://hyperskill.org/learn/step/12165,"Why SQLite?

SQL databases can be handy even in the simplest applications. However, running a database system like MySQL or PostgreSQL requires installation, configuration, and maintenance. Sometimes it can be unsuitable for us or even forbidden. In such cases, SQLite comes to the rescue.

Contrary to the typical database running as a separate process, SQLite takes a different approach: an application embeds the database code within itself, so there's no need for a separate database process. Issued SQL statements read and write the files directly on the local disk. The database with all the tables and metadata is contained in a single file. The database file format is cross-platform, thus the file can be copied and used on a different machine with a different architecture. Despite competing with regular files, SQLite can be used as a backend database to a web application. It’s also safe to access the same SQLite database at the same time from multiple applications and processes.

SQLite is one of the most widely deployed databases in the world: it's built-in on each Android and iPhone device. Let’s see it in action!

Basic Usage

In order to install and use SQLite, you need to add its dependency to a package manager or build system of your choice (Gradle, pip, npm). After that, you will be able to use regular SQL libraries to access the database.

We won't stick with any particular programming language and will explore SQLite using its command line interface: sqlite3. Calling it with a database file name as a parameter will start an interactive session with that database. If the database file does not exist, it will be created. Let’s create a new edu.db database and populate it:

Upon finishing an interactive session we see a new edu.db database file. By starting the session again, we can verify that the data was saved:

Running queries in a terminal can be inconvenient, so you can use such UI tools as sqlitebrowser instead.

Typelessness

Most SQL databases use static typing: the type of the value inserted into a column should match its column declaration type. You can’t insert a string value into an integer column. SQLite uses dynamic typing, which means that you can store any kind of value in any column, regardless of the column type. Even declaring column types is optional (however, it's desired since it helps others to understand the structure of your tables). The following definition will work fine:

SQL statements working in statically typed databases work the same way in SQLite, despite its dynamic nature. You can find out more about SQLite types in the official documentation.

Conclusion

In this topic we've figured out that using SQLite requires almost no effort. The only configurations you need are read and write permissions for the database file. The database code is bundled within an application accessing the database. Furthermore, we've taken a look at the dynamic nature of the SQL schema allowing you to store values of any type in any column.
"
118,Hashing: overview,886,9831,700,https://hyperskill.org/learn/step/9831,"Hashing is a technique widely used in programming. Whether you send a message over the internet, log in to a website, or search for a file on your computer, you are using hash functions! But what are they and what do they do?

What is hashing?

Formally, hash functions are functions that we can use to map data of arbitrary size to fixed-size values. That's quite vague, so let's look at a real-life comparison to understand them better:

Imagine you have a friend Paul who keeps a phone book. Your friend is lazy and doesn't want to spend a lot of time writing the full names of his contacts. So, instead, Paul writes only the consonants in their names. For example, instead of John Smith, Paul writes Jhn Smth. In quite a few ways, this process is similar to hashing. We can consider that ""remove all vowels"" is the hash function. We call the result of applying a hash function to some input a hash value, or simply its hash. In our case, Jhn Smth is the hash value of John Smith. Now, not all hash values will be distinct: think about two people with names Tim Black and Tom Black. The hash value for both of those names will be Tm Blck. When this happens, we call it a collision.

The main difference between our example and a real hash function is that, in our case, the hash values do not have a fixed size. A more accurate example would be if Paul wrote the first 5 letters in their names. The hash value for John Smith would be John S, for Tim Black it would be Tim Bl, and for Tim Blacksmith, it would be Tim Bl too. There are more names than possible ways to write 5 letters, so we are guaranteed to have collisions. The same thing is also true for hash functions. They take input that can be really big and return something of a fixed size, so there is no way to completely avoid collisions!

Applications of hash functions

As we mentioned in the beginning, hash functions have many applications. Let's look at a few of the most important ones:

Message digests

Say you have a message that you want to send to a friend over the internet but are afraid that someone might change its contents before it reaches your friend. One of the things you can do is to compute a hash value for your message before sending it. When your friends receive it, they compute the hash value of the message using the same hash function as you. You can then compare the two hashes and check that they are equal. Hash functions used for this have the property that it is hard to find collisions. Such hash functions are called cryptographic hash functions. They can have other properties too, like the one in the following example.

Password Storage

Ever wondered why websites don't have an option to send you your password in case you forget it, and they make you reset it? To be able to send it back, they have to store it in plain text. By doing so, if someone gets access to the password database, they can easily steal all the accounts! What websites do is to store a hash of your password. When you send the password to log in, they compute its hash and check if it is equal to what they have stored. In this case, finding collisions is not such a big problem. Here, you need to know that if someone finds the hash of your password, they should not be able to find out your password from it.

Hash tables

A more common use in day-to-day programming is hash tables. They are fast and convenient data structures that use hashing. With them, you can search, insert, or remove elements from a table. The main idea behind them is that you want to use hash values to index data in an array. For example, if you want to use a hash table to store a phone book, you can save the pair (Tim Black, 0123456789) at index Tm Blck. Then, to find Tim's phone number, you only have to search at index Tm Blck. After that, you can also save (Tom Black, 9876543210) at the same index and, whenever you need to find Tim's or Tom's phone number, you only have to search between two pairs, rather than the whole phone book. Hash functions used in hash tables are less restrictive than the ones used for message digests and password storage, and their hash values are, generally, numbers. We will look closer at hash tables in the following topics.

Conclusion

You now have an idea about hashing and hash functions, what they are and where you can use them. This should be more than enough for now to emphasize their importance. In the next topics, we will study in more detail hash functions, hash tables, and collisions.
"
119,Slicing,434,6177,705,https://hyperskill.org/learn/step/6177,"Python provides the ability to access individual elements of lists, strings, and tuples by using indexes. It is possible because these types are considered ordered sequences.
Take a look at a list containing Fibonacci numbers. We can print out any number from the sequence. Don't forget, indexes start from zero, not one:

Getting sections of sequences
Another thing you may want to do with a sequence is retrieving its part. Usually, it means getting elements from a particular section by their indexes. This is called slicing, and there is a special notation for it. It looks like accessing an element by its index, but in an improved manner:

Looks great, doesn't it? Just like with the indexing, we use square brackets, but here we add a colon to indicate that we're slicing. Actually, slicing is one of the most famous and widely used features of Python. It allows developers to do a lot of cool things.
Pay attention to the end index: it is not the index of the last element of the slice, but rather an index of the first element that is NOT in the slice (i.e. excluded index)! So the last element is not included.
A string can also be sliced:

In the same way, slicing can be applied to tuples. We hope you can try it on your own.
There's another interesting thing to note: if you set the end index higher than the last element of the sequence, no Error would be raised. Instead, all elements up to the end will be taken:

Now, we will explore slicing in more detail with the help of lists.
Forms of slicing
We've demonstrated the use of slicing with starting and ending indexes. But this is not the only possible form.
The full syntax for slicing looks like this:
sequence[start:stop:step]  # from start to stop-1, by step
This statement produces a slice of the sequence where start is an index of the first needed element (the element is included in the slice) and stop is an index of the last element (the element is not included in the slice), step is an interval between elements to be chosen.
Let's slice a list of planets picking every second planet. We start from the third (with the index 2) planet and stop at the seventh (with the index 6) one. The eighth planet (with the index 7) is not included in the slice.

Each part of the slice has a default value, so it can be omitted. If we don't specify the start index, it is considered to be 0; if we don't specify the stop index, it is equal to the length of the sequence. The default step is 1, i.e. every element between the beginning and the end is put in the slice.
Here's what happens if we slice without specifying some indexes:
sequence[:end]    # elements from start to end-1
sequence[start:]  # elements from start to the last element
sequence[:]       # the full copy of the sequence
sequence[::step]  # every element with a given step
Let's take a look at some examples to make understanding more practical.

An interesting way to use slicing is to create a copy of the sequence using [:] notation.

Indexes can also be negative. We saw this before when we accessed a single element: it means counting from right to left and starting at -1. So, when the step value is negative, the elements are returned in reverse order.

If you're using negative step with the positive start and end indexes, those should be chosen accordingly, that is, the start index should be greater than the end index!

We hope you get the general idea of slicing now.
Conclusion
Slicing allows you to get sections of sequences such as lists, strings, and tuples specifying start, end and  step. Remember that all the indexes are optional in the slice syntax because there is a default value for all of them.
In some sense, slicing is just an extension of the standard indexing with similar rules: the first index of a sequence is zero, and negative indexes start from the end. We believe, that after a bit of practice, you will be good at it.
"
120,Datetime module,547,7324,716,https://hyperskill.org/learn/step/7324,"Often, in our projects, we need to work with dates and time. For example, we may want to track the current date and time or see how long our code runs. For these purposes, we can use the datetime module. Let's look closely at what we can do with it.

datetime module classes
The datetime module has several classes that make working with time easy:
datetime.date represents standard date;
datetime.time represents standard time, independent from the date;
datetime.timedelta represents the difference between two points in time;
datetime.tzinfo represents timezones;
datetime.datetime represents both time and date together.
In this topic, we'll focus on the datetime.datetime class.

datetime.datetime
The datetime.datetime class is a sort of combination of the date and time classes. Similarly to those two, it assumes the current Gregorian calendar and that there are exactly 86,400 seconds in each day.
The constructor of the datetime.datetime objects takes the following parameters:

The year, month and day parameters are required, others are optional. All arguments (except tzinfo) should be integers and just like in real life, their values are restricted:
datetime.MINYEAR (1) ≤ year ≤ datetime.MAXYEAR (9999);
1 ≤ month ≤ 12;
1 ≤ day ≤ number of days in this month and year;
0 ≤ hour < 24;
0 ≤ minute < 60;
0 ≤ second < 60;
0 ≤ microsecond < 1,000,000;
fold in [0, 1].
The tzinfo argument can be an instance of the datetime.tzinfo class, but its default value is None, so we don't need to worry about it here.
To see how this all works, let's create a datetime.datetime object. For example, the date and time of the first human going to space which took place on April 12, 1961, at 6:07 UTC:

datetime methods
The datetime.datetime class has several very handy methods.
If you need to get the current time and date, there are two methods you can use: datetime.datetime.today() and datetime.datetime.now(tz=None). They are very similar and the only difference between these two methods is that datetime.datetime.now() has a keyword argument tz. If you don't specify it, the two methods work the same. However, in some cases or on some platforms, the datetime.datetime.now() method may be more precise.
This is an example of how they perform:

You can also transform a datetime.datetime object to a datetime.time or datetime.date objects using datetime.datetime.time() or datetime.datetime.date() methods respectively:

datetime.timedelta
Thetimedelta is a class defined in the datetime module that represents the difference between two dates or times. It allows you to perform various operations on date and time intervals, such as addition, subtraction, and comparisons. A timedelta object represents a duration, not a specific point in time.
The constructor of the datetime.timedelta object takes the following parameters:

Here are some examples of using timedelta:

Now: 2023-07-23 18:50:06.392339
Future: 2023-07-28 22:20:06.392339
Past: 2023-07-18 15:20:06.392339
delta1 is smaller than delta2
The task duration is: 8:45:00

Remember that timedelta is useful when dealing with durations and time differences, while the datetime class is suitable for representing specific points in time. Together, they provide a powerful toolset for working with date and time in Python.
Summary
To sum up, in this topic, we've familiarized ourselves with Python datetime module, its datetime.datetime class and some of the methods it has. Those were just a couple of methods available in the datetime.datetime class. There are many more: the ones that deal with timestamps or timezones or the ones that help parse and convert datetime objects. Don't worry, you'll have a chance to work with them in the next topics!
"
121,Nested lists,509,6938,728,https://hyperskill.org/learn/step/6938,"A list in Python may contain any objects as its elements, including other lists – they are called nested lists. Here are some examples of nested lists:

Accessing elements of nested lists
Like with regular lists, elements of a nested list can be accessed by indexes. Note that the nested list still counts as a single element in its parent list.

In this example, we obtain the second element of numbers by index 1. This element is the nested list [2, 3]. Then we print the second element of nested_numbers by index 1. This element is 3.
It is also possible to access an element of a nested list without an additional variable using a sequence of square brackets.
Basically, we go deeper from the outer list to the innermost when indexing. Naturally, if we ask for an element at the level that doesn't exist, we'll get an error:
Just like when we try accessing an element that doesn't exist at the level that does exist:

Matrices
Nested lists are a convenient way to represent a matrix. For example, the matrix

might be represented as:
Note that in such a list lengths of all nested lists must be the same, and they are equal to the dimension of the matrix.
When we want to extract an element from the matrix, e.g. element M[1][2] = 6, the first index selects the row, and the second index selects the column. However, as you know, it differs from mathematical representation in that numbering here starts from zero, rather than from one.
Nested list comprehension
To iterate over nested lists, we can use nested list comprehensions. It is basically a combination of two or more list comprehensions and it is quite similar to nested ""for"" loops. To illustrate basic syntax for this kind of comprehension, let's consider an example.
Imagine a school as a list of classes and the classes are lists of student names.
If you want to create a list of all students in all classes without the list comprehension it would look like this:
Alternatively, we can also use a comprehension with a double for loop, then it would look like this:
In both cases the result is going to be the same:

In this case, the order of the for loops is the same as in the notation with indentation: first the outer loop, and then the inner loop.

However, such a method may be less clear than the one without list comprehension, especially in cases when we need to use more than two for loops: it can make the code unreadable and counter-intuitive.

Consider the following line of code:
It’s not that easy to understand what the created matrix will look like. Compare to when we will put it this way:

It is much more readable, and now it is clear that the matrix will look like:
It's important to bear in mind that shorter code does not imply better one, so you shouldn’t misuse list comprehension when working with nested lists.
Summary
To sum up, lists as such are a very useful type of container in Data Structures, and now you know how to store multiple inner lists inside an outer one, reach them, represent matrices with them, and use nested list comprehensions.
"
122,Copy of an object,791,9268,729,https://hyperskill.org/learn/step/9268,"Often you need to have several copies of the same object. You already know that assigning one variable to another does not create a new object, instead, the new variable refers to the same object. For immutable objects, e.g. strings, it is enough: you can easily access and change variables independently of other variables. However, with mutable objects, if you assign one variable to another and then modify an object using any of these variables, it will affect both variables. This is so because with immutable objects, each time you try to modify them, a new object is created. Mutable objects, in contrary, are modified in place. Think, what if we want to copy a mutable object and alter the original without changing the copy? In this topic, we will learn to do so.

Copy a mutable: shallow copy
To copy an object, we can use shallow copying, it is often used with mutable containers. As you know, mutable containers, e.g. a list, store references to objects that store values. With shallow copying, we can create a copy of a list that contains the same objects, but the reference to a container will be new.

There are two ways to do this. The universal way is to use the copy function from the copy module, it works with any object.

Also, some containers such as list, set, dictionary have the copy method which can be used instead of the copy function.

There is an another method how to make the shallow copy.

In all these cases, a new list is created that stores references to the same objects.

Now, if we change one list, this will not affect the other one.

The modified list will store a reference to a new object:

Not so simple
Let's now see another example with a dictionary. When we use shallow copying, the values stored in a dictionary are not copied (look at the result of the id function):

The thing is, when we use shallow copying, only the container is duplicated but the elements remain the same.
However, you might want to copy the elements as well. For example, when elements of a list are lists themselves and you want to modify them without changing the copy. Here is how a shallow copy works without copying  inner elements:

In this example, the copied list new_lst is a new object that, however, contains references to the same lists as the initial lst. So, when we change the list that is an element of lst, we also change it in new_lst.
 

Note that there is only one object that stores number 5 because Python reuses objects containing small integers for the sake of memory usage optimization.

 
Let's see how to create a copy of a list that doesn't share its elements with the initial one.
Copy a mutable: deep copy
The deepcopy function from the copy module creates a clone that doesn't relate to the initial object.

If the given object is a container that stores references to other objects, this function recursively copies those objects as well, not only references to them. As a result, a new container with new elements is created.

 

You can notice that the deepcopy function doesn't copy objects that contain integers. Again, this is because Python tries to optimize the use of memory. Since integers in Python are immutable, this doesn't create any problems.

 
Now you can modify the initial object as you like and this will not affect the copy.

Using a deep copy may sound as a perfect solution whenever we want to copy an object: why bother about mutability if we can just use copy.deepcopy()? However, the deepcopy function has a problem: it consumes a lot of memory because it duplicates the entire structure of an object. Shallow copy uses less memory, so it's better to make sure that changing one of the copies will not affect the rest and use the shallow copying in this case.
Summary
The copy function duplicates the container but not the items in the container. It consumes less memory comparing to the deepcopy function, but might create problems because the copies share their elements.The deepcopy function creates a copy of the container and also recursively clones all items in the container. The resulting copies are independent but this requires a lot of memory.
"
123,Openpyxl,1322,12751,732,https://hyperskill.org/learn/step/12751,Error extracting text: 504 Deadline Exceeded
124,Collections module,906,10014,738,https://hyperskill.org/learn/step/10014,"The collections module provides data types similar to the built-in Python collections but with advanced features. You may have encountered some of them before, but in this topic, we will talk about collections.OrderedDict, collections.namedtuple, and collections.ChainMap.

collections.OrderedDict
OrderedDict is a dictionary-like object that remembers the order of the given keys; it never changes them. Starting from version 3.7, a built-in Python dictionary preserves the order too, so OrderedDict is now less important. However, there are still some useful features that make a big difference, we will discuss them in brief. OrderedDict was intended to be a better version of the dictionary in reordering operations and it lives up to it!
Let's say we want to create an OrderedDict with names of students as keys and their average grades as values. The order in the dictionary is strict, from the most successful student to the least one, and is to be preserved as such. To do so, we can either use the OrderedDict constructor or get the OrderedDict from a regular dictionary:

The example with conversion is relevant only to Python 3.7 and higher where the information about the order is already remembered in regular dictionaries. In earlier Python versions, this procedure would make no sense, as the order of elements in the dictionary we want to convert is arbitrary.

As OrderedDict resembles a regular dictionary a lot, we will only point out the methods that set them apart.
1. While the popitem() method applied to a regular dictionary takes no argument, the same method for the OrderedDict can take an additional boolean parameter last. If last=True, the last key-value pair is returned and deleted from the OrderedDict, and if last=False, it is applied to the first pair.
2. The move_to_end() method takes arguments as a key and, again, the last parameter. If last=True, the key-value pair moves to the end of the OrderedDict, and if last=False — to the beginning.
3. Finally, there is a difference in how the dictionaries are compared. With OrderedDict, two dictionaries are considered equal only if the order of their elements is the same, while with two built-in dictionaries, the order does not matter.

collections.namedtuple
collections.namedtuple is a factory function to make subtypes of tuples with named elements. To create a named tuple, we first invoke the namedtuple function and then use the result as a template for our future items.
In the example above, the subclass 'Person' is created. Its field names 'name', 'age', and 'occupation' are in one list, but they can also be defined in one string, separated by spaces or commas: person_template = namedtuple('Person', 'name, age, occupation') or person_template = namedtuple('Person', 'name age occupation').
Once we have the subclass, we can use the same template to create named tuple entities:

Note that the subclass name itself, 'Person' in our case, cannot be used to create instances; if we try to do so, a NameError will occur:

Instead, we should always use the defined template, person_template.
A new named tuple can also be created from a list:
Named tuples allow us to replace field values with new ones, and we can see what fields are present in it. To do this, we should use the _replace() and _fields() methods:

Note that the named tuple is immutable, just as regular tuples. This means that when we _replace() a field value, a new object is created instead of changing the existing one.

Finally, we can get an ordered dictionary out of named tuples with the help of the _asdict() function:

collections.ChainMap
Now, imagine you have created several dictionaries and want to analyze them and work with their data at once. Updating elements simultaneously in all dictionaries is not as easy as you would prefer, so the best decision is ChainMap. It allows you to make a collection of your dictionaries and, as a result, you will perform all operations on a collection instead of each separate dictionary.

You can access every item by key, as in the example below. You will get the value of the first key with the given name. If you change a value in one dictionary, this information in the chain will be changed too.
Speaking of methods, we can use usual dictionary methods and some peculiar ones to work with the chained objects. For example, there is the new_child() method that allows you to add another dictionary in your chain, and you will get a new structure with another dictionary added:
The maps method allows you to get access to a certain dictionary by its index:

The method parents gets rid of the first dictionary and returns the rest:

Note that the methods new_child and parents do not change the chain itself, they return a new object, so if we want to work with them further, we need to assign them to a variable.

Conclusion
In this topic, we've seen how OrderedDict is different from the regular dictionary, how you can work with namedtuple to store different data in one place, and how ChainMap can be used.
To sum up,
collections.OrderedDict's popitem method differs from the one in the dictionary by having a parameter last, and there is one more method move_to_end which changes the position of the item given to it;collections.namedtuple keeps diverse information about an object, and any field containing this information can be accessed by name;ChainMap serves as a container for several independent dictionaries and allows you to work with them at once.
For additional information about OrderedDict, namedtuple, and ChainMap you can check out the official Python documentation. We hope that you'll use these objects and methods in your projects!
"
125,Introduction to Functional Programming,2785,27661,739,https://hyperskill.org/learn/step/27661,"Functional programming is a programming paradigm that treats functions as first-class citizens. In functional programming, programs are constructed by composing and applying functions. Key properties of functional programming are:
Using pure functions and immutable data types,Avoiding side effects.
A pure function, like a mathematical function, takes an input and returns a value without any intermediate manipulations. For example, \(sin(x)\) simply returns a value. You give it a value of \(x\), and it returns the value the sine of it. If you give it the same value you will always get the same answer.

Unlike pure functions, python functions can set a global variable that might influence the result of a different function when that is called. It might write something to disk, or send some data across the network. These influences are called side effects.

As you can see in the above code, the function instead of doing some computation and returning the output changes the value of the global variable \(x\). The change in this value is the side effect.
Python is prone to side effects and constructing functions that aren't pure, but certain constructs make functional programming possible. They are:
First-class functions,Immutable data types.
First-class functions
Everything's an object in Python. Every variable, every function or method, boolean values, and even the None value is an object. The following code demonstrates it:

As you can see, everything in Python is an object of a certain class.
Since functions are objects in Python, just like any variable, they are:
Created at runtime,Assigned to a variable or element in a data structure,Passed as an argument to a function,Returned as the result of a function.
Functions being a first-class entity in Python allow us to create complex functions that can take other functions as input or return a function as output. These functions that either take a function as an input or return a function as output are called higher-order functions. Some common higher-order functions in Python are:
map();filter();reduce()
In the above code block, notice how the map() function takes addition, another function, as its input.
A more common example of a higher-order function is a recursive function. A recursive function calls itself in the body of the function and returns the function. The function below uses recursion to compute the sum of natural numbers up to \(n\).

Immutable data types
Data types like tuple, namedtuple, str, and int, the values that we cannot modify, are called immutable data types. These data types play a central role in functional programming because they can't be modified and hence prevent side effects in a function.
Conclusion
Functional programming is a programming paradigm that treats functions as first-class citizens.Functional programming uses pure functions and immutable data structures to avoid side effectsFunctions in python are just like any other object. They can be passed as arguments to other functions and can be returned as the output of the function.Immutable data types can't be modified.
"
126,JSON,503,6854,741,https://hyperskill.org/learn/step/6854,"JSON (or JavaScript Object Notation) is a text-based format for storing and transmitting structured data. Although it originates in the JavaScript language, it is still considered to be language-independent: it works with almost any programming language. JSON's lightweight syntax allows you to easily store and send everything from numbers and strings to arrays and objects to other apps. You can also create more complex data structures by linking arrays to each other.

Basic syntax and structure
JSON text can be built on one of two structures:
a collection of the key:value pairs (associative array);
an orderly set of values (array or list).
JSON objects are written in curly braces {}, and their key:value pairs are separated by a comma ,. The key and the value in the pair are separated by a colon :. Here is an example for you:

Here, you can see some user data in JSON format.
Keys in an object are always strings, but values can be any of seven types of values, including another object or array.  Note that you should not put a comma (,) after the last key:value pair.

Again, the value in the array can be of any type, including another array or object. Here is an example of an array:

Most often, an array will include similar elements. JSON does not support comments.

Nested objects
JSON is a highly flexible format. You can nest objects inside other objects as properties:

The data has a tree-like structure if objects and arrays contain other objects or arrays.
The nested objects are fully independent and may have different properties:

But in practice, such objects often look similar.

camelCase vs. snake_case
If you have read the JSON objects examples carefully, you might have a lingering question: what style of compound word writing should be used for JSON? CamelCase is a style where compound words are together without spaces, but each word inside the phrase starts with a capital letter. The style is called camelCase because the capital letters inside the word resemble camel's humps.
With snake_case style, compound words are written with the underscore. The right choice of JSON naming convention depends directly on your programming language and libraries. You can use both camelCase and snake_case; any choice will be valid but do not mix them in one JSON.

JSON advantages
JSON is a widespread format for data exchange on the Internet because of its strong advantages:
compactness;
flexibility;
high readability, even for people far from programming;
most programming languages have functions and libraries for reading and creating JSON structures.

JSON is a popular format for transmitting structured data over a network. When you serialize data to JSON, you can easily deserialize it back without losing any information. One of the main advantages of JSON over plain text is that it allows you to describe relationships between objects through nesting and key-value pairs. Many of the websites you visit likely use JSON as well.

Other popular applications of JSON are data storage and configuration files for other programs.

Conclusion
Now, you have seen that JSON is easy to understand and use, and it's fantastic since it's a handy tool for transferring data between applications. In working practice, you probably won't have to create JSON files yourself; you will get them from other sources, but if you want to save the code on your computer, save the files to the .json extension.
Read more on this in What is data scraping and how to do it right on Hyperskill Blog.
"
127,Introduction to Linux,851,9526,751,https://hyperskill.org/learn/step/9526,"Linux is a family of operating systems that use the Linux kernel. Widely spread, they provide many convenient tools for developers. Besides, Linux concepts became a source of inspiration for many ideas in programming languages.
The mascot of Linux is a penguin named Tux:The choice of this symbol was not coincidental. Linus Torvalds, the creator of the operating system's kernel, had a similar toy in his childhood.
A brief history of Linux
Linus Torvalds, a Finnish software engineer, created the Linux kernel in 1991. He based his development on the UNIX operating system, which was popular at that time among many organizations and scientific institutions.
The first version of the kernel turned out to be very raw, with many defects and errors, so Linus decided to publish the source code openly on the Internet. As a result, many people got interested in Torvalds' idea and took part in the development of Linux. They started sending their improvements and corrections of the bugs found in the code.
Distributions
By itself, without software, the kernel is completely useless. However, it can be a basis for developing operating systems. Since the Linux kernel was posted free of charge, everyone could customize the system according to their needs and wants. Thus, it gave rise to distributions. Distribution is one of the operating systems based on the Linux kernel with many pre-installed programs, sometimes with a Graphical User Interface (GUI) out of the box. You have probably heard of some of them at least once: Ubuntu, Fedora, Debian, Arch Linux, Gentoo. This is far from a complete list of all the existing distributions.
Commonly used distributions
Besides having some specific knowledge, you can build your own distribution, both from scratch or on the basis of already existing projects.
Where and why people use Linux
Linux kernel is free, customizable, very reliable, and undemanding to resources. Thanks to the well-thought-out file system, you can run distributions without a GUI. It also has extensive hardware support, as all free Linux drivers are built into the kernel. The scope of Linux is vast, much larger than that of all other operating systems. It works perfectly on ordinary personal computers, as well as on servers, embedded systems, and network software. Most of the supercomputers in the world work with Linux, for example, CERN. Even Android OS is based on the Linux kernel.
Such a large range of supported devices means excellent portability of programs. Often, we can run the same application on both an ordinary computer and a Linux-based smartphone with minimal effort.
Conclusion
So you took the first step in studying Linux. You have learned its benefits and realized how, with community support, it has become a major operating system on millions of devices.
Linux can provide a modern, stable, multiuser, and multitasking environment that will cost you nothing. All you have to do is pick the right distribution and, if you wish, customize it to suit your needs.
"
128,XML,505,6901,759,https://hyperskill.org/learn/step/6901,"XML (eXtensible Markup Language) is a text-based format for storing and exchanging structured data on the Internet. In this format, the data is presented as documents with a clear and flexible structure. An XML document can be stored on the computer with the .xml extension that is often used to keep configuration files of programs.

At this moment, XML is one of the most popular formats around the world, used both by small startups and huge companies. XML is especially valued for being very expressive for people and easy for machine processing.

Tags and elements
Each XML document consists of tags and elements.
A tag is a string with an assigned meaning like a book, a person or something of the sort. It is interesting that XML does not provide tags at all, but it gives developers an opportunity to invent tags independently.
An element is a building block of an XML structure: it may contain text, tags, other elements and attributes.

This document has three tags enclosed in angle brackets: <book>, <title> and <author>.
By element we understand the combination of a starting tag with the corresponding ending tag together with their content. Elements set the structure of a document since they can be nested in each other.

Our document has the following elements:
<book>....</book> contains two other elements;
<title>The Three-Body Problem</title>
<author>Liu Cixin</author>
All elements should have a closing tag (a similar tag, but with a slash / in front) or just end with a slash (/>). Here's an example of using an unpaired tag: <picture name=""sun""/>.

The first line in the XML document is called a prolog:
It specifies the version of the XML standard (usually 1.0) and defines the encoding (here it's UTF-8). The prolog is optional, but if it's there, it must come first in the document.

Note that a prolog does not have a closing tag!

Child elements
Each XML document always has a single element called root. This element can contain other elements called child elements which in their turn can have their own children.

Here, the root element <library> has two children <book> elements, while the elements <title> and <author> are the children of <book>. So, XML documents represent hierarchical structures that are often used in programming.

Attributes
XML elements can possess attributes that provide additional information about the element.
The value of the attribute is always set in either double or single quotes. For example, the name of a picture can be written as follows:<picture name=""The Black Square""/>
If the value of the attribute contains double quotes, you need to use single quotes. For example: <picture name='""Sunset at Sea"", Ivan Aivazovsky'/>
Sometimes, you can also see quotes replaced by special entity symbols (&quot;):<picture name=""&quot;Sunflowers&quot;, Vincent van Gogh""/>
An element can contain more than one attribute:<picture name='Sunset at Sea' author='Ivan Aivazovsky'/>

As you can see, in some cases, attributes can replace child elements. There is no consensus about what's better to use. It usually depends on the data you are trying to model, your tools for XML processing and, of course, the people you work with.

Note that an element can have both attributes and child elements together.

Pros and cons of XML
XML has won popularity due to its apparent advantages:
it can be easily understood by machines and people alike;
the format is based on international standards;
it has a well-defined structure which facilitates the search and extraction of information;
modern programming languages have libraries for processing XML documents automatically.

At the same time, XML has an important disadvantage. Its redundant syntax causes higher storage and transportation cost. This is especially important when we need to store or transfer a large amount of data.

Conclusion
In summary, XML is a format for saving and transferring data as documents with the .xml extension. The main components of these documents are tags, elements, and attributes. Keep in mind, though XML has its advantages like a well-defined structure, using it with a large amount of data could sometimes be inefficient due to its verbose syntax.

Now that you have learned the basic principles of XML, it is time to put your skills to practice!
"
129,Data and object mapping,652,8262,768,https://hyperskill.org/learn/step/8262,"Programming languages may include primitive types, classes, and data structures to store information. If you want to modify an object or interact with it somehow, you would probably prefer to do it in your favorite programming language. As a developer, you use tools you're familiar with. In the local environment, you can complete most of your tasks this way. However, to communicate with other systems and to store data persistently, you need to convert your local types to a commonly used data representation.

Data mapping
Assume that you are developing a social network service. Every moment, some users search for a friend, and the service should reply with some information about other users in the network. We represent each person as an instance of the Person class in the code. Let's stick to a simple diagram to avoid using any specific programming language:The problem arises when you want to retrieve information about a person from the storage you use. Relational databases often play the role of storage but in the form of tables and relations between them. Luckily, you're not the first person who faces the task of converting one common data type to another. Just find a library for data mapping, and it will help you a lot. Data mapping is matching fields of source data representation to the fields of its destination. In our case, the source is a database, and the destination is the Person class, but the operation can also be applied the other way around. In other tasks, we could use other mappings for the Person class and convert it to/from JSON, XML. We use data mapping to convert the information from one type to another, but we don't synchronize the data changes over time by default, we only want a different view at a particular moment.

Object Mapping
The structure of data in the source system may be different from the structure of data in the destination system. We could store the information about the name in one place and the information about the age in another because retrieving data to Person class is not the only purpose of the storage. For complex operations like this one, we need a more appropriate instrument such as object mapping.Object mapping is matching data between complex objects, including their behavior and the source system.The most commonly used example is ORM (Object-Relational Mapping) when the data from relational databases is matched with the classes in object-oriented languages.The main distinction between data and object mapping is that object mapping not only stores data but also emulates the behavior of an object and reflects changes in its source system. As a developer, you can call methods of the class, and data mappings will change at the same time. In short, object mapping is like data mapping, but with high-level control over changes.

The life cycle of mapping
To see what is data and object mapping in action, let's continue our work with the social network. We receive a query with some name and look for it in our data storage. As soon as we find an appropriate result, we retrieve the information about the person from the database. We fill the class instance with the result of the search.Now our class is only a data container and nothing more, and this action is an example of data mapping. If we store the object in the database, it's a reversed example.The age of a person changes over time, but the storage is not aware of such changes, so we implement a method that adds a year to the age attribute:After the age is changed in the instance of the class, the value in the storage becomes outdated. If we want to mirror it, we should put some effort into working with the storage, then we need to synchronize the information. This can take place in the same method or we can define another one for it.This operation refers to object mapping; we are not only changing the object but also synchronizing data for it. Now our object has actual information in the storage, too. Synchronization is one of the important features of mapping; we want to have a definite representation of an object in our language and in the storage it uses. However, it's not obligatory to synchronize objects every time we change them. Sometimes it's more efficient to accumulate all the changes before the synchronization.

Conclusion
We have learned two new concepts: data mapping and object mapping. We use data mapping to match data in two different systems, and we use object mapping to represent more complex objects and to add control from one system to data in another.
"
130,Object-Relational Mapping (ORM),656,8312,769,https://hyperskill.org/learn/step/8312,"A programming language can be used to process data from one state to another. If you want to save the state of data permanently, some kind of storage is required. You would normally use a relational database for this purpose, but there's a problem with this approach. Programming languages and databases work with data differently. Relational databases also have their own language called Structured Query Language (SQL).Luckily, we're not the first people in the world to encounter this issue. There is a technique known as Object-Relational Mapping (ORM) that helps solve the issue. Almost every programming language includes an ORM library. So let's uncover what ORM is all about so you can start using it!

ORM enables you to convert data from an object-oriented programming language into the format used by a relational database and vice versa. It solves the problem of matching two different system types together and synchronizes data flow between them.

The main parts of ORM are virtual tables, relationships, and operations on objects. In the following sections, you will look at what these elements are and why they are necessary.

Relational databases use tuples and tables to store data. Most programming languages have tuples but don't have tables. So, how can someone represent tables in a programming language?

The main idea is to use classes as table descriptions. You can create a class as a virtual table that represents a particular table in the database. Then, use or define methods for this class that make it possible to retrieve, change, and delete data.

To represent a single row from the table, you can define another class (some libraries use the table class itself for this purpose) and match its attributes to the table's columns. An instance of this class can manipulate both the row's values and its relationships.

Let's look at an example where a class represents a City. The table's columns match the class's attributes. In this example, name is a string, while longitude and latitude are numbers.

As you know, a class can also have attributes that represent lists of other objects. For instance, a city may have lots of streets. This format doesn't fit naturally with attribute-to-column mapping, but ORM provides ways to handle these cases too. In a relational database, the link between one row and several other rows is called a one-to-many relationship. This is similar to a class instance that has a list of objects as an attribute.

A relationship is a link that connects a value from one table to a row in another table. The database can store such links as keys. You can think of them as objects containing another object as an attribute.

Database relationships are more than simple links, though. When you delete the root row from one table, it can cause cascade deletions of all related rows in other tables.

Deleting a row from a table in a database will remove all its elements. If your database has a table called City that contains the row London, you can expect all related rows in the table Street to disappear when the London row is deleted. A street belongs to a city; without the city, there are no streets!

A programming language could either represent the above example as a class instance called City containing a list of streets or as many instances of a class called Street, each containing a City attribute. However, if you delete a street with a city value, the city will stay in the database. This is because database relationships are directional. Cascade deletions cause the removal of rows that are dependent on the table that has been deleted.

The four most common database functions are known as CRUD (Create, Read, Update, Delete) operations. They are similar to those that can be carried out on objects in programming languages.

Once you're familiar with tables and the relationships between them, you can begin to control them using an ORM library. These libraries usually provide high-level commands that look like those used for working with any other objects in the programming language. Understanding how databases are structured can help you to avoid corrupting the data they contain. Reading an ORM library's documentation before using it is highly recommended. Doing this can help you get acquainted with the effects and consequences of using its operations.

If you're still unsure whether you should use ORM in your projects, considering the pros and cons will help you decide.

Pros:
You can work with a database in the same way that you write code for other programming languages.
The library frees you from understanding SQL and the specifics of the SQL dialect used by a particular database.
Code that uses ORM is usually easier to read, write, and maintain.

Cons:
Sometimes ORM libraries generate inefficient database queries.
It can be hard to control the generation of queries.
You can't use all the features and strengths of a specific database.
You still need to learn how to work with the library itself.

If your project needs a database, it's normally good practice to start by using ORM. Taking this approach is a sensible move because it's still possible to work directly with the database further down the line if you realize that you want greater control. In most cases though, ORM will provide everything you require. To start working with an ORM library, you can consider SQLAlchemy for Python, Hibernate or JPA for Java/Kotlin, and Sequelize or TypeORM for JavaScript.

ORM makes it possible to interact with a database in an object-oriented way. Most programming languages have an ORM library that you can use for this purpose.

The main elements of ORM are virtual tables, relationships, and operations on objects. A key concept to remember is that class instances are used to represent tables and their rows.

Using an ORM library is usually the simplest way to add a database to your project. But you still need to be familiar with the library itself to do this effectively. To avoid corrupting data, it's important to understand how databases are structured before controlling them with this technique.
"
131,Intro to SQL Alchemy,1348,12935,770,https://hyperskill.org/learn/step/12935,"You can find a lot of useful applications to make and modify your own database on the Internet: Microsoft Access, MySQL, SQLite, Oracle, and so on. We can also use Python for that. SQLAlchemy is a powerful set of Python database tools. In this topic, we are going to overview the main features and connect our first database.

SQLAlchemy features
SQLAlchemy was released in 2006 and quickly became one of the most popular object-relation mapping (ORM) tools among Python developers. When we use an object-oriented programming language, it is important to think in terms of objects. SQL is not based on the object-oriented model, it is based on a relational model instead. This gap between the two model types can be overcome with the help of the ORM provided by SQLAlchemy.

You can use a model that takes a database and a Python program to transform the information from the database to Python objects, and vice versa. As a result, thanks to SQLAlchemy, we can work with objects and at the same time employ important database mechanisms.
Database API
SQLAlchemy is designed to work with different databases and Database APIs (DBAPI). Python Database API Specification is a standard for Python libraries that lets you connect any database. SQLAlchemy is not the only library that can connect databases, there are dozens, but all of them follow this standard. The standard specifies the functions that help you connect to a database, send queries, and get results. All the specifications are regulated by PEP 249.

SQLAlchemy uses different dialects to work with different DBAPI implementations. It supports the following dialects: MySQL, Oracle, Microsoft SQL Server, PostgreSQL, and SQLite. All dialects require an appropriate Database API driver.
Setup
Use pip to install the library:
Now you can start working with the database. In this topic, let's deal with a local database that was created in SQLite. You can download it here. Here's what it looks like:

The database is called Building_Database.sqlite. It contains information about buildings in an imaginary city: addresses, construction dates, heights, number of dwellers, number of floors, and the year of the recent renovation.
To connect to it using SQLAlchemy, we need to create an engine and choose the right database dialect. You can do it with the help of the create_engine() function. Don't forget to import the library in advance:

Inside the function, we need to specify the name of the dialect and write down the database name. As we connect to a local database, the URL format is slightly different. It requires three slashes. The echo attribute enables logging using the standard logging module. The Official SQLAlchemy Documentation contains more information about creating an engine for other dialects.
Now you can easily connect to the database. Just use the following statement:
Great! You are connected to the database.
Working with an existing database
Let's try to work with that database. For example, let's print the names of all database tables.

Additional information is on the left before the tables: the date and time of the command, the SQL command query, and so on. If the echo attribute is False, you won't be able to see it. Then, the names of the tables are printed as a list, even though there is only one table in our database.
 
 

Sometimes you can face the warning which informs you about the deprecation of table_names(). To avoid this warning, you can use a so-called inspector described in the Official Documentation.

 
 
Another important part of SQLAlchemy is reflection. Reflection means that you can get access to a database and get information on any SQL table objects already existing within the database. Take a look at the following code:

The ""Buildings"" table is already defined in our database, and now we want to see its structure. To do so, first of all, we need to import MetaData and Table. MetaData is a catalog that stores the database information such as tables, columns, and so forth. To reflect this data, we can use the MetaData() object. After that, use Table() and write down the name of the table that you've obtained previously. We can also specify the metadata variable to make it autoload a table using the SQLite engine. The final step is to use the repr() function. It will allow you to view the data about the table:

Summary
In this topic, we have discussed the basics of SQLAlchemy. Now, you can:


install the library and connect to the existing database of any dialect;


print the list of tables that are in your database;


print all information about the existing columns.


If you want to learn more, please, take a look at the Official Documentation. Right now, let's proceed to practical tasks.
"
132,Type casting,440,6224,787,https://hyperskill.org/learn/step/6224,"Computer science, like any other science, actually, has lots of theory attached to it. It never hurts to be familiar with some fundamental theoretical knowledge about a programming language you're learning or already using in practice. It might help you to understand the language better or the difference between several ones. In this topic, we'll learn some theory about types in Python and see how it works in practice.

Dynamic vs. Static typing
Python is a dynamically typed and strongly typed language. Dynamic typing means that only runtime objects (values) have a type, but not the variables that store them. You are able to store several values of different types in a single variable during your code execution and no errors will occur.

On the other side, in statically typed languages each variable has a type that cannot be changed during the runtime, so the code above would fail. Examples of statically typed languages are C++, Java, and Go.

Strong vs. Weak typing
Strong typing means that implicit type conversions don't happen. For example, even though ""125"" consists only of digits it's a string. To use it in arithmetic operations you need to change its type to an integer or another numerical type. Trying to use it as is leads to a TypeError.

If Python had a weak type system, such value could be interpreted as an integer to successfully perform the operation. Such behavior, when one of the operands is implicitly converted to the type of another operand, is called type coercion.

Since there is no type coercion in Python, the same operand may give different results depending on the types of provided arguments. For example, you can add two strings to get a concatenation. It is also possible to multiply a string by an integer:

The example also shows that you can print values of different types if you separate them with commas in the parentheses. The print() function will print all the arguments delimited by a space.

Explicit type casting
The process of converting a value to another type is also called type casting. Though implicit type casting is almost not allowed in Python you will often find yourself in need to define an explicit type conversion within your code. This happens a lot when you work with the user's input.

Imagine you are adding two numbers, one of which has int type and the other has a float type. In this case, during the addition operation, int type will be converted to float, but the variable itself will not change its type. This example is shown in the code below.

Imagine you asked a user to provide an age that you will later use in some calculations. To convert a string to integer type you can use the built-in int() function. This is an example of explicit type casting.

The type function is used to find out the type of the value provided.
To cast an integer to the string type use the str() function:

As you noticed, to cast a value to some type we use the function with the same name. If conversion between two types is not allowed you will see an error. Except for the str() and int() functions we covered above there is also a float() function. It converts a given value to the float type.

Here are some more examples of casting between different types:

It is important to remember that you can cast the value of any type to a string in Python. This fact is often used for debugging purposes.

Summary
This topic explores the nature of Python's type system, highlighting that it is both dynamically typed and strongly typed. Dynamic typing means that variables do not have fixed types and can change type at runtime, unlike static typing where types are checked at compile-time. Strong typing ensures that operations on incompatible types result in errors, preventing unintended type coercion, as opposed to weak typing which allows implicit type conversions. Python also supports explicit type casting, allowing developers to manually convert data types to ensure the desired type compatibility and behavior.
"
133,Command line arguments,615,7981,789,https://hyperskill.org/learn/step/7981,"Using the command line is sometimes very useful in the programmer's work. And Python scripts can be run from the command line just like its regular commands, e.g. ""cd"" or ""mkdir"". This means we can write a module that can take data as input, do something with it, and return the result. In this topic, we'll see how we can make that happen.
Running from the command line
As an example, let's take a module that multiplies two numbers and nicely prints the result, and run it from the shell:
In the line above, python is kind of a command that indicates that the Python interpreter should be used for the following script. In some cases, the system may already know how to run .py files but we will not go into details here and, for the sake of consistency, will use the python command throughout this topic.
Then, separated by a whitespace, follows the script name. Note that if the script is in another directory than the one you are working from, you should specify the path to the file. It may be an absolute path:
Or it can be a relative path, for example to run a script from the parent directory:
Finally, if the script takes any arguments, they are written separated by whitespaces after the script name.
And that's it! However, the next question is – how can we get access to the specified arguments from our Python script?
System module
To do so, you can make use of the sys module. It provides access to functions and variables that can work with the underlying Python interpreter, regardless of the OS you're using. We won't go into details talking about its features, but rather focus on the one that is the most important right now, namely, sys.argv. It performs the very operation we need: collects the arguments passed to the python script.
By calling sys.argv, we get arguments specified by the user as a list of strings. Indexing, as always in Python, starts from 0 but the first argument, sys.argv[0] is the name of our Python script as it was invoked – either the name itself or including the path to the file. The items that follow are arguments that can also be accessed by their index. Take note that they are strings, and if we need a numerical value, we should perform type conversion.
Let’s write a simple program multiply_two_numbers.py:
Checking the input
It is also worth mentioning that if we expect to get a specific number of arguments (i. e. almost always), it is a good idea to check the length of sys.argv in the program. Let's check that in our script multiply_two_numbers.py:
So, this is what our script will look like from the command line:

Within the IDE
Let's take a look at PyCharm's capabilities in comparison to the command line. Instead of manually writing the script name and arguments each time, you can set them in the configuration. For this in the Run area select Edit Configurations to open the Run/Debug Configurations dialog. 

If you do not see a similar area in your IDE, then make it visible through View -> Appearance -> Navigation Bar. You can read more on how to do it in the JetBrains documentation.
Congratulations, you got into the Run/Debug Configurations! In the Parameters field, we can set the arguments that we would write in the command line separated by whitespaces.

 Save changes and run the script. The output would be as expected:
Now, instead of running the module from the shell as python multiply_two_numbers.py 3 5 and passing arguments each time it is called, you can set them in the Parameters field and just run the program in PyCharm.
Summary
We have learned how to run Python scripts from the command line, how to get access to the passed arguments from the program itself, and that it's important to check that the arguments are what we expect them to be. We also got acquainted with PyCharm's capabilities for specifying script arguments in configurations. This knowledge will definitely help you in your further programmer's path!
"
134,XML in Python,844,9481,790,https://hyperskill.org/learn/step/9481,"As you know from previous topics, XML is a format that stores data in a hierarchical structure. An element is a building block of XML and it consists of a starting tag, the corresponding ending tag, and its content. Now, we are going to learn how to work with XML in Python.

Getting ready
There is a built-in Python submodule called xml.etree which can parse XML. However, we will use another library, lxml, and its same-name submodule etree. The reason is that the latter submodule processes XML documents faster, and the core of this library is written in C language.
Since it is an external library, you should install it first:
Then, import the etree module in your code. If you use PyCharm, you can write this line without installing lxml, and the IDE will suggest installing the library automatically.
We will work with two classes from this module: Element and ElementTree.
An instance of the Element class represents one element in the XML document. It stores information about the tag name, attributes of the tag, and references to child elements.ElementTree represents the whole XML document. It contains some general information about the XML document such as its encoding and the version of XML and also has a reference to the root element of the document.

From text to XML
Let's see how to parse XML documents: they can be parsed from a string or a file.
To parse a string, just call the fromstring() function that returns the root element of the document.

To parse XML from a file, use the parse() function. It returns an instance of the ElementTree class, so you should use the getroot() method of this class to obtain the root of the document.

Also, it might be useful to print your XML document so you can look at it. For this, there is the dump() function. It takes an element of the XML document and prints it with all its content in a beautiful way.

Now let's see how to traverse an XML document and access the information in it.

Traversing the XML tree
Since the important information is often not stored in the root element, you should be able to access child elements. In the lxml library, it is very convenient because the Element class imitates well-known Python lists. Let's see an example.
First, we parse an XML document and print it to understand its structure.

A child element can be accessed by specifying its index among other subelements in square brackets. Our root element, <country>, has three child elements: <name>, <capital>, and <states>. The tag containing the country's capital has the index 1 (remember that indices start from 0), so you can access it in way:
The structure of the entire XML document behaves like a collection of lists where each list except the root is nested into another. So, to print all states of the US that are mentioned in our document, we should first get the <states> element and then iterate over all its subelements. This can be done in the same way as when working with lists:

Note that when an element contains text, it is stored in its text attribute.

Accessing attributes
The data is not necessarily stored as raw text inside tags, there are also attributes storing some information inside the starting tags.
Let's load a new XML document with the information contained in attributes.

The Element behaves like a list when we try to access its subelements. But when we want to get attributes of a tag, the element works like a dictionary. The get() method is used to access the specified attribute. If there is no such attribute, it returns None. Note, that unlike a dictionary, you can't specify the attribute in square brackets.

The keys() and items() methods can be used to get all attributes of a tag:

From XML to text
Finally, after getting all information we need, we can save an XML document.
The function tostring() takes an element and returns a bytes object that can be later saved to a file.

The method write() saves an instance of ElementTree directly to a file. If we have worked with an XML Element, we should convert it to ElementTree first.

Summary
An element of an XML document in the xml.etree module is represented by an instance of the Element class.Work with Element as with a list if you want to access its subelements or as with a dictionary to access the attributes.Methods fromstring() and parse() are used to import XML objects from a string or a file, while methods tostring() and write() allow us to save XML objects back to files.
"
135,Regular expression,577,7580,791,https://hyperskill.org/learn/step/7580,"Manipulating text data is quite a popular task in programming as well as in real life. For example, we often may need to analyze a text, find all specific strings in a file, and so on. Processing text data can be quite a challenging problem. That's why there is a special tool called regular expressions that makes it easier and faster.

Why regular expressions?
A regular expression (regex or regexp for short) is a sequence of characters that describes a common pattern for a set of strings. Such patterns can be used to search, edit, and manipulate texts. They can either check if a whole string or its substring matches the given pattern or replace the substring with another one.

When do we need such patterns? Say we want to obtain all the files with the same extension (like .pdf), or extract all the entries of a particular name in different forms (for example, Edgar Poe, Edgar Allan Poe, E. A. Poe, etc.), all email addresses, or even find all numeric structures denoting dates (02/03/2020). With regexps, such tasks can be done in one line.

How do such patterns look? Well, at first, they may seem confusing, look, for example, at \d+(\.\d)?  or [a-zA-Z]. And they're often substantially longer. We'll start with the basics, though. Regexps may be regarded as a kind of sublanguage that most programming languages support, but there are some differences in syntax called ""flavors"". In this topic, we will consider regexps in isolation from programming languages to understand the general idea.

While learning this topic, you can visit the regexp site to play around with regular expressions from our examples. Choose PCRE as the flavor. It means Perl Compatible Regular Expressions which are the most common standard in practice.

Matching on examples: more PARKs
Let's start by exploring how matching works formally. Although a regex pattern can be quite a complicated expression containing characters with special meaning, the simplest regex is just a string of simple characters. Suppose, there is a set of words: PARK, SPARK, PARKING, MARK, QUARKS. You need to check which of them contain the word PARK. This is what happens, for example, when you perform a Ctrl+F search on a web page.

We can easily solve this problem using the PARK pattern. The pattern means that symbols P, A, R, K in a word must follow each other from the left end to the right in a word. We suppose that the whole word matches the pattern if any part (substring) of the word matches it.

Here are some explanations:
the word PARK exactly matches our pattern;
the word SPARK matches our pattern because it has a suitable substring;
the word PARKING matches our pattern due to the same reason;
the word MARK doesn't match our pattern because of the letter M;
the word QUARKS doesn't match our pattern since it does not have a suitable part that matches PARK.

To sum up, only three words match the PARK pattern. In regular expressions, the case of characters is relevant: park is not the same as PARK, i.e., they do not match. In addition, let's consider another sequence of characters PAKR. It does not match our pattern since the two characters are in the wrong (reverse) order.

The power of regular expressions
Finding substrings is not very impressive, though. The real power of regular expressions comes when you start using special metacharacters called wildcards. They allow you to define a pattern, so you can match strings that do not necessarily contain an identical sequence of characters. You can skip some characters in a string or match different characters in the same positions, or even repeat a character several times.

Let's introduce the two simplest wildcards: dot and question mark.

The dot character
The dot character . matches any single character including letters, digits, and so on, except for the newline character, unless it is specified. Let's look at our previous example again with several additional words.

As you remember, in the previous example, two words did not match the pattern because of one unsuitable character. Let's consider them and also add two additional words. Here is our new pattern .ARK with the dot character. It says: ""there is any character followed by ARK"".

Hooray, both words MARK and QUARKS match the new pattern! But the WARM word does not. Think for a minute, how can this be fixed?

Tip: The answer is to use the .AR. pattern, which is matched by WARM, CLARA, PART, and so on.

The word ARK also does not match our pattern, since it does not have a character in the . position in the pattern, while it is required.

The question mark
The question mark ? is a special character that means “the preceding character or nothing"". The question mark ? signals that the character before it can occur once or zero times in a string to match the pattern. When can we use it?

Maybe with this example, you will finally begin to feel the magic of regexps. Consider the difference between British and American spelling. Imagine, we are trying to find all the studies mentioning color blindness in some publications' archives. However, it contains different sources and their spelling may vary. What word should we look for? The answer is both!

The pattern colou?r will match the strings colour and color, but not the string coloor. It is also possible to include the possibility of different letter cases to match the uppercase ""Color"" as well. We will learn how it is done in later topics.

Let's return to our previous example. The word ARK does not match the .ARK pattern. But if we add ? right after the dot character .?ARK, the word ARK will match the new pattern since the first character is optional now.

Note how we combine the powers of the different wildcards in the combination .?. It is an underlying idea of regexps as well.

Conclusion
Regexps allow you to find matching strings by a certain pattern. They use special characters with special meanings along with simple characters in their literal interpretation:
the dot . character matches any single character except for \n;
the question mark ? character means ""the previous character can be absent from the string"";
regular expressions are case-sensitive.

We hope that you now see that regexps provide a powerful tool for processing strings and texts. With this, we conclude our introductory topic about them. Remember that there are many more applications of regular expressions that we have not yet discussed.
"
136,Regexps in Python,837,9468,793,https://hyperskill.org/learn/step/9468,"A regular expression is a sequence of characters defining a search pattern, that is, a pattern describing a set of strings. These patterns are used for searching and editing text, replacing one substring with another, and so on. The simplest example of using a regular expression is when we search for some word in a text file or on a web page. For example, if we look for the word ""python"", the string ""python"" becomes a simple regular expression — a search pattern that corresponds only to the word ""python"" and nothing else. More complicated regular expressions will be able to match a larger number of strings.
In the previous topic, we've already learned the basics of regular expressions common for all programming languages. Now it's time to see what are the specifics of using regexps in Python.
Re module and match()
You can use the power of regexps if you refer to a standard Python module called re. That is, to use anything related to regexps in Python, you must first import this module.
This module provides you with several functions that search for matches for your regular expression in different ways. Let's get familiar with one of these functions, match(). It accepts a regular expression pattern (first argument) and a string (second argument) and checks whether there's a match for the pattern in the beginning of the string.
If there's no match for your regexp right in the beginning of the string, match returns None value. Otherwise, the function returns a special structure called match object that will contain the information about the found match. We won't go into the nature of this object right now: all we need to know is that a match object is always a result of a successful match, and None is always a result of no found matches. Thus, to know if we have a match, we simply need to check whether the result is equal to None .
Let's try out some other examples! Here, there's a successful application of match() function:
Don't forget that match() won't help you with finding parts of the string that match the template, but aren't located in the beginning of the string. Check out this example:
You might also want to note that even if the match is an empty string, match object will still be equal to True, because the length of the matching string doesn't matter: only the presence of match does.
The example above suggests that you should be careful with empty templates: even though it may seem counterintuitive, they don't match only empty strings, they match all strings (at least, when you use match() function and check the presence of matching substring in the beginning of the string).
Don't forget that regular expressions by default are case sensitive, that is, it's important whether you use upper or lower case letters in your template. Two identical letters of different case won't match each other.
Alright, now that we know the basics of how the re module can be used in Python, we can talk about more complicated examples of regexp patterns.
The dot character
Regular expressions wouldn't be so useful if they could only correspond to one particular string. The true power of regexps lies in the possibility to state the presence (or absence) of some characters in the regexp pattern without even specifying these characters directly. The dot character . is one of the most important special symbols allowing to do this. It literally matches any single character, e.g., any digit, letter, space, and so on, except for the newline character \n.
Let's take a look at some examples. Here, match() will successfully find a match:
On the other hand, these examples will result in None:
Let's also recall another useful special character that we've already learned, that is, the question mark.
The question mark
The question mark ?, unlike the dot, doesn't replace any character by itself. It is a quantifier that basically means ""the previous character can be absent"". In other words, the question mark ? signals that the character before it can occur once or zero times in a string to match the pattern.
Of course, you can use the combination of the dot and the question mark. In this case, it'll mean that the string can contain either any single character or nothing.
Even these two basic special symbols, the dot and the question mark, will give you great regexp power. But remember, with great power comes great responsibility. We'll learn to handle this responsibility (and make the dot character match only itself) in the following topic.
Summary
Here is a recap:
For handling regular expression in Python, the re module is used.The match() function of the re module checks whether there's any substring in the beginning of the string that matches your regexp template.The result of the match() function is either None or a match object.A match object converted to bool always equals True.Regular expressions by default are case-sensitive.Dot . replaces any character except for \n; question mark ? means that the previous character is optional and can be missing from the string.
"
137,Escaping in regexps,877,9754,794,https://hyperskill.org/learn/step/9754,"You already know that in the language of regular expressions some characters, like the dot and the question mark, have special meaning. This way, the dot will match not only itself, but also almost every other possible character, while the question mark won't match itself at all. But what if we want to use such characters in their literal meaning? What if we want the dot to match nothing but the dot? Well, in this case, escaping comes to our rescue.

Escaping through backslashes
To use a special character in its literal meaning in your regexp, you need to put a backslash \ before it: \?, \.. The backslash \ is a so-called escape character, it helps symbols to ""escape their work duties"". However, the backslash is used as an escape character not only in regular expressions, but also in Python itself (it is the first character in such escape sequences as \t and \n). So, it's possible, though not necessary, to escape the first backslash with another backslash \ . For example, \\? and \? in the regular expression both correspond to ? in a string, while\\. and \. correspond to a single dot . in a string. Take a look at how it works in practice:

The first backslash to the left of the escaped symbol tells regular expression to treat ? or . as characters without special meaning, and the second backslash (if present) tells Python to not treat the first backslash as a start of some Python's escape sequence. Here's a less formal example showing the application of the escape symbol in regexps:

So far the escaping in regexps seems reasonable, right? But wait, there's more.

Backslash plague
Things get worse when you want your regular expression to match a literal backslash. Since a backslash is a metacharacter both in the regexp language and in Python, you have to escape it with three other backslashes, which will result in a cumbersome regexp: \\\\. The last backslash here is the backslash you want to match; the second backslash from the left serves as an escape character for the regexp language; the first backslash serves to ""escape"" the second one in Python syntax; the third one serves to escape the last one in Python syntax. Check out these examples:

SyntaxError in the second example is raised because the regexp template consists of one Python's escape symbol and one backslash. So, this backslash is left unescaped in the regexp, and regexp interprets it as an escape character, but there's nothing to escape, because no character is following this backslash.
By the way, there are no problems with matching default escape sequences whose notations coincide in Python and in regular expressions language:

Using a bunch of backslashes probably doesn't seem convenient to you, and you are completely right. Fortunately, there's a way to deal with them.

r prefix
To partly avoid the mess created by backslashes, you can always use the r prefix in your strings, for example:

The r prefix is a raw string notation prefix: it tells Python to cancel the usage of escape sequences in this string and treat all backslashes in their literal meaning. For example, the string r'\t' will be treated by Python as a combination of a backslash and a letter t, not as tabulation. This way, you'll only need to use backslash as an escape character for regular expressions. Here's an example:

You can't use r prefix with already existing strings: that is, you can't create a raw string from a variable. r prefix is only used when you write the value of your string by hand.
There's also a quick way to escape all special characters in your regular expression: re.escape function. Let's take a closer look at it!

re.escape
re.escape function can help you escape all special characters in your string automatically, without placing backslashes in the regular expression by yourself. This function takes a string with your regular expression as an argument and returns the same string but with necessary backslashes placed before every dot, question mark, and other regexp metacharacters. That's what it looks like:

The string stored in the escaped_template variable, actually, contains two backslashes, i.e. it looks like 'hyperskill\\.org': the first one is the Python's escape symbol and the second one is a simple backslash added by re.escape to escape the dot in the regular expression. When the escaped_template is printed, however, only a single backslash is left since the Python's escape backslash is no longer needed: it has already fulfilled its duty by showing that the following backslash is not a Python's metacharacter.
By the way, whitespace is a metacharacter too. It's not like it has any special meaning or function, but backslashes are always placed before it.

re.escape is useful when you want to match an entire string in its literal meaning. This doesn't happen often, though, since the power of regular expressions language lies exactly in its special symbols. So be careful: if there are any special symbols that you want to perform their duties as usual, don't use re.escape.

Note that re.escape escapes nothing but regexp's special characters only if your Python is updated to the version 3.7 or higher. If you're using earlier versions of Python, re.escape puts backslashes before every non-alphanumerical character, including, for example, !, <, >, @, etc., even though they only have their literal meaning in regexp language. However, these redundant backslashes don't change the result of the match function, since a single backslash in a regular expression never matches itself: it simply ""cancels"" the special meaning of the following character; if there is no special meaning to cancel, the backslash basically doesn't do anything at all.

Summary
In this topic we've learned that:

To use regexp's special characters like the dot and the question mark in their literal meaning, we need to escape them with one or two backslashes.
Backslashes are also used by Python's own syntax, so we can use single or double backslashes in regular expression to escape most metacharacters, but we need to use double backslashes to escape backslash itself.
To cancel backslash's escape function in Python, we can use r prefix before the string. This helps to avoid the need to use multiple backslashes for escaping.
To backslash each special character in the template automatically, we can use re.escape function.
"
138,Regexp sets and ranges,911,10035,795,https://hyperskill.org/learn/step/10035,"In the previous topics, we have learned about the dot and the question mark in regexp language, the ways of escaping them, and other regexp metacharacters. Now it is time to learn about these metacharacters and how they function.
First of all, let's start with the sets.
Sets
While the dot allows us to match almost every possible character, the sets provide us with the opportunity to be more specific in our regexp templates and narrow down the scope of our search. Each set in the regular expression takes the place of exactly one character in the string, but it defines a whole number of characters that can match it. These characters are listed inside the square brackets, []:
In the template above, we have two defined sets. The first one corresponds either to a character b or d in the string, the second one — to t or d. Here are the results for some of the possible strings:
An empty set causes an error:
An unescaped left square bracket, for which no unescaped right square bracket was found, causes the same error:
By the way, good news, everyone! There is (almost) no need for boring escaping stuff when we use sets in regexp.
Escaping in sets
Sets in regular expressions have a sort of superpower: they automatically ""neutralize"" the metacharacters listed inside the square brackets, turning them into regular characters. This way, the dot and the question mark, for example, do not have to be escaped if they are part of a regexp set:
The only metacharacters that do not fall under this rule and keep their special status are, predictably, the right square bracket ] and the backslash \. The right square bracket should be escaped to show that it is a part of the set, not the metacharacter denoting its end:
The backslash in sets, like everywhere else, serves as the starting symbol of escape sequences. So, if you just want to have a backslash in your set, you have to relieve it from this burden by escaping it using double backslash. Here the backslash is escaped and matches itself in the string:
Here the backslash is not escaped and serves as a part of the escape sequence:
By the way, you can still escape any character in the set (even if it is not ] or \): this won't change the set of matching characters. But additional escaping characters will make your regular expression more difficult to read and understand, and, believe us, this is a thing to avoid — real-life regexps are usually barely comprehensible even without unnecessary characters.
Apart from ""ordinary"" regexp metacharacters, there are, though, some characters that acquire a special meaning specifically when they're used inside the square brackets.
Ranges
One of the main things about sets is that you may not only list the characters individually but also use ranges of characters. A range is designated by a dash -. For example, if you want your set to match every letter from a to z, you do not have to list out the whole alphabet, you can simply write [a-z].
[0-9] does it for the digits. Note that regular expressions match characters, not numbers. So, the template [1-100] matches only 1 and 0, not all numbers in the range from 1 to 100.
Several ranges can be easily put in one set. They do not have to follow each other in any way:
The characters that fall within the range are determined by ASCII / Unicode encoding table, so be careful when defining ranges: they may include something unexpected or exclude something that was meant to be in your set.
To use the dash - as a regular character in a set, you should ""strip"" it of the left or right character defining the range, so just put the dash in the first or last position in the set, [-abc] or [abc-]:
Take a look at the table summarizing some of the ranges you might want to use in your programs:
[a-z]Lowercase Latin Letters[A-Z]Capital Latin Letters[a-zA-Z]Both Lowercase and Capital Latin Letters[0-9]Digits
Sets can also be handy in case you want to ban characters from your template. Let's see how this is done!
Exclusion of characters
The hat (aka the caret) ^ symbol is also a specific set metacharacter: whenever it is placed as the first character in the set, it makes the set specify the characters you do not want to see in the string. Any character that is not a part of such set will match it:
The hat placed anywhere else in the set, except for the first position, will lose its special meaning and become a regular character:
That is pretty much it about sets. Four metacharacters associated with them are easy to remember, but can turn you into a real regexp wizard!


Just in case you forgot: there are a lot of websites where you can test your regular expression, see what could be wrong with it, and correct it. For example, Regex 101 works just fine.

Summary
Let's see what we have learned in this topic!
the square brackets [] are used to designate sets in regular expressions;the sets are used to specify the number of characters to match;only the backslash \ and the closing bracket ] should be escaped in your sets;the dash - allows us to easily put a range of characters in the set;a set with the hat ^ in the first position matches every character that is not listed in it.
"
139,Shorthands,922,10142,796,https://hyperskill.org/learn/step/10142,"Previously, you have learned about sets and their most helpful and powerful features of regular expressions. Since some of them are more widespread than others, special shorthands were designed to make them easy to use. The general formula for shorthands is the backslash \ followed by a letter (for example, \s). Let's take a closer look at these metacharacters.
Shorthands for sets
Like sets, each shorthand represents one character in the string, but which character matches the shorthand and which one does not, depends on the shorthand. There are two types of shorthands that can be used in the place of character sets. Shorthands of the first type correspond to strictly described and limited sets of characters. The shorthands of the second type are negated shorthands; they correspond to sets banning certain characters, matching to anything else.
Shorthands of the first type are denoted by a backslash and a lowercase letter:

\w matches alphanumeric characters; in the general regexp language, it stands for a character from the set [a-zA-Z0-9_] . However, in Python, this shorthand is even more useful since it also matches all Unicode ""letter"" and ""word"" symbols apart from classic Latin letters (matches symbols such as ß, ê, 是). Pay attention to the underscore character _  in this set and the absence of the hyphen -, which theoretically could be there.
\d matches a digit and is equivalent to [0-9].
\s matches the whitespace characters, such as the usual space character, the tabulation, the newline character. This shorthand is equivalent to [ \t\n\r\f\v] (pay attention to the first character (the space) – it is easy to overlook).

The letters chosen for these shorthands can be easily explained and remembered: w is for word, d is for digit, s is for space. 
Negated shorthands are the total opposites of the first type. There is a ""symmetrical"" shorthand for each of the shorthands mentioned above, and they are denoted by a backslash and the very same letters, only in uppercase:

\W matches everything except for alphanumeric characters, [^a-zA-Z0-9_] in the general regexp language (in Python, other Unicode ""word"" special symbols are also added to this set) 
\D matches any non-digit character, [^0-9]
\S matches any non-whitespace character and is equivalent to [^ \t\n\r\f\v]

Shorthands are very straightforward metacharacters that barely have any specific rules of usage. And they are cool. Why not use them?
 Escaping of shorthands
You do not need to escape shorthands in your regular expressions. Although, technically, you can do it. This way, all of the following statements return the same result, no matter what you use, backslash or raw string literal, or neither:
If you need to escape a shorthand, just escape its backslash with any of the techniques we mentioned in the previous topics, like this one:
Another great feature of shorthands is that they maintain their metacharacter abilities when they are put in sets. Let's discuss it.
Shorthands in sets
As you remember from the previous topic, most regexp metacharacters become regular characters in sets, but shorthands do not do that. This makes it possible to use shorthands as the basis of your custom character set that you can enlarge by adding some other characters. It may be useful, for example, in case you want to build an alphanumeric set for a language that uses some other letters in addition to ""default"" ones:
Many great features can be dangerous, though. This feature is not an exception — do not use several negated shorthands in one set, as they are not what they may seem!
Suppose you want a set that will match everything except for digits and whitespace characters. You could write [\D\S], but that's a wrong move. The explanation is that a character matching a set should match only one element of this set, but not all of them at the same time. This way, when you use the set [\D\S], a character matching this set should match either \D or \S. So, every digit matches \S (because digits are not whitespace characters), and every whitespace character matches \D (because whitespace characters are never digits). In the end, this set matches all possible characters (looks like the dot character ., but more powerful, because unlike the dot, it matches \n too). 
Instead of [\D\S], use [^\d\s]. This set matches everything that does not fall into the categories of whitespaces and digits at the same time. 
So, keep in mind that if you are thinking about using a combination of negated shorthands in your set, you probably should replace them with a negated set and regular non-negated shorthands inside it. 
Used alone in combination with regular characters, negated shorthands behave properly in sets. You can add some of the characters banned by the negated shorthand to the set, making the scope of your set even bigger. For example, the set [\Wa-c] matches no alphanumeric characters except for the a, b, c letters:
There are a few other metacharacters that look like shorthands, but they do a slightly different thing.
Boundary shorthands
These shorthands look more or less the same: a backslash and a letter, but they do not match any characters. These tricky fellows formally match empty strings, but more specifically, they match empty strings in certain situations.

\b matches a word boundary. In other words, it matches an empty string between an alphanumeric character (any character matching\w) and a non-alphanumeric character (\W) or absence of characters. You can use it to make sure that your regular expression will match only a separate word, not a part of a bigger word. 

\B matches the absence of the word boundary, that is, an empty string between two alphanumeric characters \w. It serves for searching for alphanumeric sequences that are parts of bigger alphanumeric sequences. 

\A matches only an empty string at the start of the string. This way, you can make sure that the substring matching your regular expression will be located at the very beginning of the string. This shorthand is not so useful for us at the moment because the match() function always matches substrings located at the start of the string, but it will come in handy later. 
\Z matches an empty string at the end of the string. 

\b shorthand is the only one that you need to escape to use correctly, otherwise, it will become a Python metacharacter, not a regexp one. You can avoid escaping by adding the r prefix. In general, it is recommended to use the r prefix any time you write a regular expression, it will save you some time and make your code more readable.
By the way, \A and \Z are not widespread. They are often replaced by simpler metacharacters with identical functions.
 
The hat character ^ is identical to \A. The dollar sign $ is equivalent to \Z.

Summary
So, in this topic we have learned:

there are special short designations for some sets of characters;
these shorthands, depending on which one you use, can match alphanumeric characters, digits, or whitespace characters. They can also match any characters except these (these shorthands are called negated);
shorthands can be used in sets. You should be careful with negated shorthands in sets;
some shorthands match empty strings in special situations, at word or string boundaries.
"
140,Regexp quantifiers,955,10355,797,https://hyperskill.org/learn/step/10355,"We have already learned about sets and shorthands in regular expressions. Now it is time to learn another powerful feature that significantly contributes to the regexp flexibility. The metacharacters we are going to talk about are called quantifiers. Quantifiers always follow some other character (or a group of characters), and they are meant to specify the number of repetitions of this character in the string. So, quantifiers allow you to write not only fixed-length templates but also templates for strings of varying length. The indications for the required length of strings (the number of repetitions) can be both fixed or rough.
We already know one of the quantifiers, the question mark ?, which matches either one or zero occurrences of the preceding character. Let's see what other quantifiers we can use!
The plus quantifier
Let's start with, perhaps, the simplest and the most straightforward quantifier, the plus + quantifier. The plus + quantifier basically means ""the preceding character should appear one or more times"". That is, it matches one or more occurrences of the preceding character in the string. Look at the example below:
You can easily pair this quantifier with many other metacharacters. For example, with the dot character, to match this combination with any number of any characters except for the \n (but not the absence of any characters), or with a set of characters. So, the plus will match a sequence of the characters from this set (with one character from this set being the shortest possible sequence). 

There is also a very similar quantifier with just a slightly different function: the asterisk * quantifier. 
The asterisk quantifier
The asterisk * quantifier does almost the same thing, but the scope is a bit wider; it also matches the absence of the previous character. So, zero or more occurrences of a character are enough to match the combination of this character with the asterisk quantifier. 
You can pair the asterisk with other metacharacters in the same way as the plus quantifier. For example, the combination of the dot character and the asterisk quantifier, .*, matches any string of any length, including an empty string.
In addition to the asterisk and the plus, there is another type of quantifier. Unlike the ones that we have just talked about, it allows us to indicate a specific number of repetitions that we want to find. 
A fixed number of repetitions
In case we want to match a fixed number of occurrences of a certain character, we can use curly brackets with a number inside them, just like that: {n}. This quantifier matches exactly n consecutive occurrences of the preceding character. 
As well as the aforementioned quantifiers, curly brackets quantifier (in all its forms which we're going to discuss now) can follow other metacharacters, such as the dot character or a set, for example. 
A range of repetitions
The braces also serve for the designation of a specific range of the length of the sequence that we want to find. In its general form, this quantifier looks like two numbers put inside braces and separated by a comma: {n,m}. The quantifier matches at least n and no more than m instances of the previous (quantified) character.

Unlike Python ranges that end exclusively (that is, not including the number specifying the end of the range), the ranges in regular expressions both start and end inclusively: {n,m} matches both n and m occurrences of the character.  

Take a look at the example to see how the {n,m} quantifier works:
This quantifier is quite flexible in the way that you can leave out either n or m,  in this way mentioning only the maximum or the minimum number of occurrences; {n,} matches n and more occurrences of the character, while {,m} matches no more than m (including zero occurrences). Pay attention to the comma and its location relative to the number. If you forget the comma or put it in the wrong place, the meaning of the quantifier will be absolutely different.
Since {,m} quantifier matches zero occurrences of the character as well, be careful with it. If you omit to mention any characters that should necessarily occur in the string in your template, it will also match an empty string. Take a look at the example:
To avoid these situations, you may want to specify the minimum number of occurrences: {1,m}, for example.

Another crucial point of quantifier syntax is that there should be no spaces inside the curly brackets. If you put a space after the comma, for example, the quantifier automatically turns from a metacharacter into a simple sequence of literal characters. That is, a{2, 3} is not going to match strings ""aa"" or ""aaa"": it will only match a string ""a{2, 3}"", because the quantifier in the template is not working, it is broken by the space character. 

Greedy and lazy quantifiers
By default, all quantifiers (+, *, {n,m}, {n,} or {,m}, ?) are greedy. It means that they match as many instances of the previous character as possible. For example, when a template ""a+"" is compared against a string ""aaa"", we have some kind of a dilemma — the regex engine can return any substring as the result of the match, ""a"", ""aa"" or ""aaa"", since they all comply with the template. They consist of at least one a character. But since our + quantifier is greedy, it has no choice as it matches the longest possible substring, ""aaa"". The dilemma is resolved. 
In some situations, this behavior may not be desired for your purposes. Suppose we want to find a pair of <p> and </p> tags with some text in between them. We write a template <p>.*</p> to find such substring in a text filled with tags. See what happens there:
Even though we wanted to find substrings ""<p>paragraph</p>"" and ""<p>another paragraph</p>"" separately, we were not able to do that, because our quantifier .* is greedy; it matched the longest possible string located between <p> and </p> tags. 
If we want to change this behavior, we need to put the question mark character ?  right after the quantifier: +?, *?, {n,m}?. Yes, the question mark has another function as a metacharacter in regular expressions when it immediately follows a quantifier; it switches this quantifier from the ""greedy"" mode to ""lazy"". 
A lazy quantifier matches as few occurrences of the quantified character as possible. For example, a template ""a+?"" compared to the string ""aaa"" matches ""a"", and not ""aaa"". The aforementioned example with tags ends in a very different way:
Note that lazy and greedy modes do not work with the quantifier {n}, since it searches for a fixed number of occurrences, and cannot choose between the lesser and the bigger number of them.
Please, remember this feature and choose carefully between a greedy and a lazy quantifier according to your purposes in a particular situation.

When the question mark ? character is used to signify that the preceding character may be absent, it is equal to {,1} quantifier.

Summary
In this topic, we have learned about quantifiers in regular expressions. There are several quantifiers we need to remember:

the plus + quantifier matches one or more instances of the quantified character;
the asterisk * quantifier matches zero or more instances of the quantified character;
the fixed-length quantifier {n} matches exactly n instances;
the quantifier {n,m} matches from n to m (inclusively) instances;
we can leave out either n or m.

We have also learned about two modes of quantifiers (except for fixed-length quantifier):

greedy mode (by default) when the quantifier matches as many occurrences of the character as possible;
lazy mode (the quantifier is followed by ?) when the quantifier matches as few occurrences as possible.
"
141,Groups and alternations,1311,12676,813,https://hyperskill.org/learn/step/12676,"In the previous topic, we've taken a look at quantifiers and their role in regular expressions. So far we've been using quantifiers applied to one character only as we search for a specific character repeated over a certain number of times. But what if we want to look for a repeated substring? What if we want to specify the number of times that a string of different characters should occur in the string? In this case, we should resort to parenthesis characters (). The parenthesis in regular expressions can group desired parts of the template into single units and process them together. Let's discuss the details of their application!
In this topic, we'll come across the OR operator (an alternation) of regular expressions represented by the vertical bar |. As a programmer, you can imagine the situations where this operator is indispensable. In this regard, regexps are no different.
Groups
By default, when we put a quantifier in our template, it's applied to the preceding character. Take h[ao]{2} for example. The quantifier demands either a or o to be repeated twice, but h can only occur once. To apply a quantifier to a sequence of characters, we must use parentheses () to group the desired symbols and put the quantifier after this group. Take a look at the following example. There, we are looking for the h[ao] substring:
You can apply any quantifier you want, but the syntax remains. For example, you can mark an optional substring with a question mark quantifier ?. It will make the group match one or no occurrences of the group in the string:
So, entire parts of the template can be omitted in the string.
Nested groups
We can also make use of nested groups — you can put a group inside a group to specify smaller substring repetitions inside larger substrings. Take a look at this template that matches any number of repeated strings containing two substrings of the <letter><digit> type (for example, A0, C3):
The depth of nested groups is technically unlimited. The only problem is that the bigger number of groups are somewhat hard to read. But don't worry: most of the templates in real life are barely readable anyway.
However, the quantifiers aren't the only reason why we need groups. Groups are also a tool that gives your template a structure when you need it.
Method groups()
After comparing a template against a string, we often need to process the result (extract one part of the matching string, rearrange it, replace some of its parts). We will discuss these options in other topics. But for now, we can say that groups can help with such processing. Groups can help you to designate important parts of your regexp.
If you want to make some groups in your template, you can get parts of the string that match each group with just one groups() method. This method applies to any matched object, that is, any result of the match() function when there's a match. It returns a tuple with substrings matching the created groups:
As you can see, the first tuple element, the Python part, is the match for the first group, and the second element 3 matches the second group. In this case, the number of elements is equal to the number of groups. If a group is optional, None will appear in the resulting tuple:
In case you need to extract the string matching as a single group, you can opt for a special method.
Method group()
To extract the match for a particular group, you can use the group() method. This method accepts an integer designating the number of the group that you want to extract:
The enumeration starts from 1. If you pass 0 or call it with no arguments, the method will return the entire string:
As you can see, you need to know the group number to extract it. For that, we need to discuss the concept of enumeration.
Group enumeration
The groups are enumerated in linear order, from left to right. To be precise, the group numbers coincide with the numbers of their opening parentheses in the template. The group with the first parenthesis gets the first number.
This is also true for nested groups. Take a look at the following example:
So, in case you have a complex regular expression, just count the opening parentheses of your groups (starting from 1) to get the desired number.
If you have a repeated group in your template, with another group inside it, you'll get only the last match from the matching substring if you try to retrieve the ""inside"" group with the group() method. For example, in the following piece of code, the group() method won't allow you to retrieve the substring 2 from the second group, only 3:
There's one more powerful regexp tool. Let's go!
Alternations
In many cases, a pattern we'd like to match can contain alternative substrings — sometimes one, sometimes another. For example, when we search for a web address, it can have .com, .org, .net, etc. as a part of the domain name. We can match several domain types in one template by using |.
| is the or operator in regexps. By separating alternative substrings with vertical bars, you are matching any of these substrings with the template. Here, take a look:
In the above example, | separates three alternative options. Any string that doesn't coincide with any of the options is not going to match the template.
Groups and alternations
Also, notice that the vertical bar isn't similar to quantifiers in terms of the application scope — it's applied to the entire template until the next vertical bar occurs. For instance, if we need to find the following strings: python course, kotlin course, python lesson, or kotlin lesson, we can write the following expression first:
To mark the borders of the OR operator, we need to use groups. Put the parentheses around the entire OR expression, as in (course|lesson):
Don't forget about groups when you include alternative options to your template.
Summary
Hey, we've done a great job here! Pretty much the whole inventory of regular expression operations is at your disposal now. In this topic, we've learned that:
in regexps, parentheses () can be used to group characters into substrings;quantifiers can be applied to groups;groups are enumerated automatically. They are enumerated by their opening parenthesis, from left to right, starting from 1;matches for groups can be retrieved with groups() and group() methods;vertical bars | specify mutually exclusive substrings in a regular template;groups can limit the scope of vertical bars.
There are still a couple of Python regexp methods left to learn. After that, you'll turn to a true regexp wizard!
"
142,File types,1361,13017,816,https://hyperskill.org/learn/step/13017,"As you may already know, it is convenient to store data in files. In this topic, we'll figure out what else we can do with the files, how to distinguish them, and what their main types are.

Below we provide a list of file types in the Unix system. In other operating systems, the types may slightly differ, but the basic ones, which we will talk about in more detail, can be found almost everywhere.

Unix file types

In general, a file is a container for some information. We can put almost anything in this container: a photo, a text, a link to another file, or just another container with other nested files, etc. All this data is different and therefore the files in which it's stored are of various types.

The Unix filesystem components are:

Regular files where you usually keep your personal data such as texts, pictures, and so on.
Directories, or folders that make it easier to organize other files in the system.
Named pipes, that pass the output of one process as input to another one and have a name.
Symbolic links, which contain links to other files.
Device files, that contain data required by the operating system to interact with physical devices.
Sockets, which allow to exchange the data between processes in both directions.

We will study the most commonly used file types in more detail. These are the ones that can be found in every operating system: regular files, directories, and symbolic links.

Regular Files

Regular files are common because users usually store their data in them: documents, videos, photos, music, etc. In general, any data in such files can be presented in two forms:

textual data with some encoding, then the file will be called a text file
any other sequences of bytes without constraints to encoding, then such a file is called a binary file

To make it easier to figure out which file is text and which is binary, let's study a couple of examples. Text files usually contain texts in plain format, tabular data, configuration files, and data formats like CSV or JSON. Binary files often contain data such as video, audio, databases, and archives.

Binary and text files have different characteristics and thus require different tools to work with them. It is worth knowing these differences because it will definitely save you time when reading or writing your data to these files.

The main difference between text and binary files is that the latter has no inherent constraints. It means they can contain any bytes sequence, and they are to be opened in an appropriate program that knows the specific file format such as Media Player, Photoshop, Office, etc. On the other hand, text files can be edited in any text editor program. Also, they must correspond to several constraints such as human-readable content, line-oriented data format, universal reading of newline sequences, and so on.

Directory

Directories, which sometimes are also called folders, are containers for the files. For example, you can put your music files into one directory titled “Music”. Most file systems also allow a directory to contain other directories. It’s called a parent directory containing child directories or subdirectories. This way the organizing data is stored on a medium into tree-like hierarchical structures, where directories that have no parents are called root directories and serve as the base of this structure. This hierarchy provides clear links between files and makes it a lot more convenient to search for data on a disk. We just need to know the full path to a file, that's all. To get this full path, we need a full filename, i.e. we add the parent folder to the file, and for the parent folder, we also add its parent and so on till we get to the root.

Directory names in a full filename are usually separated by slash / or backslash \. So if there is a root directory named “root_directory” that contains a subdirectory named “sub_directory”, and in this subdirectory, there is a file named “my_file”, the file system will assign it a full filename like “root_directory/sub_directory/my_file”.

Moreover, tree-like hierarchical structures allow us to select file groups and manage them. Also, using a hierarchically organized structure, we can transfer it to another computer.

Symbolic links

Lastly, there is one more special sort of file worth considering. These files are called symbolic links in the Unix system. If you use Windows, you may know them as shortcuts. A symbolic link contains a reference to another file or directory in the form of an absolute or relative path. Let’s say you want some files to be accessed from several directories. If you copy this file and put its copies into each directory, each time you modify one of the copies you’ll have to go and modify all the others, and this feels like a waste of time. If you put symbolic links referencing this file into each directory, they would actually open the original file they are referencing.

Conclusion

To sum up, in this topic we've learned that:

personal data is stored in regular files,
the data in regular files can be either in binary or text form,
in addition to regular files, there are also directories, symbolic links, sockets, named pipes, and device files,
directories are containers for other files,
you can store links to files in special files called symbolic links.

Now, let's turn to exercises to see how well you understand the different file types.
"
143,Graph,268,15967,828,https://hyperskill.org/learn/step/15967,"We can concisely depict many real-life problems as collections of objects and links between them. Such representations are known as graphs. A graph can be considered as a set of objects, usually named nodes or vertices, and links (edges) that connect these objects with each other. 
To fully understand the importance of graphs, it is sufficient to mention that there exists a branch of theoretical computer science known as Graph Theory. Furthermore, this is undoubtedly one of the fields with the largest number of unsolved problems, and scientists from all over the world work on them from day to day. Here, however, we will focus on the very basics of this theory — only on the elements necessary to understand the algorithms that use this data structure.
A brief history of graphs
If you want to understand today, you have to search yesterday, they say. Let's learn how graphs first appeared. The history of graph theory can be traced back specifically to 1735, when Swiss mathematician Leonhard Euler solved the Königsberg bridge problem.

The Königsberg bridge problem was an old puzzle concerning the possibility of finding a path over each one of the seven bridges that span a forked river flowing past an island. But (and here's the tricky part) without crossing any bridge twice. Euler argued that no such path exists. His proof involved only references to the physical arrangement of the bridges, but essentially he proved the first theorem in graph theory.
An important graph problem
Now, let's take a look at one of the most discussed problems in modern graph theory — the map-coloring problem. The task can be stated as follows: we need to assign a color to every country, taking an obvious restriction into account — two neighbors should have different colors. Consider the following example:

Here is a partial map of Europe. To get rid of the unnecessary details of a map, we represent each country as a node and connect two countries if they are neighbors. This results in the following graph:

The figure on the left corresponds to a map with borders represented as links between countries, and the figure on the right is a graph where we've substituted each country for a node. Thus, we reduce the problem of coloring a political map to the problem of coloring the nodes of a graph. Although the example above is quite simple, such representation would be indispensable for larger maps: it allows us not only to keep the important details, but also to automate the solution to this problem.
More applications
Unsurprisingly, graphs come in handy in many areas other than theoretical computer science. Assume that you need to drive from one city to another. Chances are, you'd probably rely on services like Google Maps or MapQuest. We all use them, but have you ever thought about how they work under the hood? A possible way is to represent the map as a graph with nodes corresponding to cities and edges showing the roads. Then, in terms of graphs, our question is: what is the shortest path between the start node and the destination node?

Map coloring and finding the shortest path are not the only problems where graphs appear useful. For instance, we could represent the World Wide Web as a graph, with nodes symbolizing the sites and edges as links between these sites. In social networks, you can view people as nodes, and a link between two people meaning that one of them follows the other. In other words, a graph is a convenient structure, suitable for modeling various real-life problems.
Formal definition
Using formal language is essential when it comes to working with graphs conveniently, storing them on a computer, or describing algorithms for graph processing. Formally, a graph \(G\) is a pair of two sets: \(G = (V, E)\). Here, \(V\) is a set of nodes and \(E\) is a set of edges. Each edge is a pair of nodes connected by a link. Consider the following three examples:

Here we have three graphs. The first graph \(G_1\) consists of three nodes and has no edges. So,
The second graph \(G_2\) is the same as \(G_1\) but contains two edges:
The third graph $G_3$ consists of four nodes and four edges:
The nodes in the graphs above are labeled as numbers, but labels might actually be of different types. See the following examples:

The graph \(G_4 = (V_4, E_4)\) consists of four nodes with labels \(V_4 = \{A, B, C, D\}\) and edges \(E_4 = \{\{A, B\}, \{A, C\}, \{B, C\}, \{B, D\}\}\). The graph \(G_5 = (V_5, E_5)\) represents a group of people, with edges showing acquaintance:
Depending on a particular problem you need to solve, different types of labels might be convenient.
Directed graphs
Up until this moment, we've talked only about graphs where edges don't have any direction. For example, consider the edge \(\{0, 1\}\) of \(G_2\) that connects the nodes \(0\) and \(1\). If we swap the nodes, it won't change anything: the edge \(\{1, 0\}\) still connects the same nodes. Such graphs, where the order of nodes is not important, are called undirected graphs. A political map is a structure that we can naturally reduce to an undirected graph. If one country is a neighbor of another, the direction of the edge showing this relation is not important.
However, in some other cases, undirected graphs don't suffice. Assume that we want to model a social network as a graph. We can represent people as nodes and put an edge between two people if one of them follows the other.

In this case, the direction is important. If a user \(x\) follows \(y\), it doesn't mean that \(y\) follows \(x\). To model this and similar situations, directed graphs suit much better. You can see an example of a directed graph in the figure above:
The given graph consists of four nodes and four directed edges:
To show that an edge is directed, we use round brackets instead of curly ones.
As mentioned before, different types of graphs are better suited for modeling different problems. Depending on the task you need to solve, you can choose either directed or undirected graphs.
 
As weird as it may sound, undirected graphs can be easily converted into directed ones. Indeed, instead of every undirected edge \(\{u,v\}\), just add two directed ones, namely \((u,v)\) and \((v, u)\). Obviously, the contrary assumption is not true: directed graphs pretty often cannot be remodeled into undirected graphs. It is impossible to save the information on directions using undirected edges.
 
Summary
A graph is a convenient structure that we can use to model many real-life objects and processes. In this topic, we've considered several examples where graphs might be useful and learned how to describe their structure. Formally, a graph is a set of nodes and edges that connect these nodes with each other. If the order of nodes is not important, we say that the graph is undirected. Otherwise, we call it directed.
Yet, in order to solve real problems efficiently, you need to know more about graphs. In the following topics, we will learn some terminology used to describe graphs, consider how to store them on a computer, and then learn some efficient algorithms for their processing.
"
144,Time module,1037,10963,830,https://hyperskill.org/learn/step/10963,"Sometimes you might want to have a time-related component in your program. For this purpose, Python has a built-in time module. Let's look at what you can do with it when working on a program that prints reminders.

What time is it?
When we want to remind a user about something, we should also probably print the current time for them to know that the moment has actually come. To do that, we will import the module and use the gmtime() function:

This will print:

As you can see, the result is a little different from what we may have expected, as gmtime() returns a struct_time object. There are at least two possible ways to deal with it. Let's take a look at the information that will help us interpret the output:

valuemeaningrangetm_yearyear(for example, 2020)tm_monmonthfrom 1 to 12tm_mdayday of the monthfrom 1 to 31tm_hourhourfrom 0 to 23tm_minminutefrom 0 to 59tm_secsecondfrom 0 to 61*tm_wdayday of the weekfrom 0 to 6 (Monday is 0)tm_ydayday of the yearfrom 1 to 366tm_isdstif DST is in a region(see below)0 – no1 – yes-1 – unknown*60 is supported for representing a leap second, while 61 is there for historical reasons.

Getting back to our example, to rearrange the output, we can either use the asctime() function to convert the values into a string:

Or we can use the strftime() function which also returns a string, but it can be used to specify the output format with the directives. For example, %H is used for hours, %M – for minutes and %S – for seconds.

If you try that out yourself, you may notice that the time that the gmtime() returns is different from your current local. That is because the function gives you the time according to the UTC (which is an English-French acronym for Coordinated Universal Time) and this is probably not what you need. To print the current time for your region, use the localtime() function:

Time measurement
What if our user also has a dog that should be fed in an hour after the cat? In this case, with the sleep() function, we can just ask our program to wait for an hour and then remind the user about the dog. Let's add these lines to our program and look at the output:

Most often sleep() is used when you need some time to pass between code executions.

The module also has another useful function – time(). It returns the time passed since the epoch (starting point for counting time) in seconds — it is a float object, but you can quickly convert it into a string of the same format as asctime() using ctime(). That is, the following lines give the same output:

Note that depending on the platform, the reference point for the epoch might be different. On Windows and Unix systems, the epoch starts on January 1, 1970, 00:00:00 (UTC). You can check that by typing gmtime(0):

In the example above, as you can see, the gmtime() function takes an optional argument. It specifies the time passed since the beginning of the epoch (in seconds) which the function then converts into a struct_time object. If the argument is not provided, the current time returned by time() is used by default.

Time difference
Knowing time in seconds might be useful, for instance, if you want to find the difference between two points of time. Now, let's imagine that the cat is trying to lose some weight and along with the current time we also want to print the time passed since the last time our user has fed the cat. This example is a little artificial since in a real program you would probably have some more code to execute between the first, starting point, and the next one, which marks the end of counting, but it still serves its demonstrative purpose:

In our case, it might be enough to subtract one point of time from another in seconds and represent it in minutes or hours for readability. But sometimes, working on your code, you need to know the precise time of your program execution. With the time module, this precision can be granted with the perf_counter() function:

It may look similar to the time() function, but the time it returns is relative and is not related to the real-world-time, it is related to the processes inside hardware. This is why the perf_counter() should be used only for performance measurement.

Timezones and other peculiarities
Let's go back to our reminder program and imagine that we know that our user is now traveling, and that is why we want to let them know that the timezone has changed. This can be done using the timezone, which will show the time offset west of UTC, in seconds:

Alternatively, you can use the tzname which will print the abbreviated name of a new timezone:

Sometimes, it also might be useful to know if time in that region depends on the season of the year (this is called DST – Daylight Saving Time). Let's add this information to our notification about the time changes with the help of the daylight which returns 0 if there is no DST and 1 otherwise:

Keep in mind that the output of these functions depends on your region and might differ.

Summary
Let's summarize what we have learned in this topic. We now know about:
the Python time module;
its struct_time object, which contains all information about current time from year to seconds;
different ways to represent time (asctime(), strftime(), ctime(), gmtime(), localtime());
and several main functions that might be useful in various situations such as time and performance measurement (time(), perf_counter()), waiting for a certain time during program execution (sleep()) and getting information about regional time peculiarities (timezone, tzname, daylight).

Now, it's high time to go and try them in your program, and do not forget about Python docs if you strive to learn more.
"
145,Intro to multithreading,1818,16944,831,https://hyperskill.org/learn/step/16944,"If you are familiar with the notion of threading, you probably have an idea of how threading utilizes different parts of one process to run concurrently. A process is nothing else but a program that is currently using the CPU. Almost any process now supports multithreading. This means that multiple threads (units) will work together to achieve one common goal.

Every process has at least one thread. It is the main thread.

Let us take an example to illustrate the notion of multithreading: imagine that you are an avid fan of video games. In a video game, the process has to run different tasks — rendering, interaction with players, and, possibly, internet connection. All these tasks run in parallel because the game should be responsive all the time. To accomplish this, it employs multithreading, where each thread is responsible for running a separate task.
Another example is when you create a simple application for registration at an event. People must register if they want to attend the event, so you have prepared a simple form for attendees. If the system that saves user data is a single-threaded application, it can only process one request at a time. But what if the event is a concert for millions of people? Processing one request at a time will slow down the performance drastically. That's why it is a good idea to make the application multithreaded to allow multiple requests to be processed at the same time.
Threading in Python
Almost everything in Python can be represented as an object. Threading is represented in Python. Therefore, threading is also an object. A thread in Python can hold data, can be passed as a parameter to a function, can have various states such as locked or unlocked, and can be stored in different data structures like dictionaries, lists, and so on. 
Before jumping into code implementation, let's understand the concept of locking. A lock is a synchronization object that controls simultaneous access to an object. A lock acts as a permit: it is a vital thing in the prevention of data corruption.
The lock will be assigned to only one thread at a time. Other threads will wait for the lock owner to complete its task and return it. Thanks to the lock mechanism, it is possible to control the competition between various threads, ensuring that each one of them performs its activities without the unwanted interference of other threads.
Now, let's return to the notion of threading. Python offers two modules for thread-control in programs: _thread and threading. The main difference between them is that the _thread module implements a thread as a function, while the threading module offers an object-oriented approach to enable thread creation. Below you'll see examples that will give you an idea of how to implement threads using both built-in modules.
Let's continue with locks. A lock can be either locked or unlocked. It has only two basic methods, acquire() and release(). When the state is unlocked, acquire() changes the state to locked and returns immediately. When it is locked, acquire() blocks it until a call to release() in another thread changes it to unlocked, then the acquire() call resets it to locked and returns. Call the release() method only when the state is locked; it changes the state to unlocked and returns immediately. If an attempt is made to release an unlocked lock, an error will be raised.
If you run the snippets above, you will notice that even if we created a thread before the print statement, world! is printed 3 seconds before the Hello,  string. This happens because when using threading, our program does not wait until the delay but rather goes and executes the next lines. 
You may also have noticed that creating a thread with the threading module is more straightforward than doing the same with the _thread module. In the first example, we had to create a lock as well. Otherwise, the operating system will ignore our thread, and our Hello,  message would not have been printed out. The Official documentation indicates that the _thread module is a low-level threading API, so it is considered a good practice to use a higher-level level module like threading, where you can simply wait for all the threads to exit. In the examples below, we will follow this recommendation.
Multithreading in Python
Now that you have a good understanding of how to create a thread, it is time to make a step forward into threading and see how a program behaves when we set up multiple threads. 
As you may have noticed, since the delay variable is set by default to 0, all will be printed in the initial order: 
Let us play around with our delay variable and see what happens: 
Now, the output will be as follows:
The lines with the shortest delay are printed first, while those with a longer delay are printed at the end of our program. This is possible by implementing multithreading; otherwise, our code would have been executed line by line. This is just a simple example, but imagine processing an image or writing a huge file to a disk, and refreshing a resource on the internet. With multithreading, we can allocate the part of our code that takes longer to a separate thread and continue with the rest of our program at the same time.
Conclusion
In this introductory topic, we have briefly explained what a thread is and how it influences a process execution. We have also introduced you to Python's built-in modules — _thread and threading. There are also locked and unlocked statuses of a thread; you can use them to prevent data corruption. Finally, we've made a basic example of how to use multiple threads in Python.
Of course, this is only a beginning. We will continue to discuss multithreading in Python at length in other topics. But for now, let's turn to practice!
"
146,More on multithreading,2564,24625,832,https://hyperskill.org/learn/step/24625,"This topic will focus on how threads communicate with each other and their role in multithreading applications in Python. It's important to note that threads belonging to the same process in Python don't run exactly simultaneously. A single-core processor can perform only one computation at a time. However, even before multicore processors appeared, it was possible to have several programs running concurrently. This is similar to how you can type a new address in your browser while a website is loading. In this section, we will provide examples of how threads communicate and synchronize with each other.

Synchronizing threads
A common problem in a multithreading application concerns critical sections. A critical section is a segment of code where threads access shared resources, such as common variables and files, and perform write operations on them. But what is so critical in this part of code? You can imagine a critical section as a workplace where different workers read or write in the same notepad, and they should not delete the work of each other. At this point, it is crucial to synchronize the threads that run simultaneously in this part of code. Synchronizing threads ensures that two or more concurrent threads do not execute the instructions (a critical section) simultaneously.

Now we should define the concept of the race condition. A race condition occurs when two or more threads can access the shared data, trying to change it at the same time. As a result, the values of variables will vary, depending on which thread is running first and which was the last. Let's start with a concrete example of the race condition and its problems.

Understanding the problem of race condition
Let's explain the first example – a function called calc_price. It prints the name and the price of an item three times. Of course, this example is just a demonstration of the issue of multiple threads, since our function is very basic and has in essence only printing instructions. The race here is for a global variable named total. We initialize two threads: t1 and t2, they both will try to write and later read the shared variable. They both call calc_price but with different arguments (name and price)

In this application, each thread prints the item's name and price. The output shows us which thread was running first and which was the last. Note that the print results are not regular, in the sense that the values are mixed with each other. Each time we are running the application, the result depends on which thread is running first.

We need to synchronize them to solve this problem. Both threads t1 and t2 access the total variable, with the aim to write something inside it. The first threads that start will ""lose"" the value in the shared data, and the last running thread will overwrite it.

What is lock?
Lock is one of the synchronization techniques. A lock is an abstraction that allows one thread to own it at a time. Holding a lock is how one thread tells other threads: ""This thing is mine, don't touch it right now."" Locks have two main functions: Acquire allows a thread to take ownership of a lock. If a thread tries to acquire a lock currently owned by another thread, it blocks until the other thread releases the lock. At that point, it will contend with any other threads that are trying to acquire the lock. Only one thread can own the lock at a time. Release relinquishes ownership of the lock, allowing another thread to take ownership of it.

A solution to the problem of the race condition is by adding acquire and release functions of a Lock object. In this example, we will add the Lock class, imported from the threading library. We will define a new Lock object — l. The functions acquire() and release() will lock the instructions where total is accessed.

In the console, we will see the result shown below. Note that once the first thread has finished, the second one starts its job.

In a Lock object, only one thread at a time is allowed to execute, but occasionally, we need to execute a particular number of threads simultaneously. We can wait for a thread to finish the execution by calling the join() function. This method allows the current thread to be blocked until the target thread it has joined is finished.

Let's modify this example and add five items and prices, each represented with its thread. Also, let's change it, so three threads can simultaneously access the total price. In this case, we cannot use Lock anymore. We should go further and use the concept of the semaphore.

Semaphore
The semaphore concept is one of the oldest synchronization primitives in the history of computer science, invented by the early Dutch computer scientist Edsger W. Dijkstra. He used the names P() and V() instead of acquire() and release(). A semaphore manages an internal counter which is decremented by each acquire() call and incremented by each release() call. The counter can never go below zero; when acquire() finds that it is zero, it blocks, waiting until some other thread calls release().

Semaphores can be of two types: Binary Semaphore — this semaphore can have only two values – 0 or 1. Its value is initialized to 1. Counting Semaphore — its value can be 0, 1, or other integer values. It is used to control access to a resource that has multiple instances.

In the following example, we will create five threads, and the counter in the Semaphore object will be three. So three is the number of threads accessing the shared variable simultaneously.

As with files, you can also use the with context manager with a semaphore. It will allow you to omit the explicit calling of acquire() and release(), since it will be automatically managed by the manager. calc_price() may also look this way:

In this example, we've created an instance of the Semaphore class, called sem where the value of count is 3. This means that three threads can access sem at a time. Whenever we call the start() method, three threads are allowed to access the semaphore, and hence three threads are allowed to execute calc_price() method at a time.

In the console, you can see a result like this one:

In this example, whenever we will run the application, we will get the non-ordered values of pairs (item – price). Most probably, the result will begin with three prints; this is because three different threads are calling calc_price() simultaneously.

Lock vs. semaphore
Let's compare the two mechanisms: lock and semaphore. Both use buffers to store shared data temporarily. Each buffer is capable of holding a single item.

An overview of the main features of the Lock and Semaphore is shown below.

| Lock                                                  | Semaphore                                                      |
| :---------------------------------------------------- | :------------------------------------------------------------- |
| Only one thread per process can share the same lock. | Multiple threads of the same process can share the same semaphore. |
| Only one thread works with the entire buffer at a given instance of time.   | Threads can work on different buffers at a given time.                |
| A lock is considered an object.                       | A semaphore is considered an integer with values.               |
| Locks do not have any subtypes.                        | A semaphore can be binary or counting.                        |

Conclusion
The role of synchronization is crucial in a multi-threaded program. In this topic, we've introduced the lock object, which allows only one thread to write or read in a shared variable. Another mechanism for thread synchronization is semaphore, allowing a limited number of threads to access a shared variable simultaneously. The examples we have seen in this tutorial are trivial, used to perform simple tasks such as setting the price of the product. In real applications, you should consider these techniques and apply them to have better communication between threads.
"
147,Intro to asyncio,3145,31751,833,https://hyperskill.org/learn/step/31751,"Asynchronous programming is an essential aspect of modern software development. It allows us to write concurrent code that can handle multiple input/output operations without blocking the execution of other tasks. In Python, asyncio is a powerful library that facilitates writing asynchronous code using coroutines, event loops, and other async-related constructs.

What is asyncio?
Asyncio is a Python library that simplifies asynchronous programming. It offers a more efficient and readable way to write code that can run concurrently. Unlike the traditional approach of using threads, which can be costly and complex, asyncio utilizes coroutines. Coroutines are special functions that can be paused and resumed at specific points during execution, allowing multiple coroutines to run concurrently within a single thread. To use asyncio, you can define coroutines using the async def syntax and input the await keyword to pause execution until a specific task is complete. This lightweight and efficient concurrency approach is the reason why asyncio is a popular choice in Python development.

In this illustration, we utilize the asyncio.sleep() function to pause the execution of the coroutine for a duration of one second. This pause allows other coroutines to run simultaneously, creating a more efficient and responsive code structure.

Asyncio code with threading and multiprocessing
With concurrent programming, there are different approaches to handling tasks based on their nature. Multiprocessing utilizes multiple CPUs to perform calculations in parallel, benefiting CPU-bound tasks. Threading permits the execution of various tasks on a single CPU, making it suitable for I/O-bound operations. However, it relies on how the CPU performs context switching. Asyncio, on the other hand, provides concurrency by running multiple coroutines within a single thread and gives the programmer control over the context switching. It is a form of threading where the await keyword suspends the execution of a coroutine, enabling efficient task switching. However, asyncio doesn't inherently provide parallelism due to Python's Global Interpreter Lock (GIL).
If the task is I/O-bound, asyncio is the way to go. For CPU-intensive tasks, multiprocessing is more effective. Understanding the nature of the task helps in selecting the appropriate approach to achieve optimal performance and resource utilization.

Event loops
In asyncio, an event loop is the central coordinator for managing and executing coroutines. The event loop is responsible for scheduling and switching between different coroutines to ensure they are executed efficiently.
When a coroutine encounters an await statement representing a potentially blocking operation, such as I/O, it suspends its execution and allows the event loop to switch to another coroutine that is ready to run. This enables asynchronous execution, where multiple coroutines can progress without blocking each other.
The event loop ensures that each coroutine gets an opportunity to run and continues the execution until all coroutines are complete.
A single function call has automatically handled the event loop management.

Async and await keywords
The async and await keywords are essential in asynchronous programming. They provide a concise way to define and work with asynchronous code, allowing tasks to run concurrently without blocking each other.
The async keyword defines an asynchronous function containing non-blocking operations. The await keyword is used within the async function to pause its execution until a coroutine or available object completes. This enables other tasks to continue running in the meantime.

This code demonstrates the usage of asyncio to execute coroutines concurrently using the gather function.
The greet coroutine prints a greeting message with a given name, waits for one second using asyncio.sleep(1) and then prints the goodbye message.
In the main coroutine, we use asyncio.gather to execute multiple instances of the coroutine with different names concurrently: Alice, Bob, and Charlie. This allows the greetings and goodbyes to be printed concurrently for each name.
Finally, we use asyncio.run(main()) to run the event loop. This simplifies the code by automatically creating and managing the event loop for us.
When you run the code, you will see the greetings and goodbyes printed for each name, demonstrating concurrent execution using asyncio.

Conclusion
To sum up, Python's asyncio is a potent tool for writing asynchronous code. It allows developers to create efficient and concurrent programs using the async and await keywords. Handling multiple tasks simultaneously, asyncio enables developers to build responsive and scalable applications.
"
148,Key concepts of asyncio,3245,33696,834,https://hyperskill.org/learn/step/33696,"Asyncio is a library in Python that facilitates concurrent code writing using the async and await syntax. It's designed for managing I/O-bound tasks, enabling developers to write more responsive applications. This topic will explore the key concepts of asyncio, including awaitables, futures, tasks, and yielding control.

Awaitables
In the context of asyncio, an awaitable is an object that can be used in an await expression. Awaitables are essential for asynchronous programming, allowing functions to pause and yield control to the event loop. Three main types of objects are considered awaitable in asyncio:

Coroutines are defined with async def; coroutines are the most common type of awaitable. They can contain one or more await expressions, allowing them to pause and resume execution.

Tasks schedule coroutines concurrently. When a coroutine is wrapped in a Task object, it can run parallel to other tasks and coroutines.

Futures represent a future result. It's a low-level awaitable that provides a way to track the state of a background operation.

The following class hierarchy shows the relationships between them:

Tasks
Tasks are fundamental in asyncio that enable the concurrent execution of coroutines. They are responsible for scheduling and running coroutines in the event loop, enabling more efficient use of system resources
A coroutine, defined using the async def syntax, is a function that can pause and resume, allowing other operations to run during these pauses.

To execute the coroutine, use the await keyword or schedule it with asyncio.run() or asyncio.create_task().

Tasks are objects that wrap coroutines for execution. A coroutine becomes a task when it's passed to asyncio.create_task() that schedules it to run.
Futures
In asyncio, a future represents a computation that hasn't necessarily been completed yet. It's a low-level awaitable object that encapsulates an eventual result of an asynchronous operation.
When a future object is awaited, the coroutine will wait until the future is resolved somewhere else. This is particularly useful when you have an asynchronous operation that a non-async function will complete, and you must wait for the result.

In this example, asyncio.Future() creates a future object. The set_after coroutine is scheduled to run as a task with asyncio.create_task(), and it sets the result of the future after a delay. The main coroutine then waits for the Future to be done using await.
The ensure_future function in asyncio is another way to create a Task from a coroutine. It's similar to create_task, but can also accept a future and ensures that it is wrapped as a Task. This can be useful when working with coroutines and futures, as it allows for more flexibility in scheduling asynchronous operations.

It returns a Task object, and you can use await to wait for its completion just like you would with a Future created using asyncio.create_task().
Exception handling
Handling exceptions is a fundamental part of programming. In asyncio, exceptions work similarly to regular Python code but with some special considerations due to the asynchronous execution.
When an exception occurs inside a coroutine, it propagates up to the point where the coroutine is awaited. We can use try/except blocks to handle these exceptions.

In the code above, we are catching a ZeroDivisionError inside the my_coroutine coroutine.
If an exception is raised inside a task and is missed, the exception will be propagated where the task object is awaited. If the task is not awaited, the exception will be ignored until the task object is garbage collected. At this point, the Task.__del__ method is called, and the exception is logged as an unhandled error.

In this case, we're creating a Task from the my_coroutine coroutine, and we're catching the ZeroDivisionError where the task is awaited, inside the main function.
In summary, handling exceptions in asyncio is similar to regular Python code, but remember how your Tasks and coroutines are structured. Unhandled exceptions can lead to hard-to-debug situations, so it's good practice to handle exceptions where you expect they might occur.
Conclusion
In this topic, we've explored key concepts of asyncio: tasks, futures, and exception handling. Understanding these are vital for working effectively with asyncio:

Tasks offer a way to schedule coroutines concurrently.
Futures represent a computation that hasn't been completed yet.
Proper exception handling ensures smooth and error-resilient asynchronous program execution.

These concepts provide the foundational knowledge to use asyncio effectively, enabling you to write more robust and efficient Python code. By mastering them, you're now better equipped to leverage the asyncio capabilities in your projects.
"
149,Modulo division,988,10586,836,https://hyperskill.org/learn/step/10586,"There are four well-known basic arithmetic operations: addition, subtraction, multiplication, and division. The last one is probably the most confusing for most people. In this lesson, we'll refresh your knowledge about division and also talk about its ""modification"" for positive numbers – modulo division.
Basic division and division with remainder
Let's look at the two examples below and try to explain the difference between them:

Attentive readers may notice that in the left equation above the result of the division is an integer when in the right one it is not a natural number. That happens because \(6\) is a multiple of \(2\), while \(7\) is not. Such examples are called the non-integer division (in programming languages, it is usually known as float division), despite the result could be either integer or real. At an elementary level, the division result (speaking about natural numbers) is the number of times one number is contained within another one. In the previous example, we can see that number six contains number two exactly three times. The fractional part in the second case occurs because number \(7\) could not be represented as an exact sum of twos:

The last representation of number \(7\) illustrates that number \(2\) is fully contained in it three times. The last summand is called the remainder. It illustrates what remains if the maximum possible multiple of the divisor would be subtracted from the original dividend. In case when the dividend is a multiple of the divisor (the quotient is integer), the remainder equals \(0\). The remainder is always a non-negative integer, which is strictly less than the divisor.
Two operators which return an integer part of the division and its remainder are \(\operatorname{div}\) and \(\bmod\) respectively. Let's demonstrate how they work using an example with \(7\):

Note: \(\operatorname{div}\) and \(\bmod\) operators are identical to the integer part of quotient and remainder relatively only for positive operands. If one of the operands is negative, \(\operatorname{div}\) and \(\bmod\) operators work in another way. This is beyond the scope of this topic, but interested readers can find more information by themselves. That is why we will work with positive numbers only.
Modulo division
So let's go into details of how the \(\bmod\) operator works.
Assume that we have a number \(x=n⋅y+z\), and \(0 \leq z < y\). Then
\(x\mod y=z\)
(read as ""x modulo y is equal to z"")
In case when \(x < y\):
\(x\mod y=x\)
With the assistance of a \(\bmod\) operator, we could check whether one number is divisible by another:
\(x\) is divisible by \(y\) if and only if \(x\mod y = 0\)
i.e. x modulo y is equal to 0.
In the majority of programming languages the \(\bmod\) operator is written as %, i.e. \(x\mod y\) would be written as \(x\) % \(y\).
Examples
Now let's consider several cases to grasp what we have learned.
1. Even or not
For instance, you have a task to check if the number \(x\) is even or not. It is extremely simple using the \(\bmod\) operator. You know that a number is even if it is divisible by \(2\). So, a given number \(x\) is even if and only if \(x\) modulo \(2\) equals \(0\), i.e.:
\(x\mod2=0\)
And this means that in your code you just need to check if the condition \(x\) % \(2\) == \(0\) is met.
2. What time is it now?
As you know, in the world there are two widespread time conventions: \(12\)-hour clock and \(24\)-hour clock. Imagine that you have a friend who uses the \(24\)-hour clock and you ask him what time is it now in his city. He answered you, but, unfortunately, you live according to the \(12\)-hour one and don't understand what time is there exactly. However, this problem could be solved with the program code and the assistance of the \(\bmod\) operator.
Assume that your friend said that it is \(16\) o'clock at the moment. How to transfer it to the \(12\)-hour clock? No problem! Just think, what is a \(24\)-hour clock: people who use it just consider the full day as two full turns of the clock. Same as you, but instead of using a.m. or p.m. they numerate times continuously from \(00:00\) to \(23:59\). And the secret of conversion is taking time in \(24\)-hour format modulo \(12\).
Your friend said that it was \(16\) o'clock at the moment. Let's convert it to \(12\)-hour format:
\(16\mod12=4\) because \(16 = 1\cdot12 + 4\)
And since \(16\operatorname{div}12=1\), \(16\) o'clock is equal to \(4\) p.m.
Is it useful?
The functionality of the mod operator is very simple when you understand it. However, if it is the first time you faced it, some troubles could arise. And the reasonable question is ""Is it really useful?"". The answer is ""Absolutely, yes!"".
One of the most significant examples of usage of the mod operator is cryptography. In this area, programmers need to have a function, which is difficult to calculate the original value from, knowing its result. For instance, hackers have known that result of \(x\) modulo \(25\) is equal to \(3\). And they would like to know what is \(x\). It is a very hard task, because any number, that looks like \(x=n\cdot25+3\), where \(n\) is an arbitrary natural number, gives you \(x\mod25=3\). There are millions of possible values of \(x\). Sure, encryption algorithms are much more complicated than just taking the remainder from the division. But the idea of using it is very important.
It is also used when you need to operate with extremely big numbers and your resources are restricted. Applying mathematical basic operators (\(+\), \(-\), \(\times\), \(\div\)) not to the big number itself, but to its remainder makes your computation thousands of times easier and allows you to make conclusions faster. It is not possible in every case, but sometimes it helps a lot.
"
150,Hash function,1027,30143,837,https://hyperskill.org/learn/step/30143,"Hash functions are quite useful, right? In the past, we delved into their uses and some of their applications in data storage, fast searching, password storage, and checksums. However, we have yet to unpack what a good hash function actually looks like. In this topic, we'll explore the characteristics of an effective hash function, and examine some examples that fulfill these requirements and others that deliberately disregard them for distinct reasons.

Identifying a good hash function
Before we get started, let's refresh our understanding of hash functions. Basically, they operate like standard functions: you feed in some data, and they return a different output.

To be more specific, they utilize mathematical transformations to convert variable-sized input data into a fixed-size output called the hash value or hash code. So, what distinguishes a good hash function from an average one? Quite shortly, a noteworthy hash function displays several basic traits. Here are the properties we're particularly interested in:

Efficiency: An efficient hash function should perform data processing quickly, optimizing computational resources for actual applications.

Determinism means the function will result in the same output for a particular input no matter when and how often it's applied.

Uniformity: The hash values should be uniformly distributed, meaning the inputs should map evenly among possible hash values.

Eager to learn more? Hang tight! We'll dive deeper into each of these properties in the upcoming sections.

Efficiency
Efficiency is the lifeblood of practical hash functions, enabling fast data processing for applications like storage with rapid searching. Let's break this down:
Imagine you're working with a database system, like a vast library, that holds millions of books (records). Each book has a unique code (unique identifier). Now, consider a hash function as a super-efficient librarian who can instantly tell you exactly where a book is located when given its unique code. This librarian (hash function) quickly transforms this code into a location (hash value), enabling you to find your book swiftly. This is the beauty of an efficient hash function — it allows for rapid data retrieval and searching.

This is not necessarily a downside: in fact, it's perfectly acceptable for certain tasks, such as creating checksums and hashing passwords. The point is, the desired 'speed' of a hash function can vary depending on the specific use case it's applied to.

Determinism
The concept of determinism in hash functions is a vital aspect to understand in computer science, not only in hash functions. To simplify it, if you have two identical inputs, they should generate the same hash value.
In essence, a deterministic function is one that is not random. To illustrate, consider a function that randomly returns either 0 or 1, irrespective of the input. While this is technically a hash function, it's not a deterministic one because the output is not consistent for the same input. Indeed, it is possible that the first time you calculate the hash value of your input $n$, you get $h(n) = 0$, and the second time you get $h(n) = 1$, which is absurd. 
Anyway, can nondeterministic hash functions exist at all? It seems a bit unthinkable, doesn't it? Let's imagine you have two separate variables, and both carry the same value of 7. From a computer's perspective, these variables are distinct because they occupy different positions in its memory. But when you compare the values, they are identical. In such a scenario, the ideal hash function should return the same output. If a hash function returns the memory address of the value instead, it doesn't meet the deterministic condition. Similar functions can be useful on very specific situations.

Importance of determinism
Now, why is determinism important? It guarantees consistent results for a given set of inputs. This is particularly crucial for password storage. A hash function is employed to convert user passwords into hash values. If the hash function is deterministic, it ensures that each time a user types in their password, it yields the same hash value. This hash value is then used for comparison during the authentication process. Without deterministic hash functions, the process of password authentication would turn chaotic, making it nearly impossible to verify user identities.
Imagine a scenario where a user enters their password, and it generates a different hash value each time. The system would not be able to authenticate the user, leading to a breakdown in security protocols. Hence, the concept of determinism in hash functions is not just a theoretical aspect of computer science, but a practical necessity in maintaining secure systems.

Uniformity
Uniformity is another crucial attribute of hash functions. This essentially means that the hash function should spread out its output (hash values) as evenly as possible. Let's consider it like this — if we categorize all possible outputs from a hash function, we'd like each category or group to be roughly the same size. This helps to avoid a bottleneck or slow-down caused by too many outputs (collisions) clustering around one or a few values, known as peak keys.
In the field of cryptography, if certain groups of passwords or messages experience many collisions, they become more susceptible to hacking attempts. This could pose similar issues in systems dealing with checksums or data storage.
For instance, imagine a data storage system using a hash function that generates hash values based on the last digit of a user's ID. If the majority of these IDs end in even digits, the hash values will tend to pile up in certain 'buckets' or groups, creating uneven distribution. This clustering leads to a higher risk of collisions, which can hinder the system's overall performance and raise the likelihood of data errors and retrieval problems.

In other words, this lack of uniformity in the hash function can negatively impact the reliability and efficiency of the system.

Conclusion
By now, you're aware of what hash functions are and what constitutes a good one. We dissected the typical properties of suitable hash functions, specifically:

Efficiency

Determinism

Uniformity.

Now you're equipped to probe further, familiarize yourself with typical and cryptographic hash functions, and study other hashing techniques like hash tables!
"
151,Hash table,288,13054,838,https://hyperskill.org/learn/step/13054,"Let's imagine the following scenario: you have a lot of friends and a big shelf full of books. Some of your friends want to borrow your books, some want to return them, and some want to know if you have a certain book. So, you want to write a program that lets you add books, remove books, and check if a book is available. For this scenario, what would be the best data structure to use?

Hash tables are structures that allow us to insert and remove values, and check if a value is present in time for each of those operations. Hash tables alone cannot guarantee this time. However, paired with a good hash function, everything works well, making it one of the best data structures for this purpose.
Hash tables
Hash tables are arrays where each entry is a bucket. Buckets can hold 0 or more values of a type. They are identified by their index in the array. If we want to insert a value in the hash table, we compute its hash value and insert it in the bucket at an index equal to the hash value (modulo the size of the array). You can do the same to remove an object or search for it.

If the hash value is greater than the maximum index of buckets, we use modulo division! So, if the hash table has buckets (the max index shall be since counting starts from ), and the hash value of our element is, say, , we take the remainder of this value with the size of the array. In this case, , hence the element with a hash value equal to will be stored in the bucket with index .

Example of a hash table
Let's look at an example now. Say we have a hash table with 5 buckets, and we are inserting integers {1, 3, 5, 6} with the identity hash function. The table looks like this:

Index
0
1
2
3
4

Values
{5}
{1, 6}
{}
{3}
{}

Now let's figure out how it works. Since we're using the identity function, the hash value is equal to the value itself. Because of this, you can see that 1 and 3 are in buckets at indexes 1 and 3 respectively. Now, 5 and 6 have hash values 5 and 6, but there are too few buckets! To find a bucket for them, we take the modulo of the hash value by the total number of buckets, in this case, 5. So, 5 modulo 5 is 0, and 6 modulo 5 is 1, and you can see in the table that the values are placed in the correct buckets.
Hash set vs hash map
There are two types of hash tables. The one above is called a hash set. We can use it in scenarios where we only need to check if a value is present: for example, the book scenario in the introduction. We can still add or remove elements to a hash set, but in most cases we are not interested in getting a value out of a hash set. This happens because we already have an equal value that we need in order to search a hash table. Implementations of hash sets are unordered_set in C++ and HashSet in Java.

Another type of hash table is a hash map. Imagine you want to keep a phone book of names and numbers of friends, and want to search for phone numbers using a friend's name. If you kept a hash set of the name-number pairs, you would need to know the number to be able to search. Here, hash maps can help you. They are very similar to hash sets, but they store pairs. The first entry in the pair is called the key, and the second is the value. Only the hash of the key is used, and, when searching, we look for the value associated with a key. In the example above, the keys would be the names, and the values would be the phone numbers. Implementations of hash maps are unordered_map in C++ and HashMap in Java.
Summary

Hash tables are data structures that support fast inserting and removing values, and checking if a value is present.

Hash tables consist of buckets holding zero, one, or several values.

Hash functions are used to determine a bucket for a value.

Hash sets store objects based on their hash values; hash maps store key-value pairs based on the keys' hash values.

So far so good: however, have you asked yourself how to avoid having more than one element in one bucket? What if the number of elements is greater than the number of buckets? This and more are going to be discussed in the following topic. For now, make sure you have fully mastered the theory by solving some easy-peasy tasks.
"
152,Custom generators,651,8269,860,https://hyperskill.org/learn/step/8269,"In this topic, we're gonna learn about one more useful and pretty unique Python tool called generator. Its implementation looks quite similar to the things you already know (like function and list comprehension), so it won't be hard to master, but definitely worth it since generators have quite a few tricks up their sleeve you might find very useful in practice. Let's not waste time any more and get to know them better!

Generator functions
Imagine that in order to solve some problem, you need to obtain the first few multiples of some number a (for example, the first 4 multiples of 3 are 3, 6, 9, 12, etc.). The most straightforward way to do so is probably to define a function multiples(a,n) as follows:

So, multiples(a,n) collects the first n multiples of a together in a list that is then returned. What are the disadvantages of such an approach?
Well, imagine that n is very large. If you get all the values at once, you will need to keep a very large list in memory. Is it necessary? It depends, but definitely not if you are going to use each value just once. Or maybe you don't even know exactly how many multiples you will eventually need, you just need to be able to get them one by one till some event happens.
For cases like this, generator functions are very helpful. A custom generator can be declared in the same way as a regular function with a single difference: the return keyword gets replaced with yield.

When a regular function is called, Python goes back to its definition, runs the corresponding code with the provided argument values and returns the entire result with the return keyword to where the function is called from.
Generator functions, in turn, produce values one at a time, only when they are explicitly asked for a new one, rather than giving them all at once. Calling a generator doesn't immediately execute it. Instead, a generator object is returned that can be iterated over:

In order to get the generator function to actually compute its values, we need to explicitly ask for the next value by passing the generator into the next() function. Note that yield actually saves the state of the function, so that each time we ask the generator to produce a new value, execution continues from where it stopped, with the same variable values it had before yielding.
# This is a generator.
multiples_of_three = multiples(3,5)

# It produces the first 5 multiples of 3 one by one:

Generator expressions
Another way of defining a generator is generator expressions, which are similar to list comprehensions. The only difference in the syntax are the brackets: one should use square brackets [] for list comprehension statements and the round ones () for defining a generator. Compare:

Generator expressions are very convenient to use in a for loop. A new value is automatically generated at each iteration:

Why are generators useful?
So far, we've learned that generators produce a single value from a defined sequence only when they are explicitly asked to do so. This approach is called lazy evaluation.
Lazy evaluation makes the code much more memory efficient. Indeed, at each point in time, only values are produced and stored in memory one by one: the previous value is forgotten after we have moved to the next one and, therefore, doesn't take up space.
Keep in mind, however, that exactly because the previous value is forgotten when the new one needs to be generated, we can only go over the values once.
Summary
Those were the basics of generators in Python. Let's sum it up:

Generators allow one to declare a function that behaves like an iterator.
Generators are lazy because they only give us a new value when we ask for it.
There are two ways to create generators: generator functions and generator expressions.
Generators are memory-efficient since they only require memory for the one value they yield.
Generators can only be used once.
"
153,Iterators,677,8479,863,https://hyperskill.org/learn/step/8479,"At this point, you already know about for loops in Python that you can use to go through the elements in a list, for example. However, Python also has other similar tools with their own advantages, which we're going to learn about in this topic, so let's start!

Iterables and iterators
In Python, we call any object we can loop over an iterable. Very common examples of iterable objects are lists, strings, and dictionaries.
Iterables in Python implement the __iter__() method that returns an iterator, an object that traverses an iterable and returns its elements one by one. Iterators represent a stream of data. They implement the __next__() method, which returns the items of an iterable one by one.
You can create an iterator passing an iterable to the built-in iter() function.

 Each time you want to get the actual values, you need to pass iterator to the next() function: 

Note that when we call next() for the fourth time, we get a StopIterationexception. It's because our list contains just three elements, and iterator can only pass them once.
But do you always have to call next() manually? Not if you create and use iterators in for loop statements using the following syntax:

Python for loop will automatically create an iterator from a given iterable and get its elements one by one with the help of the next method until the iterable is exhausted. Thus, to print out the elements of my_list defined above, we can simply write the following:

zip()
Now you know how to create an iterator from a single iterable. What if you need to look over the elements of not one but multiple lists at the same time? Well, then the built-in zip() comes in very handy.
Suppose, for example, that you have two lists with the first and last names of the employees, and you need to print out the full names. With zip(), this can be easily done as follows:

zip() takes several iterables and returns an iterator of tuples, where each tuple contains one element from each of the given iterables. Note that if zip() gets iterables of different lengths, iteration will stop as soon as the shortest iterable is exhausted:

However, in Python 3.10 zip() has an optional boolean keyword parameter strict. When set to True, if one of the arguments is exhausted before the others, a ValueError will be raised:

This new option allows you to explicitly require all iterables to have an equal length and will help you to quickly detect bugs in case they don't.
enumerate()
Another very useful tool is the built-in enumerate() function, which takes an iterable and returns its elements one by one along with their indexes. For instance, the code below prints out the names of the months (stored in a list) along with their numbers:

Note that by default the counter starts at 0, but you can actually explicitly specify any starting point:

Summary

In Python, iterator objects traverse an iterable, e.g., a list.
There are several built-in functions to create iterators, for example, iter(),  zip() and enumerate().
zip() performs parallel iteration over several iterables.
enumerate() returns elements of an iterable along with their indexes one by one.
"
154,Parallel iteration,1510,14559,864,https://hyperskill.org/learn/step/14559,"Parallel iteration is the way to access elements of more than one iterable simultaneously. This can be useful when you want to combine two data structures or when you want to access more than one iterable element in one for loop. In this topic, we will learn how to do all these things using the built-in zip() function.
The zip() function
Zip() takes multiple iterables and zips them together into one iterator, just like a zipper that binds the interlocking teeth of a zip.

The function can take any number of iterables and then returns an iterator of tuples. Each generated tuple contains one element from every iterable that was provided to zip(). Let's look at the following example of passing two lists:
Take a look at how zip() takes the first element of numbers, the first element of words and zips them together into a tuple. It does the same thing for every other pair of elements. Remember, zip() returns an iterator, so we need to convert it to a list first to print the whole output. 
You can pass any iterable to zip(). Mind the following snippet:
Using zip() with unordered iterables like sets will return tuples that are paired up in random order.

Iterables with different lengths
If you pass iterables of different lengths to zip(), the number of the resulting tuples will always be equal to the shortest iterable. Any remaining data in the longer iterables will be discarded:
In the above example, we have established a zip() function with two data types: a set of four elements and a list of six. The first 4 True values have been zipped together with the shorter set, but the False values have been discarded, as they have no pair. Also, note the order — it is different!
You can pass only one iterable to zip(). In this case, the resulting iterator will contain single element tuples:

Zip() in loops
One of the most common uses of zip() is to loop over multiple iterables simultaneously. It is called a parallel iteration. We can achieve this by using a for loop over an iterator generated by zip():
In the example above, we feed zip() three lists, and it returns an iterator of tuples. Each tuple has three elements, one from each list. In the for loop header, we define a variable for each element in the generated tuple and then use them inside our print statements. The loop then goes over each tuple in the iterator one at a time and executes all the print statements. Here you can find the code visualization that can help you to better understand how it works.
Parallel iteration with dictionaries
Parallel iteration is a little more tricky with dictionaries. By default,  zip() will only generate tuples containing a dictionary's keys. To include both keys and values, you must use the .items() method in the dictionary:
In the above example, we use .items() to convert two dictionaries into item lists. Each list includes key-value tuple pairs. These lists are then zipped together to form an iterator where each generated tuple contains two nested tuples, one key-value pair from hero and one from villain. Then we assign our for loop variables in the same nested pattern and loop through the iterator.

For clarity, we have printed our zip iterator as a list. However, this exhausts the iterator of all its tuples, so it needs to be defined again before being used in the for loop.

Unzipping
Unzipping a sequence is as simple as adding an unpacking operator to an iterable provided to zip().
It unpacks phrase into three separate tuples, and after that, zip() combines back together in parallel, just like any other group of iterables. 
Conclusion
Parallel iteration is very useful when you work with different data structures. We have learned how to use zip() and combine iterables to iterate over them in parallel, as well as how to unzip these iterables further. Time to practice with a few examples!
"
155,How to improve code performance,1831,17089,865,https://hyperskill.org/learn/step/17089,"Python is a high-level programming language. It has many applications in machine learning, web development, and data analysis. It also contains easy syntax and provides various libraries for developers to increase productivity and optimize code. As a piece of code grows more complex, the program becomes inefficient. In this topic, we will learn to increase the performance of programs with built-in functions, list comprehension, generators, string concatenation, and other features.

Why optimize?
Code optimization is a way to perform a task faster and with fewer code lines. While doing this, the program consumes fewer resources. Why is optimizing so important? Let's consider an example with a search engine. If the new search engine is faster than the one we used before, it makes perfect sense to switch to the new one. That's why we need to use the best tools for development.

Built-in functions
With built-in functions, you can increase the speed of your code greatly. They have been tested and optimized to work better. If you can write your code with built-in functions, you'll improve the performance.
We import the time() method from the time module to observe the difference. We create a list of numbers from 1 to 10000000. First, we add the numbers in the function without using the built-in method. Then we add the numbers using the sum() method. With the help of the time() method, we observe that the difference is almost eight times.
You can access the entire list of built-in functions in the official documentation.

List comprehension
In Python, we often use loops to add elements to a list. While doing this, we perform various control operations. We can also use list comprehension to make this happen in a faster way. As an example, let's add numbers divisible by three to a list:
Both approaches produce the same result. But list comprehension makes the code more readable, and it also makes our code run twice as fast.

Generators
A regular list saves all of its elements in memory, but this is not very efficient. As you remember, generators are Python structures that allow data to be loaded temporarily. In this way, you get the data you need only when you call it. What's more, there are functions in Python that use the generator structure by default, for example, map() and filter(). You may want to create your generator functions as well.
Now let's look at a function we've made with a generator:
In this example, we return odd numbers in a given range. Note that creating the generator happened in no time. However, you should understand that a generator object is different from a list. Generators cannot perform some operations such as indexing and slicing, but we can iterate over our values using a for loop. If we had opted for something else, we would have needed to store all of our numbers in a regular list. In this case, if the list is large enough, it could cause memory overflow or even a crash.

Proper string concatenation
In some programs, the + operator concatenates strings. With each plus operation, a new string is created and copied over the old data. Instead, we can use a more efficient join() method:
We can also decide how to combine elements in the join method. In the example, we've combined it with space. In this way, the readability and speed of our code have increased.

Other improvements
Some Python libraries are written in the faster programming languages such as C and C++. Numpy and Pandas libraries can significantly increase the speed of your program.
Another important thing is to import third-party libraries properly: do not use dots when calling functions in these libraries to increase the speed of your program. Let's see an example:
In the code above, we have compared the two approaches with the help of the time() method. The first code runs slower because of dots; they create lookup operations. Also, explicit import enhances code readability.
io.StringIO in Python is an in-memory stream that allows you to read from and write to a string buffer as if it were a file. It provides a file-like interface for working with string data.
Using io.StringIO can save memory in certain scenarios because it avoids the need to store data in a physical file on disk. Instead, it keeps the data in memory, which can be more efficient and faster for certain operations. Let's look how to use this method.

Conclusion
To sum up, in this topic, we've learned:
Benefits of optimizing our code;Importance of using functions defined in Python when possible;Importance of generators and list comprehension;Effective string concatenation;The correct way to call a method from a library.
Now let's move on to the practice.
"
156,Decorators in OOP,923,10153,868,https://hyperskill.org/learn/step/10153,"As you already know, decorators can help change the behavior of a function without modifying its code. In this topic, we will discuss three main built-in decorators that can help us to work with classes: staticmethod, classmethod, and property.

The @staticmethod decorator can be used to bind a function to a class as its method. In the following example, we have the CharType class and the method to get the type of character:

As you can see, we may access the static method without creating an instance of the class first. Of course, we can extend the functionality by adding other methods which will interact with the static methods within the class.
Note that such static methods do not have any mandatory parameters; in contrast to instance methods we have dealt with before, the functions decorated with the @staticmethod decorator do not take self as the first argument; nor do they accept the cls argument, as opposed to class methods you will read about below. Even though a static method belongs to a class and all its instances, it does not get any access to instance internals. This method is used for a matter of convenience or to make a better design for the code.

Now, let's move on to the @classmethod decorator. As you know, a ""regular"" method takes an instance of the class as its first argument and then we use self to refer to it. Class methods, on the contrary, do not require particular class instances; they have access only to general class attributes and properties. Because of this, their first parameter should always be cls, which represents the class itself, and not the class instance, denoted by self.
In the following example, we have the class User and a single string, containing both a name and a surname. Now, we need to process the string to receive the name and the surname as two separate string variables. We are going to do it with the help of the from_string method.

As you can see, class methods are used when we do not need attributes of specific instances but want to use the class information for some purpose. The most common example is alternative constructors. For one, if the required information comes from some outer source, a file, for example, in this case, we cannot pass the data directly as class instances. We may carry out some kind of preprocessing before actually creating a new object, you have seen this case in the example above. With the help of the decorator, we call a class method using the class itself rather than a class instance.
However, we can also call the from_string method on the User instance, even though it makes less sense.

To make it clearer, let's outline the main differences between static and class methods:

Static methods have neither cls nor self as their parameters, so we cannot operate on the class or particular instances within the method. In general, they act similarly to functions outside the class and are often used as utility methods.
Class methods always take the class as the first argument, usually called cls. They are frequently used as alternative constructors that create class objects for various use cases.

Finally, let's create a basic example of the @property decorator usage. This one is designed to access a method as if it was an attribute of a class. Once again, we have an instance of the User class:

When we change the name of the user to 'Father', we notice that the full_name attribute of our object remains the same. It happens because we have only set it during the initialization.

It is a perfect case to use the @property decorator! If we define full_name using the decorator, we will evaluate the method every time it is accessed as an attribute.

In this topic, we have learned that:

the @staticmethod decorator allows us to use a function without access to class instances as a class method;
the @classmethod decorator can be used to call a method of a class instead of a class instance;
the @property decorator is helpful when we want to access a method as an attribute.

Now let's practice!
"
157,More dictionary methods,3470,36298,881,https://hyperskill.org/learn/step/36298,"In Python programming, dictionaries are a useful data structure for storing key-value pairs. Once we have created a dictionary and added elements to it, we may need to retrieve specific values or remove items one by one or altogether from the dictionary. This topic will explore various methods that can help us accomplish these tasks efficiently.

Getting and removing items
We know how to create a dictionary and add elements to it. But what if we need to get some value from the dictionary or also remove an item? The following methods will help you deal with different tasks depending on your needs.
1. Get a value from the dictionary by a key.
As you remember, we can access the value in a dictionary by a key:

However, if you try to access a non-existent key, you will get a KeyError:

To avoid the KeyError, we can use the get method that returns None if the specified key is not in the dictionary:
# 'get' method does not throw an error

With the get method, we can also define the default value that will be returned in such a case:

2. Remove the key from the dictionary and return the value using the pop method.
If the specified key was found in the dictionary, then the method will remove it and return the value:

If the key was not found, a KeyError will appear:

To get rid of it, we can provide a default argument, and it will return this default value:

3. Remove and return the last item (key, value) added to the dictionary using the popitem method:

Pay attention, if the dictionary is empty, a KeyError will appear:

Before Python 3.7, the popitem method removes and returns a random item from the dictionary, not the last one added.

Cleaning the dictionary
All the methods described above return a value or an item (key, value) upon removing, but sometimes this is not what we want. There are two ways that remove an item from the dictionary (they do not return anything) or the entire dictionary content at once.
1. Delete (remove from a dictionary) a value by its key with the del keyword:

# this will remove both the key and the value from dictionary object

# throws a KeyError because there's no such key in the dictionary

# throws a KeyError, as we've already deleted the object by the key

# deletes the whole dictionary
2. Remove all the items and return an empty dictionary using the clear method:

Differences in removal methods
You may wonder, is there any difference between dict = {} and dict.clear() ? Let's say we have another variable that refers to the same dictionary:

Then, the dict = {} just creates a new empty dictionary and assigns it to our variable. Let's go back to the example above and assign an empty dictionary to testable:

another_testable still points to the original dictionary with the same elements, so it doesn't change.
In contrast, the clear method will clear the dictionary as well as all the objects referring to it:

Summary
In this topic, we discussed methods for getting values from a dictionary and removing items from it. We learned about the get method, which allows us to retrieve values from a dictionary by a key while avoiding KeyError exceptions. The pop method enables us to remove a key-value pair from the dictionary and retrieve the associated value. Additionally, the popitem method removes and returns the last item added to the dictionary.
We also explored two ways to clean a dictionary: using the del keyword to remove a specific item by its key and the clear method to remove all items from the dictionary. We also highlighted the difference between assigning an empty dictionary to a variable and using the clear method, emphasizing that the latter clears the dictionary and all objects referring to it.
By understanding these methods, developers can effectively manipulate dictionaries, retrieve values, and remove items as needed, enhancing their ability to work with this data structure in Python.
"
158,Pydoc,2017,18505,885,https://hyperskill.org/learn/step/18505,"Everyone knows how necessary good documentation is. When other programmers read your code, comments might be sufficient, but users won't see them. Users are going to read the documentation. Indeed, you've read many pieces of documentation, but have you ever written one? If you're thinking about long hours of painfully trying to formulate your thoughts – don't worry; it's much easier than that. The pydoc module was created for precisely that – generating documentation fast and straightforwardly. Let's learn how to use it!
Documenting functions
The pydoc module is part of the Python standard library, so you don't have to install it. There's no need to import it into your code; it can be used in the command line. Usually, your workflow is this: you write some code, save it to a file, run pydoc through the command line – and get the documentation. Easy, right? Let's go through this process step-by-step.
Pydoc isn't magic. It doesn't create documentation on its own; it just derives it from docstrings. You probably remember what a docstring is: a string, usually in triple quotes, that documents classes, modules, or functions. If there are no docstrings in your code, pydoc will use comments to generate documentation. So that's it, pydoc just takes docstrings or comments you've written and creates neat and easy-to-read documentation from it.
To see how it works, we have to write some code first. Let's start with a simple function:
Now, we'll save it as greet.py and open the command line. In the command line, we go to the directory where our file is stored and type pydoc -w greet (or python -m pydoc -w greet). Note that it's just greet, without the .py! -w means we want our documentation as an .html file. Documentation will be printed in the console if you don't use this argument. Here's what it may look like:
The wrote greet.html line means that the documentation has been created. Now, it's stored in the greet.html file in the same directory as greet.py. Let's have a look at this file:

What do we have here? At the top, there's the filename (greet in our example) and the file path. Then, there's the Functions section, where all defined functions are listed: in our case, it's only one, greet(). Then you have the function's docstring. Simple, yet effective! 
Now let's try something more advanced – documenting classes and methods.
Documenting classes
The process of documenting classes isn't much different from functions, but let's see how it's done. We'll define the Cat class to store a name and age of a cat. We'll also define the say_hi() method inside that class. Here's the code:
Pydoc imports modules to document them, so any code on the module level will be executed. For example, if our code has cat = Cat('Johny', 2) and cat.say_hi() lines, pydoc would execute them. We don't need that, so if there's something executable in your code, don't forget to put it under if __name__ == '__main__':
The documenting process is the same as before: save the module to cats.py, run pydoc -w cats in the command line and open the cats.html file that pydoc has created. Here's how it looks:

Now, the Functions section is gone, which makes sense, as we haven't defined any functions in this example. But there we have the Classes section, where we can see our Cat class with its docstring, its methods, and their respective docstrings. There's also a section on data descriptors which is just a standard part of class documentation.
We had def say_hi() in our example, it was considered a class method, not a function, since it's inside the class. If we define a function outside the class, it summons the Functions section right after the Classes section.
Now we know how to document both classes and functions. Let's see how comments affect our documentation.
Adding comments
Until now, the documentation in our examples was generated from docstrings. However, pydoc can use comments as well. How it uses them depends on where they're placed and whether there are any docstrings.
Let's get back to our example with the greet() function. For this example, we'll remove the docstring and add several comments:
Let's generate the documentation and see if any of the comments are there:

As you can see, only two of our comments made it to the documentation. The comment at the top of the file was placed at the top of the documentation. The comment before the function has taken the place of the docstring. Other comments have been ignored. So how does pydoc decide which comments to use? The rules are:
Ignore the comments inside functions and classes;Ignore the comments at random places (like at the end of the code);If a function or class has no docstring, use the comment just above this function or class;If there's no docstring at the top of the module, use the comment at the top.
 

The rule of thumb is that pydoc prioritizes docstrings over comments.

 
Now, let's see what happens if we keep all the comments but also add some more docstrings:
Greet.html looks like this:

There are enough docstrings, so pydoc completely ignores the comments. It makes sense: while docstrings describe the behavior of modules and functions, comments can be just thoughts or ideas for fellow programmers. So, they are only used if there are no docstrings.
Now that you know all the basics; let's have a closer look at pydoc in the command line.
Command-line arguments
So far, we've seen the -w argument only; it means we want to write the documentation to an .html file. However, there are more arguments. Type pydoc -m in the command line to see all of them.
The arguments -n, -p, and -b are used to start an HTTP server to browse the documentation.
There's the -k argument (k for keyword). It lets you search through all the modules you have installed looking for a keyword. Note that only the first line of each module description will be browsed. For example, if you type pydoc -k statistics, you'd get a list of all modules with the word ""statistics"" in the first line of the description.
You can use pydoc not only for drawing documentation for your programs but also for accessing documentation of other modules or built-in classes. For example, if you type pydoc statistics, you'll get the statistics module documentaton printed in the console. If you add -w (pydoc -w statistics) you'll get an .html file with that documentation. It's equivalent to help(statistics), but if you want a prettier and more colorful representation, give pydoc a go!
Conclusion
In this topic, we've covered the basics of creating documentation with pydoc. Now you know how to document modules, functions, classes, and methods. Let's quickly go through the main points:
Documentation is generated from docstrings;If there are no docstrings, the module will use comments;Pydoc runs on a .py file in the command line;Use pydoc filename to see the documentation in the console and pydoc -w filename to save it to an .html file.
If you want to learn more, check out the official documentation. Now it's time to practice!
Read more on this topic in Commenting the Right Way in Python Code on Hyperskill Blog.
"
159,Defaultdict and Counter,616,7989,891,https://hyperskill.org/learn/step/7989,"Dictionary is an incredibly versatile data structure. However, it has its limitations. In this topic, we'll look at one special dict method that makes working with dictionaries much easier as well as some dictionary-like objects useful in particular situations.
Method dict.setdefault()
Often dictionaries are used to store frequencies of elements from some collection. You may want to store word counts from a text, or values from a list. How would you do it? Well, the obvious way is to loop through all the elements and increment the count of the element you've encountered by one. However, you have to check if the element has already been encountered, otherwise you may get a KeyError. This may be tedious: you have to write an if statement, or catch exceptions, or handle None values (if you use dict.get()).
As you may have guessed, there are easier ways to deal with this. One of them is the dict.setdefault() method.
Let's check out an example. Suppose we want to create a frequency dictionary for the text below.
How can we use dict.setdefault() to create a frequency dictionary? Well, the method takes two parameters: key and optional default. It returns the value of the key and if it is not present, sets it to default (or None). Following this logic, for the frequency dictionary, the default value should be 0.
 As you can see, we've successfully created a frequency dictionary in virtually 3 lines of code! No need to handle exceptions or check conditions.
The setdefault() method is particularly useful when the value is a mutable object, for instance, a list or even another dictionary. Suppose we want to create a dictionary of indexes of all occurrences in the list. This is how it can be done.
Here we use the enumerate function to iterate over elements of text_list and get their indexes at the same time. Since dict.setdefault() returns the value for the key, we can directly append the new value to the list.
This method is also handy when dealing with missing values. If we're not sure that some object is a key in the dictionary, we can just set its value in the process:
As a result of the code above, the word ""are"" will be added to freq_dict with the value 0.
collections.defaultdict
Along with the dict.setdefault() method there is another way to manage default values: defaultdict from the collections module.
defaultdict is a dictionary-like object defined in collections. The only significant difference is that when creating a new dictionary, we can specify a default_factory parameter. default_factory should be a function-like object that determines the type or the value of the parameter. For example, the default_factory can be a list function: list. In this case, the default value of any object will be an empty list.
In our example with the frequency dictionary, the default_factory should be int: the default value of the int() function is 0. Let's see how that can be used:
Note that you shouldn't call the function object you're setting as default_factory!

defaultdict also makes it extremely easy to deal with missing keys because we have already defined a default value for any object:
As you can see, we don't really need to do anything: if you've defined the default_factory parameter, dealing with missing keys doesn't cause any errors. Like with dict.setdefault(), the missing keys are added to the defaultdict if we try to check their values.
collections.Counter
Now, all the ways of creating frequency dictionaries we've covered so far work perfectly fine. However, they require a bit of work, that is creating a dictionary and going through the list and counting the elements. You'll be happy to know that there is a very straightforward way to do it without all the work: Counter object from collections.
Counter is another dictionary-like object used specifically for counting the elements of an iterable object. Take our example again:
That's all it takes to create a Counter, which is essentially a frequency dictionary! 
Another advantage of Counter is that the count of a missing object is 0, no KeyErrors are raised! However, the missing object isn't added to the dictionary if we try to check its value.
Counter supports most of dict methods and also has some special methods of its own. For example, the most_common(n) method, which returns a list of tuples of n most common elements with their counts. If n isn't specified, all elements are returned in the descending order of their frequencies.
Note that since Python 3.7, Counter preserves the insertion order of elements (just like dict). So, elements with the same count are returned in the order of their appearance in the original collection.
Summary
In this topic, we've seen how you can define default values for dictionary keys, deal with missing keys, and create different types of frequency dictionaries.
To sum up,

dict.setdefault is used to set a default value for a particular key;
collections.defaultdict defines a default value for all objects;
collections.Counter counts elements of an iterable object.

For additional information about defaultdict and Counter you can check out the official Python documentation.
We hope that you'll use these objects and methods in your projects!
"
160,Glob module,1576,15061,894,https://hyperskill.org/learn/step/15061,"In this topic, we would like to introduce the glob module. It can find files and directories on your computer whose names match a specific pattern. It is a simple yet steady module if you spend a lot of time working with files.
This topic covers two glob methods — one searches for files; the other creates searching patterns. Once you master this topic, you will be fully equipped to use the glob module! One more thing. This module is a part of the Python Standard Library, so you don't need to install it from an external source.
Patterns
The glob module lets you use wildcards to search for files and directories whose names follow particular patterns. The rules for these patterns are the ones used by Unix Shell. They resemble regular expressions but much simpler:
WildcardMeaning*matches 0 or more characters?matches a single character[0-9]specifies a range of alphanumeric characters (from 0 to 9 in this case)[abc]matches only one character from the sequence (either a, b, or c in this example)[!abc]matches any character that is not in the sequence (any character that is not a, b or c)
All other characters are literals that match themselves. Don't worry if you are a bit lost right now. We will show examples in the following sections.
Searching for one file
As we have already mentioned, the glob module is quite straightforward. It has only three methods: glob, iglob, and escape. We start with the first one, as it is most wanted. Before we begin, don't forget to import the glob module to your program.
The syntax of the glob() method is glob.glob(pathname, *, recursive=False).
It returns a list of filenames that match the pathname (a pattern where you can use wildcards). The recursive flag is False by default; it means that the search will be performed only in the provided directory. If you set it to True, the pattern ** will match any files and subdirectories not only in the provided directory but also inside all subdirectories.
The * in between the pathname and the recursive flag passes this flag as a keyword argument. In other words, you can write glob('my_dir\**', recursive=True) instead of glob('my_dir\**', True).
The pathname can be either a path to an existing file on your computer (an absolute or relative) or a pattern.

As you remember, an absolute path starts from the root of the file system like C:\Users\User\my_dir\image.gif. Relative paths start from the current directory. For example, if your current directory is User, it will be my_dir\image.gif.

Both ways can help you with finding a file on your machine.
Searching for multiple files
Routinely, you may want to find multiple files that match a certain pattern. Let's look at some examples. For instance, you want to find all jpg files in a directory. First, you need to write a pattern. It would look like this: my_dir\*.jpg. Remember that * matches any number of any characters. After this, you insert it into the glob.glob() method, and that's it:
Now, let's try to find all files the names of which contain only one character. We don't know possible extensions of these files. That's how we can do the trick:
? matches one character; . matches a dot; * stands for any number of symbols. Since it comes after the dot, it also indicates the extension of our files.
What do we do if we need all filenames in one directory? There's a simple solution – use the asterisk!
It returns a list of all files and subdirectories in the my_dir directory.

If no files or directories are matching your search, it will return an empty list.

Iterable glob
glob.iglob() returns an iterator that yields the same values as glob(); the only difference is that it doesn't store them. As with any iterator, it can come in handy if you have a limited amount of memory. Here's what the call looks like — glob.iglob(pathname, *, recursive=False)
The pathname is written in the same way as in the glob() method, and the recursive flag also works the same.Let's say we want to find all files with a three characters name where the first two characters are any digits. The third one is any character except 0. To do it, we need square brackets and an exclamation mark:

[0-9] represents a range. It is any number from 0 to 9. [!0] means any character which is not 0; . is literally a dot; * is any number of characters after a dot, in other words — the extension.

Don't forget that ranges can include letters, too. For example, [p-s] means any letter from the p-q-r-s range.

This search can return the following files: 12a.txt, 345.jpg, 00j.csv but not 120.txt.
With Python 3.10, you can use the new root_dir and dir_fd parameters in glob() and iglob(), which allow you to specify the root directory for searching.
Escaping
The last method glob.escape() can escape special characters: *, ?, and []. In other words, * would no longer mean ""any character""; it would mean only an asterisk. A question mark would be a literal question mark. The brackets will be mere brackets. It may be useful if these characters are in the filename you would like to find.
The syntax is even simpler than in the previous methods: glob.escape(pathname). Note that there is no recursive flag. This is explained by the fact that glob.escape() doesn't search for anything. It returns a string — a pathname with escaped characters that you can then pass to glob.glob().
Let's say we need to find a subdirectory with the [dir] name. glob.glob('my_dir\[dir]') will not work in this case. Remember that [] is a special symbol, and, in this case, your query will return a subdirectory called d, i, or r, if there's one. So, how do we find our [dir]? That's where we use the escape method:
First, we get a string with the escaped characters we needed for the search. Then we perform the actual search and get a list with results. The escaped string [[]dir] contains [] to select the left bracket [; it is no more identified as a special symbol. Then we write the rest of the string as-is — dir]. The right bracket is a special symbol only when it follows the left bracket.
Conclusion
In this topic, we have learned:
to write patterns for file searching with the help of special characters — *, ?, [ - ], [], [!];to search for files and directories using the patterns and the glob.glob() method;to create generators to yield filenames with glob.iglob();to escape special characters with glob.escape().
Now let's move on to practice!
"
161,Yield from,2565,24636,895,https://hyperskill.org/learn/step/24636,"Previously, you've learned some basics of generators. Let's revise the most important points. You already know that a generator is declared the same way as a regular function, with a single difference: the return keyword gets replaced with yield. A generator declares a function that behaves like an iterator and gives you a new value when you ask for it. Due to this, generators are memory-efficient: they only require memory for the one value they yield. Also, yield actually saves the state of the function, so that each time you ask the generator to produce a new value, execution continues from where it stopped. Now, it's high time we learned one more useful feature of the keyword yield. Let's see how yield from works and why it is useful.

Yield from expression

As you can see, this generator yields numbers from 0 to 199. However, what if you need to split it into two generators in order to reuse them later? You can rewrite the code the following way:

This generator() also yields the numbers from 0 to 199. However, it seems unnecessary and repetitive to iterate over both generator2 and generator3 once again and yield their values. That's where yield from comes in handy. Let's rewrite the code, using this expression:

This version gives the same result, but the code looks much cleaner and is easier to write and read. In the code above, generator() is the delegating generator, while generator2 and generator3 are called sub-generators. So, by using yield from you can delegate a part of generator operations to a sub-generator. This allows you to divide the code of the main generator and put a part of it into another one. The syntax is also very easy:

yield from <expr>

Note that <expr> can be any iterable: list, dictionary, another generator, etc.

Why is it useful?
Basically, you can use yield from to make it easier to correctly iterate through and yield values from another iterable.
For simple iterators, yield from is equivalent to a for-loop, but it also contains the full range of generator features and allows generator code to be fractured in an easy and straightforward way.

When the code execution comes to yield from <exp>, the iteration of <exp> starts and yielded values are sent to the outer generator right away. It goes on until <exp> is exhausted and returns StopIteration. After this, the execution of the outer generator continues.

Let's have a look at one more example that demonstrates this:

When you call the code above, firstly, word will be iterated until the end, and then execution of the outer generator will go on:

Thus, the main benefit of using yield from <expression> is the opportunity to divide generators into several sub-generators. As a result, yield from makes coding easier and more efficient. If you are interested in seeing more examples of cases when and how yield from turns out useful, check out the PEP.

Summary
In this topic, you've learned the syntax of the yield from expression and have found out what a delegating generator and a sub-generator are. Let's sum it up:
a delegating generator is a generator in which the yield from <expr> syntax appears;a sub-generator is a generator used in the <expr> part of the yield from <expr> syntax;the yield from expression allows dividing the generator into multiple sub-generators without extra rewriting;the yield from expression allows yielding values from another iterable inside a generator;for simple iterators, yield from is equivalent to a for-loop syntax;the yield from expression makes code easier and cleaner.

Let's practice all of this right away!
"
162,Any and all,597,7800,900,https://hyperskill.org/learn/step/7800,"By now, you certainly know that Python has a lot of different built-in functions that help developers work more efficiently. Built-in functions are always available, so you don't need to declare or import them. Just call such a function whenever you need it. You have already seen one of those functions, it is  print(). Today we will learn two more built-in functions any() and all() and find out how and when to use them.
Be careful though, these functions work only with iterable objects, e.g. strings and lists. A list is iterable, so we will use it to illustrate the theoretical part and to show how any() and all() work.
Function any()
The result of the any() function call is the boolean value: it returns True if an element or a group of elements in an iterable object are evaluated True. Otherwise, it returns False. Let’s take a look at the example. Imagine that you and your friends, Jam and Andy, wrote a test and got your results in the form of a list with True and False values.  The test is passed if at least one answer is correct. Now you need to check if you and your friends passed that test.
As you know, the value True corresponds to 1, while False can be represented by 0, therefore, you can replace the boolean values with the numerical ones in the list above and get the same result.
In fact, all numbers other than 0 will be regarded as True, even the negative ones. That part stems from how the bool() function works.
Now back to our test example, you passed with one correct answer. What about your friends, Jam and Andy? Andy has a different list of results to check.
Unfortunately, your friend Andy failed. What about Jam? Well, this friend of yours didn't write the test at all, so he got an empty list of results.
The list doesn't contain any elements, and since no True value is to be found the any() function returns False.
So what does the any() function do? First, it takes a list as an argument, then evaluates all the elements of this list to find at least one True, if so, it returns True, otherwise, the result is False.
Function all() 
The all() function works pretty much like any(). The difference is that all() function checks if all the elements of an iterable object are True and returns True if they are. Otherwise, you get False. Do you remember the story from the previous section where we checked the results of the test? Let's proceed. Imagine yet another test, this time the final one. To succeed, you should answer all the questions correctly. How did it go this time for you and the two friends of yours?
As you can see, not all the answers in your case are correct, so you didn't pass the test. What about Andy's results?
Luckily, Andy passed. Jam seems to have a vacation. His list of results is empty again.
The list doesn't contain any elements, but the all() function will return True because it searches for any False values. No False values result in True. Be careful with this scenario.
Non-boolean values
Pay attention to the fact that any() and all() can take a list containing non-boolean values. Let's recall how they are evaluated.
Empty sequences, e.g. strings and lists, as well as zero, are equivalent to False, the same applies to the constant None. Non-empty sequences are equivalent to True.

Be cautious, the result of calling the all() function on an empty sequence differs from converting an empty sequence to a boolean value. The result of all(list())  is True, the result of bool(list()) is False. 

Here is a list with false values. any() and all() will have the same behavior in this example:
Now, let's look at the scores of some simpler subject:
As shown, all() doesn't return True for a list where false values are present. Consider the last case:
The list biology_scores has no false values, that's why both functions result in True.
Also, you can turn the elements of your list into the boolean values via comparison. Suppose, we have a list of scores and want to check whether some are equal to 3 or greater. It can be done like this:
However, lists may contain different elements, e.g. strings or nested lists, in such cases, the behavior of any() and all() would depend largely on the contents. Keep that in mind.
Conditions
Coders often use any() and all() functions in conditions. It helps to check the elements of iterable objects quickly and to avoid complex constructions.
Let's choose a candy box for Valentine's Day. Each box contains several types of sweets. But you are interested in the even amount of candies of each type because, obviously, you will share them with your valentine.
if any([candy % 2 for candy in box]):
    print(""It is not a proper gift."")
else:
    print(""Perfect!"")
Short and sweet, isn't it? Life is like a box of chocolates! As long as the values you deal with can be converted to True and False, it's safe to use both functions in conditions.
Summary
We learned what any() and all() functions can do and how they work. As you can see, these functions are an efficient tool that helps check conditions and may improve the readability of your code.
"
163,Math magic methods,565,7444,901,https://hyperskill.org/learn/step/7444,"If you want to improve and upgrade your classes, chances are that what you need can be done with magic methods. Dunders in Python provide a wide range of functionalities, from type conversion to attribute managing. In this topic, we'll focus on ""mathematical"" magic methods: the ones that deal with arithmetics and comparisons.
Arithmetic operations
There is a group of magic methods representing common arithmetic operations:

__add__() : addition (+)
__sub__() : subtraction (-)
__mul__() : multiplication (*)
__truediv__() : division (/)
__pow__() : exponents (**)

This list is not exhaustive, there are many other methods, but these are the most common ones.
However, the question is when would we need to use them? Let's consider an example.
This is a class that represents complex numbers. A complex number is a number that can be expressed as \(a + bi\) where \(a\)  and \(b\)  are real numbers and \(i\) is the imaginary number: the solution of the equation \(x^2 = -1\) . So \(a\) is the real part of the complex number and \(b\) is the imaginary one. Just like ordinary numbers, we can add two complex numbers, multiply them, do subtraction and division and many other standard operations. Let's create two complex numbers and try to add and multiply them:
As you can see, we cannot simply add two complex numbers using the standard operators in Python. We could, of course, define custom methods like add or multiply and call them when we need to do math with complex numbers, but it wouldn't be too convenient. A more elegant solution to this problem is to define magic methods __add__ and __mul__ in our ComplexNumber class and then simply use standard operators with our complex numbers. Here's how it would look:
First, let's go over the details of the methods. Since both addition and multiplication operators are binary, the methods take two arguments, self and other. other is a name typically used to denote another object of the same class. These parameters represent the operands of these operations and in this case, self is the left operand and other is the right one. If the operator was unary, the method would only take self as a parameter. 
Both methods also calculate the real and the imaginary part of a new complex number and then return a new ComplexNumber object as their results.
If we try to calculate the sum and the product of our complex numbers now, we won't get any errors:
If we wanted to define other operations, for instance, subtraction or division, we would do it similarly. The main principle with these methods is to understand what a particular operation means for your object and then define the corresponding method. 
Augmented assignment
Python also has a number of methods for augmented assignment: a combination of standard arithmetic operations with the assignment. Their names are pretty self-explanatory so you can probably guess what operations they stand for:

__iadd__();
__isub__();
__imul__();
__itruediv__();
__ipow__();
and others...

For our complex numbers, let's define the method for += operator:
This is how it works:
All magic methods for augmented assignment should return an instance of the class (self) so that the assignment works correctly.

Comparison operators
Another thing we might want to do with our objects is to compare them. Here are the magic methods that define the behavior of the comparison operators:

__eq__() : equality (==)
__ne__() : inequality (!=)
__lt__() : less than (<)
__gt__() : greater than (>)
__le__() : less or equal (<=)
__ge__() : greater or equal (>=)

Let's again take our class of complex numbers. Let's create 3 complex numbers and try to compare them.
Two complex numbers are considered equal if and only if their real parts and imaginary parts are respectively equal. But, as we can see above, this is not how it worked in our program. This is because all numbers are different objects: the code checks them for identity, not equality, and since they have different id numbers, they are not considered the same. 
We need to define the __eq__ method so that our comparisons run smoothly:
Now if we try to compare our two numbers we will get the correct result:
Other comparison operators can be defined in a similar way.
Summary
In this topic, we've covered dunders that are useful when you want to introduce a little bit of math in your classes. A big advantage of magic methods is that you don't have to define them if you don't need it. But if you do, they're there to make your life easier!
"
164,Sep and end arguments of print,569,7452,1012,https://hyperskill.org/learn/step/7452,"You already know that, to print out objects, you can use the print() function. For example, the following lines of code will show us the value of a variable:

But did you know that print() can take multiple keyword arguments?

The separator

For example, with the sep argument you can specify the separator between objects to be printed (the separator itself must be a string).

The default value of this argument is space, that is, writing print('Gadget', 'Hackwrench', sep=' ') gives the same output as writing print('Gadget', 'Hackwrench'):

You can also use an empty string as sep when you want to print several objects together:

It will work even if you combine different values, such as integers and strings, in the example above.

The end

The argument end determines how the string we want to print should end. The default value is '\n', which means that it ends with a newline. So if you give no arguments to the function and simply write print(), it will shift you to a new line:

The output will be as follows:

However, just as with the 'sep' argument, we can set this argument to end with any other string.

Unpacking objects

The first arguments of the print() function are objects we want to print. For example, if it's a list characters = ['Humphrey the Bear', 'Spike the Bee', 'Fat Cat'], writing print(characters) will yield the output ['Humphrey the Bear', 'Spike the Bee', 'Fat Cat']. But what if we want to print objects from a list, not the list as a whole? In Python, there's a convenient and neat way to do so. Writing an asterisk * before a list means that its elements will be unpacked and passed to the function one after another:

An important detail to understand is that the elements will be separated by spaces. This is so because the snippet of code could be replaced by the line print('Humphrey the Bear', 'Spike the Bee', 'Fat Cat') with the default sep=' ':

Summary

We rediscovered the built-in print() function and examined some of its arguments, sep and end.

Note that the mentioned arguments are so-called keyword arguments. You should explicitly specify them when calling the function because all other (positional) arguments are considered as objects to be printed.

As you can see, arguments of the print() function provide useful ways of managing output. Keep that in mind when working with strings!
"
165,Program execution,418,6047,1022,https://hyperskill.org/learn/step/6047,"What does it mean to write a program in Python? From the programmer's point of view, it implies writing certain instructions in a file and then executing it in Python. We can simply create a .txt file with the following statement:

And then execute it from the command line in the following way (suppose, we named it example.txt):

You may know that all Python files are supposed to have a .py extension, but we can write the code in a .txt file as well. Usually, programmers don't use text editors for programming, they use IDEs (Integrated Development Environment), a special program designed for software development. However, one thing remains — the source code is just a set of specific instructions.
It's not all that simple. You may have heard that there are interpreted and compiled programming languages. Maybe you've also heard that Python is an interpreted language. But do you know what that means?

Interpretation
The process of program execution may seem something like this to you:

The interpretation part, in fact, fits into the middle part of this scheme:

The majority of Python programmers just stop inquiring further from this point. Let's try to explain what the interpretation means in this case.
During the interpretation part, the software goes through your program and executes the code, line by line. This software is called an interpreter. It is a part of the standard Python installation package. So, an interpreter is a layer of software logic between your source code and your hardware.

An interpreter can be written in any programming language. The default Python interpreter is written in C, it is called CPython. This is what we install from the official Python website.

Interpreted or compiled?
To understand what is under the hood of Python, let's find out what lies behind the concept of interpreted and compiled languages.
Before we start, let's discuss an easy example. Imagine you have a wonderful apple pie recipe that you want to bake, but it's written in French and you don't know it. There are two ways for you to deal with it. The first one is if someone had already translated the recipe text into English. At that moment, you could read the English text and bake an apple pie. Consider this translated recipe as the compiled version. The second way is if you have a friend who knows French. When you are ready to bake a pie, your friend stands nearby and translates the recipe into English line by line. In this case, your friend is an interpreter for the interpreted version of the recipe.
With compiled languages, when a programmer wants to run a source code, they need to use a compiler first. It is the special software that translates the source code into a special language. This language is called the machine code. It is a set of instructions executed directly by your processor. The problem is that different types of computers operate with different machine codes, so the source code compiled in Windows may not work on a Mac.
Interpreted languages also include a compilation step, but the compiler turns your source code into the so-called byte code, an intermediate language. The byte code is a lower level (more detailed), platform-independent, and more efficient version of the source code. We need a special abstract computer (the Python Virtual Machine in our case, but more on that later!) to execute this code.
In fact, the interpretation step consists of three phases:

Byte code is saved as a .pyc file after the compilation. If the source code of the program has not been changed since the last compilation, Python will load the existing .pyc file, bypassing the compilation step.
Below you can see the readable byte code. The second column contains the instructions in the order of their execution. If something is unclear, it's OK. You don't have to know the byte code inside out to write programs.

Python Virtual Machine
The byte code is supplied to the PVM (Python Virtual Machine) after the compilation. It may sound quite impressive, but in fact, it is nothing more than a big piece of code that iterates through the byte code instructions, which were received from a compiler, and executes them one by one. It is an internal part of the Python system and you don't need to install it as a separate program.

PVM in CPython does not convert the byte code into the machine code. It can execute it right away.

This complexity is hidden from a programmer for a reason. The interpretation is fully automated, and you won't need to think about it at all. Remember that Python programmers simply write the code and run the files, Python does everything else.
Summary
Python is an interpreted language. It compiles the source code to the byte code before the execution. Executing a Python program implies both compilation and interpretation.
When your program is turned into the byte code, it's executed line by line by the PVM. That's why Python is slower than compiled languages such as C++ or C.
"
166,Python Global Interpreter Lock,1897,17523,1024,https://hyperskill.org/learn/step/17523,"The subject of this topic probably won't bother you as a Python developer unless you work on C extensions or with multithreaded programs. However, you're likely to come across threads or processes, at least for educational purposes. Let's stay fundamental and consistent in the pursuit of knowledge and try to understand what a Global Interpreter Lock is.
The purpose of GIL
A Global Interpreter Lock (GIL) is a mechanism that protects Python objects from being accessed by several threads at once. It allows only one of the threads to take control over the interpreter and execute the bytecode. In other words, it can solve the issue when multiple threads can manipulate the same objects simultaneously, as this may lead to crashes, data corruption, erasure, and other dubious behavior. Let's discuss this a little bit more thoroughly.
One way to solve the problem we've described above is to isolate objects from the threads they're working with. Sounds logical, right? Not so fast, as this may lead to the so-called deadlocks. A deadlock is a state in which each thread is waiting for another thread to release a lock. Let's clear it up a little. You have two threads; both need to manipulate objects A and B. The first one starts with A, while the other starts with B. You end up in a situation when the first thread is waiting for the release of B and the second for A. But nothing happens.
Luckily for us, there is a GIL. A GIL is a single lock, and, as we have already discussed, it locks the interpreter. We can guarantee thread safety only if we let one thread do the job while blocking all the rest. So, we block this thread, which has been executing the bytecode so far, and let the other one do its job. This way, we make sure that all threads run one by one. To visualize the idea, look at this picture from the famous presentation about GIL in Python given by David Beazley:

Does this mean that Python is single-threaded? Yes, it does.
The GIL and multithreading
If you had a hard time solving serious multithread-related issues, you probably heard that a GIL doesn't have a good reputation among the developer community and often gets criticized for restricting Python to a single thread. Moreover, due to threads, CPU-bound programs not only become single-threaded because of the lock but also face an increased execution time in comparison to single-threaded programs. Let's consider the example from the talk we have referenced above and see for ourselves.

The final numbers depend on the machine you use, but you can spot the trend. We won't discuss here why this happens; you can find the answers in the talk above if you're interested in details.
For those Python developers who are keen on writing multithreaded programs, the picture looks pretty bad. However, don't be discouraged. There are at least a couple of workarounds.
Multiprocessing: the most common approach is to use processes instead of threads. In this case, each process gets its own Python interpreter, and the GIL won't be a problem anymore;Alternative interpreters: GIL is only implemented in CPython; however, there are plenty of other Python interpreters you can use: Jython (Java), IronPython (C#), and PyPy-STM version (Python).
Why is it still there?
The short answer is: because it's not that easy to remove it.
First of all, Python was designed before the spread of multithreading and gained most of its popularity thanks to the simplicity it offered. When the concept of multithreading was introduced, extensions for the existing C libraries started to appear in Python, so it became necessary somehow to provide consistency and thread safety. One of the popular solutions back then was to utilize a GIL. Secondly, removing a GIL from Python will inevitably lead to disrupting many Python packages and modules, and consequently, to various incompatibility difficulties. Last but not least, a GIL has its advantages and disadvantages, as do its alternatives, but it was added for a valid reason. Everything has its purpose.
Conclusion
Let's sum up the points we've discussed in this topic:
Python GIL is a mechanism that isolates Python objects from several threads;GIL purpose — it prevents data corruption and deadlocks; it also guarantees the safety of threads;GIL operation — it locks the interpreter and allows only one thread to do its job;GIL role — it makes Python single-threaded;GIL workarounds for multithreaded programs — multiprocessing and alternative Python interpreters;And, lastly, why it's still here with us; it's not that easy to get rid of it as it infers serious consequences.
"
167,Errors,419,6052,1025,https://hyperskill.org/learn/step/6052,"At this point, you probably already know that writing code sometimes might be frustrating because not everything works as you'd expect. So, in this topic, we'll finally examine the main reason for this frustration — errors.
The first thing you need to know about programming is how to print Hello, world!. The second one is that this might be challenging, as even such a tiny script can contain various errors. Here you are:
If you run this code, you'll get this:
Traceback is a stack trace that appears when your code causes an error. It reports detailed information on that particular error, indicating the specific files in which the error occurred. Nonetheless, the most informative lines for us right now are the last two. They point out the mistake in your code.
This might seem a bit frustrating, but errors are generally designed to allow Python to communicate with you. Whenever you see those threatening red lines – don't panic! Just follow what they are saying.
Syntax errors
In the example above, we can see the magic word SyntaxError that is likely to haunt you throughout getting used to Python. A large variety of different errors are referred to as syntax errors. They usually mean that Python has encountered a problem while trying to compile your program and can't even execute it.
If you carefully read the text of a traceback, it will help you find mistakes and correct them quite quickly, as you can see an arrow pointing to the exact place where Python found the mistake in your code. Every syntax error has an associated value. It describes an error in detail. In the example, EOF in the message SyntaxError: unexpected EOF while parsing stands for the end of a file. This message means that something else had been expected after your statement, but you didn't pass it to the interpreter. In our case, there should've been a closing round bracket ).
Mistakes won't be so obvious all the time. The message you'll get as an associated value will likely be the most common and obscure invalid syntax which isn't really helpful. To locate the issue, it's enough to know that the error is in the syntax.
Common errors for beginners
Some of the most common syntax errors are:

Wrong spelling of keywords and function names, e.g., While instead of while, pint instead of print;
the wrong number of parentheses in function calls, e.g., print just one round bracket;
Indents are also fertile soil for errors. Therefore, use spaces and tabs carefully;
Quotations marks. Don't forget to wrap a string in quotation marks of the same type: triple quotes for multi-line strings or double or single quotes for ordinary strings.

Modern IDEs check everything for you and kindly highlight where you have made a mistake or typo, but don't rely on this too much, and be ready to read the traceback yourself.

Mind that Python stops compiling your program after finding the first Syntax error, so it might take a while to fix every single mistake.

Check the following piece of code, for example. It looks like a Petri dish of syntax errors:
Take a deep breath, reread the article, and continue perfecting your programming skills! As you can see, there are plenty of syntax errors in this tiny piece of code. If you've checked and corrected everything from the list above and yet you encounter those error messages – don't worry! Once again, it's just Python trying to tell you that something went wrong.
Conclusion
In this topic, we learned what traceback is, looked at syntax errors in detail, and went through several common mistakes you, as a beginner, may encounter.
"
168,Linters and helpers,2032,18652,1026,https://hyperskill.org/learn/step/18652,"Good and clear code is critical. It not only works but is easy to read and understand. ""Code is read more often than it is written"" is a famous phrase by Guido van Rossum, the founder of Python. You should keep in mind that other people are going to read your code to inspect and contribute to it. It's up to you to make this task easy!
We have the PEP 8 style guide that tells us how to name variables, how many blank lines to use, and so on. It makes the code explicit and consistent, but there are so many conventions! As a beginner, you will certainly have a hard time trying to stick to them. Fortunately, we have linters. A linter is a tool that analyzes your code and reports all the bugs, logical and stylistic errors. In this topic, we'll learn the most popular Python linters: pycodestyle, pylint, and flake8. We'll also have a look at some other tools. Let's start!
You can use pip install modulename to install all the modules mentioned in this topic.
Getting started
Before we start, we need a piece of code to test our linters. Here's what we have:
As you can see, there are plenty of mistakes here:
no whitespace after # in a comment;two imports on one line;the imported modules aren't used in the code;the function name starts with a capital letter;a string longer than 79 characters;no whitespaces around =;a typo in the second return statement, there's no variable named strng.
Will the linters detect all our mistakes? Let's try and see!
Pycodestyle
We start with pycodestyle – a tool previously called pep8. It checks if your code is compliant with the PEP 8 style guide. That means it doesn't catch logical mistakes, only stylistic ones.
First, we save our code as file.py and then run pycodestyle file.py in the command line. Here's the output:
So, what do we see here? Each line is formatted like this:
file name: line number: number of character: error code and a description
Pycodestyle informs us about missing whitespaces, blank lines, and long lines. The main errors are there. However, it ignores Function1 – a function name starting with a capital letter. Unnecessary imports and a non-existing strng variable are also ignored. Which makes sense – as you remember, pycodestyle doesn't catch logical errors.
There are more features you can use. For example, --show-source will display the lines of code with errors. Pycodestyle --show-source file.py will output error messages like this one:
The --show-pep8 argument will print out the conventions of PEP 8 that are not followed by your code, often with examples and detailed explanations. Pycodestyle --show-pep8 file.py prints an error message like this:
These options can be used together if you want to see both the code line and the PEP 8 text. Just use pycodestyle --show-source --show-pep8 file.py.
There are other useful keywords like --statistics that shows how many times each error was found; --ignore=error code allows you to ignore certain errors. Run pycodestyle -h in your command line to see all the options available. You can also read about them in the official documentation.
Autopep8
We've mentioned two tools: linters and helpers. What is a helper? It's a tool that automatically edits your code. One such tool is autopep8 – an automated version of pycodestyle. Let's see how it works.
The standard way of using autopep8 is autopep8 file name. This will only display the corrected version in the console. We want to modify our file, too, so we need autopep8 --in-place file.py. There's no output in the console, but the file now looks like this:
As you see, many of the mistakes are corrected: import statements are now on separate lines, there are enough blank lines and there are spaces around # and =. However, the long string is unchanged. The logical errors are left out as well since autopep8 only corrects what is detected by pycodestyle.
We strongly recommend you to learn the style conventions and use them yourself instead of referring to helpers. However, sometimes a tool like this may be useful.
Flake8
Now, let's have a look at flake8 – another tool based on pycodestyle. This time it's not a helper, but another linter. Its main advantage over pycodestyle is that it detects logical mistakes as well. Let's check it out!
We call flake8 the same way as other tools: flake8 file.py. Here's the output:
Flake8 highlights the same things as pycodestyle, but it also points out logical mistakes. It sees that we haven't used both of our modules; the string variable is also not used and the undefined strng name. That's an improvement!
This tool also has several keyword arguments. For example, --show-source, --statistics, and --ignore work the same way as in pycodestyle. Check out the documentation for the full list of available options (or use flake8 -h to see a help message in the console).
Pylint
The next tool we'd use is pylint. Its functionality is very close to flake8, though pylint generally produces longer, more detailed output. It's one of the most popular linters in Python, so let's have a look!
The design of this tool is similar to others; we run pylint file.py. Let's see what we get:
That's longer than anything we've seen so far. It's also the first time all our mistakes are pointed out. Pycodestyle ignored logical issues, flake8 didn't notice a function name starting with a capital letter. Pylint sees it all!
Pylint also complains about missing docstrings and the naming of a and b variables. Why didn't any of the previous linters have a problem with that? The thing is that pycodestyle (and flake8 too, they are based on one another) only checks your code for consistency with PEP 8. However, pylint also has its recommendations, one of them is that variable names should be at least 3 characters long.
Now you see, why some people dislike pylint: not all of the error messages are equally useful. It's possible to customize this linter, telling it you're okay with short variable names, no docstrings, and other stuff, but it takes time. If you're willing to give it a go, you can learn more in the official documentation.
It's also the only linter that gives your code an overall rating. Ours was rated at 0 out of 10, which is... oh, well. However, it is not reasonable to reach for 10 out of 10, since pylint often complains about insignificant things.
IDE inspections
Saving your code to a file, running it through the command line, going back to correct it, then running again – that's weary. What if we could do it in real-time while writing the code? Many IDEs need plugins to do that, but PyCharm doesn't. PyCharm is a Python IDE developed by JetBrains, and in this section, we'll see how to use it for error detection.
PyCharm can detect almost all kinds of mistakes, but some warnings are disabled by default – to avoid bothering you with things you may not care about. However, to see how it works, go to Settings > Editor > Inspections and check all the boxes in the General section.
Now, let's paste our code in the PyCharm (no need to save it to a file this time). Then, click on an icon in the upper right corner that may look something like this:
It means PyCharm has one error (the red sign), one warning (the yellow sign), and six ""notifications"" (the beige sign) for us. Let's have a look at them:
As you see, it captured both stylistic and logical mistakes. They are ordered from the most severe to less severe ones: first errors, then warnings, then notifications. We also see the number of lines where problems occurred.
PyCharm provides you with a clear overview of all potential problems in your code. The output is easy to read and also easy to customize; while with pylint you'd have to write a whole script. No need to save your script into a file first. If you need more information on code inspections, visit the official PyCharm web page.
Conclusion
In this topic, you've learned about linters and helpers and why they're helpful. Now, you can check your code for mistakes with pycodestyle, flake8, pylint, or inspections in PyCharm. You also know how to correct the code automatically with autopep8. Let's quickly go through the main features of each tool:
Pycodestyle checks your code for compliance with PEP 8; it only sees stylistic mistakes;Autopep8 is a helper that automatically corrects issues that pycodestyle finds;Flake8 detects both logical and stylistic mistakes;Pylint detects all kinds of mistakes too, but it uses its style recommendations as well as PEP 8, so the output is long and some error messages may be insignificant;PyCharm catches all kinds of mistakes, allows you to check your code on the go (without saving it into a file and going to the command line), and allows for easy customization.
We hope that now it'd be easier for you to write beautiful, consistent code. Now let's practice!
"
169,Exceptions,420,6042,1027,https://hyperskill.org/learn/step/6042,"Imagine the situation: your code is syntactically correct and beautiful, it is being executed without any trouble. Great! But wait, when you continue writing the program, something else appears in the messages from Python! And the program is only partially executed. Sounds familiar? In this topic, we'll finally try to figure out what is going on when something like this happens.

A different type of error
Some errors in your code will not prevent the program from running. It will only crash while trying to execute a “broken” line: a line with an error called an exception. Thus, exceptions are the errors detected during the program execution (interpretation), whereas syntax errors are those detected during compiling the program into byte-code.

Indeed, we can see that some of the prints worked, while others (print() which contains the error, and yet another one after it) didn’t. Thus, all the code before the exception is executed properly, and everything after is not.

You already know that the most important and informative part of an error in Python is the last line. It contains a clear and distinct description of the error Python has encountered. In this case, we can see ZeroDivisionError, which is quite informative, right? One can’t divide by zero.

Similar to syntax errors, nearly all the built-in Python exceptions have an associated value that indicates the detailed cause of the error. Exceptions are not unconditionally fatal: later you will learn how to handle them.

Most common exceptions for learners
Perhaps, the most common exceptions people see while they are still learning Python are NameError, TypeError and ValueError.
NameError is usually raised when you haven’t defined your variable before using it or you have done it incorrectly.

Remember that variables are case-sensitive in Python and they’ve got to be defined before usage.

The associated value sometimes tells you the exact problem, so it's going to be really easy to fix it.
TypeError is raised when an operation or function is applied to an object of an inappropriate type. The associated value is a string giving details about the particular type mismatch. A common case for it is when you’re trying to perform arithmetic calculations on several unsupported operand types:

Here we’re trying to sum up a string and an integer, which will cause an exception again:

ValueError can be raised if you’re trying to use a variable of the correct type, but with an inappropriate value. For example, it's the case when you are trying to make an integer of a string, which has no integer value:

If you have any trouble trying to understand what the error is, you can always copy-paste the last line of a traceback and google it. Moreover, you're strongly encouraged to do so, as 99% of the troubles that the learners face have already been solved on specialized forums.

Summary
We've learned the exception basics, so now you are familiar with this concept and some of the most common exceptions in Python. Here's a recap:
A program will not be compiled and executed if there are syntax errors in it.On the other hand, exceptions don’t prevent a program from being compiled and run, but as soon as the line with an exception is being executed, the program crashes.There are certain tools to handle exceptions and even to raise them on your own, and soon you will learn more about it.
"
170,Built-in exceptions,1106,11680,1028,https://hyperskill.org/learn/step/11680,"Even good programmers make mistakes sometimes. You can divide an integer by zero by mistake or miss a bracket when working with lists. Python handles these cases pretty well, it usually doesn't lead to unexpected bugs. But if they happen, the built-in exceptions are raised. In this topic, we are going to present a detailed description of built-in exceptions. Specifically, we'll look at SyntaxError, TypeError, OSError and ValueError in this topic.

Hierarchy of Exceptions
We should note that all built-in exceptions have a hierarchy, some of the exceptions in the hierarchy may lead to more specific exceptions. Take a look at the full structure of the built-in exceptions:

Don't be afraid, we know, it's hard to remember the hierarchy at once. You can do it step-by-step when you have free time. Below we try to focus on the main features of the structure you need to know.
First of all, remember that the BaseException class is a base class for all built-in exceptions, which we can consider as the root of all exceptions. This exception is never raised on its own and should be inherited by other exception classes. In terms of this hierarchy, other classes are known as subclasses of the root class. For instance, the IndexError is a subclass of the LookupError class. At the same time, the LookupError itself is a subclass of the Exception class.
The BaseException subclasses include SystemExit, KeyboardInterrupt, GeneratorExit and Exception.
The SystemExit is raised when the sys.exit() function is used to terminate the program.The KeyboardInterrupt is raised when the user hits the interrupt key, e.g. Ctrl+C during the execution of a program.The GeneratorExit appears when your generator is being closed (it will be covered later).The most common subclass is the Exception class. It contains all exceptions that are considered as errors and warnings.

Built-in Exceptions Types
Before we start analyzing the pieces of code, take a look at the table with the built-in exceptions that programmers often meet in their code:
ExceptionExplanationSyntaxErrorRaised when a statement uses the wrong syntax.TypeErrorRaised when any operation/function is applied to an object of inappropriate type.ValueErrorRaised when any operation/function accepts an argument with an inappropriate value.OSErrorRaised when a system function returns a system-related error.ImportErrorRaised when the imported library is not found.EOFErrorRaised when such built-in functions as input() reach the end of the file (EOF) without reading any data.NameErrorRaised when a local or global name is not found.IndexErrorRaised when a sequence subscript is out of range.

Now, let's shed some more light on them! We'll check some of them in a later topic.

SyntaxError
The first error is the SyntaxError. Take a look at the first example:

The list doesn't have the right-side bracket ], that's why the SyntaxError is raised. Below is another example:

The expression is wrong and Python tells us about it by raising SyntaxError.

The SyntaxError is generally very easy to fix: you should make sure that all brackets, commas, quotation marks are in place and that everything is syntactically correct in the line that the error points out.

TypeError
Now let's observe a TypeError:

We tried to concatenate a string and an integer, that's why the TypeError was raised. This can happen to you while solving coding tasks on the platform. For example, if you read input and forget to convert it into an integer before performing some operations:

To get rid of this error, check that you perform operations on variables of the correct data type.

ValueError
In the code below, the input accepts a string that can't be converted to an integer, that's why the ValueError is raised:

This error may also occur with a list:

The method remove() can't delete the specified string from the list because there's no such element there.

The ValueError can be caused by various reasons. The general advice is to read the error message and check that the function can process the given object.

OSError
The next example illustrates the OSError. Some subclasses of this error may appear when you work with files. For example, if we try to open a file that doesn't exist, the FileNotFoundError will be raised:

Of course, there are a lot of other examples when the OSError and its subclasses can be raised.

When an OSError occurs, the reason for it is stated in the description.

Summary
So far, we highlighted some important issues dedicated to the built-in exceptions:
we reviewed the hierarchy of exceptions;we learned what classes and subclasses stand for;we analyzed some built-in exceptions and discussed the way around them.
If you are keen on reading more information, check the Built-in Exceptions part of the official documentation. For now, let's proceed to the comprehension tasks and applications to strengthen your knowledge!
"
171,Exception handling,449,6270,1029,https://hyperskill.org/learn/step/6270,"At this point, you already know what errors can occur while you work on your code. You might even know how to deal with some of them. But what if you cannot control some parts of your code, like the user input? Moreover, users don't always follow the instructions, so making your way through it is the only way. Don't worry; Python, as always, has your back. In this topic, you'll learn some tools to help with emerging errors.
Suppose you have a simple calculator. It can only divide numbers. Users input two numbers, and then it prints the result.
Let's run it:
Now let's try the impossible:
Something is wrong here, and the program crashes! To prevent this, use the try-except statements where you think it may lead to errors. The place where we divide is the result variable. Let's brace it with the try-except blocks:

Exception handling keywords
Here you can see not only try and except keywords but also else and finally. The entire exception handling block works as follows:
First, if there is no exception, Python executes the try block: everything between try and except;If an exception occurs, the rest of the try block is skipped. After that, Python checks whether the exception type matches the specified exception after the except keyword. It executes the except block and continues with the program after the try-except block.If an exception doesn't match the specified exception, it is called an unhandled exception. The execution of your program stops with a traceback.The else block is executed only if there were no exceptions in the try block, as though it was a more familiar if-else statement. It's better to use else than adding code to the try block, as you can avoid accidentally catching another exception if you haven't initially planned to catch with the try block and be aware of it in time.There can also be the finally keyword. The finally clause is always executed before leaving the try-except block, whether an exception has occurred or not.

So, let's try running our program now!

See? Now, your program works even if the user makes a mistake and wants to divide by zero.
Handling several exceptions
But what if the user doesn't understand what the number is and enters, for example, one?

Oh, no! The annoying traceback again! Why? Well, because you specified only the ZeroDivisionError exception in the try-except block. There's also a ValueError exception here, so Python doesn't know how to deal with it in your program.
The built-in exceptions have a hierarchical structure. So, you can do the following and identify no specific exception:

This way, you catch any exceptions from the list. But it also works for KeyboardInterrupt and other helpful exceptions. It is a bad practice in programming, so it is better to use two or more except blocks for different exceptions:

The except clause also may specify multiple exceptions as a parenthesized tuple, for example:

Due to the hierarchical structure, one exception can catch numerous exceptions:

Sometimes, you can't even predict the exception type in your code. In this case, you have no choice but to use the most general exception. For that purpose, instead of using pure except: statements

except Exception contains all Python exceptions except for GeneratorExit, KeyboardInterrupt, SystemExit. So if you use this structure, you can still finish your program by means of a keyboard or commands, which causes SystemExit.
Conclusion
To deal with exceptions without terminating your program, Python has a try-except block;There are two more blocks to expand the possibilities to change the behavior of a program: else executed only if there are no exceptions in try-block, and finally performed at the end of the try-except block whether the exception happens or not.All the exceptions comprise a hierarchical structure: some exceptions also include others.If you want to catch all possible exceptions, use the except Exception construction.
Using them wisely will make your code sustainable and effective; you'll prevent many user mistakes and keep your program running even under unexpected circumstances.
"
172,User-defined exceptions,936,10217,1041,https://hyperskill.org/learn/step/10217,"In this topic, you are going to learn about user-defined exceptions. We will discuss the structure of custom exceptions, how to create and use them in our code.
You are familiar with how to deal with built-in exceptions. However, some programs may need user-defined exceptions for their special needs. Let's consider the following example. We need to add two integers but we do not want to work with negative integers. Python will process the addition correctly, so we can create a custom exception to raise it if any negative numbers appear. So, it is necessary to know how to work with the user-created exceptions along with the built-in ones.
Raising user-defined exceptions
If we want our program to stop working when something goes wrong, we can use the raise keyword for the Exception class when a condition is met. You may come across either your or built-in exceptions like the ZeroDivisionError in the example below. Note that you can specify your feedback in parentheses to explain the error. It will be shown when the exception occurs.
Now let's see how this function works with different inputs:
If there is a zero, the program will stop working and will display the built-in exception with the message you specified; note that if we had not raised this exception ourselves, it would have been raised by Python but with a regular message. If y is a negative integer, we get the user-defined exception and the message. If the integer is positive, it prints the results.
Creating a user-defined exception class
If you are eager to create a real code for processing user-defined exceptions in Python, you need to recall the basics of object-oriented programming. Exceptions should be derived from the Exception class. In the following code, we create a new class of exceptions named NegativeResultError derived from the built-in Exception class. Note that it is good to end the name of the exception class with such word as Error or Exception. For now we'll just use pass inside the class.

In the example_exceptions_2(a, b) function below we use the try-except block. If the result of the division is positive, we just print the result. If it is negative, we raise an exception and go to the corresponding part of the code with except to print the message.
Let's see the results of the function for different inputs.
Now let's see what happens if we raise the exception right away.
You can also create several exceptions of your own. An example is in the code below:
Different errors give different outputs:
Specifying exception classes
In previous sections, we displayed messages about errors by printing them ourselves in the except-part of the try-except block. However, we can also create the message inside the exception code using __str__.
Take a closer look at the except {class} as {variable} construction. It can help you print the message that is specified inside the class.

Now, the function will work as follows:
What is more, if we raise the exception instead of handling it, the message will still be shown:
Of course, __str__ is not the only method for specifying your exception. The __init__ is also suitable for working with exceptions. In the LessThanFiveHundredError class below, the __init__ accepts our custom argument num , which is included in the message.
The error will also show the message we specified, but now it can use the given parameters:
Summary
As far as you can see, user-defined exceptions are not so tricky as they may seem at first. To deal with them, you should remember some key features:
use the raise keyword to make your exception appear;don't forget about Exception class when creating your code;specify and customize your exception with __init__ or __str__.
Only the practice counts when you try to learn something. So, switch on the following tasks to improve your skills of user-defined exceptions.
"
173,Hashable,598,7823,1043,https://hyperskill.org/learn/step/7823,"You may remember that when discussing dictionaries in Python, we mentioned that not every object can be a key in a dictionary. In this topic, we'll finally break it down by explaining what feature an object has to have so it could be used as a key in a dictionary and why, what Python types do not have that feature, and what it has to do with immutability.

What does ""hashable"" mean?

In Python, only hashable objects can be dictionary keys (or set members). The notion of hashable objects is, naturally, connected to the hash table concept. According to official Python documentation, an object is hashable if it has a hash value that doesn't change during its lifetime and can be compared to other objects. In practice, it means that to be hashable objects need methods __hash__() and __eq__(). Both these methods are needed because the hash table can only guarantee that equal objects have the same hash value. Unequal objects may also have the same value, so we need additional constraints.

Why is it that only hashable objects can be keys in a dictionary? You may remember, that hash tables allow us to search for elements in constant time O(1) which is extremely efficient. Python dictionaries (and sets) implement a hash table by default so their keys need to be hashable.

Hashable and unhashable types

In previous topics, we have discussed which objects in Python are mutable and which are not. Let's revise this information very quickly. Strings and integers are immutable because we cannot modify them. Putting it simply, if we write integer += 5 or string += ""end"", new objects are created, and these integer and string variables refer to the new objects, not the initial ones. Sets, lists and dictionaries, on the other hand, are mutable, so when we alter them, the same objects are modified.

In Python, built-in immutable objects like strings or integers are hashable while mutable containers like sets, lists or dictionaries are not. Immutable containers (like tuples) are hashable if their elements are hashable. Don't forget about frozensets: they are also immutable and hashable.

Let's see examples of how it works.

There are two ways to get the hash value of an object: built-in hash() function or __hash__() method of an object. They are equivalent: in fact, hash() function internally calls the __hash__() method. If we call any of these two methods several times, we'll still get the same value: it is consistent during the lifetime of an object provided no changes occur.

For unhashable objects, the function hash() and the __hash__() method throw TypeError. The same happens if you try to make them dictionary keys or set members:

The __eq__ method allows you to compare two values and check if they are equal. Think of it as the equality operator ==.

As shown, the method __eq__ has a wider application, therefore, you can compare both mutable and immutable objects. The comparison typically results in either True or False, however, the NotImplemented object may crop up in cases when the types of given values cannot be compared.

Immutable containers

Immutable containers are hashable if their elements are hashable because the hash value of a container is calculated using the hash values of its elements. You can see it in the tuple examples below:

For built-in types, the hash value depends on the data stored in the object and not on its identity. This is evident when we have two different objects with the same values. Let's take a look at two tuples:

As you can see, even though these are different objects with different ids, their hash values are the same. This means that in a dictionary these two objects will be considered as one:

The fact that hash values depend on the data in the object also explains why mutable containers are not hashable. If they were, their hash values would change when they would change within the same lifetime of an object. However, the objects in the dictionaries are searched by their hash values. So, when the hash value of an object changes during the lifetime, the key-value pair is lost to you.

Hashable check

In order to avoid errors, we may want to check if an object is hashable. This can be done with the help of the collections module. This module has an abstract base class Hashable that we can use. The ""hash check"", so to speak, is carried out with the isinstance() function:

Evidently, for hashable objects, this function will return True, otherwise — False. Below are some examples:

All of the built-in immutable types you have learned so far are hashable, and the mutable container types (sets, lists, and dictionaries) are not. So for present purposes, you can think of the characteristics hashable and immutable as synonymous.

Hashable custom classes

Objects of custom classes are hashable by default. This is because the class object, which is the parent class of all custom classes, has both __hash__() and __eq__() methods. You can define a custom implementation of these methods but there are several tricky parts when it comes to that. We won't be covering them in this topic and, anyway, in most cases, default implementations are enough. One thing we will point out, though, is that unlike built-in types, custom classes have their hash values derived from their id's and not their data.

Summary

To sum it up, dictionaries can only use hashable objects as their keys. In Python, an object is hashable if it satisfies the following two conditions:

*   We can calculate its hash value (that is, an object has the __hash__() method)
*   We can compare it to other objects (that is, an object has __eq__() method)

The concept of hashable objects is connected to the concept of (im)mutability. Even though they are different, a good rule of thumb is that immutable objects are hashable (with a few exceptions).
"
174,Operations with tuple,834,9439,1045,https://hyperskill.org/learn/step/9439,"You have already learned the tuple basics, now it’s time to examine this datatype in more detail. As you know, tuples resemble lists in many aspects, but they are immutable and can't be changed once created. So, tuples are both similar to lists and different in some respects.
Similarities
All operations on lists that do not alter the sequence itself can also be applied to tuples:
1. We can add tuples to each other and multiply them by a number:
2. We can find the first index of an element in a tuple and count how many times an element occurs:
We can also specify an interval for searching:
The first number is the index of the element to look from, the second one is the index of the element where to end the search. The last index is not included, so we've only checked the elements ""kiwi"" and ""orange"" with indexes 3 and 4 respectively.

Be cautious, if the value is not present in a tuple, the index() method will raise ValueError.

3. Like lists, tuples can contain elements of any data type, which also implies that they can be nested in each other:
4. Tuples are iterable, so we can iterate and enumerate through them:
5. Finally, we can test if an element is contained in a tuple using operators in and not in:
Everything discussed above applies to lists as well, but now it's time to learn more about the differences.
Differences
It has been mentioned that tuples, as opposed to lists, can be used as dictionary keys. This is due to their immutability: only hashable objects can become dictionary keys.
However, only tuples composed entirely of hashable elements can be used as keys in a dictionary.
Unpacking
As you know, tuples are immutable, so they are the optimal container to keep and pass data unchanged. Another feature of tuples is that they can store data of any type. It's the reason why tuples are a usual format to pass mixed values, for example when we return several values from a function.
 Consider a tuple with several facts about you: your name, your age, and what you did last summer:
 It can be very useful to save each part in three different variables, so we can use the fact that tuples can be unpacked. Generally, the number of variables must match the length of a tuple:
Sometimes we need only a concrete variable, and keep the other in some other container. Use the unpacking operator * in this case, it will create a list for any variables of remaining elements:
We can retrieve values from tuples two ways: getting elements by index or unpacking a tuple to variables.
Swap values
An interesting characteristic of Python is connected to this fact. In programming, a common task is to swap the values of two variables. In most programming languages, you will need to use an additional temporary variable to store one of the values:
However, Python allows us to do the swap in only one line:
The thing is, Python evaluates assignments starting from the right-hand side. Firstly, a tuple of two elements, b and a, is created in the memory. Then, the already created tuple is assigned to the left-hand side. As the left-hand side is composed of two identifiers, the tuple is unpacked, so that the identifier a on the left is assigned to the first element of the tuple, and the identifier b — to the second element.
Summary
In this topic, you have learned the features of tuples that are the same as those of lists: addition, multiplication, the methods index() and count(), the ability to be nested, iterability, and membership testing. You have also learned what sets tuples apart: immutability that allows them to be used as dictionary keys. What's more, you now know how to unpack tuples and swap values of two variables in only one line of code. Now, you are ready to use this knowledge in practice!
"
175,Python unpacking operators (* and **),1624,15401,1046,https://hyperskill.org/learn/step/15401,"Today, we will cover how to unpack something, and how one * and two ** asterisks will help us with this. The chances are you have encountered the asterisks in Python before. They usually perform mathematical operations, * stands for multiplication, and ** is used for exponentiation. However, these two operators, also known as starred expressions, have another application for iterable object unpacking. Let's discuss it at length.
What is unpacking?
Even though you may have never seen this term before, you have encountered packing. Take a look at the following example:
The values in the code snippet above are ""packed"" together in a tuple. The reverse operation is called unpacking, where each variable is assigned to the corresponding tuple item. The variables for unpacking are on the left side of the assignment operator =:
Remember that the number of variables on the left should be equal to the number of the elements on the right. Otherwise, it raises a ValueError:
Packing and unpacking can be performed not only with tuples but with any other iterables: lists, sets, tuples, strings, and dictionaries.
You may be wondering, why asterisks? The answer is straightforward — they make our coding life a little bit easier. Let's have a look!
The single asterisk operator
The single asterisk operator unpacks all the iterable variables that haven't been assigned to any variable. Let's look at an example. Suppose you want to extract the first and the last item of a list without indexing:
As you can see, the ""unused"" items have been automatically assigned to the variable marked by an asterisk. This snippet is similar to the one below:
This trick also works with lists of two items:
In the example above, the middle variable ends up being an empty list. There are no values that can be assigned to it, as the first start variable is assigned to 1, and the end variable is assigned to the last item on the list, 2.
One more thing. If for some reason you want to unpack all of the items in an iterable into a single variable, you need to convert it to a list or a tuple first. A simple trailing comma will do the trick; it will make our variable a list that can take as many arguments as you want:
The purpose of the single asterisk
Why do we need it? When working with data, you sometimes need to split a sequence into ""first-rest"" or ""last-rest"" pairs. For instance, your data can contain row numbers as the first element, so you would want to separate them into different data structures. Using the * operator keeps the code clean and compact. Compare the two snippets below:
In the same way, you can unpack iterable items when passing them to a function. Suppose you have a list of arbitrary numbers and a function that takes three numbers as arguments and returns the result of their multiplication:
Instead of having to manually pass each argument to a function using indexing, you can simply unpack them with * operator:
Looks pretty neat, right? Remember that the number of arguments must still be equal to the number of elements in an iterable object.
As you may already know, Python includes some functions that can take an unlimited number of arguments. Take the built-in print() or zip() functions. Or any other functions that you decide to implement manually. Have a look at the following examples:
We can also print the elements from several iterable objects:
Moreover, we can join multiple lists together:
Even though we have performed the above operations mostly on tuples and lists, you can also do the same with sets and strings. We've also mentioned unpacking dictionaries, haven't we? Unlike others, dictionaries are stored in key-value pairs. What happens if we try to unpack them with the * operator?
Note how it prints only the keys of the dictionary without values.

To unpack dictionary keys, values, or key-value pairs, you can use the * operator together with dictionary operations dict.keys(), dict.values() and dict.items().

The double-asterisk operator
While the single-asterisk operator unpacks lists, tuples, strings, and sets, the double-asterisk operator can unpack dictionaries. Unfortunately, dictionaries cannot be unpacked in the same way as lists and tuples. The code below will result in an error:
Nevertheless, we can still use ** to do any dictionary operation.
Let's assume we want to define a function that will return the sum of dictionary values. We can do it like this:
Keep in mind that on defining a function, the function arguments must have the same name as those in a dictionary.
Similarly, the double asterisk can merge several dictionaries:
You can merge not only multiple dictionaries but also add extra key-value pairs to the existing ones. For instance:
Or even create a copy of a dictionary and update its values at the same time:
Conсlusion
In this topic, we have covered a very powerful tool — the unpacking operators. Here are some crucial things for take-away:

A single asterisk * unpacks items from lists, tuples, sets, and strings;
A double asterisk ** unpacks dictionaries;
Using a single asterisk on a dictionary will unpack only dictionary keys;
You can pass all iterable items to a function with the help of unpacking operators;
You can merge and update iterables using the starred expressions.
"
176,Assert statement,959,10372,1048,https://hyperskill.org/learn/step/10372,"Testing exists in a great variety of programming languages, its aim is to check whether your code contains errors and if so, what their causes are. It does not have to be hard, you can start with easy steps. In this topic, we are going to deal with the assert statement. It is a useful debugging tool that uses Boolean logic and checks whether a given expression is true or false. If the condition is True, the program will keep running. Otherwise, it will return the AssertionError.
Syntax of assert statements
The assert keyword can be used in two ways.

The <condition> attribute shows what you want to test, so it is always required. When the condition is false, the AssertionError is raised. The optional <message> attribute may be used to specify the message displayed with the error. Now let's illustrate assert statements in action.

For instance, if you enter the word dog in both examples, the condition word != 'cat' will be True, and you will have the following output:

However, if you happen to enter cat, the AssertionError will be raised. In the second case, an error message will also appear.

As you can see, the AssertionError is a built-in error, so you can handle it with the try-except block, i.e. print the message without stopping the program.

We can also check several variables or use more sophisticated logical expressions with the help of the assert keyword:

Finally, the assert keyword can be used with functions. In the example below the AssertionError is raised when the parameter 2 given to the function does not fulfill the condition in the test_mark(i).

Assert vs Raise
You may have noticed that raise and assert are similar to each other. What is the actual difference between them?
raise is used for raising an exception;assert is used for raising an exception if the given condition is False.
Let's analyze some examples.

As you can see, the raise keyword together with the if-else statement is very similar to the assert keyword, but their purposes are different. In the first case, raise is used mainly for data validation, it allows you to customize exceptions and raise errors of your choice, while assert is mainly used for debugging, e. g., to stop the execution based on a certain condition and return a message that will help debug faster.
The Python documentation (the Assert Statement paragraph) also provides an explanation of how the assert keyword works. The first example shows raising the error without a message and the second one — with the message.

The __debug__ is a built-in variable that is True by default and is only set to False when Python is started in the optimization mode, so the first lines can be interpreted as if True.
Mind the difference between the raise and the assert keywords and use them wisely.
Summary
In this topic, you have learned some basics of the assert keyword, a tool for program testing:
the purpose of the assert keyword is to check whether a condition is False;to use the assert keyword, we should specify the mandatory attribute <condition> and an optional <message>;as opposed to raise, the assert keyword is used for debugging.
Now, let's proceed to the tasks.
"
177,Match object and flags,1343,12902,1049,https://hyperskill.org/learn/step/12902,"Regexp template syntax is pretty much the same across all major programming languages. The main features of the Python regexps as opposed to any other programming language are special functions and objects of the re module.
First of all, it may be a good idea to get to know what exactly you are going to get when your regexp template matches a string. In this topic, we'll take a look at the Match object and its attributes. Also, we'll check out the flags that we can apply while calling any matching function. Flags are a small part of the re module, but they can simplify the regexp processing a lot.
Match object
As you can remember from the introductory topic on Python regexps, when your regexp template isn't found in a string, the matching function returns None.
However, when the match is successful and an example of your template is present in the string, match()  returns a so-called Match object containing the data about the matching substring: the contents (a match attribute) and starting/ending indexes in the original string (a span attribute).
When a Match object is converted to boolean, it is always True. This way, you can use a simple conditional statement if match: to check whether your template matches the string. It'll be False if the statement returned None. And if you have a match, it will be True.
This check is usually required to avoid errors in your code. You can't perform the same operations when you have None as if you had a Match object. The errors can stem from this. What can we do then? Let's see...
group() method
What makes Match objects useful is that they contain important information on the results of the matching operation. By calling the group() method with no arguments, you can extract the substring that matches your template:
If you try to call group() from None, it will raise an AttributeError:
This is the reason why you may want to add the conditional statement we've discussed above if you're not sure that your template will match the string.
Extracting match indexes
You may need to know where the matching substring starts, in other words, the starting index of the matching substring in the original string. It can be done with the start() method that returns a starting index (an integer):
This method may be confusing when you use match() function, because it always searches for matches starting at the beginning of the string. However, with other matching functions that you will encounter a bit later, start() becomes more useful.
You can similarly extract the ending index of the string with the end() method:
As you can see, the end() method doesn't return the exact index of the last character of the matching substring, it adds 1 to it instead. This feature can facilitate slicing:
To extract both indexes at the same time, use the span() method. Instead of a single integer, it returns a tuple with two integer elements, the starting and the ending index of the matching substring.
Let's check out function flags — a special kind of attribute to make the regexp search engine more powerful.
Function flags
It's important to keep in mind that regular expressions by default are case-sensitive, letters of the upper and the lower case are treated as different characters.
To make your regex case-insensitive, you can use a special flag when you call the match() function (or any other function for matching). It's called re.IGNORECASE. Pass it to the function as the value of the optional flags argument:
re.DOTALL is another very useful flag. It can be used in the same fashion; it matches a dot character with literally every character, including \n (as you probably remember, by default, a dot character doesn't match a newline character).
To enable several flags at once, pass their sum as the flags value or use the | operator.
These flags can make your regexps concise and readable. There are many other flags in Python, you can read more about them if you're curious.
Summary
In this topic we have discussed the following points:

when a regexp template is not found in a string, None is returned by the matching function;
when a regexp template is found in a string, you get a Match object as the result of the matching function call;
to extract a substring that matches your template, use the group() method of the Match object;
to extract indexes of the matching substring in the original string, use start(), end() or span() methods;
flags can simplify your regexps: re.IGNORECASE makes your regexp case-insensitive, re.DOTALL make the dot character match \n character, as well as any other possible character.
"
178,Regexp functions in Python,1456,14180,1050,https://hyperskill.org/learn/step/14180,"In previous topics, we have pointed out the basics of regular expressions in Python. However, the only regexp function that we have used so far is match(). In this topic, we are going to cover the main regexp functions that will improve string matching.

Main functions
Take a look at the table below to find the most common functions and their descriptions:

Methods
Description

re.match(pattern, string, flags=0)
Checks whether a pattern is present at the beginning of a string.

re.search(pattern, string, flags=0)
Checks whether a pattern is present anywhere in a string.

re.findall(pattern, string, flags=0)
Returns all matches in a list. If used with one capturing group, returns only this group matches. If used with more than one group, returns tuples of capturing groups.

re.finditer(pattern, string, flags=0)
Returns all matches as an iterator.

re.split(pattern, string, maxsplit=0, flags=0)
Splits a string based on a pattern. If used with groups, outputs a text matched by a pattern. A text matched by a pattern outside the group won't be in the output.

re.sub(pattern, repl, string, count=0, flags=0)
Searches for a pattern and replaces it with a specified piece of text.

re.compile(pattern, flags=0)
Compiles a pattern for reuse.

In the following sections, we will cover them one by one.
Matching the beginning of the string
The match() function takes a regular expression pattern and string as arguments and checks whether the beginning of the string matches the pattern. It returns a special Match object when a match is found and None, if otherwise. Let's recall how it works. Mind the following snippet:

As you can see, result_2 contains no matches as the difference between the beginning of the string and the given pattern is the punctuation mark.
Matching any string part
The second function is search(). It is very similar to what we have seen before. It also takes a regular expression pattern as the first argument and a string. However, the difference is that search() checks for matches throughout the string. Similarly, the search() function returns a Match object if there's a match or None, if otherwise:

Both search() and match() return only the first pattern occurrence in the string. For example, if you want to find the roads pattern:

Finding all matches
You may wonder what to do if you want to find all pattern occurrences in a string. In this case, the findall() function comes to the rescue. Like any other function discussed above, findall() also takes a pattern and string as arguments. There is one subtle difference. The function returns not a Match object but a list with strings that match the pattern. If there are no matches, it returns an empty list:

Note that the findall() function returns a list of tuples when a pattern contains one or more groups. Let’s have a look at the following example:

This can be helpful as now you can loop over it to do the computation for each tuple. For instance, you can count the total number of all the fruit you have bought.

Be careful when you have a pattern with one capturing group. In this case, findall() will return strings that are matched by this group only. The strings matched by a pattern outside of that group will be omitted:

There is another function finditer() that behaves the same way as findall(). It finds all possible pattern matches in a string and returns an iterator of regexp match objects instead of a list.
Splitting
As you may have guessed, the split() function splits a string by occurrences of pattern and returns a list of strings. As usual, it takes a pattern and a string as two arguments. Note that if the beginning (the end) matches the pattern, then the first (the last) element will be an empty string:

This function can take an additional maxsplit argument. It specifies the number of splits. By default, maxsplit is set at 0. It means that the string will be split by the maximum number of pattern matches. If, for instance, maxsplit is 3, then three splits will be done, and the rest of the string will be returned as the final element of the list:

In addition to what we have just said, when you use split(), the matching substrings are removed from the final list. If you want to store them, you can simply use capturing groups. Compare the results below:

Be careful! If you employ capturing groups, strings that are matched outside those groups won't be returned:

Searching and replacing
The sub() function takes three arguments: a regular expression pattern, a replacement string, and an initial string. It replaces all pattern occurrences with the specified replacement. If no occurrences are found, it returns the unchanged string. The sub() function also takes an optional argument count, it is the maximum number of pattern matches for replacement. Let's look at examples:

Precompiling patterns
The last regexp function that we are going to talk about is compile(). It allows you to compile a pattern and reuse it later in the code. It takes a pattern (a string) as an argument and returns a special Pattern object that we can use later with other functions we've covered today. Let's see how to compile a pattern and reuse it:

Compiling and saving the resulting regular expression object is convenient if you plan to use it further. It saves time and improves your performance.
Summary
In this topic, we have discussed popular regular expression functions that we can use to match a pattern in a string. Here is the recap:

Use match() to find a pattern at the beginning of the string or search() to check whether a pattern is present anywhere in the string;
Use findall() or finditer() to find all pattern occurrences, the former returns a list while the latter returns an iterator;
Use split() to split a string and sub() to replace a matching string with another one;
If you are going to use the same pattern many times, you can precompile it with compile() to save memory and time.
"
179,Regexp flags in Python,1469,14243,1051,https://hyperskill.org/learn/step/14243,"If you work with Python regexp functions regularly, you know that sometimes they require additional parameters. These additional parameters are called flags. In this topic, we are going to cover compilation flags that can help you with adjusting regular expression patterns.

Compilation flags
Regexes contain eight compilation flags. They can be passed as values of the optional flags argument to any function. These flags change the behavior of your patterns. Each flag has two names: a long one, re.IGNORECASE, for example, and a short one, re.I in this case. Below you can find a table with all flags that will be discussed further:

FlagsDescriptionre.IGNORECASE or re.IIgnores a case.re.DOTALL or re.SAllows the . metacharacter to match a newline.re.MULTILINE or re.MAllows the ^ and $ metacharacters to match each line.re.VERBOSE or re.XAllows whitespaces and comments in pattern compilation.re.ASCII or re.AMakes \w, \W, \b, \B, \s, \S match only ASCII characters.

In version 3.11, a new flag re.NOFLAG was added, which means no other flags. re.NOFLAGcan be used as the default value for the function.

They can seem a bit overwhelming. Don't worry, we will take a look at each of them in more detail further on.

Ignoring a case
As you may know, regular expressions are case-sensitive. To make your regular expression treat uppercase and lowercase letters equally, you can use the re.IGNORECASE (re.I) flag:

Changing metacharacter behavior
Re.DOTALL, or re.S for short, is another very useful flag. It matches the special . character with any character, including the newline \n character. If you remember, the dot meta metacharacter doesn't match a newline by default:

By default, the ^ character matches only the start of a string while the $ character matches only the string end. Re.MULTILINE (re.M) flag matches them with the beginning and the end of each line in a string, respectively. Let's compare:

Making patterns more readable
Unlike other flags, Re.VERBOSE or re.X doesn't change the way your pattern behaves but makes the pattern compilation more comprehensible instead. Most of the regexp patterns are complex and barely understandable, and re.VERBOSE allows for two things during compilation:
Whitespaces can be used for alignment;Hash signs # can be used for adding comments.
Let's see how re.VERBOSE can improve the pattern that matches e-mail addresses:

Tip: If you use the re.VERBOSE flag to make a pattern match whitespaces and hash symbols, you need to escape them. For instance, \#.
Matching ASCII only
By default \w, \W, \b, \B, \d, \D, \s and \S match the entire UNICODE. To make a pattern match only ASCII characters, you can use re.ASCII or re.A:

One last thing. If you are going to use several flags at the same time, use either the | operator or +:

Conclusion
In this topic, we have covered the main compilation flags that can improve your regexes. Let's recap them:
Compilation flags are passed as values of the optional flags argument;To ignore a letter case, use re.IGNORECASE;To make the . metacharacter match newlines, use re.DOTALLTo make ^ and $ metacharacters match the beginning and end of each line, use re.MULTILINE;If you want to add comments and whitespaces inside the regexp pattern, use re.VERBOSE, but don't forget to escape the hash symbol and whitespace if you want your pattern to match them.And finally, to make your pattern match ASCII characters exclusively, make use of re.ASCII. Remember that by default, regexps match UNICODE characters.
"
180,Preconditions and postconditions,1461,14251,1052,https://hyperskill.org/learn/step/14251,"When designing your regular expression patterns, you can use lookaround assertions to make your patterns match specific strings that follow or precede another pattern. Lookaround assertions are enclosed in parentheses; they do not return the matched pattern. That's why we can also call them zero-width assertions. We will look at them in more detail in the following sections.
Positive lookaheads
The first type of assertion that we are going to discuss is the positive lookahead. It is a regexp pattern that looks as (?=pattern).Patterns with a positive lookahead match the pattern to the right side of the target match. For example, JetBrains (?=Academy) will match JetBrains only if Academy follows it. Let's have a look at how they work in the code snippet below:
Negative lookaheads
A negative lookahead is a regexp pattern that takes the form of (?!pattern). It does completely the opposite: patterns with a negative lookahead return a match if a pattern defined in parentheses doesn't follow a string. In our example, JetBrains (?!Academy) will return a match only if JetBrains is not followed by Academy. Compare the results below:
Positive lookbehinds
A positive lookbehind assertion pattern is an expression like this: (?<=pattern). In the same way as the positive lookahead, a positive lookbehind matches a string if the specified phrase precedes it. In our (?<=JetBrains )Academy example, Academy is the output. Mind the following snippet:
There are two crucial things to account for if you opt for positive lookbehinds:
A positive lookbehind pattern can only match strings of fixed length. In other words, you can use patterns like JetBrains or [Jet |Brains ], but you cannot use \w+, JetBrains{1, }, or JetBrains.*, as their length can vary. Similar patterns with positive lookbehinds raise an error:
Patterns that start with positive lookbehind assertions do not match the beginning of a string. We recommend using the search() method instead of match() if you want your pattern to match the beginning of a string:
Negative lookbehinds
The last assertion that we are going to look at is the negative lookbehind. You can define it as (?<!pattern). Negative lookbehind matches a string if the current position in the string is not preceded by the match:
Similar to the positive lookbehind, the negative lookbehind pattern matches only strings of fixed length. Also, patterns starting with negative lookbehind assertions don’t match the beginning of a string, so avoid using match().
Conclusion
In this topic, we have covered simple but useful regex tools called lookaround assertions. Let’s recap:
Positive lookahead (?=pattern) provides a match if the text is followed by the specified pattern;
Negative lookahead (?!pattern) provides a match if the text is not followed by the specified pattern;
Positive lookbehind (?<=pattern) provides a match if the text is preceded by the pattern;
Negative lookbehind (?<!pattern) provides a match if the text is not preceded by the pattern;
Lookbehind assertions do not match the beginning of a string, so prefer search() over match();
Lookbehind patterns work with fixed-length strings only.
"
181,Unit testing in Python,1017,10795,1053,https://hyperskill.org/learn/step/10795,"In this topic, we are going to learn about unit testing in Python. First, let's go back and recap what unit testing is. A unit is a small part of the code that performs one task, and we write tests to determine whether the unit works correctly.
In general, units take input data and generate output data. So with unit testing, we know the input and the expected output, and we just compare the actual output with the expected. We can write numerous tests checking most of the case scenarios. Unit testing enables developers to detect bugs at early stages and notice if the code works incorrectly after changes.
We can do unit testing either manually or automatically. It is rarely done manually because it is a very time-consuming task. Python provides a lot of instruments for automated unit testing. unittest is the most popular test framework in Python, so we are going to learn how to use it in this topic. But it is not the only tool in Python for unit testing; you can also use, for example, nose, pytest, or doctest.
Getting started
unittest is a module from the standard library with a great set of tools for writing tests. To see how it works, we will write a simple calculator and then test this program. This is the code of our calculator:
Now, the calculator.py module contains four different functions that perform basic arithmetic operations: addition, multiplication, subtraction, and division. We are going to write unit tests to check that these functions work as expected. 
It is better to store tests in a separate file, and it is advisable to start the name of the file with test. So we create a new file test_calculator.py and import the unittest module and the module we are going to test, that is the calculator. Note that the tested module should be in the same directory.
Time to test
Now, we are ready to test our program. To do this, we will write one or several test cases. A test case is a basic unit of testing, it checks that the tested unit produces the right output when given various kinds of input. We create a test case by subclassing the general unittest.TestCase class: 
In our case, the tested unit is the whole calculator.py module, but we could write a separate test case for each function. In Python, the tested unit can be a class, a method, or a function.
All tests will now be defined as methods inside this class. Let's write the simplest test to check the result of our add() function:
The names of the test methods must start with test. Otherwise, it is not going to work properly.

In the example above, we use the assertEqual() method from the unittest.TestCase class: it checks that the two given arguments are equal;  otherwise, we will get an AssertionError and the test will be marked as failed.
Note that inside one test we check several cases, how the function works when two positive numbers are given, one positive and one negative, and two negative numbers. It is important that we check all possible border cases and all cases when something can go wrong.
The tests for the multiply() and subtract() functions will look similar. 

PyCharm allows you to create tests in a simpler manner, you just need to right-click the name of the tested function or class and choose the option Go To, and then Test. You can learn more about writing tests with PyCharm in this tutorial. 

Assert methods
The unittest.TestCase class provides special assert methods that are used for testing. You have seen one of them in the example above, we checked that the result of the addition is correct with the help of the assertEqual() method.
All assert methods accept a message argument that, when specified, is used as the error message if the test fails:
You will see how error messages are displayed in the following sections.
Now, let's write tests for the divide() function. We can write most of the checks using the already known assertEqual() method, so we are not going to mention them. However, our function is also supposed to raise an exception when the divider is 0. We must check this as well and will do so with the help of the assertRaises() method. It works a bit differently from assertEqual(), and two ways to use this method are shown below.
1. We can pass several arguments to the function: the exception that we expect (ValueError), the function that we test (divide), and then all arguments that the function takes (5, 0).
2. Alternatively, we can use a context manager, within which we call the tested function as we have done it before:
All other assert methods are similar to the assertEqual() method, so we are not going to discuss them separately. In the table below, we list all widely-used methods:
If you want more information about the assert methods, you can read the official Python documentation.
Running tests
Once the tests are ready, we should run them and check the code. However, if you run test_calculator.py as a usual Python file, you are not going to get any information about the result of testing. To see the results, you should run the file from the command line, from the directory where the test_calculator.py is located. You need to enter either of the commands:
python -m unittest

python -m unittest test_calculator
If we do not specify the name of the test file, only files which start with ""test"" will be executed.
There is also an easier way to run the tests right from the editor and get the message. We just need to add the following lines at the end of our code:
if __name__ == ""__main__"":
    unittest.main()
Now, if we run the module directly (not imported in some other module), then all our tests will be collected and executed. In commands, '-m' does exactly the same.
After that, you will get a message with information about the tests. We talk about these messages in detail in the next section.
Test outcomes
When the tests are executed, we get a message which provides us with information about the result of testing. For example, if we run the tests we have written for our calculator, we will see the following message:
....
----------------------------------------------------------------------
Ran 4 tests in 0.001s

OK
OK means that all tests went well, and so do the dots that correspond to the succeeded test cases. So, from this message, we know that:
4 tests were executed;all tests succeeded.
Now let's imagine that we made a typo in the add() function, and accidentally put '-' instead of  '+':
Then, we'll get the following message:
F...
======================================================================
FAIL: test_add (__main__.TestCalculator)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\...\test_calculator.py"", line 11, in test_add
    self.assertEqual(calculator.add(6, 4), 10, 'Error when adding two positive numbers')
AssertionError: 2 != 10 : Error when adding two positive numbers

----------------------------------------------------------------------
Ran 4 tests in 0.003s

FAILED (failures=1)

This message tells us that:
4 tests were executed;3 tests passed (dots);one test failed (the letter 'F' and the number of failed tests explicitly shown in the last line);where something went wrong (the 11th line; in the test_add method);what went wrong (assertion failure).
Note that together with the AssertionError, we see the message that we specified in the code: ""Error when adding two positive numbers"". It helps us understand what the error was.

The tests are executed alphabetically, so the order of dots and letters in the first line does not correspond to the order of tests in our code.

There is also a third possible outcome — ERROR. The errors occur when a test raises an exception other than AssertionError. In such cases, we see the letter 'E' in the first line and the information about the occurred problem. 
Let's say we wrote in the tests for the divide() function the following assertion:
def test_divide(self):
    # tests for the divide function
    # ...
    self.assertEqual(calculator.divide(10, 0), 0)
Then we would get the following outcome:
.E..
=====================================================================
FAIL: test_divide (__main__.TestCalculator)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""C:\Users\...\test_calculator.py"", line 28, in test_divide
    self.assertEqual(calculator.divide(10, 0), 0)
  File ""C:\Users\...\calculator.py"", line 16, in divide
    raise ValueError('Can not divide by zero!')
ValueError: Can not divide by zero!----------------------------------------------------------------------
Ran 4 tests in 0.003s

FAILED (errors=1)

First, it tells us that an error occurred in the line No. 28, in the test_divide (the letter 'E' is the second of all the dots). Further in the message, we can see that the divide method raises a ValueError if we try to divide it by zero. As a result, the ValueError does take place, which is not AssertionError, so the test is considered neither failed nor passed.
Summary
In this topic, we have discussed the basics of unit testing in Python using the unittest framework. The main points to remember are as follows:
We write tests in a separate file, in the very beginning of which we import unittest and the tested module.A test case is a basic unit of testing that checks whether the tested unit produces the right output when given various kinds of input. To create a test case, we subclass the unittest.TestCase class. All the tests will then be defined as methods within the class.We use assert methods for writing tests. The most commonly used assert method is assertEqual().Tests can result in 3 possible ways: Success — the test passes, everything worked as expected;Failure — the test doesn't pass and raises an AssertionError exception, meaning that the assertion failed;Error — the test raises an exception other than AssertionError.
"
182,Unittest in more detail,1061,11265,1054,https://hyperskill.org/learn/step/11265,"Testing is a very important part of writing any software application or product. Some developers write tests for the application before the code. This is called test-driven development (TDD). We have special Python libraries that can be useful and the unittest is one of them.
We have already learned the basics of the unittest testing framework — we've learned how to create test cases and tests, how to use assert methods, how to run tests, and how to read the message about the result of the tests. However, the unittest framework provides a lot of other tools to make testing easier. We will learn some advanced features of the library in this topic.
setUp and tearDown methods
Sometimes we need to create class instances, temporary files, or access the web in the tests. These resources are called fixtures. Suppose you write several tests for the same class. You may think that you will have to create an instance of that class manually for each test. It can be a repetitive and time-consuming process. The unittest.TestCase class (namely, the setUp() and tearDown() methods) provides an easy mechanism to configure and clean up any fixtures.
The code inside the setUp() method is executed before every test method and the code inside the tearDown() method is executed after every test method. These methods save us from having to write the same code for each test. Now let's see these methods in action!
The Calculatorclass has two arguments, the first and the second, and has two methods, add() and subtract(). Now let's write tests for the Calculator class using the setUp() and tearDown() methods.
To get the clear picture about the order of the methods, we will add a print statement with the name of the method at the end. In the setUp() method we create an instance of the Calculator class with two arguments, 5 and 1. We add the tearDown() method, but we don't write anything there, because we don't need it to perform any actions for now. After that, we will write the tests for the add() and subtract() methods.
For the test_add() and the test_subtract(), we check whether they work with the arguments we used in the setUp() method first, if everything is ok, we change the arguments and check again.
Let's run our tests. If everything works as expected, we would get the following message:
The print statements show the order of methods' execution. The setUp() method is executed before each test method, and the tearDown() is executed after each test method.
In both test methods, we checked the expected output for the arguments we wrote in setUp() first. This is because the setUp() method runs before each test method. So even if we change the arguments in the test_add() and check that they have changed, in test_subtract() we write the assertion for the initial arguments.
The tearDown() method can be used when we work with files. For example, in the setUp() we can create a file that we are going to use in a test method, and then we can automatically delete it using tearDown() after the test method was executed.
The unittest also provides possibilities for class and module fixtures.
Command-line options
You know that tests can be executed from the command line, but we have some cool features for you.
Sometimes the module with the tested unit and the file with tests are located in different directories. For instance, you have test_calculator.py located in a different directory than calculator.py. To do this, we need to run the command line from the directory of calculator.py and specify the path to test_calculator.py:
When the tests are located in the same directory as the tested unit, we can specify not only the file we want to run but a test case and even a test method. Let's see how it works with our test_calculator.py.
If we want to specify a test case (our code has only one case, but there are more usually), we should write the name of the test case in the command line:In this case, only the tests from the test_calculator module in the TestCalculator test case will be executed.If you want to execute only one test method, for example, the test_add(), add the name of this method:It comes in handy when you are dealing with one particular test method that you need to check. Note that the setUp() and tearDown() methods will also be executed.We can also run several test modules at once — you just need to type their names in the command line one after another:In this case, all tests from these three modules will be executed in one run!It is possible to combine all these options. For example, we can run all tests from test_caculator.py file and only test_add() from test_calculator2.py like this:
There are several command-line options that allow us to modify the testing process and the output we receive.
We can run tests with more detail, or higher verbosity. To get the details for each test, we need to type '-v' (verbosity) before the name of the test module:
We will get the following output:Another useful feature accessible from the command line is when the tests are stopped after a failure. Just type '-f' before the name of the module:
The list of the command-line options is bigger, we only described the most useful and commonly-used features. If you feel that you need to know more about this, you can type '-h' (help) and read the explanations:

Summary
We've learned more about the unittest framework.
The code inside the setUp() method is executed before each test method.The code inside the tearDown() method is executed after each test method.We can specify not only a module but also a test case and a test method if we use the command line.We can get details for each test method by typing '-v', or stop the tests after the first failure or error by typing '-f' in the command line.
"
183,Flask testing basics,2955,29493,1055,https://hyperskill.org/learn/step/29493,"Software is everywhere, and a new one appears even as we speak. To create good software you not only need to understand the problem it solves. You also need to have enough quality checks before releasing it for usage as a product. The aspect of quality is where tests come in. Tests are written to make sure the software is bug-free and with no unexpected behavior with different inputs. The cost of fixing a bug in testing is usually very less compared to fixing it in production.

In this topic, we will identify what needs to be tested, explore different testing practices, understand some recommended strategies, and finally look at Pytest, a very popular testing library in Python. Software testing is both an art and a science, and we should understand that writing good tests is a skill that helps one write better software. Therefore, it is important to self-update on this as much as one can.

Identifying what to test

Testing is an opinionated subject and identifying what to test is different for different projects. There is a way of development called test-driven development (TDD) where you write tests first and then implement the feature. That is more suitable when you are implementing something new. But let's see some best practices for existing projects, like an existing e-commerce website:

*   Start with testing the critical components of your system, things that cannot be out of service for the system to work, for example, a database that cannot be absent for your system to work
*   Define how users will use your system, and define tests in accordance with that, for example, how should an item search be processed in the backend for a logged-out user vs a logged-in user vs a first-time user?
*   For any new feature of the system, add tests. For example, how to enable a logged-out user to place orders in a system with minimum information.

Types of tests

There are several types of tests in different stages of a software project. Each has its own purpose. To understand better, let's look at their definitions and some examples:

| Testing          | Type of tests   | Definition                                                                                                                                                                                                                                                                                 | Example                                                                                                                                                                                                                                                                                                                                                             |
| :--------------- | :-------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
|                  | Unit tests      | Tests for components at a low level in an isolated manner, like a class method. These can be automated and it is recommended to have a lot of unit tests for different components.                                                                                                    | Testing an individual function that calculates the square root of a number.                                                                                                                                                                                                                                                        |
|                  | Integration tests | Tests to verify two or more components or services work well together.                                                                                                                                                                                                                  | Testing a workflow that involves querying a database.                                                                                                                                                                                                                                                                                        |
|                  | Functional tests  | Tests two or more components, but focus on the business requirements of the application. These tests are similar to integration tests but they are expected to be correct from a functional point of view.                                                                             | Testing a workflow that involves querying a database and the output of the query should be as per the user's authorization in the system. The user should not be able to see records for which they don't have authorization.                                                                                                            |
|                  | End-to-End Tests| Tests the application from a user point of view in an application environment, these are expensive to run when automated and it is recommended to have minimum required E2E tests.                                                                                                       | Logging in as a user and running a workflow with expected user behavior and evaluating the results.                                                                                                                                                                                                                                     |
|                  | Regression Tests  | Regression tests are a combination of functional and non-functional tests that you run when the software has some changes. They validate that new software is not breaking existing functionality. Choose them carefully as they determine the time spent in testing in many cases.        | Logging a user and being able to place an order on an e-commerce website, this functionality should not change even when we integrate a new feature like a new payment service.                                                                                                                                                   |
|                  | Performance Tests | Tests that evaluate the performance of a software system under a specific workload. These tests help to measure the scalability, reliability, and responsiveness of an application. It can determine if an application meets performance requirements, locate bottlenecks and measure stability during peak traffic. | Ensuring accessing the system URL takes less than a threshold and the system behaves well under increased load.                                                                                                                                                                                                                   |
|                  | Acceptance Tests  | These tests involve everything that is needed to get the software accepted. These may be functional tests, E2E tests, and performance tests. These tests are formally defined and can be used as a criterion for decision-making on software adoption.                                | This is subjective but depends usually on how the system is designed and what are the criteria for accepting the system                                                                                                                                                                                                                |

When you start the project, you should focus on writing more unit tests to test smaller components of the project. Then as more features appear you can focus on writing more integration and functional tests to business-wise validate your work. And as the project becomes a real-life big project with periodic deployments, focus on regression tests to keep deployments smooth, performance tests to abate any performance degradation, and acceptance tests for final acceptance to the customer.

Pytest: getting started

Several testing libraries exist in Python like unittest, nose, doctest, and others. But pytest is the most commonly used library because of its simple setup and good features to write different types of tests. In order to install pytest, we need to run the following command

pip install pytest

Once you install pytest, it runs via the command line or via Pycharm IDE directly. To run it via Pycharm, select Preferences > Tools > Python Integrated Tools -> Default Test Runner -> pytest. Best practices for pytest are as follows:

*   Store all tests in a tests/ directory
*   File names should strictly start with test\_
*   Function names should strictly start with test

Pytest example 101

Let's create a file util.py with the following code to test. This is a simple util function that checks if a number is even which raises TypeError in case the input is not an integer.

For creating tests on it we should create another file test\_feature.py with the following code.

Now there are two ways to run pytest, one using a command line, where you can run the command pytest from the directory of util.py file. You would get the following output.

The second is using Pycharm where you can run the tests directly by right-clicking on the file and then see the test results. Usually, pytest runs any file with a name starting with ""test\_"", but this setting can be changed. Also, pytest relies on assert keyword in Python to evaluate a test as success/failure. If you write your tests as classes (much like the unittest framework in Python) then name your class and test methods containing the substring ""test"". For example,

Here the test\_method will be executed, while the do\_not\_run\_this\_test will be skipped.

Testing scenarios with pytest

Pytest provided customization for running tests to make the test suite useful. You will see some of the use cases of testing and what support pytest provides. We are running all the following examples for the is\_even function in the command line using pytest -rA -v command, -rA prints the detailed report and -v increases verbosity.

Running the same test with multiple inputs

It may be needed to run the same test with multiple inputs to examine the code from multiple angles. pytest provides @pytest.mark.parametrize decorator to do this:

For tests marked as @pytest.mark.parametrize we see it is run with multiple inputs with the test\_many function. The input parameters num, res are passed one by one and evaluated as can be seen in the logs. Also, note that the name of the variables defined in @pytest.mark.parameterize(""num, res""... should match the input to the test\_many(num, res).

Handling exceptions inside tests

Sometimes we expect exceptions in tests, for example, if you pass a string input to the is\_even function you get a TypeError in Python, as you cannot divide a string by 2. To handle this, pytest provides pytest.raises for custom exception handling.

Skipping tests based on the environment they are run

Some tests work only in certain environments, for example, you can have tests that run only in Python version 3 versus tests that run in Python version 4.

To run them all together you can use @pytest.mark.skipif decorator specifying conditions to skip the test.

Also, you can entirely skip a test using @pytest.mark.skip by providing a reason.

Running tests that share a common grouping logic

Sometimes it is desirable to run tests together that have a common theme of existence, or you can mark a group of tests to run together in order to test a specific scenario.

Two tests, test\_even and test\_odd are marked in the same group. In order to run them you can use the command pytest -rA -v -m ""non\_zero\_integer\_only"" , -m to specify the marker name. Note: without defining the marker in pytest.ini you will get a PytestUnknownMarkWarning. The output of this test is as follows. (Note only non\_zero\_integer\_only marked tests are run)

Software Tests as Documentation

While the primary purpose of software tests is to ensure code correctness and reliability, they also serve as valuable documentation. Well-written tests act as living documentation for your codebase, providing clear examples of how different components should behave and interact. This can significantly enhance a project's maintainability and ease the onboarding process for new developers.

To maximize the documentative value of your tests, follow these best practices: use descriptive test names that clearly state what's being tested, include setup context to show necessary preconditions, write clear and specific assertions, comment on complex logic when needed, and group related tests logically. By treating tests as documentation, you ensure that your ""documentation"" remains current and accurate, as tests are typically updated alongside the code that is being tested.

Conclusion

You took a deep dive into understanding how testing works in general, what are the types of tests, and what are some of the best practices for testing. Then you took pytest and looked at how to run it in general and with markers. Pytest has many other features like fixtures, profiling which are useful in maintaining a strong test suite. You also explored how tests can serve as valuable documentation for a project, providing clear examples of component behavior and enhancing code maintainability. Testing is always a crucial domain to master and it should be used to write better software.
"
184,Profiling code on Flask,3122,31548,1056,https://hyperskill.org/learn/step/31548,Error extracting text: 504 Deadline Exceeded
185,How to read a traceback,1111,11710,1058,https://hyperskill.org/learn/step/11710,"""Anyone who has never made a mistake has never tried anything new."" — Albert Einstein.
A programmer, like any other person, should be very careful to avoid mistakes. In real life, you may not understand exactly where you did something wrong, but in programming, there is a traceback that will point you to the mistake! It is very important to learn to read it. In this topic, we will not dwell on specific exceptions but will try to convince you instead that traceback is very important and you should try to get all the necessary information from it.
Traceback insides
You've already learned to read a simple traceback and know that the last line is usually the most useful. Sometimes, a traceback can contain several lines of code, and you need to understand how to find the error. It happens a lot with functions, so we'll show you this as an example. Let's write a function is_positive() that prints whether the given number is positive or negative:
Can you spot the error? If executed, it will throw the following TypeError:
Let's go up starting from the last line and divide the traceback into parts:
The last line of the traceback always contains the name of the exception that was raised and the reason why it might have happened. Then there's the line of code that triggered the exception. This part of traceback contains the full path to the numbers.py file, the line number where the error occurred, and the name of the function where this line is located. This block is similar to the previous one, but it refers to the line of code that called the function with the broken code. The location of the function call is also given: the module name and the line inside the file. The <module> means that an error occurred in the executable file.
As you might have guessed, the number needs to be turned into a string value using the str() function to make this code valid.
Find a way
Traceback can be extra useful with other imported modules. Let's create a new file import_numbers.py, import and then run the very same is_positive() function from our previous module, numbers.py:
We are going to get the sameTypeError again:
This traceback is very similar to the previous one, but this time, the path to the module with the error will be changed (""/full/path/to/numbers.py"") as well as the module with the function (""/full/path/to/import_numbers.py""). The main thing, though, remains — thanks to the traceback, we can find out the exact line of the exact module where the error occurred.
Now we understand that our traceback consists of several blocks. In our example, we got the following bottom-up structure:1. The name of the error and its description.2. The location of the module that contains the ""broken"" function code line and the line itself.3. The location of the executable file and the executed function.
In practice, a traceback can contain a good number of blocks. It simply means that many functions were called until the exception was thrown.
""Long"" problems
Let's add another function to our code; check_numbers() accepts a list of elements and prints the result for each number. The user may want to specify a number in a string format, such as ""2"", so we use the try-except statement to handle this situation. Otherwise, we would have had problems in the line ""if number > 0:"", because we can not compare str and int values. Take a look at the code below:
Now, what if a user wants to specify a number in words? Like this:
 Then we get something that is not quite legible:
What happened? In fact, this traceback clearly tells us that During handling of the above exception, another exception occurred. The first part of the traceback above these words tells us about the TypeError exception, which we tried to catch with the try-except statement. The thing is, during the execution of this block, another exception was raised, the one that we see in the second part of the traceback. A new ValueError exception occurred in the except TypeError:  block because we tried to pass a string ""Two"" to the function int(). That is, when handling the first TypeError exception, we received the second ValueError exception.
As you can see, tracebacks can contain a lot of information. It is important not to get lost in it and be able to find errors in your code, as well as to be ready to go back to our past mistakes and correct them.
Summary
Let's not forget the ""through hardships to the stars"" mantra, or, in our case, through a traceback to the working code:
It is important to be able to read the traceback and locate your errors.The traceback is divided into ""blocks"" that contain information about the error and its location.It is more useful to read the ""blocks"" from the bottom up.If several exceptions occur, the traceback will show all of them, from the earlier to the more recent errors, so that the last error is shown in the last line.
"
186,Dataclass,2602,25094,1094,https://hyperskill.org/learn/step/25094,"How often did you have to write the tedious __init__, __repr__, and other standard class methods? Countless times. If you are bored with repeatedly writing the same thing, know there's a solution – a data class! A data class is a new feature in Python 3.7+ that allows you to create classes straightforwardly. It doesn't add any new functionality but automatizes some routine work and helps you get the same thing but with fewer lines of code. So, let's dive into it!
Creating a class

For this topic, ensure you have Python version 3.7 or higher installed. Otherwise, the code won't work.

As we've mentioned, the purpose of a data class is to create classes with less code. To see it in practice, let's first create a class via standard procedure:

Now, let's do the same with the data class. First, we import it from the dataclasses module, then use the @dataclass decorator and write our class. Here's the code:

We have the exact attributes there: name and number, but we don't need to add self. We don't even need def __init__()! But we have to specify the data type (str and int in this case), otherwise a NameError is raised. 
In these examples, OldClass and NewClass behave the same. However, NewClass is much faster to write!
If you want to add default values, you can do the following:

If you have many attributes with default values and some without, the attributes without default values should be placed first.

With data classes, you don't need to write the __init__ method, since it is implemented automatically. In total, there are four methods created automatically in every data class:

__init__ to initialize the object;

__repr__ and __str__ to create a string representation of your class;

__eq__ to compare class objects to each other.

We'll learn more about them in the next sections.
String representations
After we've defined a class, create class instances in the usual way:

As you remember, we haven't written the __repr__ method. Still, we get a neat representation of the class when we use print():

You can constantly redefine this method if you want to print something else. Just do it the usual way. Note that when you write any methods inside a data class, you need to use self like in any other class.

If we try to print our new class object now, here's what we get:

So, if you define __repr__ or __str__, the standard ones would be overridden, and your implementation would be used. The same goes for the __eq__ method.
Equality check
The __eq__ method compares class objects to each other. For standard class definition, you need to add it; otherwise, you'll end up with something like this:

Now, let's try it with dataclass:

We haven't written the __eq__ method in either of the examples, but with dataclass, it's implemented automatically — if all the attributes are equal, class instances are also equal. If you want a different comparison logic, write your __eq__ method, which will be used instead of the default one.
Comparison and sorting
Now, we know how to determine if two class instances are equal. But what if you wish to compare them using a > operator? For now, it would result in an error:

However, if you want to implement a comparison by an attribute, it won't take many lines. Do three simple things: specify order=True when using the decorator, write a sort_index attribute, and a __post_init__ method. Let's compare our class objects by the number attribute. Here's what the code looks like:

Let's go through this code in more detail. First, we import not just dataclass but field too – it's a function we'll need in the next lines. Then, we specify order=True in the decorator. We create the sort_index attribute and set it to int (since the number attribute should be an int) and make it field. In dataclass, field() is just another way to create a class attribute, specifying more information. In this case, we require field() to specify init=False. This means that sort_index won't be initialized when a class instance is created. Instead, it will be initialized in the __post_init__ method, the one that is called right after the __init__. Inside the __post_init__ we set self.sort_index to self.number, specifying that we want to compare our class instances by the number attribute.
Now, let's create some class objects and try to compare them:

As you can see, it works perfectly! What's more, we can also sort our objects now.

Here's the resulting list:

Note that what we see here are the default string representations. If you want to avoid including the sort_index in our representation, which might be redundant, as it has the same value as number, we can do it the following way:

Adding repr=False when defining a class attribute, this attribute won't be included in the string representation.
Frozen objects
The last feature of the data class we'll look at is creating frozen objects. Let's say you want to prohibit changing the attributes of an object after its creation. Easy! Just add frozen=True to the decorator like this:

Now, let's try to create a class object and then reassign the name variable.

You get an error. Why would you want your objects to be immutable? There can be many reasons, but the main ones are having less side effects in your code and just not having to think about what happens if this or that attribute gets changed later. So, if you need some read-only class objects – go for frozen data classes! 
Conclusion
In this topic, we've covered the main features of dataclass – a new way of writing classes in Python 3.7+. Let's make a quick recap of the main points:

Data classes offer an easier way of creating classes;

The functionality that a data class provides is not unique – the same things can be achieved with the regular classes, but they might require more code;

String representation is automatically generated in a data class;

Equality check is implemented automatically, too; two data classes are considered equal if all their attributes are the same;

You can freeze your objects to prohibit assigning new values to the attributes.

Of course, data classes provide many more possibilities; use the official documentation to learn more about that. Now, let's turn to practice!
"
187,How to choose a collection to use,1446,13907,1095,https://hyperskill.org/learn/step/13907,"As you may know, there are four main data collections in Python: a list, tuple, set, and dictionary. It may seem a little overwhelming and complex at first, but a good Python developer needs to have a good grasp of data structures because they are the program's building blocks. This topic will point out the differences and similarities between data collections and help you decide which suits you better.

Properties to look at
Different data collections have different properties. Let’s briefly recall them.

How elements are stored: both lists and tuples can store elements in a single row or several rows and columns, so they allow stacking. Sets, on the other hand, store elements only in a single row. Dictionaries store elements in key-value pairs.

Duplicates: lists and tuples can have duplicate elements. In dictionaries, keys cannot repeat themselves, while values can be the same for different keys. Finally, sets cannot have two items with the same value.

Mutability: except tuples, all other collections are mutable. We can change the stored elements.

Order: all data structures excluding sets are ordered, so the elements preserve their order.
Unfortunately, dictionaries became ordered only in Python 3.7. If you are using earlier versions of Python, there is a dictionary subclass OrderedDict that remembers the order of added entries. You can find it in the collections module.

Indexing: in lists and tuples, we can access the constituent elements through indexing and retrieve indexes of the required elements. Dictionaries and sets cannot be indexed. However, you can use the list() constructor. It takes an iterable (a set, a dictionary, or a string) as a parameter and creates a list of iterable items.

Below you can find a comparison table that can help with the decision.

List
Tuple
Set
Dictionary
Mutable
+
-
+
+
Duplicates
+
+
-
(-) keys
(+) values
Ordered
+
+
-
+
Indexing/Slicing
+
+
-
-
Storage type
row/column
row/column
row
key-value

Questions to ask yourself
There are several questions you can ask yourself that will help you make the right decision.

Am I going to perform membership tests? For example, you want to write a program that will consider a user input valid only if it is a part of a collection, otherwise it is invalid. In this case, use a set. In general, sets are preferred over lists when you want to do lookups because sets are implemented as hash-tables. They perform membership tests faster, especially when you have a lot of data. Here is an example of when it's a good idea to use a set:

Is the order important? If so, use a list. As you know, lists can be indexed, so it is possible to find an element by its position or find the position by the name of the element:

But what if the positions are important and the values are fixed? As you may have noticed, the names list above is mutable, we can expand it or remove some elements. What if we do not want that? Then, choose a tuple over a list. Not only are tuples immutable, but they are also iterated over faster than lists with large amounts of data. For example, let’s assume we have a tuple of weekdays, and we want it to stay the same all the time:

What if I want to extract a value of an element not by its index but by its key? Then, a dictionary is the best choice. Take a mapping between a person’s name and their age:

Conclusion
In this topic, we have discussed the various properties of four main Python collections. We also have taken a look at various questions that can help you with choosing a data structure. To sum up, when choosing the right collection, think about which elements you are going to store, how you want to access elements, and whether you want the collection to be mutable. Practice makes perfect. After a little while, you will be able to choose a collection without a doubt.
"
188,Timeit module,1819,16953,1113,https://hyperskill.org/learn/step/16953,"If you've had some experience with coding, you may know that there are many ways to code the same thing. How can we know which one is the best? One of the solutions is to compare the running time. The faster code pieces are commonly better than the slower ones. That's where the timeit module can help. It measures the execution time of a short code snippet and helps you understand how efficient it is. You can use this module both in the Python interface and in the command line.
Timeit operation
Before we get to the code examples, let's take a look at what timeit does. If you're familiar with the time library, you may wonder, why timeit? Put down the time before and after the execution, and then subtract! Easy money. Why is timeit better?
The running time of your program can be affected by background processes that have nothing to do with your code. Time doesn't take it into account, while timeit does. First of all, it runs your code snippet many times, not just once. The default value is 1 000 000. Though, you can change it. So, if you run the timer once, it keeps repeating your code. In the end, you get the total execution time. You can also repeat the timer if you want. In this case, the code is executed 1 000 000 times, and the module records the execution time. After this, the code is executed 1 000 000 times again, and the new execution time is recorded. It happens over and over again, as many times as you specify in the arguments. The default value for the command-line interface is 5. If you're using the command-line interface, it repeats the measurement 5 times and reports the best time. You can do that in the Python interface as well. It allows you to be sure of your code efficiency. However, you cannot completely avoid the system's impact, so don't be surprised when you run the timer several times only to get slightly different results. One more interesting thing – since timeit runs your snippet many times, it provides the running time for many executions, not just one. 
As we have mentioned above, the timeit module can be accessed in two ways: in the command line and from Python. We'll start with the latter one.
Introduction to timeit
timeit is a built-in library, so you don't need to install it. Just import it to your code:
Now you're ready to go! First, let's take a look at the syntax:
stmt means statement. It's your code snippet. Note that it must be str;
setup is the code that you don't want to repeat in the loop (for example, an import statement); it will be executed once, and the module will then subtract the execution time from the result. It must be str;
timer is the function that measures the time. By default, it's time.perf_counter(), a function well-suited to measuring short durations;
number is the number of the stmt executions you want to have in one loop. The default value is 1 000 000;
globals allows you to specify the namespace to run the code. By default, stmt is executed in the timeit namespace.

The return value is a float indicating seconds.
Let's look at an example. For now, we'll keep our code snippet simple and add two numbers. Note that the str of your code must be either a multiline with triple quotes or contain a semicolon that separates the expressions. Both of these would work:
How do we measure execution time?
That's how timeit works. We have provided only stmt. Writing the stmt word is optional; the method would work with timeit.timeit(snippet) only. We've found out that adding 5 to 7 one million times takes Python approximately 0.11 seconds.
Experimenting with options
Let's see how the result will be changed if we alter the number argument. If we decrease it to 1000 repetitions, we will get better timings:
Now, let's try 100 000 repetitions. It will take more:
How to determine the number of repetitions? You can get along with the default value. Another option is to use autorange that will determine the value on its own. We'll get to that a bit later.
You can also repeat the loop. To do it, use the timeit.repeat() method:
As you can see, this method takes the same arguments as timeit.timeit() plus an additional one – repeat. The default value is 5. The output value is a list of float values. Typically, you'd be interested in the lowest value in the list since the higher ones tend to reflect the background activity in the system. Let's have a look at an example:
The value of repeat is 3, so we got three results. timeit.repeat() calls the timeit.timeit() function several times and shows you the results.
Let's take a moment to discuss setup. In this example, we'll find out how fast math.sqrt works. This function calculates the square root of a number. To use it, we need to import the math module first. That's where the setup argument comes in handy — we don't need to import the module one million times:
What if you have a lot of import statements? Setup would take too long. While there's no big problem in having a huge setup statement, there's a more elegant way to do it. Use the globals argument! globals = globals() will allow your stmt to be executed in the global namespace. To put it simply, the function will take the import statements, variables, and functions declared outside the timeit.timeit(). Let's see how it works with the same example of the square root:
If you don't pass either a setup or a globals argument, you'll get NameError because there's no math inside the timeit namespace. Sometimes, globals=locals() is preferable. You can read a more detailed explanation of that on the StackOverflow forum.
Building a Timer class
You can also build a class with timeit:
Let's say we want to know the list comprehension execution time. Try to do it with a class:
We've created a class instance, but we haven't measured anything yet. To do it, use either the timeit() or repeat() method that works the same way as before:
We have used the autorange method. It chooses the number of repetitions in the loop automatically, aiming at total execution time >= 0.2 seconds. 
The return value is tuple, where the first element is the number of repetitions, and the second one is the time measured in seconds.
Once we've covered the main points of how timeit works in the Python interface, let's move on to the command-line interface.
Command-line interface
Using timeit from the command line is somewhat straightforward. The module does a lot of work for you, like determining the number of repetitions inside the loop and repeating it several times. First, let's have a look at the syntax:
-n is the number argument. It specifies how many times the statement will be repeated;
-r is the repeat argument that determines how many times to repeat the timer;
-u means unit. It allows you to choose a time unit for the output. You can choose either nsec (nanoseconds), usec (microseconds), msec (millisecond), or sec (seconds);
-s is setup — an initial statement that is executed once;
-h means help and displays a short usage message.

Do you remember the autorange method from the Python interface? As we have already mentioned, the command-line interface does it for you without special commands! If you don't pass the -n parameter, Python will calculate the value automatically.
Let's say we want to see how fast the split() method works. It creates a list from a str and divides it by whitespaces. How do we measure its execution time using the command line? Note that the statement has to be provided in double quotes:
Python has chosen 2000000 as the value for number and has run the timer 5 times. Now, it reports the best time: 149 nanoseconds. 
Conclusion
In this topic, we've learned how to use Python timeit module. Let's quickly go through the main points:

timeit measures the execution time for short-code snippets;
timeit.timeit() is the basic function you'd use most of the time. This function repeats your code in a loop 1 million times, but you can change that using the number argument;
Use setup or globals for import statements;
Use timeit.repeat() if you want to call timeit.timeit() several times;
You can create a timeit.Timer() class instance;
You can also use timeit in the command line.
"
189,Itertools module,678,8487,1117,https://hyperskill.org/learn/step/8487,"You are already familiar with iterators and know how to create an iterator from a list or other iterable objects. In this topic, you will learn how to create iterators from multiple collections (e.g., two lists) with the help of the methods implemented in the itertools module.

The itertools module contains some useful iterator building blocks. To use its functionality, you will need to import the module first:

itertools.chain()

itertools.chain(iterable1, iterable2, ...) is handy when you need to treat a number of consecutive sequences as a single sequence. The code below prints out the names of all the students taking different subjects:

So, the itertools.chain takes a number of lists (or any other iterables) as input and returns an iterator that returns the elements from the first list one by one until the list is exhausted, and then proceeds to the second one and so on until all the lists are exhausted.

Note that this approach is different from concatenating all the lists first and then looping over the resulting list because itertools.chain doesn't actually create this intermediate concatenated list and therefore saves up memory.

The itertools module implements other useful combinatorial functions, such as product() and combinations().

itertools.product()

Another useful tool is the itertools.product(iterable1, iterable2, ...), which takes several iterables and returns the elements of their Cartesian product one by one. Cartesian product of several iterables is an iterator of all possible tuples such that the first element is coming from the first argument, the second element is coming from the second argument, and so on. Here is an example:

Again, note that these combinations are not stored in memory but produced on-the-fly, only when the for loop asks for a new one. This is especially important when you work with a lot of data. Compare:

itertools.combinations()

Imagine that you need to obtain all possible combinations of r items from an iterable containing n elements.

For example, let's consider all possible combinations of any two numbers between 1 and 1000000. There are so many of them it's practically impossible to fit in memory. How to deal with this problem? Use iterators! itertools.combinations(iterable, r) does exactly what we want. Take a look at the example:

itertools.groupby()

Something else we can do with an iterable using itertools is to group its items by a key. That is done with the itertools.groupby() method. It takes one iterable and an optional key argument that determines the criteria for grouping the items.

Let's look at an example. Suppose we want to group names in a list of students.

We didn't specify a key, so an identity function was used and we ended up grouping the same names.  itertools.groupby() returns an iterator for each key, so if we need the items later, we should store them in a list.

Note, that the input iterable generally needs to be sorted according to the same criteria as the key before we pass it to itertools.groupby(). That is because a new group is created every time the key changes, so if we hadn't sorted the list, we would have gotten the following groups:

If we want to group items by specific criteria, we should pass it as a function to the key argument. You can define a custom function or use the lambda function. For example, we can group names by their lengths:

Summary

The itertools module implements useful iterators.

Iterators don't work as finite sets but rather generate elements one-by-one.

Using an iterator helps to save memory.
"
190,Match statement,3587,37658,1120,https://hyperskill.org/learn/step/37658,"Pattern matching is a programming paradigm that enables developers to match data structures and extract information based on their shape and content. It is widely used in functional and declarative programming languages, and was introduced in Python 3.10, which has taken the language a significant step forward in terms of expressiveness and readability.
In this topic, you will learn the syntax of pattern matching and creation of complex patterns, as well as some core concepts and use cases of this feature.
Syntax
A similar concept had already been implemented in C++ or Java (switch construction). So, if you've previously worked with those languages, you might find the syntax familiar. To use pattern matching in Python 3.10, you need two main keywords: match and case. Let's look at a simple example to better understand this concept:
As you can see, we've declared a function http_handler that processes HTTP responses and prints the matching message. Note that an underscore wildcard (_) covers any other cases not mentioned above.
Patterns
Now that we've grasped the basic syntax, let's dive deeper into pattern matching. In the previous example, we used an integer in the match expression. However, we can create much more complex cases. Patterns defined after the case keyword can include literals, variables, boolean operators, and many other constructs. For instance, if you want multiple statements to match a specific case, you can use the ""boolean or"" (|) operator:
Now, the message ""OK"" prints for both ""200"" and ""201"" HTTP responses.
You can also use lists and declare variables inside a case. Imagine you have a program that takes an input from the user and runs the corresponding command. To parse such input, you would usually create a complex if-else statement. Let's see how you could accomplish the same using pattern matching:
Let's dive deeper into the code: the split() function returns a list, so we use lists in every case statement. In the second case, we defined a variable word. This syntax means that any list of two elements with the first element equal to ""say"" will match this case. The third case is similar, except that now the list can be of arbitrary length, and the first element should be ""execute"". We used a star (*) to make args iteratable, and looped through them, calling some_function for each of the arguments. You could also use tuples instead of lists by replacing parentheses with square brackets.
It's possible to blend lists with a ""boolean or"" (|) operator and add conditions for a more precise pattern, like so:
In this example, we're parsing a command from the input and checking if it meets the requirements. In the first case, we specified the possible options for the ""ls"" command. The second case can match if the second argument of the list represents an existing path in your file system. The function behavior is showcased below:
Pattern matching also supports the use of dictionaries like this:
As you can see, the pattern matching feature lets you write significantly cleaner and more readable code. The examples above barely scratch the surface. You can even use custom classes as patterns to match, as such:
We've declared two classes: Student and Teacher. Please note the @dataclass annotation is essential for pattern matching to work. Remember, data classes are designed only to hold data values and usually don't have any methods. Now we can define patterns by describing the values stored in the fields. The syntax is similar to what we've previously discussed about lists and dictionaries. Our function will behave like this:
Matching logic
In Python 3.10, the match statement evaluates each pattern in order and matches the first suitable case, disregarding the rest. So, if you were to declare two identical patterns, the one listed first would be matched:
For this reason, it's forbidden to declare case _ before all the other cases are listed. Since the wildcard (_) would make the remaining clauses unreachable. Also, writing such code results in a SyntaxError.
Pattern matching is excellent for working with data classes, not only because it helps write cleaner code. It's also implemented in a lightweight way. When declaring a data class in a pattern, no new instance is created. The case merely checks that the passed object is an instance of the corresponding class and has required field values, without creating a new object.
Compatibility and limitations
Despite how effective the pattern matching feature is, it's crucial to note that it's not backward compatible with earlier Python versions. It's available in Python 3.10 and subsequent versions. This means that if you want to leverage the features of the match statement, you must ensure you're working with these newer Python versions.
Pattern matching can also have performance constraints. If a programmer writes overly complex patterns, which are costly to assess, or uses large data structures, the performance impact of using the match statement can be considerable for large datasets, complex structures, or performance-critical applications. However, for typical code, this impact should be negligible. You should profile your code to identify any bottlenecks and consider alternative optimization strategies, such as simplifying patterns or optimizing data structures. Furthermore, overly complex patterns can diminish readability, as in the following example:
By just looking at this line, it's tough to decipher exactly what it should do. Even though you might remember its purpose when you wrote it, you will likely soon forget. Not to mention other developers who see this line for the first time. Therefore, please avoid constructing such patterns.
Conclusion
Structural Pattern Matching in Python 3.10 is a transformative addition to the language. It offers a new way to work with data structures, simplify code, and improve readability. With the capacity to succinctly match and extract data from complex data, Python developers can now tackle a broader range of tasks more effectively, from data analysis to software development. As can you, now that you've learned:
The syntax of pattern matching;How to create sophisticated patterns to work effectively with complex data;How pattern matching can enhance the parsing process;How to use data classes inside patterns.
"
191,More operations with list,3469,36290,1123,https://hyperskill.org/learn/step/36290,"A list in Python is an ordered collection of elements, where each element can be of any data type. Lists offer a range of operations that allow us to manipulate and work with the elements stored within them. In this topic, we will explore the basic operations that can be performed on lists in Python. We will learn how to insert elements, check if elements exist, and search for specific elements. Understanding these operations will enable us to effectively work with lists and harness their flexibility for various programming tasks.

Inserting elements at a specified position
As you know, the list.append() method is how we add new elements to the end of a list. If we want to add a new element in the middle, we use the list.insert(position, element) operation. The first argument is the index of the element before which the new element is going to be inserted; so list.insert(0, element) inserts an element to the beginning of the list, and list.insert(len(list), element)is completely similar to list.append(element).

Now, you can fill any empty list with something useful!
Membership testing in a list
Another thing that can be quite useful is checking if an item is present in the list. It can be done simply by using in and not in operators:

Searching specific elements
Sometimes, knowing that the specified element is in the list is not enough; we may want to get more information about it — how many times the element occurs in the list and at which position.
The method count() can help with the quantity:

We can use the method index() to get the position of the element. It finds the index of the first occurrence of the element in the list:

We can also specify the interval for searching: list.index(element, start, end).

# if we don't specify the end of the interval, it automatically equals the end of the list

Be careful — the end index is not included in the interval.

It is also good to know that if the element we are looking for is not in the list, the method will cause an error:

Summary
In conclusion, we have covered more operations related to manipulating and searching elements in a list. We have learned how to insert elements at a specified position using the list.insert(position, element) operation, allowing us to add elements anywhere in the list. Additionally, we explored membership testing using the in and not in operators, which helps us determine if a particular item is present in the list.
Furthermore, we discussed the count() method, which provides us with the number of occurrences of a specific element in the list. The index() method allows us to find the position of the first occurrence of an element, and we can even specify an interval for searching.
By understanding these operations, we have expanded our ability to manipulate and search elements in Python lists. If you require further information, it is recommended to consult the  Python Data Structures documentation for a more comprehensive understanding of these topics.
"
192,Sorting problem,274,4954,1155,https://hyperskill.org/learn/step/4954,"The sorting problem often arises in programming practice and is one of the most studied problems in computer science. There are a lot of different algorithms for solving the problem. Often, sorting is the basic building block for other algorithms; hence, understanding sorting is integral to solving many other problems.
What is sorting?
Very often we need to organize a sequence of elements. The required order can be ascending or descending. Usually, the ascending order is taken by default.
To represent sequences of elements, many languages support arrays or lists.
Here is an array of six elements:

As a sorting result, we get another array of the same size:

Many programming languages provide built-in algorithms for sorting lists and arrays. There are many different sorting algorithms in computer science, and in the following sections we will learn their basic principles.
What can we sort?
It is possible to sort data of different types:

numbers in accordance with the arithmetic order;

Unicode characters in accordance with their order in the Unicode character table;

strings (lexicographically or by size);

dates and times in accordance with the chronological order.

Also, it's often possible to sort data of more complex types if we know how to compare items. As a rule, such data has one or more fields called sorting keys, by which sorting is performed.
Key features of sorting algorithms

Time efficiency. The size of an array we want to sort is very important for efficiency. If we want to sort an array consisting of a few dozen elements, we can use any sorting algorithm. But what if the array contains a lot of data? In that case, we should use more effective sorting algorithms, otherwise, the results might take too long.

Stability. An array may contain several elements with equal values. Stable sorting algorithms always sort such elements in the same order as they appear in the input. Otherwise, the sorting algorithm is unstable. Stability is important when we sort complex structures such as objects, strings, or something else.

In-place/out-of-place sorting. An algorithm performs in-place sorting if it requires only a constant amount of additional space, otherwise, the algorithm performs out-of-place sorting. The larger the size of the array, the more additional memory out-of-place algorithms require.

Internal or external sorting. An algorithm performs internal sorting if the data is kept entirely within the main memory of the computer. In turn, we need external sorting when the data does not fit into the main memory of the computing device. In such a case, we keep it in the slower external memory (usually a hard drive).

In the following topics, we will consider sorting algorithms with different properties.
Many sorting algorithms compare array items during sorting, but some algorithms use other techniques to sort. Such algorithms are also known as non-comparison sorting algorithms.
Conclusion
In this topic, we have introduced a rather big subject — algorithms used to sort items. There are many of them we use separately or to build other, more complex algorithms. We can sort numbers, dates, Unicode characters, strings, as well as not-so-obvious data types, provided we use sorting keys. Most algorithms use comparison to sort elements, but also there are non-comparison algorithms. When dealing with sorting algorithms, we have to consider their stability, time complexity, and whether they use in-place or out-of-place, internal or external sorting. The following topics will provide more detail about different kinds of sorting algorithms and their implementation.
"
193,The Shutil module,1687,15831,1208,https://hyperskill.org/learn/step/15831,"We already know how to interact with the operating system. In this topic, we will learn some of the high-level operations: copying and removing files and directories with the help of the shutil module. You can easily automate file operations without diving into low-level semantics, such as creating file objects or closing files.

To use the shutil module, you will need to import it first:

Copying

Every day we copy, delete, rename, or move various files and folders. If we want to copy our file in the current directory, we can use the shutil.copyfile() function:

This function copies the contents of the source file to the destination file. It takes two parameters: a source file and a destination one. In the code above, we use the os.listdir() function to show the current directory content.

Another useful function is shutil.copy() that allows copying files into another directory:

The shutil.copy() function takes two arguments and copies the file with the same permissions. If the file is read-only, it will have the same permission in the target folder. However, the metadata of files, such as the time of creation, accessing, and modification, will not be preserved.

Copying file with metadata

When you use functions described in the section above, they create a new file with the same contents. Sometimes, however, you may need to clone a file with all metadata. In this case, you can use shutil.copy2().

As we can see in the example, the shutil.copy2() function takes the same arguments as shutil.copy() and copies the metadata from the source destination. In the output, the Mode, Accessed and Modified lines remain the same, but the Created line differs from the source file. This variation may occur as a result of different operating systems. For example, on Windows, the file owners and ACLs (permission list of file or directory) are not copied, as they may be private.

Copying and removing a directory

The shutil.copytree() function allows copying a complete directory to the destination directory recursively:

This function, again, takes two arguments — the source and destination directory. The destination directory should not exist; otherwise, the FileExistsError exception will be raised. We can also specify the copy_function argument. By default, it is the shutil.copy2() function.

If you want to delete an entire directory, you can easily select the shutil.rmtree() function.

It takes a path as an argument. If the path does not exist, FileNotFoundError will be raised.

Moving and finding files

It is easy to move the file or directory from one place to another with shutil.move(). This method takes the source and destination paths as the parameters and returns the absolute path of the new location.

If the source is a file, and the destination is a directory, it moves the file and retains its name:

You can move the file to a different directory and change the filename:

Additionally, it is easy to move an entire directory from one place to another:

If the destination path already exists, shutil.Error will be raised.

Another helpful function is shutil.which(). It finds the path to the provided executable application like Python3 or Java:

The shutil.which() takes the executable file as a parameter. If it can't find the location, it will return None.

Making an archive

In this section, we will take a look at how to archive files in a specific format. First, we need to know the available formats. For this, we will use shutil.get_archive_formats():

As we can see, the available archiving methods include bztar, gztar, tar, xztar, and zip. There is a way to register a new archive format with the shutil.register_archive_format(). The procedure is described in the Official Documentation in detail.

Now, we can perform the archiving with shutil.make_archive():

It takes the name of the file, archive format, and directory as arguments. With this simple action, we have compressed a file in the compressed_algo file.

Conclusion

In this topic, we have learned about high-level file and directory operations with the shutil module. When using this, we don't need to perform operations such as opening, reading, and closing files. Let's take a brief look at the operations we have discussed:

shutil.copyfile allows us to copy files in the current directory;shutil.copy copies the contents of the file to the destination file or directory;shutil.copy2 is similar to shutil.copy. It preserves the metadata;shutil.copytree copies an entire directory to the destination directory;shutil.rmtree deletes a directory;shutil.move easily moves a file or directory to the destination;shutil.which finds the path to the executable file;shutil.make_archive allows us to compress the files in the given format.

For additional information, you can check the Official Shutil Documentation.
"
194,Search in a string,855,9558,1209,https://hyperskill.org/learn/step/9558,"One of the essential skills when working with data is to be able to search it and locate specific bits of information. Working with textual data in Python, you may need to get some information about its content: whether it includes a specific substring (i.e. part of the string), where this substring is, or how many times it occurs in the text. In this topic, we will learn how to do it.

A substring searching algorithm
We'll start with a substring searching problem. Given two strings, text and pattern, we need to identify whether there is at least one occurrence of the pattern in the text. The simplest and most natural way to solve this problem is to sequentially consider all substrings of the text whose length is equal to the length of the pattern and compare them with the pattern itself. If at least in one case all corresponding symbols match, the pattern is found. If none of such attempts were successful, we should indicate that there is no pattern in the text. Here's how this simple algorithm can be implemented in Python:

The function named contains takes two strings, text and pattern, as input and returns True if text contains pattern and False otherwise.
At each step of the outer for loop, we create a variable named found and initialize it with True. Then, in the inner for loop, we start comparing pattern with the current substring of text. If at least one of the corresponding symbols doesn't match, we set the variable found to False and break the inner loop. After the inner for loop is done,  we check the state of the found variable. If it remains True, this means that each symbol of pattern matches the current substring. In this case, we return True indicating that pattern is found. Otherwise, we move to the next iteration and start considering the next substring. In case none of the comparisons were successful, that is, the outer for loop finishes all iterations, the function returns False indicating that pattern is not found.
Here is how this algorithm can be used:

Now we know that there is a substring searching algorithm and how to implement it in Python. However, there are also built-in functions and operators that solve the problem. Let's see what they are.
Membership testing
Another way to define if there's a specific pattern in our string is called membership testing, and it is implemented with the help of the operators in and not in. When we write pattern in string, the left operand should be a string, and membership test checks if string contains pattern as a substring.
If membership test returns True, this means that there exists a position in string starting from which you can read the pattern in the string.

Interestingly, an empty string is considered to be a substring of any string.

Boolean search in a string
Apart from knowing that a substring just occurs in the string, we can determine that the string starts or ends with a specific pattern. Methods startswith() and endswith() return True if the pattern is found and False otherwise.

Optional values for start and end that bound the search area can be added: string.startswith(pattern, start, end). When we specify only one additional element, it's automatically considered as start.

In the example above, when we specified the start argument as 2, we limited the search to the substring ""_email@something.com"", which actually doesn't start with ""email"". Then we fixed this off-by-one mistake by setting start to 3.
Note that the substring bound by the start and end indexes does include the character with the start index but does not include the element with the end index.

The substring defined for the search in the first case is ""ail"", while in the second one it's ""ail@"".
Element position
Now, as we know how to check if a string contains a substring, starts or ends with it, let's learn how to define the exact position of the substring. We can use the methods find() or index() to do so:

They work absolutely the same except that the former returns -1 if it can't find the given element, while the latter raises ValueError.

So, all the examples with find() below will work with index() as well.
We can search both for single characters and for longer substrings. In the latter case, the index of the first character of the substring is returned.

In the string friend, the substring end occupies positions from 3 to 5, and the start index is returned. Keep in mind that both methods return only the index of the first occurrence of the element we search for.

However, we can additionally specify an interval for searching, just as with the boolean search: string.find(pattern, start, end).

Once again, the end index is not included in the search area.
Alternatively, we can use methods rfind() and rindex() to search backward from the end of the string.

Element number
Finally, it's often useful to count how many times an element (a char or a substring) occurs in the string, and for this, we can use the method count().

Summary
In this topic, we have examined different aspects of searching through a string and learned how to locate specific patterns. Now you will be able:

To implement a substring searching algorithm in Python,
To test for membership in a text,
To check that the string starts or ends with a specific pattern,
To find the exact position of a substring,
To count how many times a pattern occurs in the text.

This knowledge will be helpful in real-world tasks, so let's practice it!
"
195,Testing user input,977,10494,1211,https://hyperskill.org/learn/step/10494,"When we write programs in Python, we often want to interact with a user, for example, to ask them to enter a value to obtain a further result. We need to be very careful with that! Users may enter something other than what they were asked for, and it can lead to unexpected errors. To prevent this, we should test the user's input. The idea is to take into account all scenarios and process them correctly. This topic will cover the basics of such testings.

Types of values in testing user's input
Input values can be divided into three groups:

expected values are correct input values, a program requires them for implementing next steps.
border values when we deal with numeric input; they limit the range of expected inputs and may be included or not, so they could either be expected or invalid values. We mention them separately because you should always be careful with them.
invalid values are incorrect inputs: they are not what we asked for.

Now let's illustrate different types of values with an example. Imagine, we ask a user to input a number:
So that:

The integers from 26 to 49 are expected values. They are expected from a user.
25 and 50 are border values. In our example, we have not specified whether we want them or not, so they can be either expected or invalid values. In a real program, we will have to explain it to the user and process them accordingly.
Other integers, floats, or strings are invalid values.

In the following sections, we will discuss the ways of testing such inputs in our code.
If statements for testing
Let's modify our code and read the user input step by step so that we could process every value without errors. First, we create a function that checks the given integer and prints a message if it is a correct value or not:
Be careful, the border values are not included! Let's run our code several times and see what we will get with different integers as inputs:
As you can imagine, such conditional statements are not enough to test the user input. Let's see what else we can do.
Try-except block to deal with exceptions
If our user enters a float or a string, the ValueError will occur because the int() function would not be able to convert the input into an integer:
This behavior is wrong for our program! It should continue executing if an invalid value was entered. To deal with the error, we can use the try-except block. Note that we modify the lines where the program takes the input.
Now, if the user enters a float or a string, it will produce no errors:
The while loop can also be extremely useful for us in the task of handling the user input.
While loop for continuous input request
In the previous examples, we needed to re-run the code each time to enter another value. However, when working with a user, our program should ask for the input until a correct value is entered. We can do so with the while loop.
In the example below, we combine if statements, try-except block, and while loops for multiple checking. We also consider the border values as the expected ones from now on. We should specify this in the message for a user, and process the values respectively in the code. Note that it is more convenient now to read the input inside the function.
Now, the program will run until the user enters what we asked them to:
Finally, our program can process all types of inputs, and will not crash if the user behaves unexpectedly.
Built-in methods for string testing
Our previous examples described integer inputs, but in a great number of situations, we need to deal with strings. Checking strings may be needed in various situations. Imagine that you are creating a program to check the password reliability. Python provides several methods that can be used for string input testing. They will allow you to check, for instance, if your password contains both integers and letters of different cases. Below we present a table with the string methods and their brief explanations.

Method
The returned value

str.islower()
True if there are only symbols of the lower case in the string.

str.isupper()
True if there are only symbols of the upper case in the string.

str.isalpha()
True if the string consists only of letters (upper/lower case).

str.isdigit()
True if the string consists only of digits.

str.isnumeric()
True if the string consists of digits and characters that have features of Unicode digits (their Numeric_Type feature is set to Digit, Decimal, or Numeric). For instance, the fraction ⅝ is a symbol of Unicode, meanwhile the string ""5/8"" contains three symbols. The second example will return False as there is a slash, whose type is not the Numeric_Type.

str.isalnum()
True if the string consists only of digits and letters (upper/lower case).

Now let's look at an example. There is a function below that takes a string and checks if it is a name; it should contain only letters, start with a capital letter, and the rest of the letters should be lowercase. These conditions are very simple and may not identify all names correctly, but you can still see how the string methods work:
If any of the conditions is not met, False will be returned and the code will execute the else statement.
Take a look at the question mark in the third input. It is not a letter, so x.isalpha() returns False.
Summary
The testing of user inputs is a pivotal step for creating a working piece of code. It allows us to process all possible inputs of a user and prevent some errors. So far, we have discussed the following:

we have three main types of input values: the expected (correct values), the border (end-points of the expected range), and the invalid (incorrect values) ones;
how to test inputs with the help of the if statements and update your testing code using the while loops and the try-except blocks;
the methods that can be used for string testing — str.isdigit(), str.isalpha(), str.isnumeric(), str.isalnum(), str.isupper() and str.islower().

Of course, these methods are the basic ones. For instance, you can process inputs with the help of regular expressions. You can find out more about them in our topic on regular expressions.
"
196,Argparse module,1074,11389,1237,https://hyperskill.org/learn/step/11389,"If you're writing a user-friendly program, one way to make it more universal is to use the command line and let users specify all the necessary parameters and their values themselves. Thus you can design a program capable of taking different numbers (a calculator, for example) or a path to a file, as is often required. Then the user won't need to go inside the script trying to find where and what should be replaced.
The argparse is one of the modules that let you do that. It allows you to pass the arguments through the command line and also assign names to them, use them as “flags”, automatically generate messages for users, and do a lot of other cool things we will get to a bit later.
We will write a script called recipe_book.py as an example that takes up to five ingredients and prints a recipe of a dish you can cook with the provided ingredients.
Getting started with argparse
The first thing is to import the module:
The next step is to create an ArgumentParser object which will store all the information about the arguments:
The ArgumentParser is a class. In Python, classes are used to define the data and the behaviors of similar objects. The ArgumentParser has quite a number of parameters that you can specify, but we only invoked description which is quite handy in order to explain to a user what your program is for in general. Now let's add some arguments.
Adding arguments
To do that, we will use the add_argument() method:
We also need to note the difference between the optional and the positional arguments. When parsing, if an argument has a dash - or a double dash -- prefix, it'll be treated as optional. Let's take a closer look at the first line of the code in the example above. With optional arguments, traditionally, a single dash - denotes a short version of a name (usually consisting of only one letter), while a double dash -- is used for a full argument name. When specifying this argument from the command line, you can use either of these variants. Since positional arguments are used without a prefix before them, they can have only one name.
The add_argument() has a lot of useful parameters, but we are going to look at the most commonly-used ones. For example, the parameter “action” is responsible for what should be done with a command-line argument. By default, it just stores the value passed to the argument, though it's not the only option.
Since pretty much everybody has some salt in their kitchen, we'll assume that our users always have salt on hand. So, instead of making users specify salt as one of the numbered ingredients, we'll let them toggle its presence in the recipe with a simple flag. In the example above, we have done so by setting the action to the “store_true”. It is used to assign boolean values to the corresponding arguments. The salt value will be False by default but if the user lists --salt among the arguments, the value will be changed to True. There's also an opposite option, store_false: the argument's default value will be True, but it will be made False if the argument is listed.
For action = ""store_false"": the default value is True. For action = ""store_true"": the default value is False.
The same can be achieved by specifying the default parameter:
This time the argument isn't used as a flag any more, so, if you'd like to change the value, you will have to define it in the command line explicitly: --pepper ""True"".
Finally, since we're only at the beginning of the development process of our program, it might be useful to limit the choice of each ingredient to only those used in our recipes. This can be done with the choices parameter that will show the acceptable values for a particular argument:
Another useful parameter you see here is help. It contains a brief description of an argument and also allows you to guide a user in their work with a script.
Parsing arguments
The parse_args() method is used for reading argument strings from the command line:
Now we can access the values specified by a user as attributes of the args. The long versions are used as attribute names:
Note that we can't use short versions of arguments: for example, args.i2 will not work.

In case a user didn't specify an optional argument in the command line, the value is set toNone by default:
So far, the code of our program in the “recipe_book.py” module looks as follows:
How do you actually use that in the command line?
Now let's see what it looks like from the user's perspective. Here's a sample call of our program from the command line:
What's important to note here is that the format argument value and argument=value are equivalent:
However, if a user tries to use an option which is not given in the choices parameter, it will raise an error:
Note that the first thing displayed is the 'usage' of our program. We did not specify it ourselves when creating the argument parser, so it was generated automatically from the parser's arguments. In the 'usage', we can see that the value 'bread' is not supported by our program, and the error message also explains this fact.
Remember the help parameter we discussed earlier? When a user specifies --help or -h as an argument in the command line, the description for each argument is displayed:
Again, first we see the 'usage' of our program, then, there's the description we wrote, and, finally, the list of all arguments.
Summary
In this topic, we briefly familiarized ourselves with Python argparse module. There are three main steps to get the job done: first, create the ArgumentParser object; then, add arguments with add_argument() method; finally, parse them with the parse_args() method and use them in your program. Since what we discussed here is more of a review than a full description, it's definitely worth reading the argparse section in the official docs for more details, especially to learn about different parameter options you can use in your program.
"
197,Set operations,744,8991,1251,https://hyperskill.org/learn/step/8991,"One of the main features of sets is that they allow you to perform mathematical set operations, such as intersection and union. That is, if you have two or more sets, you can use special methods to see which objects are contained within each of these sets, or objects present in one of them but not in the other, or get the total set of objects contained in every set at hand. Why not learn more about this useful set functionality?

Union
Before we start, it must be said that you can perform each set operation in two ways: by using an operator or by calling a method. So, first, let's see how it works with the simplest operation — union. When you perform a union on two sets, you get a new set that comprises all the elements of the initial sets. The set method for this is (quite obviously) referred to as union, and it should be called as a method of one of your sets that accepts another set as an argument: A.union(B). Here is an example:

You can do the same by means of the operator |, the syntax for which is more straightforward. You simply put the operator between your sets, just like that: A | B.

You can also unite sets without creating a whole new set — just by adding all the elements from one set to another one. The operator for that is |= (A |= B) and the method is called update. Check this out:

Now, what other set operations do we have?
Intersection
Intersection allows you to get only the objects that are present in each set. So, by calling the method intersection or by using the operator & in the same manner as for union, you can see what your sets have in common.

In order to delete from the first set all the elements that are absent in the second set and leave only the elements that both sets contain, you can use the operator &= or the method intersection_update.

You can probably guess the next operation we're going to tackle!
Difference
Difference operation is equal to the simple subtraction of sets: as a result, you'll get a set containing all the unique elements of the initial set. The name of the method, difference, is as predictable as the operator -.

Similarly to previous operations, to remove from your set all the elements present in the second set without creating a new collection, you can address the difference_update method or the operator -=.

So far so good! Though, we still haven't mentioned a couple of details you may find important.
Methods and operators: what's the difference?
Mind that syntax is not the only difference between using a set operation method and an operator. More importantly, a set operator requires both arguments to be sets, while the method only demands this from the first one — while the second argument can be any iterable object, for example, a list or a string. In this case, the method will create a set out of the second argument implicitly (that is, by itself, without your interference).

Also, sometimes it happens that you don't have specific variables for each of your sets, for example, you store them all in some container. How do you quickly find an intersection or a union of all these nameless sets? With the help of the operation set method and the asterisk (*) operator (it is used to ""unpack"" containers; let's not go into details of this operator now, though): set.method(*list_of_sets). Watch this:

So, now when you know all this, set operations will faithfully serve you!

Do not forget about frozenset — this data type also supports all of the above operations.

Summary
Let's sum it up:

you can perform union, intersection and difference operations on sets,
each operation has two versions: one of them returns a new set and another updates the existing one,
there are two ways of calling each operation: by method and by operator.
"
198,Lambda functions,523,7092,1290,https://hyperskill.org/learn/step/7092,"In programming, it's often useful to know alternative ways to implement something. It not only shows your knowledge and creative analytical thinking, sometimes one implementation just fits better for some reason like the time it takes to execute or memory it needs. Also, as you probably know already, that reason is often the number of lines of code. So, in this topic, we'll learn a great alternative to small functions!
Defining a lambda function
Imagine that you want to write a function that takes a number and doubles it. If you already know how to define functions in Python using the def keyword, you will probably write something like this:
Well, there is actually another way to define such small functions in Python using the lambda keyword. The following function is completely equivalent to the one defined above:
This function doesn't have a name and is, therefore, called anonymous. Since in Python anonymous functions are declared with the lambda keyword, they are often referred to as lambda functions.
Let's take a look at the syntax in its general form:
A lambda function can take any number of arguments separated by commas, but it must consist of a single expression. This expression is evaluated and the result is returned. Note that you do not need the return statement here. For example, the following anonymous function computes the remainder of the division of the sum of two numbers by two:
In case you want to put a condition in some lambda function, you'll have to use the so-called ternary operator first_alternative if condition else second_alternative:
Classic conditional statements will not work within a lambda function.
Invoking a lambda function
Alright, but how do we call such a function if it does not have a name?
Python syntax allows us to do so by enclosing the function in brackets and passing arguments right away:
Alternatively, it is also possible to assign a function object to a variable:
However, assigning an anonymous function does not comply with the official style guidelines. It's reasonable to declare your function explicitly with the def keyword in case you want it to have a name.
When is it useful?
You might have noticed already that the function from our example above is fully equivalent to a 'normal' function defined as follows:
But if we can always use a normal function instead, why are lambda functions useful? 
Well, lambda functions are handy, for example, when you use them in combination with another function. Take a look at the following example:
The function create_function takes one argument, number n, and returns a function that multiplies any given number x by that n. You can use it further in your program to quickly define a bunch of functions, for example:
As you can see, the functions doubler() and tripler() are designed rather uniformly: they take a single argument and return it multiplied by 2 and 3 respectively. Thus, lambda functions can be embedded into a larger function, like create_function() in our example.
Summary
Let's go over the main points we discussed:

Anonymous functions are functions defined without a name.

You can use the lambda keyword to define anonymous functions in Python.

A lambda function can only contain a single expression.

Lambda functions are particularly handy for one-time use, or when combined with other functions.
"
199,Map and filter,634,8122,1291,https://hyperskill.org/learn/step/8122,"Functional programming is a programming paradigm that treats computation as the evaluation of mathematical functions. Even though Python isn't a purely functional language, it implements some functional programming functionality, for example, lambda functions that you are already familiar with. In this topic, you will learn about other useful functional programming tools: map() and filter().

map( )
Suppose you have a list containing some numbers:
numbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Imagine you now want to obtain a new list that contains the numbers from the list above multiplied by 2. 
You can of course always pass the numbers one by one and collect the output in a for loop:
doubled_numbers = [2*n for n in numbers]

print(doubled_numbers)
# The output is [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
However, there exists another way to do so with the help of the built-in map() function. Let's take a look at its syntax:
map(function, iterable)
map() takes a function object and a list (or any other iterable, e.g., an array or a dictionary). The function is then applied to each element of that list, and an iterator is returned. You can explicitly convert it to a list using the list() function to see the result.
So the code from the example above can be re-written as follows:
def doubler(x):
    return 2*x

doubled_numbers = map(doubler, numbers)

print(list(doubled_numbers))
# Outputs [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
Note that we can always combine map() with lambda functions:
doubled_numbers = map(lambda x: 2*x, numbers)

print(list(doubled_numbers))
# Outputs [0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
map() comes in handy when a function you want to apply several times takes multiple arguments. In that case, you can simply pass more than one list to map(). The values for each argument will be then taken from the corresponding list.
The code below, for example, computes the sum of three lists:
x_list = [1, 2, 3] 
y_list = [4, 5, 6]
z_list = [7, 8, 9] 

s = list(map(lambda x, y, z: x + y + z, x_list, y_list, z_list))

print(s)
# The output is [12, 15, 18]
Here is its visualization for better understanding.
filter( )
Let's continue working with our list of numbers from 0 to 9:
numbers = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
Imagine now that you want to obtain yet another list which contains only the odd numbers from the list above.
To that end, the built-in filter() function comes in handy.
filter() takes a Boolean function, i.e., a function that returns True or False, along with a list, and constructs a new iterator from the elements of the list for which the function returns True. This iterator can be then converted to a list. The syntax is as follows:
filter(boolean_function, iterable)
Thus, we can collect all the odd numbers from our list in the following way:
odd_numbers = filter(lambda x: x % 2, numbers)

print(list(odd_numbers))
# The output is [1, 3, 5, 7, 9]
As you might have already noticed, you can do the same thing using a list comprehension:
odd_numbers = [n for n in numbers if n % 2]

print(odd_numbers)
# Also outputs [1, 3, 5, 7, 9]
 
map( ) and filter( ) or list comprehension: what should I choose?
As you have probably noticed while reading this material, map() and filter() can always be replaced by list comprehensions. So, what should be preferred? 
Even though Python implements the functional programming functionality such as  map() and filter(), it isn't a functional programming language. Therefore, many developers argue that more 'pythonic' ways should be preferred where possible. Also, some programmers find list comprehensions more readable and easy to understand.
At the same time, under some conditions, map() and filter() can be faster than list comprehensions, so it's definitely worth keeping them in mind.
Summary

map() and filter() come from the functional programming paradigm.
map() evaluates some function on multiple parameter values in an iterable.
filter() finds a subset of elements of a list that satisfy some condition.
map() and filter() can be replaced with list comprehensions. However, sometimes they can be more computationally efficient.
"
200,Basic UPDATE statement,766,9067,1304,https://hyperskill.org/learn/step/9067,"Typically, we don’t just store data: we need it to reflect the current state of things in real life as closely as possible. One can get a promotion at work, so their title needs to be changed. You can buy a gift for your friend and the amount of money in your bank account has to be adjusted accordingly. For cases like these, SQL has a special operation that helps to change values in cells of the already existing rows – UPDATE.

General form
What information is necessary for making an update? Name of a table where we want to change data, column name(s) where the data resides and an expression to calculate a new value for each specified column:

""Column name-expression"" pairs are separated by commas. Generally, it is allowed to use any valid SQL expression. You can type a correct combination of literals, operators, functions and column references here, just remember about type consistency; trying to update an integer column with a text is never a good idea.

Imagine that you work as a developer for ABC Industries Ltd. The company has a lot of data and uses SQL to work with it. Information about their personnel is stored in a table named employees. For each employee there is a department id (integer), their last name (text), their salary (integer) and its upper limit (integer):

If for some reason all workers need to be moved to department #14, we could write the following:

Since we used an integer value in the column department_id of integer type, the query is correct.
Here's what the table looks like after running the query:

Column references
As mentioned earlier, new values don’t have to be constant literals. Oftentimes, they are composed based on data that is already present in the table cells. Each column reference represents the current value stored in the corresponding row cell.
What if we want to celebrate such a massive change in the company's structure and give our employees a raise?
Absolute values won’t do here, so their current salaries should be used:

The addition of an integer value to an integer column produces a value of integer type as a result, which means that type consistency requirement is met.

Pay attention: during the execution of UPDATE, every row of a table is considered individually. If we want to use old value(s) to compute a new value for a cell, only cell(s) from the same row will be taken into account.

It’s possible to update multiple columns simultaneously, so we can achieve the same result using only one query instead of two:

Let’s try to come up with something more elaborate: set new salaries to 80 percent of their upper limits and omit the fractional part that might appear. For the last part of the requirement, we can use the floor() function that takes a real value and returns an integer value.

As you see, the update is a fairly simple operation, but in practice, it often comes in handy.
Summary
We've seen that updates are really helpful when we need to change some data in a table. All you need is to use the UPDATE ... SET syntax and specify the column name and the new data that you want to insert. It's also possible to update multiple columns and use any SQL functions.
Great! Speaking of practice: are you ready for some tasks?
"
201,How to read the documentation,1170,12125,1313,https://hyperskill.org/learn/step/12125,"Most programmers are used to googling an answer when they don't know how to do something or ask a question on a forum like Stack Overflow. Sometimes, on forums, you can come across such an abbreviation as RTFM. It has slightly different meanings, but we will focus on ""Read the following manual"". It speaks for itself, doesn't it? If you see such an answer, it means that the question could have been answered by reading the corresponding manual or documentation.
Reading the documentation is, indeed, an essential skill for a programmer. To understand why it is so, let's consider several points:

The official documentation is the most truthful and complete source.
It contains up-to-date information for the latest versions.
The same code can be written in different ways, but the documentation contains the best practices.

These reasons should already be enough for you to open up to the documentation and hope that it will open up to you!
Main source of documentation
Of course, Python has its own complete and up-to-date official documentation! Let's take a look at the site header:

By default, we see the latest version of Python, but you can find documentation for older versions as well. For convenience, you can also select another available language or use the Quick Search field to find the information you need.
Below you can see parts of the documentation. Let's take a quick look at some that are important to us:

Tutorial is the one to start with when discovering the Python world.
Library Reference provides more detailed information on how Python works and what features it has. In this section, you will spend most of your time as a Python programmer.
Python Setup and Usage contains tips on how to install and configure Python environment on different platforms.
Python HOWTOs are various guides on specific topics.

You can also download the documentation in a format convenient for you on the download page.
The docs contain a lot of information, but don't be afraid, you don't have to read everything at once. The main thing is to learn to find answers to your questions.
Official Python documentation
The best way to learn something is to try it yourself, so let's refer to the documentation of the math module as an example. We suggest that you open it and take a look at it yourself first. Below we describe what you can find there.
First of all, documentation tells us what a particular module is used for:
This module provides access to the mathematical functions defined by the C standard.
And also about various restrictions:
These functions cannot be used with complex numbers...
For each function from this module, you can find a description of what it does and what value you get as a result. Consider the math.fabs(x) function:

Moreover, the documentation will indicate which errors we may encounter when calling the function with invalid arguments.
Also, there are often some sections that are specific to the module itself. In math, for example, ""Constants"" is such a section and it contains a list of all constant values defined in the module, as the one below:

Finally, in the See also section at the very end you can find alternatives or additional information:

 

If you need to quickly find information about a specific module, function, and so on, use the page search in the browser (Ctrl + F, or ⌘ + F on Mac)
 
Documentation of third-party libraries
In addition to the standard libraries that come with the default Python installation, there are also third-party libraries. They are developed by third-party programmers (hence the name) and serve a specific purpose. Therefore, another source of information that you will often come across is the documentation of third-party libraries. 
Let's consider the documentation for one of such libraries — Colorama, which ""makes ANSI escape character sequences (for producing colored terminal text and cursor positioning) work under MS Windows"". As we can see, just as the official documentation, it starts with a short description of what the library is used for.
Also, you will find information on how to install a third-party library:


and examples of what you get as a result (follow the link and see for yourself!).
Then, the documentation will always contain examples of how to use the library in various cases illustrating its capabilities. We will not show it here, but you can see it yourself in the Colorama documentation.
In order to get used to the documentation, you can familiarize yourself with its structure using examples of some other third-party libraries: Matplotlib, SymPy, PrettyTable, BeautifulSoup. Not all of them may be clear to you yet, but it's okay! In programming, you often have to face new things. However, all of them usually consist of the same parts: a short summary of what the library is used for, installation guidelines, and a list of functions with descriptions and usage examples.
 

Note that documentation of third-party libraries is not always full and up-to-date. It is written by the developers themselves, so keep that in mind.
 
Some help()
Often you need to get information while writing code, and Python has a built-in help system for such cases, allowing you to get a quick reference about an object. To do this, you need to call the help() function and pass an object as an argument. For example, it can be a function:
Note that the function in such a case is written without parentheses.
Now, let's try to get brief documentation about the sqrt() function from the math module:
The thing is, you should either import the module first:
or pass the name of the object in quotes like this: help('math.sqrt').
All in all, it is a convenient method to get short info about the usage of an object without searching for its documentation on the Internet.
Conclusion
Remember that just reading the documentation from the beginning to the end will not turn you into a good programmer. The most important thing is practice, and practice makes perfect. Documentation is just an instrument, but still, it's important to know how to use it.
Hyperskill tries to answer all the questions it poses, but it also encourages learners to look for additional information outside the platform if they want to know more. Documentation is the first assistant in this matter. After this topic, we hope you are ready to search for some additional information in the documentation.
"
202,Random module,448,6263,1314,https://hyperskill.org/learn/step/6263,"Sometimes it happens that we lack data and need to make up a bunch of new examples rather quickly. Of course, you can spend some time writing those examples yourself, but it's not so efficient, right? It would make more sense to shift the responsibility to your computer, namely, the Python's built-in module random. In this module, a random search is used to generate elements and is performed using an algorithm whose starting point is a seed. The seed allows us to save the current state, making it easy to reproduce the same numbers on several code executions. Therefore, the results given aren't random at all and, technically, this module should have been called pseudo-random. Nevertheless, it may be useful for a large number of applications, such as modeling and simulation.

Random method: first steps

After we've managed to do the previous task, it's possible to try the random.random() function that will provide us with a pseudo-random number from 0 to 1:

We can also control the pseudo-random behavior by specifying the seed manually, i.e. configure the new sequence of pseudo-random numbers using the random.seed(x) function. You can set your own number or omit the optional argument x and consequently current system time would be used by default.

Now try to set the x argument. Haven't you noticed the change of the result? If you choose 5, you'll get 0.6229016948897019 as a result, if 20 – 0.9056396761745207, etc. Thus, the seed controls the behavior of pseudo-random in Python and can be used with any other function of the random module.

Random basic functions

Moving forward, other useful functions are:

random.uniform(a, b) – returns a pseudo-random float number in the range between a and b:

random.randint(a, b) – returns a pseudo-random integer number in the range between a and b. Note that the last element of the range is included too (in contrast to range())!

random.choice(seq)– returns a pseudo-random element from non-empty sequences:

random.randrange(a, b, c) – returns a pseudo-random number from a range between a (inclusive) and b (exclusive) with a step c. The latter argument allows you to generate random numbers by a given step. In the example below, given the step 5, the function can output any number from 3, 8, ... 98. What is more, just like with the range() function, the start and step arguments may be omitted with the default values 0 and 1 respectively. It means that the function can take one, two, or three parameters:

random.shuffle(seq) – shuffles a sequence. Attention: it doesn't work with immutable datatypes! Mind that after applying this function we print the list itself, not random.shuffle(tiny_list) since it will result in None.

random.sample(population, k)– returns a pseudo-random k length list from a population sequence. This function is used for random sampling without replacement:

Furthermore, there are plenty of other functions that are used in common mathematical practice, e.g. random.gammavariate(alpha, beta) that is used for gamma distribution or random.gauss(mu, sigma) that returns the Gaussian distribution. If you need such a narrow-specialized function, you can consult the Python documentation.

The pseudo-random generators of the random module should NOT be used for security purposes. If you are intending to work with passwords, security tokens and other sensitive data, check out the secrets module. It's considered more reliable since it generates secure random numbers.

Summary

To sum up, in this topic, we've looked closely at random module from a Python standard library and its basic functionality. Now you can use it in your projects yourself!
"
203,Math functions,447,6256,1316,https://hyperskill.org/learn/step/6256,"We already learned how to perform basic arithmetics in Python. We covered addition, subtraction, multiplication, division and several other built-in operations. But if we want to do more complex operations on numbers we can use built-in mathematical functions or functions from the math module.
math module provides useful mathematical functions and constants. This module is available on every platform in the standard library, you just need to import it with the import statement.
Advanced arithmetics
There are built-in functions abs, round, pow, max and min:

abs(x) returns the absolute value of x (i.e. value without a regard to its sign);
round(x, ndigits) returns x rounded to ndigits number of decimal part digits;
pow(x, y) returns x raised to the power of y;
max(a, b, c, ...) returns the largest argument;
min(a, b, c, ...) returns the smallest argument.

abs() and pow() functions have equivalents in the math module. The key difference of math.fabs() and math.pow() is that they always return floats:
Remember that in order to use definitions from math, you should import the module first.
Suppose you raised x to the power y, and then forgot y. You can recover it using the math.log() function:
math.log(pow, x) returns z such that x raised to the power z equals pow. If the second argument x (called the base of the logarithm) is omitted, it is considered equal to a special number e (approximately 2.718):
Besides the round() function, we can use floor() and ceil() from the math module to obtain integer values from floats:

math.floor(a) returns the nearest integer less than or equal to a;
math.ceil(a) returns the nearest integer greater than or equal to a.

The math module also provides the sqrt function to calculate the square root of a number.

Geometry
The number \(\pi\) is often used in geometry and other mathematical fields. It is the ratio of the circumference of a circle to its diameter. It can be found in the math module as pi.
The next example shows how to calculate the circumference of a circle:
There are also common trigonometric functions available in the math module:

math.cos(a) returns the cosine of a radians;
math.sin(a) returns the sine of a radians;
math.degrees(a) returns angle a converted from radians to degrees;
math.radians(a) returns angle a converted from degrees to radians.

As you can see, due to a limited precision of floats the value of degrees is actually 59.99999999999999 instead of expected 60.0.
It is impossible to cover all the math module in this topic so you can learn more from its documentation.
The volume of a cylinder
Let's assume we have a cylinder with the height h = 5 and the radius of the base r = 3. The formula for the volume of a cylinder is \(V = \pi r^2 h\). This is how we can calculate the volume using Python:

In the code above, we used the round function to get a prettier value for printing.
Summary
In this topic, we've learned several new advanced arithmetic operations, familiarized ourselves with arithmetics and geometry in math module, and calculated the volume of a cylinder. As you can see, it is possible to round a number or find a maximum value in Python using just built-in functions. However, now you can use functions from the math module for more advanced tasks.
"
204,Float special values,720,8804,1318,https://hyperskill.org/learn/step/8804,"When thinking about numbers, we tend to imagine something practical and specific, rather than abstract. The first thought might be to count things: how old are we, how many animal species are there on our planet and how many stars in the sky. It comes naturally to our minds, that's why we put the label natural on those numbers. Yet, there's more to the picture. Counting is not the only thing we are good at. For example, we can measure physical quantities to explore the world around us. These real-life challenges are better described by real numbers. As you know, floats represent real numbers in Python, but they have more to offer. Today we will discuss some abstract concepts and find out in what respect the Python floats have gone beyond the real number line.
What is infinity?
The concept of infinity might be somewhat difficult to perceive. Let's try to visualize it! We can take our galaxy for starters. Is the Milky Way big enough? Until about 100 years ago, you might have thought so, but the answer is different now (here is a timeline to consult with). So what comes next: two galaxies, a galactic cluster, the universe, the multiverse? Let's stop right there and highlight the pattern of such reasoning.
When we call something infinite what we basically mean is that it is always possible to add one more. No matter how large is the number we come up with, the infinite value will be greater than it. Say, we've picked a really large number n, well, there will always be n+1 and so on.
Infinity constants
In Python, infinity is a constant greater than any real number. This special value is denoted as inf. Where can you encounter it? For example, you intend to convert 10^3000 to float:
This number is too large to be represented, but you can still convert it to float if you pass it as a floating-point literal. The second line doesn't generate an overflow and returns inf instead, which is pleasant because you can work with it and perform further arithmetic operations.
If you want to experiment with an infinite value, there is a better way to obtain one. Just use floating-point literals again: either ""infinity"" or ""inf"". The case doesn't matter, what is more, your string may contain leading and trailing whitespace characters:
Infinity has a counterpart -inf. The negative infinity constant is less than any real number. You can get it just as easily:
The constants inf and -inf support basic arithmetic operations, as all floating-point numbers do:
Let us dwell on a few details. First, you can't have two infinities or double infinity. It's an ever-increasing value in case of inf, and sort of the ever-decreasing one when it comes to -inf. Both constants are part of the floating-point arithmetic system, so its rules will generally apply. In case of addition, multiplication or subtraction, you are likely to get infinity (the sign depends).
The division examples may also prompt some questions. In Python, division by zero always raises ZeroDivisionError, however, in other programming languages, you can get away with this if at least one of the operands is a real number.
In real-world tasks, inf and -inf can be used for comparisons. They can be used to optimize algorithms and find the lowest and the highest values in some list of values, for example, the lowest cost.
Now, we need to clarify nan, to which we devote the next section.
Meet NaN
Floating-point numbers include another special value called NaN, which stands for Not a Number. NaN is not equal to any floating-point number (including itself and ±inf). The idea behind NaN is that forbidden arithmetic operations still need a value to return. Here is an example:

As you are well aware, multiplication by zero results in zero. The NaN value is even more contagious: most arithmetic operations on it return NaN. However, a counter-example is NaN ** 0, it produces 1.0.

The systematic use of NaN and infinity constants was introduced by the IEEE 754 standard in 1985. IEEE 754 specified how numeric values should be represented in computer hardware and addressed many issues found in diverse floating-point implementations.

NaN vs None
Although, the constants NaN and None sound similar, there is a difference between them. None is a singleton object that denotes no value at all. None evaluates to False in boolean expressions, while NaN doesn't. As opposed to None, NaN is different in every given case, it never equals to itself: you should consider NaN != NaN true.
The real-world application of NaN is related to the lack of numerical data. Missing values crop up in datasets due to numerous reasons. When the data is insufficient, NaN is commonly used to substitute missing floating-point values. Try not to mistake it for None.
math.isnan()
Since the equality test NaN == NaN doesn't work as intended, you might wonder how to test for NaN values. There is a solution in the standard library. The function isnan(x) from the math module determines whether x is a floating-point ""not a number"" value.

The function returns True only when its argument is NaN.
math.isinf()
The math module also provides a function isinf() to check for an infinity value (either positive or negative).

As seen from the example, math.isinf() works for both inf and -inf and returns a boolean value.
math.isfinite()
The function math.isfinite(x) returns True if x is neither an infinity value nor a NaN, and False otherwise.

math.isfinite() helps find the floating-point numbers distinct from the special values.

Similar functions can be found at other resources. For example, the library for scientific computing NumPy provides the following functions: isinf, isposinf, isneginf, isnan and isfinite. We recommend that you use some of the mentioned functions, for they are more likely to return the up-to-standard result.

Summary
Let's go over the main points:

Python floats include the special values inf, -inf and nan.
The inf constant is greater than any real number. To create it, use float(""inf"") or math.inf. Its main use case is comparisons.
The -inf constant is less than any floating-point number. You can obtain it via float(""-inf"") or -math.inf. It has the same application as inf.
The nan constant stands for ""not a number"" and is not equal to any float. You can encounter nan when dealing with data analysis. It often indicates missing floating-point values in the dataframes. Use float(""nan"") or math.nan to get it.
The math module has functions designed for special value tests: math.isinf(), math.isnan(), math.isfinite().
"
205,Updating selected rows,862,9603,1320,https://hyperskill.org/learn/step/9603,"Being able to change data in all rows of a table is impressive, but in reality, it rarely comes up. Having to update a few rows happens much more often. Filtering out rows we are not interested in can be done with the WHERE clause.

WHERE clause

As usual, a logical expression in the WHERE clause can combine several simple expressions. The only requirement is the following: an expression must produce a BOOLEAN value for each row of a table. Only those rows for which the expression produces TRUE will be updated.

For example, imagine that there is a table named groups. This table stores information about the existing student groups in North-Western County college:

Due to the recent policy update from the college administration, the number of students in all groups taking algebra has to be cut to 40. At the same time, Ms. Gibbs realizes that her literature course is more popular than she thought, so she would like to increase the number of students taking her course up to 40. Let's reflect these changes in the table:

WHERE clause doesn't change a lot in the basic template for UPDATE queries but plays a crucial role. You don't want to introduce unnecessary changes in your data and have to fix them after. As a first step of composing your query, think about which exact rows need to be updated and write the WHERE part; after that, feel free to change the data any way you want.

Conclusion

Using WHERE in the UPDATE operation is easy: it follows the same principle here as it does in other SQL operations. Now it's time to check your knowledge.
"
206,The string module,1601,15332,1321,https://hyperskill.org/learn/step/15332,"At this point, you have already heard about Python strings and probably gained some experience using them. However, the Python standard library also has the string module that offers additional tools to work with strings. One way or another, programmers interact with strings rather often, so let's expand our knowledge about this Python domain using the string module.

Constants
Since string is a module, we need to import it first:

The first tool we are going to look at is the string constants. They are basically strings that contain a certain type of characters — punctuation marks, digits, uppercase English alphabet, and so on. The string module employs ASCII characters only. ASCII (American Standard Code for Information Interchange) is one of the character encoding standards used in electronics.

Below is a table with the names and contents of every string module constant:

NameDescriptionContentsstring.ascii_lowercasethe lowercase English alphabetabcdefghijklmnopqrstuvwxyzstring.ascii_uppercasethe uppercase English alphabetABCDEFGHIJKLMNOPQRSTUVWXYZstring.ascii_lettersthe concatenation of ascii_lowercase and ascii_uppercaseabcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZstring.digitsnumbers from 0 to 90123456789string.octdigitsdigits used in the octal number system that can represent any number with 8 digits01234567string.hexdigitsdigits used in the hexadecimal number system that can represent any number with 16 digits0123456789abcdefABCDEFstring.punctuationa set of characters for punctuation marks!""#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~string.printablethe printable Python ASCII characters – digits, ascii_letters, punctuation, and whitespace0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!""#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~ \t\n\r\x0b\x0cstring.whitespacethe whitespace ASCII characters – a space, a tab, a linefeed, a return, a formfeed, and a vertical tab'\t\n\r\x0b\x0c

We can access them with a simple command:

You can use these constants to check whether a character of interest belongs to one of the groups above, to remove or add the characters from your strings, or to distinguish them in someone else's code. Let's say you've written a calculator and want to test if the input contains only digits. To do that, you can use a membership operator in that will return a boolean value True if your item is in the sequence or False if otherwise:

The helper function
There is only one helper function in the module: string.capwords(s, sep). It capitalizes each word in a string. You can also provide your own separator; the default value is a space:

What is considered a ""word"" depends on the separator — it may be everything in between:

In the first case, the separator is a comma, so each piece of text between the commas is capitalized. In the second case, the separator is a space, so there's only one ""word"" that is capitalized.

Formatting
The string module also offers a few advanced ways to format string. For instance, you can customize your own string with the built-in Formatter class. The ability to change the default way of formatting is very useful but quite specific, so we won't consider these things in the topic, but you're more than welcome to learn about them yourself. 
Anyway, we will take a look at template strings. They are another tool for string formatting. As the name suggests, it can create string templates to fill them in later:

Pretty convenient, right? You can use them if you want to generate the same string with a couple of differences, for example, for greetings.

Conclusion
In this topic, we have learned a little more about Python strings by investigating the string module from the standard Python library. It has predefined string constants with groups of characters that can be used for membership tests. It contains the string.capwords() function that capitalizes each word in a string which can be beneficial sometimes. And, finally, this module suggests several advanced ways to string formatting. Hopefully, you'll find this new information useful in practice. Speaking of which, let's resolve some challenges! 
Read more on this topic in Working with Python Strings on Hyperskill Blog.
"
207,Profiling in Python,1882,17427,1323,https://hyperskill.org/learn/step/17427,"Today, you've decided to finish an elaborate program. The code is almost finished; you've started the initial testing, but the program doesn't perform as fast as you've expected. ""Why does it take this long and occupy so many resources?"" you wonder. The answer is simple if you start looking in the right direction.

To improve the performance of your code, you need to analyze and measure the metrics of interest. This analysis is also called profiling. Profiling a Python program means a dynamic analysis that measures the execution time of each function. This may give you some insights into possible optimization.

At first glance, it may seem obvious where your code is struggling, but if you don’t profile, it could be difficult to pinpoint the bottlenecks. Lucky for us, Python provides many great modules to measure the program statistics.

The time module

To profile your code, you need to know how to clock the time. You can use a timer for this:

Timers are easy to implement. However, using a timer on any function shows us the run time of that specific function only. If you want to use this approach for finding the bottlenecks, you need more information. You need to account for the following points to carry out efficient profiling:

We should know the total run time of the program to have a better picture of the relative function run time. For example, if a function takes three minutes to execute, does that represent 5%, 15%, or 60% of the total run time?

We should understand what we're trying to achieve to label a piece of code as a bottleneck. Even if a function takes 10 minutes to run, we should worry about its inefficiency only, provided we are confident that other parts are OK.

A profiler package like cProfile can help us find the bottlenecks in our code.

Profiling with cProfile.run()

cProfile is a deterministic profiler for Python and is recommended for most users, as the official documentation states. In general terms, it creates a set of statistics that displays the total time spent in certain parts of the code and how often the portion of the code was called.

cProfile is written in C as a Python extension and a built-in module. It doesn’t affect the amount of time much. The cProfile module provides a simple run() function that is sufficient for most cases. All you need to do is to pass what you want to profile as a string statement to run(). Let's take a look at an example of profiling the recursive algorithm for the Fibonacci sequence and gather some information on the algorithm performance:

As you can see, the profiler has recorded information on our function. Let us see how we can interpret it:

Headers  Description
ncallsThe number of calls. We should try to optimize the functions that have a lot of calls or take too much time per call.
tottimeThe total time spent in the function, excluding the time taken to call sub-functions. This column is crucial for us. We can see that the fib_recursive function is called 2692537 times, with a total time of 1.321 sec.
cumtimeThe cumulative time. In other words, it is the total time spent in the function plus the time spent in all sub-functions. As an example, imagine that our fib_recursive function is appended to a list; every number there is passed in as an argument. The time spent calling the append function would be stated here, not in tottime.
percallThere are two “per call” metrics. The first one is the total time per call, and the second one is the cumulative time per call.
filename: lineno (function)Provides data about the filename and the line number of each function.

Now, let us see another approach of the same Fibonacci sequence, but this time we use a list algorithm:

We can see a huge improvement in the number of calls per function, and the algorithm gets executed in no time. The recursive function in Python for Fibonacci numbers seems so easy until you try it for yourself and look at the profiler. The algorithms above are simple examples. Imagine a real-world scenario, where you need to create an algorithm that searches through an enormous amount of data. In this case, it is really important to have a good-performing algorithm.

Profile class in cProfile

cProfile.run() is sufficient in most cases, but if you need more control over profiling, use the Profile class in cProfile. Let's take a look at a for loop inside the fib_list function:

First, create an instance of the Profile class called profiler and collect the profiling data by calling the enable method. When you want to stop collecting the profiling data, call the disable method. After calling the function, we can simply print the results to the standard output by calling the print_stats() method. The resulting table will look similar to the one from the first example, but it won't contain unnecessary profiling information from other parts of our code.

Since it’s hard to tell where your program spends the time, you should start by profiling your entire program using the cProfile.run() function before narrowing it down to a single section. We can also format the collected statistics using the pstats.Stats class constructor to create an instance of the statistics object called stats and use a text stream to save the results. Don't forget to take a look at the official documentation.

The Stats class creates a statistics object from a profile object and prints the output to the stream that is passed to it, in our case, io.StringIO() is a text stream. The Stats class also has a sort_stats method that sorts the results based on the provided criteria. In this case, the criterion is SortKey.CUMULATIVE. As described in the official documentation, the sorting criteria can be in the form of a SortKey enum (added in Python 3.7) or a string (using cumulative instead of SortKey.CUMULATIVE is valid). After creating the results and printing them to the stream using the print_stats() method, you can print them to the standard output by calling the getvalue() method from our text stream.

Conclusion

In this topic, we've discussed the importance of code profiling and explained different approaches to it in Python:

Profiling with the time module is an easy way to measure the execution time of any part of a program;
cProfile.run() provides more detailed information like the total number of calls for each function or the total time spent in the function;
The profile class from cProfile is fit for more precise control over profiling.

There are a lot of other things to cover (such as external modules for profiling), but we're going to do it in other topics. For now, let's turn to practice!
"
208,The pprint module,1726,16213,1324,https://hyperskill.org/learn/step/16213,"For programmers, it's essential to see the output of the variables regardless of the programming language. Sometimes, however, the output in the console isn't what we expect. You may have faced this problem when you tried to output a dictionary or a list variable to the console. Lucky for us, there are libraries to format the output of our variables! We don't need to worry about many loops and prints to format the output. One of such libraries is pprint. This library is a native Python library that you will meet in this topic.

Printing data
To start using it, import it first. Don't get confused because the method and the library have the same name:

Then, we can use it as part of the usual print() method:

At least for now, you can spot no difference, except for the quotes. pprint retains quotes, while standard print does not. Also, the difference will be visible when you try to print more complex data structures such as lists or dictionaries.
Let's create a list with dictionaries inside and then print this list using the two methods:

If we use the common print() method, the whole list will be printed on one line. It makes it rather clunky:

If you refer to pprint(), each object will be printed on a new line:

Much better! You may also notice that the dictionary was sorted by the key name. This happens because, by default, the sort_dicts property is True; we will discuss this property later on.
Properties
The name of this library stands for Pretty Printer. It allows you to format output. In this topic, we will focus on the pprint method.
Let's take a look at some settings and their default values.
stream=None — use this property when you want to write the content to a file-like object.;indent=1 — number of spaces added for each nesting level (if it can't fit within the given width limit);width=80 — maximum number of characters that can be printed on each line. If the line exceeds this limit, the remaining characters will be printed on a new line;depth=None — maximum number of nesting levels that may be printed; anything beyond this level is replaced by ....;compact=False — this property affects how long sequences (lists, tuples, sets, etc) are formatted. If it's False, each item is placed on a separate line; otherwise, it tries to fit items within a given width limit.;sort_dicts=True — this property displays the key-value pairs of the dictionaries sorted by key.underscore_numbers=False — if this property is True, integers will be formatted with the _ character as a thousand separator. However, if it is set to false (the default), no underscores will be displayed.
Keep in mind that these default values will be reset each time you invoke the method. We will discuss how you can define a global configuration later in this topic.
Indent and width
Let's start with the indent. We will set the value to 2. Each object will be aligned by 2 spaces:

Let's say you have a small screen, or you are working with several windows. If you don't want to scroll the terminal to the end of the line to see the data, you can limit the line width using the width property:

Even if a key-value pair exceeds the line size limit, it will be kept on the same line.
Depth, sort_dicts, and compact
What if you don't want to display the owner list? You can set the depth to 2, so the maximum number of nested objects is only two. Since the list of owners is inside a dictionary that is inside a list, it will not be displayed:

You can see that the contents of the owner list are replaced with dots. The data structure is maintained, so you can easily identify the object type.
Earlier, we have discussed that dictionaries are sorted by key name by default. If you want to preserve the insertion order, you need to change this property to False:

sort_dicts has been first introduced in Python 3.8. If you try to use it in the previous version, it will raise the exception: TypeError: pprint() got an unexpected keyword argument 'sort_dicts'

The compact property is False by default. This property is best with lists, so let's create one:

If you print it as it is, this will be the result:

Each list has been printed on a new line. We can now work on visualization. However, if you want to compress the output, change the compact property to True, and the values will be compressed along the lines, as long as they do not exceed the width limit.
Let's see an example:

As you can see, everything is printed in two lines.
Setting a global configuration
If you don't want to set the properties every time you invoke the pprint method, you can import the PrettyPrinter class constructor and create an object with the desired settings. If you need to change some settings, you can change them in one place.
First, you need to import the constructor from the library:

Then, create an instance of this class with the settings you want:

Now, all you have to do is to call the pprint method from the object you've just created:

Conclusion
In this topic, you have learned about the pprint library and its purpose. You can now format the output of your data to print complex data structures without struggling to visualize them.You have also learned that you can use the pprint method and define the property each time you want to use it. You can also create an instance of the PrettyPrinter class and define the global settings for the method. If you are eager to learn more, you can always check out the Official Documentation.
"
209,os and os.path,3386,35533,1332,https://hyperskill.org/learn/step/35533,"Python comes with a wide range of built-in modules that further enhance its capabilities. One such module is the OS module, which provides functions for interacting with the operating system. This module offers a portable way of using operating system-dependent functionalities, like reading or writing to the file system. In this topic, you will learn more about the OS module, such as accessing and removing directories and files in the file system.
Also, another significant part of the OS module is os.path a submodule that includes various functions for manipulating file paths. It provides the necessary tools to extract information from file paths, split them into their components, and check the validity of the paths. 
Access
With os you can test whether the given path exists and learn whether it has special access rights. This functionality is implemented in the os.access(). Apart from the path, the function takes another argument, the mode value, which denotes an available way of operating or using a particular object on the system, e.g. reading or executing a file. We will cover all four possible mode values.
The mode os.F_OK is used to check the specified path for existence. If we create a new directory and want to make sure that it has been created successfully, we can simply write one line, similar to the one below:

The directory some_new_project returned the Boolean True value. We specified a relative path, but you can indicate the absolute one, too.
To learn about access rights, os.access() uses uid (the identifier of a user on the system) or gid (the identifier of a user group). So, we can figure out the permissions of a certain category to directories or files. Here, the available modes are:

os.R_OK to check for readability of the path (that is, the user has the permission to see the content of the file / directory);
os.W_OK to check the writability of the path (permission to write to the file / directory);
os.X_OK to check if the path contents can be executed.

In the example below, we specify the path to a plaintext file in course: and the result is a Boolean value. As you can see, the file is both writable and readable, but we cannot execute it, because it is a plaintext file.

Removing directories and files
We will look at two functions for deleting directories and files.

os.remove() deletes the specified file, the relative or the full path to which we pass as an argument.

os.rmdir() removes a single specified directory. Before using it, make sure that the directory you want to delete is empty. Otherwise, an OSError will be raised.

At this point, we will stop with the os. We will discuss the os.path functions in the two remaining sections.
Path components in os.path
os.path is mainly used for manipulating paths.  Different operating systems use different conventions for pathnames, so there are actually several versions of this module with the very same functionality: for example, posixpath for UNIX-style paths or ntpath for Windows paths. We can always import os and then use os.path instead of working with them separately, the functions will work the same way as in the modules suitable for a specific operating system.
We will start with four functions that allow us to manipulate the path components.

os.path.join() joins several given components to create a new pathname. For example, we can pass it as an argument to the os.makedirs() to create nested directories. The example below shows the output for Linux first and then for Windows:

os.path.split() splits a pathname into a tuple (head, tail), where tail is the very last component of the given pathname and head is everything else preceding this last component. The example below illustrates it for the UNIX-style path and then for the Windows-style one:

Based on the latter function, the os.path.dirname() returns the directory of the path (head).

Accordingly, os.path.basename() returns the tail, whether it is the file name or the name of another directory.

Path's validity
os.path also has several functions that allow us to check whether the given path is an absolute or a relative one; whether it refers to a file or directory. Below, we will list three examples of such functions.

os.path.isabs() simply checks if the path we pass to it is the absolute one; in this case it returns True:

os.path.isdir() checks whether the given path refers to a directory.

os.path.isfile(), on the contrary, checks whether the specified path refers to a file.

So far, in these two sections, we gave a small overview of the basic os.path functions.
Conclusion
In summary, the OS module in Python is a built-in module that allows programmers to interact with the operating system. In this topic, we looked at more functions of the OS module. The os.path submodule further enhances these capabilities by providing functions to manipulate and validate file paths. Understanding and utilizing the OS module and its os.path submodule can significantly simplify working with files and directories in Python. Whether you are developing a small script or a large application, the OS module is a key component in the Python programmer's toolkit.
"
210,Class vs instance,490,6677,1334,https://hyperskill.org/learn/step/6677,"By now, you already know that Python makes a distinction between class attributes and instance attributes. If you recall, class attributes are the ones shared by all instances of the class, while instance attributes are specific for each instance. Moreover, class attributes are defined within the class but outside any methods, and instance attributes are usually defined within methods, notably the __init__ method.
Now let's go over the difference between class attributes and instance attributes in more detail.
Changing attributes
This class has three class attributes, kind, n_pets, and pet_names, as well as three instance attributes, defined in the __init__ method, spec, name, and legs.
Let's create instances of that class and see how changing class or instance attributes works in Python:
We've created three instances of the class Pet that have the same class attributes and different instance attributes. Now, it would make sense to change the value of n_pets because we now have more than 0 pets. Since n_pets is an integer, which is an immutable type, we can change its value for the whole class only if we access it directly as a class attribute:
If we tried to change the value of n_pets via the instances it would not work as we wished:
Even though all instances have access to the class attribute, if those attributes are immutable, changing their value for one instance doesn't change them for the whole class.
The same would be with the attribute kind, since strings are also immutable in Python. If we change it for the object ben (since a goldfish is not a mammal), it would stay the same for other attributes (as it should):
In cases where there's a handful of unique objects that need to have a different value of the class variable, this is totally fine. However, if there're a lot of those objects, you should consider making this attribute an instance attribute!
The situation with the pet_names attribute is different. The pet_names attribute is a list and, therefore, mutable, so changes to it affect the whole class. See below:
If for some reason, we wanted the class attribute pet_names to store different values for different instances, we could do that by creating a new list instead of appending to the existing one:
But this doesn't seem very convenient or necessary: after all, this is a class attribute and the idea behind it is that it stores values common to all the instances. So, again, if you want some attribute to store unique values, make it an instance attribute!

Another way to look at this situation is in terms of (re)assignment. =, +=, and similar operators are assignment operators. When we try to modify the class attribute from the instance using these operators, we essentially create a new instance attribute for that particular object. This is why other instances and the class itself are unaffected by this change — because we assigned some value to a newly created ""instance attribute"". Adding a new element to the list with append, for example, is different because there is no reassignment happening, we just modify the existing list.

Like, for example, the variable legs. It is an instance attribute, even though it is not explicitly passed as an argument of the __init__ method. The default value is 4, but we can change it if we ever need to. That would be helpful for the object ben because the fish doesn't have legs (they do have fins, but let's save the question of whether a fin can be considered a leg in this context for another time). This is how we change the value of legs for the object ben:
And that's it! There are basically no tricky moments with changing instance attributes because, again, they affect just one object.
Adding attributes
In addition to changing attributes, we can also create attributes for the class or a particular instance. For example, we want to see the information about the species of all our pets. We then could write it in the class itself from the very beginning, or we could create a variable like this:
Another thing we could do is to create an attribute for a specific instance. For example, we want to remember the breed of the dog called Avocado. Breeds are usually relevant in the context of dogs (cats have breeds too, but they are not that different) so it makes sense that we would want only our dog to have that information:
Here we created an attribute breed for the object avocado and assigned the value corgi to it. Other instances of the class Pet as well as the class itself wouldn't have this attribute, so the following lines of code would cause an error:
Summary
In this topic, we've shown the differences in using class attributes and instance attributes.
Class attributes are used to store information available for all instances of the class, but using them may be tricky if we don't take into account the type of the variable.
So, in what cases would we want to use class attributes? Well, firstly, if we want to define default values for all objects. Secondly, to store necessary class-specific constants (mathematical ones, for example). And lastly, to keep tabs on the data of all objects like in the example with pet_names. You may want to have easy access to particular information of every instance of your class and in that case, you could use a mutable class attribute.

Remember that how the values of class attributes change depends on whether they are mutable or not. Take that into account when writing your program and operating the objects of the class!

Instance attributes, on the other hand, store information that is different for every instance, and it is obviously their main function. Changing and adding new instance attributes may only affect a single object, but still, pay attention to the alterations that you make.
We hope you now know the difference between class and instance attributes and that you'll use them successfully in your programs!
"
211,More built-in exceptions,3412,35730,1353,https://hyperskill.org/learn/step/35730,"In Python, various types of errors can occur during program execution. These errors are known as exceptions and are raised when certain conditions are not met or when unexpected situations arise. In this topic, we will explore some commonly encountered exceptions in Python, including ImportError, EOFError, NameError, and IndexError. Understanding these exceptions and their causes is crucial for writing robust and error-free Python code.

ImportError
The ImportError may occur if you import a non-existing function:

Or when a spelling mistake was made in the module name:

Note that in this case, the ModuleNotFoundError is a subclass of the ImportError. Why so? The module math exists in the first example, but there's no such function as square. In Python, there's no special error subclass for this situation, so a more general ImportError is raised. In the second example, however, we try to import the module that doesn't exist in Python, so the ModuleNotFoundError is raised.

Apart from checking the spelling, make sure that the module you want to import is installed. If you forgot to do so, it would not be available in your program, so Python will raise this error.

EOFError
Now let's discuss the EOFError which is raised when the input has no data to read. You can run into this error on the platform when, for instance, you have 2 integers as an input, one per line, but you call input() three times:

Then, the output of the tests can look like this:

You will not come across this problem often outside Hyperskill. When you get this error on Hyperskill, make sure that you read the input exactly as many times as it is stated in the task description.

NameError
Take a look at the following code:

The function print() is misspelled, so Python does not recognize it. The situation is the same when you mess up the variable names:

If you get this error, just make sure that all functions and variables are correctly spelled and refer to the existing objects.

IndexError
Finally, let's proceed to the IndexError.

The list in the example above contains the only element, but we try to get an element with the index equal to 1. Mind that indexing in lists starts with 0. That's why the IndexError is raised.

This is a very common mistake with lists. Check the indexes you are passing to your list with care and mind the number of values it has in total.

Summary
In conclusion, this topic has provided an overview of several important exceptions in Python. We have discussed how these exceptions can occur in different scenarios, such as working with files, importing modules, handling input, and accessing elements in lists. By understanding the specific causes and subclasses of these exceptions, developers can effectively troubleshoot and debug their code. It is essential to pay attention to details like spelling, correct function and variable names, and proper indexing to avoid these exceptions.
"
212,What is CSS,587,7678,1364,https://hyperskill.org/learn/step/7678,"Web pages written solely in HTML tend to look somewhat boring. They simply fail to draw attention to the content because visitors get lost in a bunch of elements without good design. Perhaps HyperText Markup Language alone was enough to entertain Internet users in the early '90s, but now they've grown pickier and harder to impress.

The first versions of the HTML standard did not provide any means to change the way information was presented. It relied entirely on the styles built into the browser. The urgent need to give sites personal designs prompted HTML to add ""enhanced tags"" which allowed for broader control over how the information was displayed. As a result, HTML code became difficult to understand because of the terrible mixture of logical and design tags.

To separate markup from design management, CSS was developed. This division made code simpler and cleaner, reducing the duplication of lines.

What is CSS

CSS (Cascading Style Sheets) is a language responsible for the visual presentation of documents written in HTML. CSS allows changing the colors of the elements, their height and width, the location of individual blocks, background images, and much more. CSS files are saved in .css format.

To date, the latest version of this technology is CSS3. It even has its own logo:

A web page made with CSS would be drastically different from the very same page created without it. See for yourself in the following example:

On the left is a screenshot of a web page written in HTML, on the right — in HTML and CSS.

Don't worry if the CSS code above seems unclear. It's simply here to demonstrate how CSS is written.

Here are a few more examples that demonstrate how using CSS for styling can make websites look more attractive and visually appealing.

Netflix homepage without CSS:
Netflix homepage with CSS:
Hyperskill homepage without CSS:
Hyperskill homepage with CSS:

The contrast is evident. It's hard to believe it's the same page, what a makeover!

Why use CSS

CSS got really popular, which makes a lot of sense when you think about all its benefits:

It makes HTML pages more beautiful.
It saves developers time. You can write a CSS file once and then connect it to several HTML pages.
Pages load faster. Instead of writing the same property to different HTML elements, it is enough to write one CSS rule and apply it to several elements at once. Less code means faster loading time!
It's compatible with multiple devices. Style sheets allow you to optimize content for more than one type of device. Using the same HTML document, you can present different versions of a website for computers, laptops, and smartphones.
Last but not least, it is supported by all the latest browsers.

Short History of CSS

The concept of cascading style sheets was proposed in 1994 by Håkon Wium Lie, a Norwegian scientist and IT specialist working for the W3C consortium at the time. The first version of CSS (CSS1) was published only as a recommendation in 1996. In that version, it is possible to control the size of the font and change its style to or from italic and bold. One could also draw frames around the blocks, change the background, change the colors of the text, align tables and images, and much more.

CSS2 was released in 1998. That version allowed you to control the location of elements on the page and set different styles for different media. For example, it became possible to display the same web page with an individual design for computers, printers, and mobile phones.

CSS3 appeared in June 1999. The main feature of CSS3 is the ability to create animated elements without using programming languages.

Conclusion

CSS is most often used as a tool to describe and design the appearance of web pages written using markup languages. CSS is a powerful tool, and it's frankly difficult to imagine modern websites without it. This technology can change the appearance of HTML pages for the better: after CSS touch-up they look magical. So, let's master this magic together!
"
213,HTML attributes id and class,552,7527,1365,https://hyperskill.org/learn/step/7527,"Creating web pages is neither rocket science, nor a piece of cake, so sometimes you might find yourself in pretty difficult situations. You may even start to think that there is no way out of them! For example, how do you change the style of one particular tag if there are hundreds of the same tag in the HTML markup of the web page? Or how do you apply the same style to a lot of different elements without having to duplicate the CSS code and wrap these elements in a new tag?

Fortunately, there are no problems without solutions. The two problems we brought up can easily confuse a beginner developer, but we will prove to you that sometimes difficult tasks have very simple solutions.

For more flexible management of the web page elements design there are HTML attributes id and class. They are needed to identify the elements. Let's take a look at the features of these attributes, see what they have in common, how they differ, and how to work with them.

id attribute

In order to work with a particular element when there are many similar ones, you need to endow it with a unique identifier using the id attribute. It gives you the opportunity to come up with a name for the selected element; the id attribute takes this name as a value. Here is a syntax example:

In this example, title is the unique name of the element. Styles can now be applied to this element not through the tag selector, but through the value of the id attribute.

To work with this attribute efficiently, keep in mind a few things:

When creating a unique name, you can use only Latin alphabet characters (A-Z, a-z), numbers, hyphens, and underscores. For example, names Navbar, nav_item, and margin-b-40 will be correct.
The id name should not contain spaces. That is, names like our products will not be valid.
The id can be used for only one element; you will not be able to work with multiple elements that have identifiers with the same name.
Identifiers are case-sensitive: id=""FirstHeader"" and id=""firstheader"" are different identifiers.

Class attribute

When you need to give many different elements the same look, the class attribute comes in handy. As a value, it takes any name you come up with. Unlike the id attribute, a web page can have many elements with the same value for the class attribute. Consider an example:

In this example, all the div tags have the same class – card. This is very convenient because now you don't need to fiddle with each element individually through tag selectors; it is enough to specify the style only for class.

You can apply several classes to one element. To do this, you just need to write the names of the classes separated by a space. It will look like this:

In this example, the div element with ""Card 1"" as text has two classes at once: card and profile-card.

The rules for naming class are exactly the same as for id: when creating a name, use only Latin characters (A-Z, a-z), numbers, hyphens, and underscores. Do not use spaces and keep in mind case sensitivity.

Points to remember

Use id when you need to target a specific, unique element on the page. For example, the main header, a specific form, or a unique button.
Use class when you want to apply the same styles or behavior to multiple elements. For example, grouping all the buttons with the same design, styling all the cards in a grid, or highlighting several elements.
Duplicate id Values: Remember, an id must be unique. If you accidentally assign the same id to multiple elements, it can lead to unpredictable behavior, especially in JavaScript(you'll learn this in next topics).
Overusing id: While it's okay to use id when needed, it's often better to use class if there's any chance that you might want to style or manipulate multiple elements together.

Conclusion

Next time when you face a problem like that, do not clog the code – often there is a simpler solution that lies on the surface. Understanding this will help you a great deal with creating web pages. Hopefully, now the tasks associated with the identification of elements will not confuse you since you know that they only seem scary at first glance.
"
214,Connecting CSS to HTML,551,7418,1390,https://hyperskill.org/learn/step/7418,"Technically, it's possible to create a web page using only the capabilities of HTML, but its appearance will not seem modern and pleasant to the eye. In order to give the web page a unique design without resorting to programming and overly difficult logic, you can use the CSS (Cascading Style Sheets) technology. With the help of CSS, it is possible to change the color of the elements, the font, text style, as well as the size and location of individual blocks on the page.You can connect CSS styles found on the Internet to your HTML file or write your own. An example of ready-made CSS templates is Bootstrap. CSS styles are saved in files with the corresponding extension .css. The number of styles you can connect is unlimited. However, remember that heavy styles may slow down the rendering of the page.This topic covers the several ways to connect CSS files to an HTML document.

External CSS
CSS styles written in a separate file are called External Style Sheets. To include External Style Sheets in an HTML document, use an unpaired <link> tag. Take a careful look at the syntax in this example:

The href attribute specifies the file's address, and the rel attribute with the stylesheet value tells the browser that we are connecting styles and not something else.It is best to include the styles inside the <head>, but it's not a strong requirement. The <link> tag will also work fine elsewhere on the page.

Internal CSS
CSS styles can be written directly in HTML markup instead of a separate file. Such sets of styles are usually called Internal Style Sheets. They are wrapped in a paired <style> tag and must be located inside <head>:

This method of connection is good only when there are very few styles. Remember to always put the volumetric CSS code in a separate file. This practice makes HTML code cleaner and lets you reuse CSS for other web pages.

Inline CSS
You can also define a style for a single element using the HTML attribute style. In this case, CSS properties are written as attribute values:

CSS priority
When applying CSS to HTML document, there's a hierarchy of specificity that determines which styles take precedence. This hierarchy is especially important when dealing with External CSS, Internal CSS, and Inline CSS:

Inline CSS: Has the highest priority. Styles applied directly to an element using the style attribute will override other styles.
Internal CSS: Defined within the <style> tag in the HTML document. It has higher priority than external CSS, but lower than inline CSS.
External CSS: Linked using the <link> tag. It has the lowest priority among these three methods.

When using multiple external CSS files, the order of linking in the HTML document matters. Files linked later in the document have higher priority over those linked earlier.

For example:

In this case, layout.css has the highest priority among the external stylesheets, theme.css has medium priority, and styles.css has the lowest priority. This principle allows developers to organize their stylesheets effectively, with more specific styles overriding more general ones.

Conclusion
Now you know how to connect CSS to your web page in three different ways, so you can make your page truly appealing and very unique. Understanding how to effectively use and prioritize these methods will enable you to create visually appealing and well-structured web pages. Remember to use external stylesheets for large and reusable styles to keep your HTML clean and maintainable.
"
215,Basic syntax,592,7722,1391,https://hyperskill.org/learn/step/7722,"CSS has its own code rules. The syntax of this language is not complicated: it is a list of parameters responsible for the design of elements on the page.

Basic CSS syntax can be schematically described as follows:

selector { property: value; }

CSS syntax consists of two main parts: a selector and a declaration block that is put in curly brackets. Let's look at them more closely.

Selector

Selector indicates which HTML elements the styles will be applied to. For example:

h1 { color: red; }

In this case, the style will apply to all <h1> elements on the page. The text of the <h1> elements will turn red.

You can write multiple selectors separated by commas, and all styles specified in the declaration block will be applied to them. For example:

h1, p { color: red; }

Here, styles are applied to two HTML tags at once. All <h1> and <p> elements on the web page will have a red text color.

Declaration block

Declaration block contains one or more declarations separated by semicolons. Several declarations look like this:

div {
  width: 500px;
  height: 50px;
  color: yellow;
}

In this example, three styles are applied to <div> elements simultaneously: specify width equal to 500 pixels, change the height value to 50 pixels, and make the entire text yellow.

Each declaration includes a CSS property name and a value separated from each other by a colon. Property determines what exactly will be altered: background, text color, position on the page, or something else. The value of a property is a kind of refinement of what it will be changed to. Each property has its own individual set of permissible values. We will learn about the most common properties and their permissible values in the following topics. Take a look at another example:

span { font-size: 25px; }

In this case, font-size is a property applied to the elements and 25px is the value. As you probably guessed, here we changed the font size to 25 pixels in <span> elements.

Declaration blocks are always enclosed in curly brackets.

Conclusion

Here's the deal: there are numerous existing CSS properties: more than 500! One can't possibly memorize them all, so if you forget something, do not hesitate to simply look it up. It's alright, really, as even the most experienced developers refer to guides and resources! The important thing is to grasp the basics of CSS syntax. Let's make sure you do!
"
216,CSS Selectors,594,7738,1394,https://hyperskill.org/learn/step/7738,"Imagine you're at a large party where everyone is wearing name tags. Now, you have a bunch of party favors to hand out, but they're not for everyone only for those who meet certain criteria. Maybe you want to give a favor to everyone named ""Bob,"" or perhaps to those wearing a red shirt, or even to those who arrived in a group. How do you quickly and efficiently find these people? This is essentially what CSS selectors do on a webpage.

CSS selectors are the tools that help you identify and select specific HTML elements on a webpage to style them using CSS. Think of selectors as the criteria on the name tags that help you decide who gets what party favor. Whether you're targeting all paragraphs, every element with a specific class, or elements that are nested in a specific way, CSS selectors are your go-to for applying styles.

In this topic, we'll dive into the different types of CSS selectors.

Basic Selectors

The basic selectors include:

CSS element selectors use the name of the HTML element to which you want to apply the style as the selector. The styles will be applied to all similar elements in the layout of your web page. Consider the following example:

In the example, the brown color is applied to all HTML elements p on the web page.

CSS id selector is used if you need to work with a specific element when there are many similar elements. It takes its name from the value of the id attribute of the HTML tag you need. A symbol # is placed in front of it so that the browser understands that this is an id selector.

Consider the following css code.

In this example, the font size is applied only to the HTML tag with the attribute id=""big""

CSS class selector is useful when you need to give a lot of different elements the same look. The name of the selector is taken from the value of the class attribute of the desired HTML tag. A dot . is placed in front of it so that the browser understands that this is a class selector.

Here's an example of a CSS code:

In the example, the background color is applied only to the HTML tags with the attribute class=""blue""

The universal CSS selector, denoted as *, allows you to apply specific styles to all elements within an HTML document. This selector is often used for setting a consistent base style across an entire webpage, such as box-sizing, margins, or padding, or even applying fonts.

Here is its syntax:

The universal selector is a useful tool in CSS, but it should be used carefully to ensure that it does not lead to performance issues or conflicts with other styles. It has the lowest specificity, which means any other defined styles will override it.

Specificity

Specificity is a measure used to determine which CSS rule applies if more than one rule matches a particular element. This is calculated based on the different types of selectors used in a CSS rule. The specificity hierarchy from highest to lowest is inline styles, IDs, classes, attributes, and elements. For example, an ID selector (#example) has higher specificity than a class selector (.example), which in turn is more specific than an element selector (div). Specificity is calculated on a per-selector basis, and in cases where two selectors have the same specificity, the latest rule defined in the CSS is applied.

Inheritance

In CSS, inheritance controls how properties flow from parent elements to their children, which helps in avoiding duplication of properties and makes the stylesheet easier to manage. However, not all CSS properties are inheritable. Properties related to text formatting, like font-family, color, and font-size, are typically inherited by child elements, but properties related to box model like width, height, margin, and border are not inherited. This means that unless explicitly specified, child elements do not inherit the box model properties from their parent elements.

Best practices

To write efficient and maintainable CSS:

Use class selectors over ID selectors for reusable components: Classes are ideal for styling reusable components because they can be applied to multiple elements without affecting the uniqueness constraint that ID selectors impose. IDs are unique per page and should be used for identifying singular elements that require unique styling or scripting.

Keep specificity low to avoid conflicts: Keeping specificity low (for example using single classes or element selectors instead of complex chains or inline styles) ensures styles are easier to override and maintain. This practice reduces the risk of conflicts and makes the debugging process smoother.

Use combinators and descendant selectors to minimize redundancy: Use child (>), adjacent sibling (+), and general sibling (~) combinators to target elements in relation to others while writing less code. Descendant selectors (space-separated) help in applying styles to elements nested within others without increasing specificity excessively. This approach promotes cleaner and more scalable CSS.

Comment your CSS to explain why specific styles are applied: Comments are crucial for maintaining CSS files, especially in a team environment or for future reference. They should explain why a particular style is applied, any specific considerations or exceptions it covers, and how it interacts with other styles. This practice is particularly useful for unusual or non-obvious styling decisions that could confuse someone revisiting the code.

Conclusion

CSS selectors are a fundamental part of web design, enabling you to apply specific styles to desired elements. Mastering the use of different selectors, understanding specificity and inheritance, and following best practices will enhance your ability to create visually appealing and maintainable websites. As you continue to practice, experiment with these selectors to gain a deeper understanding and proficiency in styling web pages.
"
217,File modes and permissions,1450,13953,1448,https://hyperskill.org/learn/step/13953,"You already know what files are, how to create them, and what files Unix has. Now let's find out how we can access them. Below we will discuss what authorization levels there are in Unix, who may have access to the files, and what limits users' actions in regard to the files.

Authorization levels
Unix systems like Linux can be accessed by many users simultaneously. They can also be used in mainframes and servers without any modifications. But this raises security concerns as arbitrary or even malicious users can corrupt, change or remove crucial data. For effective security, Unix divides authorization into 2 levels:

Ownership
Permission

Let's study each of these two levels starting with the Ownership.

File ownership
File ownership, in other words, signifies users that can work with a file. Every file and directory in Unix is assigned 3 types of ownership described below:

A user is the owner of the file. By default, the person who created a file becomes its owner. So, the user can sometimes be called an owner.
A group contains several users. All of them have the same access permissions to the file. The group is useful when you have a project where a number of people require access to a file. Instead of manually assigning permissions to each user, you could add all the users to a group, and assign group permission to a file so that only the members of this group and no one else can read or modify the file.
Any other user who has access to a file is the one who did not create this file and also does not belong to a group. Practically, it means everybody else. Hence, when you set the permissions for others, it is also referred to as set permissions for the world.

Now, the big question is how does Unix distinguish between these three user types, so that user A cannot affect a file which contains user B's vital data. This is where permissions come in, defining user behavior.

File permissions
File permissions reflect what users can do with a file. Every file and directory in Unix has the following 3 permissions defined for all the 3 types of users discussed above:

Read permission gives users the authority to open and read a file. Read permission on a directory provides users with the list of its content.
Write permission gives users the authority to modify the contents of a file. The write permission on a directory gives users the authority to add, remove, and rename files stored in the directory. Imagine you have a write permission on a file but do not have a write permission on the directory where the file is stored. You will be able to modify only the contents of the said file. However, you will not be able to rename, move, or remove the file from the directory.
Execute permission lets users run a program. If the execute permission is not set, they might still be able to see/modify the program code (provided read and write permissions are set), but not run it.
No permission means users can't do anything with a file.

It's possible to combine all these permission types, and there are eight possible variants of such combinations. They are shown in the table below:

In the Symbol column, permission combinations are abbreviated. So, - means no permission, w means write, r means read, and x stands for execute. Also you can define a permission set using its corresponding three-digit octal number. Thus, 7 is the same as rwx and 2 is the same as -w- and so on. Let's take a look at some examples and common cases below.

Common cases
The whole permission set presented as symbols can look like this: -rwxrw-r--, where the first - implies that we have selected a certain file. If it were a directory, d would have been used instead of the first -. After it, there are 3 triplets of symbols. Each of them defines permissions for owner, group, and other users correspondingly. So, in the example, the owner can read, write and execute the file. The group can read and write, while the other can only read the file.

The most common sets presented as octal numbers are as follows:

755 is commonly used by web servers. The owner has all the permissions to read, write and execute it. Everyone else can read and execute but cannot make changes to the file.
644 means only the owner can read and write. Everyone else can only read. No one can execute this file.
655 means only the owner can read and write and cannot execute the file. Everyone else can read and execute and cannot modify the file.
777 means every user can read, write, and execute. Because it grants full permission, it should be used with caution. However, in some cases, you will need to set the 777 permissions before you can upload any file to the server.

The directory permissions are similar but differ from the file ones in some ways. Let's figure this difference out.

File permissions vs directory permissions
It is important to remember that the right to read, write and execute in a directory does not imply the same rights to all files from that directory:

FileDirectoryReadOne can open a file and see its contentOne can view information about files with ls -l command if execute permission is also set, and only name of files if execute permission is not setWriteOne can change the contents of the fileOne can rename, delete and create files if execute permission is also setExecuteOne can run a fileOne can enter directory with cd command and have access to files

Conclusion
To sum up,there are two authorization levels in Unix: ownership and permission;there are three ownership types in Unix: user, group, and other;permission set may include such actions as read, write and execute;there are two ways to represent a permission set: as symbols or as octal numbers.
"
218,Working with file modes and permissions,1451,13961,1457,https://hyperskill.org/learn/step/13961,"You may already know that in Unix, files have access settings and that there are several permissions and limitations for users. In this topic we will learn how to change access settings using commands in the Unix terminal. Let's find out how to do it below.
 View file permissions
First of all, it's good to know what file permissions you already have. To check it, you can use the ls command and its option -l. Just type ls -l <filename> in the terminal, and you will get something like this:

Here you see who the file owner is, the creation date, and the permission set -rw-r--r--.
Also, you can use the stat command. It displays information about the files and file systems in more details than ls -l. The other difference is that file permissions here are displayed as octal numbers:

To shorten this output and view only access information you can use the grep command. It finds and displays only those strings that contain the word Access:

In the same way, you can find out the permissions for the directory.
So, now you know how to see file permissions. Let's find out how you can change them.
Change file owner
If you want to change the owner of the file and/or a group, you can use the chown command. Its syntax is as follows: chown user <option> /path/to/file. In the user field, you need to specify the user to whom you want to delegate the file. You can also specify a group separated by a colon, for example, user: group. Then not only the user will change, but also the whole group. For example, let's take the save_the_world.txt and transfer it to superman user and also change the group:
chown superman:marvel ./save_the_world.txt
If you want to change the owner of an entire directory, you can use the same command, just write the path to the folder instead of the file path. The path can be specified as both absolute and relative as in the example above.
If you want these changes to apply not only to this directory but also to all its subdirectories, add the -R option:
chown -R superman:marvel ./save_the_world.txt
Great, now you know how to change the owner and the group. The next step is to learn how to ""change the file mode"" (another way to describe access permissions).
Change file mode
To change the file mode you can use the chmod command. With this command, you can set permissions to read, write, and execute a file/directory for the owner, group, and the world. The syntax of the command is as follows:
chmod permissions filename
There are two modes to use this command: an absolute mode and a symbolic mode. This means that we use either octal numbers or characters to define a permission set. Let's study some examples for the absolute mode first.
We have a file modify_it_now.exe and its permissions are -r--r--r-- or 444 in octal. The task is to change the mode so that the owner can read, write, and execute the file. The group should be able to read and execute, and the others should be able only to execute.
In the absolute mode it will look like this: 751. So, you can type in the terminal:
chmod 751 modify_it_now.exe
Now let's move on to the symbolic mode.
Symbolic mode
As for the symbolic mode, you can modify permissions only of a specific owner. This mode involves mathematical symbols to modify the Unix file permissions:

+ adds permission to a file or a directory
- removes permission
= sets permission and overrides permissions set earlier

Also, it's important to know user denotations:

u is user/owner
g is group
o is other
a is all

The syntax thus will be as follows: chmod <user denotation> <operator> <permissions>.
So, if we want to modify the file permissions, we should type:
# modifying user permissions
chmod u=rwx modify_it_now.exe

# modifying group permissions
chmod g=r+x modify_it_now.exe

# modifying other permissions
chmod o=r+w modify_it_now.exe
Here we override the permissions so that users can read, write and execute, group can read and execute, and others can read and write.
In case we want to set the same permissions for all, for example, so that everybody could read, write and execute the file, we should type:
chmod a=rwx modify_it_now.exe
And if we want to only allow the others to read our file, we might use +:
chmod o+r modify_it_now.exe
This way we do not override the whole permissions set but change the concrete permission. In the example above we added the reading permission to others without changing the rest.
Finally, if permission is to be removed, we should use the - operator.
Conclusion
To sum up,

both ls -l or stat commands will give you the information about the file permissions;
using chown command you can change the owner of the file and the group;
with the chmod command you can change the mode of the file;
remember the two ways to change the file mode: absolute and symbolic.
"
219,Files in Python,701,8691,1458,https://hyperskill.org/learn/step/8691,"Often data for your program comes from the outside in the form of files. We all know what files are, we all use them in our everyday lives so it makes sense to incorporate them in a project. In this topic, you'll learn how to work with external files.
The general scheme of working with files is the following: open the file, do what you need with it, then close it. Let's consider these steps in more detail.
Open file
Before we can try to do anything with a file, we need to open it. Python has a lot of built-in functions for working with files so we don't even need to install or import any modules. To open a file, we can use the built-in function open().
The open() function has one required parameter file which is a path-like object. The path-like object is a str or bytes that represents a path in the file directory. In our example, the file parameter has the value ""my_file.txt"" which means that the file ""my_file.txt"" lies in the current working directory. In this topic, we won't get into details about paths and directories, so we'll just assume that all our example files lie in the current working directory.
The object my_file we've just created is a file or file-like object. It just means that we can use different kinds of file methods on this object.
The open() function has a number of optional parameters. If you take a look at the official Python documentation, you can learn more about them. In this topic, we'll look at two parameters: mode and encoding.
The mode parameter
One of the most important optional parameters of the open() function is mode. This parameter regulates how we want to open our file and what for. The following options are available:
Access modes'r'Open for reading. If the file doesn't exist, an error occurs.'w'Open for writing. If the file already exists, it will be overwritten.'a'Open for writing. If the file already exists, append to the end of the file.'b'Open in binary mode.'+'Open for updating (reading and writing).'t'Open as a text
Let's look at the example below.
As you can see, we specified the mode parameter right after the name of the file. Now the file is opened for writing.
A couple of things need to be said about modes.
First of all, by default, files are opened for reading as a text, so the default value of mode is 'r' or, more precisely, 'rt'.
Second, as you can see, we can combine modes to do what we need. For example, if we want to open an existing file and be able to read and update it, we should set the mode as 'r+'.
Third, we can choose the format in which we want to open files. The main options are text or binary, 't' and 'b' respectively. This corresponds to the difference between str and bytes objects. So, if you want to open a file for writing in binary, the mode should be 'wb'. Note that since text format is the default format, most of the times 't' is omitted.
Some modes cannot be combined with each other: thus, only one of the options 'w', 'r', and 'a' must be specified, we can't open a file with 'ar' mode. Similarly, we must choose either 'b' or 't', the file can't be opened both in the text and binary modes.
Lastly, we should mention an important difference between options 'w' and 'a'. Both these modes are used for writing to a file. The only difference is that 'w' truncates the file before writing to it. In other words, if the file already exists, its contents are deleted. The 'a' behaves differently: if the file exists, anything that we write to it will be simply added to the end of the file. You can differentiate them by a simple word association: 'w' is for write, and 'a' is for append.
Encoding
The encoding parameter specifies the encoding that should be used to decode or encode the text file. It is needed when we open the file as a text, and the default value depends on the platform. Below are some examples of opening files for reading in different encodings:
You may know that if you're not using the right encoding on your file, the information will not make sense at all. So, if the file you're trying to open looks weird or wrong, sometimes it makes sense to fiddle with this parameter.
Closing the file
After working with a file, we need to close it. Closing files is extremely important! In most cases, a file will be closed eventually when the program finishes working. However, there is no guarantee for that. In order to ensure the safety of the data, we must make sure that the file is closed in the end. One of the ways to do it is by using the close() method on the file: 
This is not the only way, nor the most efficient. For now, it'll do and you'll learn about other ways in another topic.
Summary
In this topic, you've learned the basics of working with files in Python: how to open and close them. When opening files, you need to specify what you are opening them for, for example, reading or writing. By default, files are opened for reading as a text. Sometimes we also need to specify the encoding of the file so that our data can be properly encoded/decoded.
In the following topics, you'll learn about what you can actually do with the file and how it can be done!
"
220,Reading files,632,8139,1459,https://hyperskill.org/learn/step/8139,"If you have a file, you might want to view its contents. In this topic, you'll learn different ways to read files in Python.

Read file
To read the file, first we need to open it in the reading mode. Now that the file is opened, how does the actual reading part go? Let's first choose a file that we want to read. So, imagine we have a file called 'animals.txt' that looks like this:
Dog
Cat
Rabbit
Sea turtle
Penguin
To read the file, you can:

use the read(size) method;
use the readline(size)  method;
use the readlines()  method;
iterate over the lines with a for loop.

The first three ways are special file object methods while the last one is a general Python loop. Let's go over them one by one.
read()
read(size) reads the size bytes of a file. If the parameter isn't specified, the whole file is read into a single variable. So, this is what we'll get if we apply it to our file:

readline()
readline(size) is similar to read(size) but it reads size bytes from a single line, not the whole file. Lines in files are separated by newline escape sequences: '\n', '\r' or '\r\n'. We'll settle on '\n' in this topic. Yet, keep in mind that this escape sequence depends on your operating system.
Let's proceed with our example. The file 'animals.txt' contains 5 lines. Here is what we'll get if we try to read 3 bytes from each line:

As you can see, the output does not contain the first three characters from all 5 lines. This is because when we specify the size parameter, we get size bytes from the line until it ends and only then go to another line. The newline character is considered as a part of the line here. So, in our example, we need two passes of readline(3) to read the first line which has three characters and a newline character (4 bytes in total). This is where all those empty lines in the output come from.
readlines()
readlines() allows us to read the whole file as a list of lines. Here's what it looks like:

Here you can actually see that the newline character is a part of the line! This method works well when the files are small, but for large files, this may be inefficient.
for loop
The most efficient way to read the contents of a file is to iterate over its lines with for loop.

This is the best way to read large files because we can just work with one line at a time or work with specific lines and discard the rest.
Summary
So, in this topic, we've seen how to read the file's contents. This skill is quite useful because sometimes it's easier or more convenient to read a file using Python than to open it directly. Again, these are the available ways to do it:

read() method reads the file as a whole;
readline() reads the file one line at a time;
readlines() reads the file as a list of lines.
the best way, however, is to use for loop to iterate over the lines of the file.
"
221,Logging,1703,15957,1460,https://hyperskill.org/learn/step/15957,"By now, you probably have an understanding of what logs are. Now, it is time to take a step further and explore the built-in Python logging module.

The logging module
According to the Official Documentation, the logging module defines functions and classes that implement a flexible event logging system for applications and libraries. In other words, this module provides a flexible framework for outputting log messages.
To use this module, we need to import it and configure a logger. Let's take a look at the example below:

As you can see, we use % with string formatting. We do it for backward compatibility. The logging package pre-dates newer formatting options such as str.format().

By default, the output message has the following format: {LEVEL}:{LOGGER}:{MESSAGE}. This format can be changed by using the format attribute when configuring the logger. To do it, we need to call the basicConfig() method:

There are other attributes that you can use to merge data from the log record into the format string, such as asctime and lineno. To get more information and other available attributes, refer to the LogRecord attributes page of the Official Documentation.
You probably noticed that only the warning message was printed. This happens because the default configuration of the logging module is set to the WARNING level, so the info level is not shown in the output. Let's explore what log levels are.
The log levels
It is important to provide a priority scale when logging. A log that notifies the developer that the application is going to crash should be more visible than a log that indicates that there are no problems.
The logging priority scale in Python consists of five different hierarchical log levels. Each log level has a numeric value associated with it. It is much easier to determine if a specific level has to be logged or not.

DEBUG: 10 — the messages at this level provide detailed insights about the application. It is typically used by developers when they have a bug. If you log a message at the debug level instead of print(), you can avoid removing the print statement when your debugging phase is over;
INFO: 20 — at this level, the messages confirm that things are business as usual. We can regard the messages at this level as checkpoints of our program;
WARNING: 30 — the messages at this level indicate that something went sour. The program is still working, but the output could be weird;
ERROR: 40 — as suggested by the name, the messages at this level suggest that the application is not working correctly. The output will be affected;
CRITICAL: 50 — the highest level. The program may be unable to continue running and will no longer produce an output.

The logger class
Logger is the main class of the logging module. It can help us interact with the log system and output log messages:

logging.debug(""message"") — to log a message at the debug level;
logging.info(""message"") — to log a message at the info level;
logging.warning(""message"") — to log a message at the warning level;
logging.error(""message"") — to log a message at the error level;
logging.critical(""message"") — to log a message at the critical level.

As a practical example, we can run the following script:

The output to the console will be:
It is critical to understand logs!
Running this line will result in an error message!
You must catch that bug! It is a warning!

In the previous example, only the messages from the WARNING (or higher) level can be output! This happens because the default configuration of the logging module is set to the WARNING level. To output all the messages, we need to set the level attribute to the DEBUG level:

The output of this piece of code will be as follows:
It is critical to understand logs!
Running this line will result in an error message!
You must catch that bug! It is a warning!
My info is that you are here!
I'm debugging!
If you add filename='' and filemode='' parameters to the basicConfig() method, you will also be able to save the output into a file for later use:

In this case, the messages won't be printed but directly written into the file.
Better logging
If you would like to do more complicated logging tasks, you may need to use a more professional approach to it.
At the advanced level, we use a logger object to track events in the code. We need to set up our logger object in four steps:

If you run the script, you will get the following output:
2021-09-19 22:55:05,829 | DEBUG: Here you have some information for debugging.
2021-09-19 22:55:05,830 | INFO: Everything is OK. Keep going!
2021-09-19 22:55:05,831 | WARNING: Something strange has happened, but it's not critical.
2021-09-19 22:55:05,831 | ERROR: Something unexpected and critical has happened.
2021-09-19 22:55:05,831 | CRITICAL: A critical error! The code cannot run!
As you can see, we have created a logger object and set its level. Then, we have created the console handler and set its format. We have also added the console handler to the logger object and, finally, we initiated the logging. Now, you can imagine how hard it would be to replicate the same functionality with print() statements.
There are many advanced tools and settings that you can use in your logger. We won't get into detail now. You can learn more about all available tools and settings in the Logging Cookbook.
Conclusion
All developers make errors, and all programs may crash. It is important to identify and resolve the issues quickly. The logging module is one of the most powerful tools at our disposal to easily determine the source of issues in our code.
In this topic, we have introduced you to the main player of the logging module: the logger class. You also have got a sense of what log levels are and how to set them. There is more to discuss on logging, but for now, let's practice what you have learned!
"
222,Traceback module,2064,19003,1463,https://hyperskill.org/learn/step/19003,"If you work with Python, you are probably familiar with the traceback concept. Traceback represents the Python call stack state when a program crashes. Whenever the code gets an exception, the traceback will provide the information on what went wrong.
As a quick reminder, when Python calls a function, an object called stack frame is pushed into the call stack. The call stack keeps track of function calls. Each frame in the stack keeps track of function arguments, local variables, and so on. When the function returns the expected output, the stack frame disappears from the top of the call stack.

A stack frame represents a single function call. You can visualize functions that call one another as virtual frames stacking on top of each other. For this purpose, Python uses a special stack data structure.

In this topic, we will take a closer look at the built-in traceback module, but before we do that, let's see how the Python interpreter generates the traceback error. 
In the example above, we can see that the error traceback generated by the Python interpreter is not always that clear and informative. We may need to modify the stack traces according to our needs when we need more control over the printed traceback. We may also need more control over the traceback format. Here is where the built-in traceback module comes in handy. It contains methods that let us extract error traces, format, and print them. This can help with formatting and limiting the error trace.
According to the official documentation, the traceback module provides the standard interface with the methods that fall into several common categories and are available for extracting, formatting, and printing stack traces. It is similar to the Python interpreter when it prints a stack trace.
Traceback print methods

Parameters like limit, file, or chain are present in multiple methods of the traceback module, and they have the same meaning across all methods.

Let's start with the print methods. As their names suggest, they are used to print stack traces to the desired output target (standard error, standard output, file, and so forth). 
The first method is print_tb(tb, limit=None, file=None). It accepts a traceback instance (for example, a raised error traceback) and prints traces to the desired output. It also allows us to limit the trace amount by specifying the limit parameter. If we don't specify a limit, it will print the whole stack trace. Another important parameter is file; it specifies where the trace output will be redirected to. We can give a file-like object, and it'll direct traces to it. We can also specify the standard error and standard output with sys.err and sys.out as file parameters; traces will be directed to them. If no file is specified, then by default, it'll output traces to the standard error. To get specific information from the traceback, we will use the exc_info method of the sys module that returns a tuple (exception type, exception value, exception traceback) with information about a recent exception that was caught by the try-except block. You can read more about the exc_info on the official documentation page.
Another useful method is print_exception(exception_type, value, tb, limit=None, file=None, chain=True). It can be used to print exception information, as well as the error stack trace. We need to provide the exception type, value, and traceback. The chain parameter is a boolean flag indicating whether we should include the trace for chained exceptions (occur when another exception gets raised inside an except block) or not.
Lastly, we want to mention print_exc(limit=None, file=None, chain=True) that is a shorthand for print_exception(*sys.exc_info(), limit, file, chain) and returns the same output. Whenever it is called, this method will print the last exception that happened in the program.
Traceback extract methods
There are two methods for extracting in the traceback module. The first one is extract_tb(tb, limit=None) that accepts a traceback object as a parameter and returns an object representing a list of the ""pre-processed"" stack trace entries (an object containing attributes: filename, lineno, name, and line) extracted from the traceback object tb. It is useful for changing the formatting of stack traces:
The second one is extract_stack(f=None, limit=None) which extracts raw traceback from the current stack frame. The return value has the same format as the extract_tb method. Let's see it in action:
Traceback format methods
We can also format the stack trace after its extraction. We can do it with the format functions included in the traceback module. These functions can be useful if we want to print an error stack because it returns a list of strings with formatted messages. 
format_list(extracted_list) takes a list of tuples as an argument (for example the result of extract_tb() or extract_stack()) and returns a list of strings ready for printing; each string ending with a newline. Every string in the resulting list corresponds to the item with the same index in the argument list. 
Another useful function is format_exception() that works in the same way as print_exception(). The major difference is that it returns a list of strings where each string is a single trace of the stack.
The last thing is format_exception_only(exception_type, exception_value). It takes the exception type and value as input and returns a list of strings specifying the exception description. Below is a simple example: 
There are also shorthand functions for formatting the traceback error, for example, format_tb(). It works the same as print_tb() with the only difference that it returns a list of strings, where each string is a single trace of the stack. We won't get into details about these functions; they are worthy of a more detailed discussion later, but you can always read more in the official documentation. 
Conclusion
Learning how to read the error traceback is extremely important for us as developers. It is one of the first steps in learning to ""speak"" the computer language. Now, we've taken a step further. We've seen how we can extract information from the traceback, how to format it conveniently, and how to print it. We can do it with the help of the traceback module functions like extract_tb(), format_list() or print_tb(). There are many other aspects to cover, but for now, let us practice what we've learned so far!
"
223,Working with PDF in Python,1789,16720,1464,https://hyperskill.org/learn/step/16720,"Everyone is familiar with PDF files. Portable Document Format (PDF) is a file format developed by Adobe Systems. It was introduced in 2008 as an open standard and governed by the ISO under the ISO 32000 standard. Each PDF file is a complete representation of a document. It can include images, texts, tables, styles, links to web pages, and other multimedia elements. It maintains the exact format of the document, so PDF is one of the most popular formats for printing. The PDF specification also provides for encryption, digital signatures, file attachments, and metadata. To view it, we need a PDF reader like Adobe Reader® or a web browser. PDF ensured the transit from paper to digital format. We can create documents and send their electronic version anywhere. In this topic, we'll learn how to read an existing document and create .pdf files in Python.

Reading PDF using Python
PDF documents are binary files; they are more complex than plain text files because they may contain different fonts, colors, tables, and so on. In this section, we will use the PyPDF4 library to work with this type of file. First, let's install it using the Python Package Index (PyPI) with the command below. If everything is fine, you'll see the package version:

Now, let's use the PyPDF4 library to extract the metadata from dummy.pdf. You can download it here. Don't forget to put it in the same folder as your python script! The PdfFileReader class provides all necessary methods and attributes to access data in a PDF file. In the example above, the .getDocumentInfo() method extracts the PDF metadata that is drawn up when a PDF is created:

Let's take a look at the dummy.pdf metadata:

Writing PDF files
The PdfFileWriter class creates new PDF files. Before you can save it, you need to add some pages. You can leave them blank. Let's write a new file with a unique page from the dummy file. In the code snippet above, we use .getPage() to get a specific page. In that case, both pages are 0 because the dummy.pdf file has only one page. We have also used .rotateClockwise(90) and .rotateCounterClockwise(90) to change the orientation of the first page to the right and the second one to the left. Then, we call .addPage() to add the rotated version of every page to the writer object. Finally, we proceed to create a new PDF using .write(). PdfFileWriter objects can create new PDF files, but they can't write new contents from scratch other than blank pages. This is a limitation. Next, we will learn an alternative way to generate PDF files.

Creating a PDF from scratch
Let's continue with fpdf2. This is a minimalist library that allows us to generate PDF documents. It is a port of FPDF that is written in PHP. Let's install it with the Python Package Index (PyPI) as we've done with the previous library:

The fpdf2 library is simple, small, and versatile, advanced-level, but it's also user-friendly, comprehensive, and well-maintained. Have a look at the following example: As a result, we can get the following PDF: We've created an FPDF object with the default values: the pages are in A4 portrait mode, the unit of measurement is a millimeter. It is possible to set the PDF in landscape mode (L) and use other page formats (such as Letter or Legal), as well as different units of measurement (pt, cm, in). As you've seen, we are using the .cell() function to add a line of text to our file. A cell is a rectangular area with text. It is rendered at the current position. We can specify some of its dimensions: width and height in the units defined in the FPDF object (for borders) and text alignment. Note that w is a required argument. The fpdf2 library has a great deal of other interesting features, such as changing the font color, adding multiple cells, header, footer, images, etc. You can check out the Official Documentation. Finally, the PDF document is closed and saved in the directory using the output method.

Conclusion
PDF is the standard for secure sharing and distribution of electronic documents around the globe, both on corporate intranets and on the Web. In this topic, you've learned how to use the PyPDF4 library to read PDF files with the help of the PdfFileReader class and write the new ones using the PdfFileWriter class. You've also learned how to create custom PDF files with the fpdf2 library.
"
224,BeautifulSoup: working with XML,1370,13097,1465,https://hyperskill.org/learn/step/13097,"In this topic, we will discuss how beautifulsoup can help us with XML. Beautifulsoup is a library for processing HTML and XML files. It provides parsing, information extraction, web-scraping, and a lot of other useful features.
Imagine, your boss gave you a pile of unified XML files. You need to extract the text from them for further analysis. Files are myriad; no way you could handle them manually. That's wherebeautifulsoup comes in handy. It can parse the files and get the information from them.
Installation
You can install beautifulsoup with pip. Note that 4 in the name makes for the official name of the library: 
You also need the lxml library to enable the parser that we'll discuss below. You can install it like this:
Do not forget to import the library before you start:
You don't need to explicitly import lxml to parse your files, it will be automatically done once we set the parser type.
First example
Below is an example of an XML file:
To start processing it, we need to read this XML file just like any other file. You can rewrite the code later to automatically read the files one by one:
And create a BeautifulSoup object:
The first argument is the opened document and the second one is the type of parser we'd like to use. 
 
Keep in mind that xml is the name of the parser while lxml is the name of the library we need to install and import to be able to use that parser when creating the soup variable. xml parser type won't work the way we expect it to work without lxml installed.
 
Now soup contains the parsed document and a tree. You can use prettify() to make it more readable: 
Finding information
Even though the output above looks decent with prettify(), it is somewhat hard to follow. It'll get even more confusing with larger documents. If you're interested in something particular, look for tags. Tags are not unified in XML, they may differ from document to document, so you'll have to find the ones you're looking for by yourself. Once you have found the tags you need, you can use the following methods to find them in the tree:


find() returns the first occurrence of the tag in the tree:


find_all() returns the list that contains all occurrences of the tag you are searching for:



 
If the specified tags are not found, find() returns None; find_all() returns an empty list.
 
If a tag has an attribute, you can include it in the search: 
This query is different since we've added a dictionary specifying an attribute name (key) and the value it stores as the second parameter.
Alternative way
Another way to search for tags is soup.<tag> where <tag> is the tag you're searching for. This will return the contents between the specified tags. If several tag pairs were found, it will return only the first occurrence:
You can also find out additional information about tags with main relationship types in XML files: 

parent shows the tag inside which the one you're searching for is placed:


children shows the tag(s) that are placed in the searched tag:

tag4.children returns a generator, so we need to make it a list to be able to see the contents. The contents method is similar to the children attribute but returns a list instead:


siblings shows the tag(s) that are placed on the same level as the searched tag. Siblings may precede (previous_sibling and previous_siblings) or follow (next_sibling and next_siblings) it. Previous_siblings and next_siblings both return generators:

Extracting information
The results we've got can be improved; let's learn how to extract the data. We'll learn how to extract the text contained in tags and attribute values.
Earlier, we have created a variable with a list of the <director> tags. To print them out, you can use a for loop and the text method to get the text data:

Each t.text returns a text paragraph from the page.
Another helpful method that can be used to get the tag attributes is get(). Include a quoted attribute of the tag you need to extract in round brackets.
Summary
In this topic, we have covered the main features of beautifulsoup. If you work with XML, it can help you with:

creating a parse tree;
searching for tags by their names and relations;
data extraction.

If you need more information on beautifulsoup, take a look at the official Beautiful Soup Documentation.
"
225,Natural language processing,777,9157,1502,https://hyperskill.org/learn/step/9157,"Just like most people around the world, you probably interact with computers and mobile devices daily. Have you ever wondered how these machines manage to understand you? Maybe you are a computer engineer, but common users certainly aren't, so generally, they communicate with machines in a different way. If you are interested in how it is done, get ready to peek under the hood and explore the world of language technology.
Natural language
Apart from user-friendly interfaces, there's another important thing: computers actually need to understand our human language. Scientists call our language natural, as opposed to artificial like Esperanto or Interlingua or formal languages, which include the programming ones.
Natural languages were not built on purpose by somebody. They evolved in human communities. The rules of our conversation and writing are not fixed in some laws, it's more like a social contract. We learn to speak like we learn to move, breathe, or digest. No wonder, it's difficult for computers to analyze ""natural"" texts because even we, the humans, misunderstand each other. Understanding language requires a complex approach.

Indeed, the current language technologies have an interdisciplinary basis. It is based on linguistics, psychology, computer science, machine learning, and even ethics. Let's move on to a bit more formal introduction.
Natural language processing
Natural language processing, or NLP for short, is a branch of artificial intelligence that helps with interaction between computers and human languages. It involves processing of large text data. Texts are usually grouped into a special collection called corpus. Text corpora are convenient to work with, but if you want to process language efficiently, it's crucial to know how it is organized.
We share a common linguistic background if we speak the same languages. Computers cannot understand words, grammatical rules, and connotations that we choose. Natural languages have many levels: syntax, morphology, semantics, and so on. The linguistic analysis at multiple levels can show us text's internal structure. It can help us solve various real-life problems.
Main applications
In NLP, we use computers to solve language-related tasks, and it has already shown great promise.
Conversational agents from sci-fi books have made their way into reality. Nowadays, they converse with us to guide, train, support or simply entertain. Communication with dialogue systems usually consists of several stages. First, a program recognizes human speech, which may be difficult due to various accents, speech difficulties, and pronunciation characteristics. The transcribed text is then analyzed and represented semantically, so that the computer can understand and respond. The last stage is speech synthesis. That's quite an engaging field indeed, as diverse as human beings themselves.

The architecture of dialogue systems may include natural language generation. At this step, the program selects parts of data to focus on, structures the content, and puts ideas into words. You can generate replies to keep up the flow of conversation or even work with non-textual data, for example, to describe what's on a picture. It's called image captioning.
Spell checkers and writing assistants may seem a bit down-to-earth, but they certainly make your life easier. They can correct your misspellings, check grammar, catch punctuation mistakes, and spot other issues. These tools rely on statistical patterns found in a language to improve your writing.
Machine translation seems vitally important in some cases. Why should there be language barriers? In terms of input and output, a text is translated from a source language to a target language. Of course, there are some difficulties in between. It's always good to know that machine translation, being one of the earliest challenges in computational linguistics, now includes a vast number of approaches and applications.

Sentiment analysis and opinion mining are generally applied to texts of a smaller size, for example, tweets or online reviews. The idea is to separate what is said (an opinion) from how it is said (an emotion, or polarity). It is useful for identifying trends in social media and developing new strategies in marketing.
Text summarization helps create a concise summary of a document. First, the task is to identify the most important, the gist. Then, you can either extract and compile the original data or transform it into a brand-new text. Either way, it's a superpower in the world overloaded with data.
And we're only getting started. We will recommend resources for further study, but now, it's time to sum up.
Conclusion
Let's highlight the main points we've discussed:


Natural language processing (NLP) is a branch of artificial intelligence that builds a bridge between computers and human languages;


This research field relies on various disciplines, such as linguistics and computer science.


Natural language processing tackles a wide variety of language-related problems and has many real-world applications.


 
 

Hopefully, we have advertised NLP just enough to attract you and spark your interest (that's what we aimed for!). If you are bursting with curiosity now, check out Speech and Language Processing, a brilliant book by Dan Jurafsky and James H. Martin. You can also start learning Python, a great programming language with lots of NLP tools.
"
226,Introduction to NLTK,3097,31188,1503,https://hyperskill.org/learn/step/31188,"NLTK, short for Natural Language Toolkit, is a Python library for NLP. It provides modules for various language-related tasks, including part-of-speech tagging, syntactic parsing, text classification, named-entity recognition, etc. The library includes a lot of datasets and pre-trained models available for free. It is designed to support NLP researchers and learners. Besides its practical application, NLTK is suitable for beginners in computational linguistics methods.

Installation
To begin working with NLTK, install it first. You can do it through pip:
Now, If you want to use it, import it at the beginning of our program:
Once you have installed the library, you may also want to download external datasets and models. The datasets include, for instance, collections of classic literary works, samples of web conversations, movie reviews, as well as various lexical resources like sets of synonyms. As for the models, NLTK provides several models, for example, the pre-trained word2vec. It allows you to find out the relations between words. NLTK also has a couple of pre-trained models for sentiment analysis and so forth. The whole list is available on the official NLTK site — NLTK Data. Use download() to get to the resources:
The method without arguments opens the NLTK Downloader window. You can select the required data there. Choose all in the Collections tab to obtain the entire collection. Alternatively, you can type all as the function argument. It will get you the entire set:
Any package or collection in NLTK can be downloaded the same way. Their IDs are the arguments of nltk.download(), as in the example above.

Advantages and disadvantages
We have mentioned that nltk is a great starting point for studying NLP due to its academic nature. The documentation is clear, easy to comprehend, and includes numerous examples. Additionally, we would like to highlight some other benefits:

NLTK proves to be highly suitable for carrying out NLP tasks.;
It is convenient to access external resources, and all the models have been trained on dependable datasets.;
Texts are often supplied with annotations.

However, there are some restrictions:

NLTK may not be the optimal solution for certain tasks, as it can be slow when dealing with large datasets or real-time processing;
Although built-in models may not be the most advanced, they still serve as a valuable starting point.;
Although the library offers various conventional machine learning techniques, it lacks resources for neural network training.

NLTK applications
Let's take a quick look at the applications of NLTK. Take a look at the table:

Application
NLTK modules

String processing
tokenize, stem

Accessing corpora
corpus

Collocation discovery
collocations

Part-of-speech tagging
tag

Syntactic analysis
chunk, parse

Machine learning
classify, cluster

Evaluation metrics
metrics

Probability and estimation
probability

Let's start with pre-processing. Before processing any data, specific steps should be taken. Firstly, tokenization is necessary, breaking raw textual data into smaller units like words, phrases, or other entities. Secondly, lemmatization or stemming is performed where different word forms are normalized and reduced. NLTK has special modules for these procedures: nltk.tokenize and nltk.stem.
You may require additional pre-processing to remove high-frequency words; these words have little value. nltk contains wordlists of common words for several languages. Such words are called stopwords; they can be found in nltk.corpus.stopwords. With the help of the same corpus module, you can get access to other corpora of nltk.
The library is also good for other tasks, such as collocation discovery. Collocations are two or more words that frequently appear together (best friend, make breakfast, save time). Such phrases can be extracted with the help of nltk.collocations.
Another task is part-of-speech tagging. Annotation is done using the pre-trained model included in nltk. It also has tools for chunking, a procedure related to part-of-speech tagging. Through chunking, the tool can recognize groups of sentences that are syntactically related, including noun phrases. However, while chunking is helpful in some regards, it cannot provide a comprehensive understanding of a text's syntactic structure. Parsing is necessary for a more in-depth analysis of a text's syntactic organization. Additionally, NLTK includes a module for generating tree representations of the inner sentence structures.
Another thing that NLTK can do is text classification and clustering for fundamental machine learning. To evaluate the performance of your NLP tasks, use the evaluation metrics provided in NLTK.
Last but not least, NLTK has ways of statistical counting. Most of them are included in the FreqDist class of the nltk.probabilitymodule. For example, you can learn about word frequency distributions in your text.

Conclusion
In this topic, we have acquired knowledge of the installation process of the library and the acquisition of its external resources. We have also assessed the benefits and drawbacks of utilizing this resource and highlighted various modules that can be used for natural language processing tasks. It's important to note that NLTK offers many possibilities beyond what we have covered. You can explore them by looking in the NLTK documentation.
"
227,Intro to MySQL,1783,16662,1516,https://hyperskill.org/learn/step/16662,"MySQL is one of the most popular Relational Database Management Systems in the world. That's why we also use MySQL during the educational process. In this topic, you will learn about this DBMS, its advantages, disadvantages, and peculiarities.

What is MySQL

MySQL introduces a relational database management system (RDBMS). It allows users to interact with databases (view, search, add and manage data).

MySQL is developed by Oracle — the largest manufacturer of software for organizations. The official website of MySQL is https://www.mysql.com. There you can get detailed information about the product, its developers, and installation instructions.

SQL and MySQL

In a nutshell, SQL is a querying language and MySQL is a database management service. SQL is a language used to operate with records. MySQL is a system that allows storing data in an organized database. So, the MySQL provides your interaction with information using the SQL query language.

For example, there are many other RDBMS besides MySQL: Microsoft SQL Server, PostgreSQL, Oracle Database, and others. All of them use SQL as query language.

Advantages of MySQL

MySQL has several advantages that make this RDBMS in high demand. Let's look closer at the most important ones of them.

Security. Data security in MySQL is an amazing benefit. Especially for applications where some confidential data or money transfers are processed. For example, in eCommerce, banking, and government websites.

Scalability. MySQL provides great scalability that allows building high-load systems without taking many places on servers. This solution allows a complete customization database with unique project requirements.

Performance. Thanks to its high performance, MySQL can process lots of queries quickly. So you can build high-load systems without having to worry about performance.

Workflow control. You can manage all the features based on the needs of your project. MySQL is also cross-platform, so it can efficiently work on Windows, Linux, and macOS.

Disadvantages of MySQL

Like any other technology, MySQL has some disadvantages as well. Let's talk about some of them.

Big amounts of data. MySQL is not very efficient in handling very large databases.

Hard to debug. MySQL doesn't have as good a developing and debugging tool as compared to the paid database management systems.

Despite this MySQL is still a very good solution for different projects. Therefore, MySQL is used by Uber, Netflix, Amazon, Twitter, and other big IT companies.

Conclusion

So, now you know a little more about MySQL. You also should mind that MySQL's syntax of SQL can be different from other database management systems.

Let's review some key facts:

MySQL is an RDBMS that uses SQL as the language for querying databases.

MySQL is one of the most popular database management systems, and it has its advantages and disadvantages.
"
228,Alter table,858,9579,1517,https://hyperskill.org/learn/step/9579,"Sometimes we need to modify our table: add a new column, drop the existing one or change the column type. We can create a new table with all these changes and delete the previous one, but it's easy to lose data during this process. Luckily, SQL provides a statement that can modify the existing tables, ALTER TABLE statement. It can be used to create, delete or change the type of columns.

Adding a new column
Imagine there is a new international company that has employees from around the world, and you're trying to help them keep their records. There is a table employees that looks as follows:

For now, the table doesn't store any contact information, but it would be great if we actually had everyone's contact emails. We don't have a column for this information, so we need to add one.
You can add a new column to your table with a simple query using the ALTER TABLE statement with ADD COLUMN.
The following query will add the column employee_email to our table employees:
As you can see, we specify the column type in our query the same way as we do when creating a table with new columns. In our case, column employee_email will have the VARCHAR(10) data type.
After the query execution, our table has an empty column for contact emails:

Changing the data type
We created the column employee_email with the VARCHAR(10) data type, but some people have very long emails like 'johntomasyork@emailservice.com'. This email will not fit the limit, so we won't be able to add it unless we change the data type of the column.
To change the data type, make a query with ALTER TABLE statement and MODIFY COLUMN:
As a result of the query execution, column employee_email will have the VARCHAR(45) type. Now we can add long emails to our table:

If you decide to change the column type, it should either be empty before the change, or the new data type must be compatible with the old one. Otherwise, you will get an error.

Note that here we provide MySQL example and syntax for changing the data type. In other SQL dialects this query will look a bit different.

Dropping an existing column
In our table employees, we have information about the native city. For the sake of conciseness, let's get rid of this column.
To drop this column from the table, use the following query with the ALTER TABLE statement and DROP COLUMN:
Once we have executed this query, our table employees will look as follows:

Remember that this query deletes the column with all the information stored in it.

Renaming a column
Speaking of conciseness, we can change the column name employee_email since it is clear that stored emails belong to employees.
Let's change the column name to email. You can do it with a simple query with the ALTER TABLE statement and CHANGE:
Now our column with emails has a shorter name:

As you can see, there is a type declaration in the query: if you want to change name and type, you can do it at the same time. Otherwise, just add the previous column type to the query as in the example above.
We provide MySQL syntax for renaming a column. Please, remember, that not all SQL dialects have the same syntax for changing a column's name, and some of them might not have it at all.

Summary
To add a new column to the existing table, use this simple query template:
The following query template can delete a column from the table:
To change the column type, you can use this template:
To change the column name (and, possibly, datatype), use the following template:
Please remember that in different SQL dialects the syntax may vary.
Now you know how to add, rename, delete and change the type of columns. This is not all that ALTER TABLE can do. You will learn more about this useful statement in the future.
"
229,PRIMARY KEY constraint,881,9781,1518,https://hyperskill.org/learn/step/9781,"Sometimes we need to be sure that all the rows in our table are unique. For example, we want to store information about the conference participants: their name, email, date of birth, and city; we want to make sure that no one is registered twice. In this case, we should find a combination of data that is unique for each participant. Maybe some people will have the same name, but they surely won't share the same personal email, so we can use this field as a unique key to prevent creating duplicates. This unique key is commonly called a primary key.

PRIMARY KEY constraint

The PRIMARY KEY constraint specifies a set of columns with values that can help identify any table record. This constraint can be specified in the process of creating a table. Let's create a table named chefs with columns chef_id INT, first_name VARCHAR(20) and last_name VARCHAR(20). We assume that all chefs have individual identifiers, so we will make our chef_id column the primary key:

The PRIMARY KEY constraint means that the chef_id column must contain unique values for each chef. No two chefs can have the same chef_id.

Since the primary key has to identify each table row, it must be unique and cannot be null.

Another important thing is that a table can have one and only one primary key, but it is allowed to include multiple columns in it.

For example, consider the employees table with columns department_id, employee_id, and name. We assume that it's possible to have two employees with identical identifiers across different departments, but it is impossible to have several employees with identical id's in a single department. So, we can have tuples (42, 15, 'Ann Brown') and (43, 15, 'Bob Freud') in the table, but we cannot add a tuple (42, 15, 'John Smith') to that table since there already is an Ann Brown with an id '42'.

In this case, we can define a named PRIMARY KEY constraint on multiple columns when we create the employee table:

The syntax from the query above can also be used to create a named PRIMARY KEY constraint on one column.

Add PRIMARY KEY to an existing table

If we already have a table without a primary key, we can add it using the ALTER TABLE statement.

Assume that we have a table named countries that was created as follows:

We want to make the column country_name our primary key.

To add an unnamed PRIMARY KEY constraint to the column country_name, we use the ALTER TABLE ADD PRIMARY KEY statement:

The column country_name is already unique and cannot contain null values, so it is safe to make it a primary key of the table countries.

Be careful when adding this constraint to a non-empty table: we will get an error if we already have duplicate or null values in the potential primary key.

We can also add a named PRIMARY KEY constraint to an existing table using the ALTER TABLE ADD CONSTRAINT statement. Let's define a PRIMARY KEY constraint on multiple columns for a table students. This table has columns name VARCHAR(60), birth_date DATE, and department VARCHAR(40).

The query below will add a primary key pk_student. This primary key will have two columns: name and birth_date:

Drop PRIMARY KEY

Another thing that we need to be able to do is to delete a primary key from a table. Let's delete the primary key pk_student from the table students.

To drop the PRIMARY KEY, use ALTER TABLE DROP PRIMARY KEY:

Since a table can have only one primary key, we don't have to specify the constraint name.

Conclusion

Now you know what to do if you need unique rows in a table, how to define a primary key in SQL, add a primary key to the existing table and, if necessary, delete it. Let's practice!
"
230,SQL Alchemy mappings,1362,13033,1519,https://hyperskill.org/learn/step/13033,"In the previous topic, you learned the basics of SQLAlchemy. It has a lot of useful features. For example, mapping. It transforms SQL objects into Python ones. There are two main mapping types in SQLAlchemy. One is classical mapping, the other is declarative mapping. We will discuss these types below.

Classical mapping
Classical mapping refers to the configuration of a mapped class that was created with the mapper() function. We need to define a database table and the corresponding Python class separately to link them with mapper(). After that, all changes to the table and class made via SQLAlchemy are saved in your database. Classical mapping is a base mapping system provided by the ORM. Take a look at the snippet below:

First of all, we import Table and MetaData constructions to create a table. We also need to import Column, Integer and String to define table features. Mapper can help us to associate the table with the class. After that, we define the animals variable, in which we create an instance of the Table() class, store the name of our new table, and specify the metadata. Then we need to define columns for data. Each column should have a name and datatype (a string or an integer). For string, it is a good idea to specify the length. Simply stated, an SQLAlchemy string is similar to SQL VARCHAR. Finally, if you need to define a primary key, you can assign True to the primary_key parameter. This parameter means that the data in a specific column is unique and can't be repeated twice.
The next step is to define the corresponding Animals class. It should have the same name as the table we have created. The Animals class specifies the details about our table such as petname, age and weight. These names should also correspond to the columns, otherwise, errors will occur when you set to add information to the database.
Finally, the table metadata is associated with the Animals class via the mapper() function. It means that you can easily modify your database with a Python class and save the changes later. The mapper returns a new mapper object.

Declarative Mapping
Declarative mapping is a concise version of classical mapping. We don't need to specify a class and a table separately, we can do it all in one class. Let's try to write a concise form of the previous snippet:

Our code has become more readable, hasn't it? This time we import declarative_base, a basic function that constructs a base class for defining a declarative class (the Animals class will be declarative). It is assigned to the Base variable in our example. Inside the Animals class, we define the name of our table and the columns with their parameters. Mind that you can define a name either by using __tablename__ or a hybrid approach described in the Documentation. We don't use the mapper() function here, as both the table and class have already been associated in the declarative class.

We don't need to use __init__ in the snippet above. declarative_base()contains the built-in __init__, so you don't need to define it.

After that, we can create an engine to carry on with our table:

This is our SQLite engine. The create_all() function saves our table in SQLite format. As the echo is True, you will see a log:

Hooray! Our table is ready.

Sessions
The mapper() function and declarative extensions are primary interfaces for ORM. Once our mappings are configured, we can proceed to the primary interface. It is also known as a session. It helps us to communicate with our database and ensures that all operations run smoothly. You can modify your database and save the changes during the session. To start one, you can use the following statement:

The Session class is defined with sessionmaker(), a configurable session factory method that is bound to the engine object. When the session object is set up, we can use the default constructor — session = Session(). After that, it remains connected to the engine until we commit the changes or close the session object.
Suppose, we want to add some information about animals to the table:

We are using the Animals class to store the information about each animal in the corresponding column. To proceed, we need to add entries to the table with session.add(). After that, we can tell the Session that we want to save the changes to the database and commit the transaction. You can use session.commit() for that. Let's have a look at the log and make sure that everything works well:

Summary
This topic was just a brief introduction to mappings in SQLAlchemy. So far, you know:
about two main mapping types: classical and declarative;that it is important to initialize a table and a class separately in classical mappings;that declarative mapping concisely maps a class;how to create sessions, add information to the existing table, and save the changes.
If you want to learn more about mappings, feel free to visit the Official Documentation. But for now, let's practice!
"
231,SQL Alchemy querying and filtering,1580,15111,1520,https://hyperskill.org/learn/step/15111,"After learning to map our class and create a session, we can move on to the next step, querying and filtering data from a table. To achieve this, we will use query() and filter() methods, but first, we will discuss the Query constructor object and how to use it.

**Query constructor object**

According to the documentation, a Query construction object is the source of all SELECT statements generated by the ORM. What does it mean exactly? A Query object will generate a SELECT statement for columns of our table and rename each column to a variable name as per PEP convention. Here's what it may look like. Once passed, it will create the animals_petname variable for the table called Animals with the petname column. After this, you'll be able to access the values in the corresponding column via this variable.

To use a Query object, you first need to import it; it will also require a mapped class. Let's have a look at the snippet below where we define the mapped class from the previous topic:

Now, we can pass our mapped class to the Query constructor as an argument, and it will return a query object:

The query variable is an instance of the Query constructor. It allows us to use all Query methods. We will discuss it later in this topic.

Let's take a closer look at our query object.

It is magic in action — the Query constructor generates an SQL SELECT statement for each column of the animals table and renames each column to a variable following the PEP convention. There's no need to worry about creating SQL queries for each column of our table, the Query object does this for us. Now, we can work with the values of each column. This is very useful if you're set to create more complex queries and compare the values in one column. We will learn how we can work with these variables in another topic.

**Selecting from the table**

We have learned to create an SQL statement, but before we start working with the data in the table, we also need to create Session(). You already know how to do it:

Now, let's consider two ways of how we can handle data. The first one is the Query constructor, but this time we should also specify our session. It can be passed either as a second argument to Query() or you can use the with_session() method; both options are identical:

# The code above is equivalent to:

The second way is using the query() method of our session:

There is no difference between the two; both will generate a query object. It is up to you to choose which one you like.

**Retrieving all values**

Now, once we have the query object, we can start working with the values from our table. First, let's add some values:

We will start with the all() method.
all_rows = query.all()
It returns a list of tuples with the values from our query. We can use a for loop to process them. Each object inside the all_rows variable is an instance of the Animals class:

Now, we can retrieve the values by the attribute names that are defined inside the Animals class:

**Retrieving certain values**

What if you don't want to select all attributes, as you're looking only for certain ones? You can specify the attributes you want by passing the class and the name of the attribute as a parameter to your query object:

You can pass as many attributes as you want but separate them with a comma. Since we are selecting attributes directly, the output will contain a tuple with the attributes of the Animals class:

Another useful method is count(). It will return the number of rows that match a special criterion. Remember that the number of rows is not the same as the number of values. The number of values and rows will be the same only when you select one field from the table. For example, we have 6 values and 2 rows in the snippet above, so the method returns 2.

**Filtering the table**

To filter the data, you can use the filter() method. No surprise that you need to pass the exact parameters of what you want to filter as a parameter. For example, if you want to filter all animals with the Billy pet name, use this: Animals.petname == ""Billy"". It is a boolean expression by nature:

The above code will generate the following SQL statement:

In WHERE animals.petname = ? the question mark will be replaced by the value we are looking for, in this case, Billy.

There are no limits on what you can filter. For example, you can use more than one parameter and only a few specific attributes. You can pass any number of attributes and any number of parameters. Also, since a parameter is a boolean expression, you can use another boolean operator as well, for example >=. Let's see an example in the code snippet below:

First of all, we specify the attributes we would like to select — Animals.age and Animals.weight. Then we create two boolean expressions: the age and weight of an animal. We have only one animal that satisfies both conditions, so it produces only one result. If the criterion does not satisfy any field, the query will return nothing.

**Conclusion**

You learned how to use the Query constructor object that generates an SQL SELECT statement, so you don't have to worry about building complex SQL queries. That there are several ways to do this.
Now you know how to retrieve all values from the table and access the returned objects and specify certain attributes. You can also provide table filtering that allows you to select the data that falls under certain specifications. Now, how about putting it all into practice with some exercises?
"
232,SQL Alchemy updating and deleting data,1681,15776,1521,https://hyperskill.org/learn/step/15776,"Now, you are more familiar with the SQLAlchemy library, and you know how to create, select, and filter tables. In this topic, we will take you one step further in mastering this useful library. You will also learn how to update the tables you have created, how to update all fields or only the required ones with the update() method, and how to delete rows with the delete() method. We will also discuss the precautions when performing these tasks.

Creating a table
We need a table first! Let's create one and populate it with data. The procedure is familiar to you, so we won't dive into much detail. We create a table named Employee with the following fields: id, name, position, and salary.

We have created our table and mapped it. Now, we need to add data into this table to work with it. Before this, we need to create a session:

Once the session is created, it's time to fill it. We will add four employees with positions and salaries:

This is how the table will look like:

The update method
Let's now talk about updating data. It is done with the help of the update() method, but we need to specify the field we want to update first. We'll also need a session, a query, and the mapped class. Let's start by creating a query:

If you want to increase the salary of all employees by 1000, use the following syntax:

The syntax is similar to a dictionary. You need to specify the fields in the curly brackets. In this case, the salary field is the key, and the quantity is the value. We take the current salary Employee.salary and increase it by 1000:

After that, we need to commit the changes:

Now, let's see how the table will look like:

We can see that the salary fields in the table have been changed, but what if we want to update just one field? We can do that by filtering only the fields we want.
Updating by criteria
Let's say we want to increase the salary of one employee. We can do this in several ways. We can filter by id, by name, by position, and so on. In our example, we want to increase William's salary by 1000, so we will select it by name. To select only one row, use the filter() method and pass the name as a criterion:

After that, use the update() method on the filter in the same way as for updating the values above:

The above code represents the following SQL statement:

Updating several fields
We can also change several fields with one update. You need to separate each key-value pair by commas like in a dictionary. Let's say we want to decrease the salary of the person who has a senior position and change their position just for kicks. First, we need to filter by position:

Inside the update() method, we need to specify the fields we want to update. In this case, it's salary, position, and their respective values:

if you use a field that is not in the table, the InvalidRequestError exception will be raised:

The delete method
The delete() method works just like the update() method. The main difference between them is that you don't need to pass any arguments.
If you use this method in your query, all rows in your table will be deleted. Be careful! If you run the following code, it will delete all rows in your table, and you end up with an empty table:

The fields will be deleted only if you commit the changes. Before using session.commit(), make sure that you want the results.

To delete only the desired rows, you can filter the field just like with the update() method:

The above code is equivalent to the following SQL statement:

As you can see, the entire row that contains Nancy has been deleted. It helps avoid data inconsistency. After all, it doesn't make sense to have all the other fields without the field name.

Be aware that all fields that meet this condition will be deleted! For example, if you have 5 employees whose names are Nancy, all of them will be deleted.

That is why it is advisable to delete by specific criteria or by unique fields, for example, id.
Conclusion
In this topic, you have learned two essential update() and delete() methods. They both will help you a lot when you work with tables.

The update() method changes specific values of the rows in your table. You can filter the ones you want, or you can update all rows at once.

The delete() method works similarly to the update() method, but be careful with it because you can end up deleting all data in your table.
"
233,NoSQL,1568,15003,1566,https://hyperskill.org/learn/step/15003,"The idea of storing data in tables is pretty straightforward, but it might not be the most suitable way of storing unstructured data. So for this one and many other cases, NoSQL databases are often used. They can also improve performance and in some ways facilitate development. NoSQL databases became popular when the amount of data increased and relational data were not able to handle it properly.

What is a NoSQL database?

The title ""NoSQL"" was introduced by Carlo Strozzi in the Strozzi NoSQL database. This database was relational but didn't use SQL for its queries.

Nowadays, ""NoSQL"" is used as an umbrella term for many databases, usually non-relational. ""NoSQL"" stands for ""Non-SQL"" or ""Not only SQL"". The main difference from SQL-like databases is that NoSQL databases don't store data in relational tables.

Which kinds of NoSQL databases exist?

The name 'NoSQL' is very vague. It doesn't say anything about how exactly this database works. However, at the moment, there are four most popular types of NoSQL databases:

Key-value stores: these databases map key to a value, implementing a hash table. This data structure is also known as a dictionary. They are usually used to store information that needs quick access, for example, cache. Examples: Redis, DynamoDB.

Wide-column stores: these databases use tables and rows as relational databases. But the difference is that the format and names of columns might change from row to row in the wide-column store. They might be treated as two-dimensional key-value stores and are usually used for storing versatile objects. Examples: BigTable, Apache HBase.

Document databases: originally were created to store documents in XML format. But nowadays, they can work with different formats of data such as JSON, YAML, BSON, and others. Examples: MongoDB, Apache CouchDB.

Graph databases: databases that operate with nodes and edges (relationships). They are used to represent data where the most important part is relationships between objects. Graph databases are very useful in identifying patterns in semi-structured and not structured data. Examples: InfiniteGraph, Neo4j.

You can read more about these types of databases in the next topics.

Why NoSQL database became popular?

With time the amount of data that needed to be stored increased drastically. For example, according to the research in ten years (2010 -- 2020) the amount of data worldwide increased by 32 times.

At the same time the cost of storing devices decreased:

source

With the increasing amount of less structured data, it became more difficult to create templates to store it in relational databases. Thereby NoSQL databases became more and more popular in the modern world of development.

BASE principles

NoSQL databases became popular in the conditions of continuously increasing amounts of data. They had to offer simpler horizontal scalability (the system should be able to handle bigger loads only by adding new machines). Usually, NoSQL databases don't offer consistency between the instances of the database, but instead, they offer eventual consistency. It means that eventually, the data stored on every instance of the machine will be the same. The time needed for a database to become consistent is usually expressed in milliseconds.

In general, NoSQL databases follow BASE principles: Basically Available, Soft state, and Eventual consistency. The Basically available principle means that the database is available at all times. The Soft state means that the state of the system can change even without input data, for example, for making the system consistent.

When to use NoSQL databases?

NoSQL databases were created when relational databases became too complicated. And this is still the biggest reason to use a NoSQL database. If the project needs to operate with semi-structured or not structured data, NoSQL will be a good choice. Besides, NoSQL database can have other benefits. For example, some NoSQL databases were designed to handle big data, and they have all kinds of optimizations helping to make working with them more effective.

Development time is usually shorter for the NoSQL databases. In the modern world, it might also be an important point to consider.

When not to use NoSQL databases?

NoSQL databases, in general, don't offer consistency, and sometimes it might be very important, for example, in applications that handle bank transactions.

The other questionable moment is the query language. If lots of complicated queries, including joins, are required, usually NoSQL databases are not a good choice because the query interface is quite limited. This is changing, and query interfaces are becoming more and more sophisticated, but at the moment, relational databases are still much better in this regard.

NoSQL databases are more agile than relational databases, and because of it, they have become very popular. They allow developers to work easily with unstructured data and offer eventual consistency.

Conclusion

There is a wide range of different databases named NoSQL databases. When developers are choosing a database for their projects, NoSQL databases definitely should be taken into consideration, especially when working with unstructured data. NoSQL databases don't have to be consistent but usually they eventually become so.

Read more on this topic in Relational vs. Non-relational Showdown on Hyperskill Blog.
"
234,What is MongoDB,1386,13231,1567,https://hyperskill.org/learn/step/13231,"MongoDB is a document-oriented database used for storing and processing huge amounts of data. The name comes from the word ""humongous"" which highlights the key value of this database.

The MongoDB logo
Classified as a NoSQL database, MongoDB consists of schemaless JSON-based documents which are handy to represent complex data and leverage all the possibilities provided by the flexibility of the JSON format.
According to the DB-Engines Ranking, MongoDB is one of the most popular databases, and it is the top one among other NoSQL databases. Learning about MongoDB and its features is useful for any developer who keeps up with modern programming technologies and Big Data.
Features
MongoDB has a number of features that make it a sought-after database for developers. Here are some of the crucial ones:

All data in MongoDB is stored as JSON documents (though technically, in binary JSON format – BSON) grouped by collections.
Collections don't have to have a similar structure. For example, documents in the same collection may have different fields. One document can have fields of different data types, the data does not need to be reduced to the same type.
The data model in MongoDB allows you to easily represent complex hierarchical structures as well as store arrays.
MongoDB is intentionally developed as a highly scalable and fault-tolerant database for large amounts of data. To achieve it, MongoDB should be run in a cluster environment where several connected databases work together. However, it is possible to start only a single instance. It can be useful while developing, experimenting, or learning to work with MongoDB.

These and other features make MongoDB useful in projects that need to handle big data, user data management, content, and delivery. It is well suited for high-performance distributed web applications such as Amazon or eBay. MongoDB supports all popular programming languages and can be used for free as an open-source solution.
Installation
MongoDB can run on different platforms: macOS, Linux, Windows, or inside Docker. You can find a guide on how to install MongoDB on the official website.
After installing, check the installed version by running the mongod --version command in the terminal. It will show you something like this:

If you get the version number after running the command, it means that your installation was successful and you can start using MongoDB.
Conclusion
In this topic, we've introduced you to the document-oriented MongoDB database. You've learned about its crucial features, installed the database and learned how to check its version in the terminal. Good news for those who do not like to use the terminal: in addition to the console, later you can use a specialized graphical client Compass to work with MongoDB. Using Compass will allow you to manage data, add, modify, and delete it. Good luck with your studies and the tasks ahead!
"
235,Writing files,659,8334,1571,https://hyperskill.org/learn/step/8334,"One very important skill for programmers is knowing how to create new files or add information to existing ones. In this topic, you'll learn to write and append to files in Python.
Write to file
Well, the first step of writing to a file in Python is, of course, opening the said file for writing. The basic mode for writing is 'w', which allows us to write text to a file. There are a few things we need to pay attention to, though. First, this mode allows us to create new files. This happens when the file we're trying to open doesn't exist yet. Second, if the file already exists, its contents will be overwritten when we open it for writing.
Now that the file is open, we can use the write() method. file.write() allows us to write strings to a file – other types of data need to be converted to a string beforehand. Let's see it in action.
If we read the same file and print its contents, we'll get this:
Note that the strings are written to the file exactly as they are. When we call the write() method several times, the passed strings get written without any separators: no spaces, no newlines, just strings combined together into one.
Writing multiple lines
If we want our file to have multiple lines, we need to specify where the ends of the lines should be. Lines in files are separated by newline escape sequences: '\n', '\r' or '\r\n'. We'll settle on '\n' in this topic. Yet, keep in mind that this escape sequence depends on your operating system.
Suppose, we have a list of names and we want to write them to a file, each on a new line. This is how it can be done:
If we print the lines of the file as a list, this is what we'll get:
As you can see, our file has four lines with the four names from the list. If we wanted the names to be on the same line separated by whitespace, we would do it similarly, but instead of \n, we would add a space.
Another method for writing the files is file.writelines(). writelines() takes an iterable sequence of strings and writes them to the file. Just like with write(), we need to specify the line separators ourselves. This is how we could've written the names.txt file using this method:
In the end, we got the same file as before, the only difference is that the original strings had to come with the separator.
Append to file
The 'w' mode works perfectly fine if we don't care if anything gets deleted from the existing file. However, in many cases, we want to add some lines to the file, not overwrite it completely. How can we do that?
Well, we can use the 'a' mode which stands for append. As you might have guessed, this allows us to write new strings to the file while keeping the existing ones.
Suppose, we want to add the name Rachel to the names.txt.
Here's how we can do that:
Now if we print the lines of the file, the output will look like this:
Conclusion
In this topic, we've looked at a basic file operation — writing to files. Depending on whether we want to keep the original contents of the file or not, we can use the mode 'a' or 'w' respectively. The actual writing can be done with write() or writelines() methods.
"
236,Context manager,702,8702,1572,https://hyperskill.org/learn/step/8702,"We live in a world of limited resources, so one of the most important skills in life (and in programming) is knowing how to manage them. We cannot teach you how to manage your resources in real life, but we can help you effectively manage resources in Python with the help of context managers.
When to use context managers
The main purpose of context managers is, as you might've guessed, resource management. What does this mean in practice? The most common example is opening files. Opening a file consumes a limited resource called a file descriptor. If you try to open too many files at once, depending on your operating system, you may get an error or completely crash your program.
To avoid file descriptor leakage (as presented above), we need to close the files after we're done with them. Closing the files is done with the close() method.
This works perfectly fine if we have relatively simple programs. However, as our programs or our file manipulations get more complicated, determining when and how to close the files may get tricky. In other programming languages, a common way to deal with this is a try ... except ... finally block. In Python, we can use a context manager. Basically, the context manager guarantees that all necessary operations will take place at the right time. In the example with opening files, the context manager will close the file and release the file descriptor when we are done working with the file.
with ... as
Now that we know why we need to use context managers, let's learn how to do that. A context manager is introduced by a with keyword followed by the context manager itself and the name of the variable. The basic syntax is the following:
statement here is anything that acts like a context manager (meaning, it supports specific context manager methods). It can be either a custom made context manager or Python's internal one. Below are some examples of context managers you may come across in Python. You don't need to know what they are now. This is just additional information you may find interesting:
File objects (and other streams like io.StringIO or io.BytesIO);Sockets;Locks and semaphores in the threading module;Database connections;Mock objects.
We can also nest this construction:
With Python 3.10, you can use enclosing parentheses to continue across multiple lines in context managers:
Most commonly, with ... as statement is used when working with files. Let's see how we can do that.
Working with files
A file object that we get when we use the open() function acts as a context manager, so we can use it as the statement part of the code. This is how it can be done:
As you can see, it is very simple! It also allows us to shorten our code a little since we don't need to explicitly close the file at the end.

Note that you actually can explicitly close the file within the with ... as statement, it won't be an error. You just don't need to!

Coming back to the situation with a million files, this is how it looks if we use context manager:
Now, let's look at a more realistic example. Suppose, we have a file with a list of movies directed by Quentin Tarantino named tarantino.txt. We want to read this file and print the titles:
We'll get the following output:
Reservoir Dogs
Pulp Fiction
Jackie Brown
Kill Bill: Volume 1
Kill Bill: Volume 2
Grindhouse: Death Proof
Inglorious Basterds
Django Unchained
The Hateful Eight
Once Upon a Time in Hollywood
Now, imagine that we want to process these titles, say, make them all lowercase, and have it saved to a file. If you open several files at once using the with...as construct, then you only need to write with once and write as as many times as there are files to be opened. Here's how it can be done:
The file tarantino_lowercase.txt that we've created in the process, will contain the titles of Tarantino movies written in lowercase.

A backslash (\) in the code snippet above is a line continuation character. It is used to place a single long statement on several code lines.

Summary
In this topic, we've learned about context managers, special structures used for effective managing of resources. Basically, context managers help make sure that all necessary operations have been carried out. Context managers are usually introduced by a with ... as statement.
In practice, you'll most commonly encounter this in opening files. However, you can also create custom context managers for your own purposes, but this is a skill for another topic!
"
237,Introduction to type hints,3425,35824,1604,https://hyperskill.org/learn/step/35824,"When programming in Python, the variable type doesn't need to be specified at creation. Instead, the data type is determined during runtime, making programming more accessible and leading to potential bugs that can be challenging to detect and fix.
Python 3.5 introduced type hints (PEP 484 and PEP 483) to address a common issue, and this feature has since been improved in newer versions. Type hints enable developers to specify the expected data types of variables, function arguments, and function return values and then check them. This is especially beneficial because Python doesn't perform any type checking at runtime, and type hints provide an effortless way to perform static analysis and runtime type checking.
In this topic, you will learn more about type hints and how to implement them in your programs.
Using type hints
Type hints can be used for variables, function arguments, and function return values. 
Let's look at how we can use type hints on variables first. To use type hints on variables, use a colon : followed by the data type the variable is supposed to store. While multiple data types can be specified for the same variable, we will learn how to do it later. Here is an example of using type hints for different variables:
Next, let's look at how to use type hints for function arguments. This syntax is essentially the same as the syntax for the variable-type hints. Use a colon : followed by the required data types. Here is the syntax and examples of using type hints for function arguments.
Finally, you will learn how to specify what type of value the function will return using type hints. To do this, we use ->, followed by the data types the function is supposed to return. Take a look at the syntax:
Why type hints?
Type hint allows you to understand function signatures (argument types, return type), can help you run static checkers on your code, and can increase code readability. When you implement type hints in your code, you specify:

types of data you want a variable to store

the types of arguments you pass to a function

or the type of values to return

Doing this will make your code more readable and allow people to understand how to implement your functions easily. 
To understand the last reason why type hints were introduced, let's look at an issue that has plagued Python since the very beginning:
This program divides two numbers. However, two values need to be a number. If a string replaces the number, for example:
The program gives an error message:
This problem results from the dynamic nature of Python and the fact that Python does not check variable data types during runtimes. The program, therefore, does not know the data type of variables till runtime. This allows such errors to occur during program execution.
If there were a way to find these errors during compilation, such problems would never arise. And that is why type hints were introduced.
Type hints in action
Let's look at the problem we discussed earlier.
In this program, the variables i and j should only store numerical values int or float. To make it easier to understand, let's use int for i and j, and use float for k. After implementing type hints, the program will look something like this.
We can now run the program since we have used type hints in our code. When this program starts, we get the following error message:
Oops, something went wrong! Why is it there? The error message is the same as the previous one. Did the type hint do anything at all? 
Well, no! When a Python code runs, the type hint is ignored. So, type hints won't magically convert incorrectly placed values and correct them. So why are we using type hints here?
Type hints check whether the data used is the correct data type or not. This is done before program execution. For this, we need to use a static type checker. Mypy is the most popular type checker; we will use it for the following examples. However, before you can use mypy, you need to install it first. Execute the following command in your console.
This code will automatically download the latest version of mypy and can be used right after installation. After that, we can use it to check whether the type hint assignments are compatible or not:
Before we run it, use mypy to check the type of assignments. To do this, we need to use the console command
We get the following error message.
Great! Mypy has successfully checked the program and revealed the discrepancy in the type of assignment. So we know there is an issue before the program runs, and we can fix the problem.
After correction, we can now recheck the program:
Success: no issues found in 1 source file

Excellent, there are no issues. You can finally run the program and get the output.
Multiple data types
In the previous example,
i and j could be floating point numbers. Python is a dynamically typed language, and a variable should be allowed to store multiple data types in Python. Therefore, there is a way to specify multiple data types using type hints. 
In earlier versions of Python (3.5–3.9), this was achieved using union:
Note the following line
With Python 3.10 onwards, you can also use the bitwise or operator (|) to achieve this,
After specifying multiple types of variables, let's move on to functions. Let's implement type hints for the arguments of the function first. You can do this using the same method used for variables. 
 Finally, to specify the return types for the functions, we use the same syntax, but after ->.
You can specify multiple data types for variables, function arguments, and return values.
Conclusion 
Python is a dynamically typed language, and the developers of Python intend to keep it that way. Therefore, to fight the issues caused due to the dynamic nature of Python without resorting to using the static declaration of variable type, Python 3.5 introduced type hints to allow programmers to run static checkers on your code like mypy. They can also help understand function signatures (argument types, return type) and increase code readability.
In this topic, you also learned the following:

To implement type hints for variables variable_name: data_type
To implement type hints on functions def function_name(arg1:data_type1, arg2:data_type2, ...) -> return_data_type:
To install mypy using the console with the command pip install mypy
To use a static type checker mypy using the console command mypy file_name.py to check whether type hint assignments are compatible or not 
To specify multiple data types using type hints for earlier and current Python versions.
"
238,Type hints and classes,3514,36892,1605,https://hyperskill.org/learn/step/36892,"It is well known that Python has dynamic typing, but it also supports type hints that help prevent code errors. Although type hints don't affect the actual behavior of a program, using them consistently can improve the readability of your code. In this chapter, we will explore the use of type hints in more complex scenarios.

Base class as a function argument
One of the main concepts in Object-Oriented Programming is inheritance. Type hints can also be used to annotate classes and their successors. Let's take a look at a toy class hierarchy:
The code above represents a Base class, which has two descendants: Derived1 and Derived2; Derived1 also has one descendant — Derived11, as follows:

Let's look at how we can pass such objects as function arguments. To pass an object of the Base class, use the following statement:
Such function can accept any class from our toy hierarchy:
Note how we declared all objects with the Base type; since all of them are either Base or its successors, type hints allow such annotations.
Now consider a function with a slightly different signature:
Let's try to pass the same objects to this function:
Note that passing objects of classes Base and Derived2 to the function is now incorrect and will fail to type check at runtime since it only accepts successors of the Derived1 class, and Type hints would inform you about those inconsistencies.
Generic classes and functions
Type hints can also be used when creating generic classes and functions. Recall that a generic class encapsulates operations that are not specific to a particular data type, meaning that fields and methods of such class can be generalized with a specific parameter. One of the most common usages of generic classes is user-defined collections: arrays, hash maps, trees, queues, etc.
First, let's discuss type variables to parametrize a generic class or function. To declare one in Python, use the construction T = TypeVar('T'). This also makes T valid as a type within the class or function body. Here is a simple example of a generic function in Python:
This function accepts a list of values of the same type and returns its first element or None.
Now that you know how to declare a type variable, let's delve deeper into generic classes. To create one, we'll need the already familiar TypeVar and abstract class called Generic. The syntax for such a case would look like this:
Now, let's delve into the code snippet and examine it line by line. The type variable parametrizes our class T; we already know how to declare one. The following line contains the definition of MyGenericClass, where we can notice that our class inherits from Generic class, an abstract base class for generics. To put it simply, type hints syntax implies that a class is marked generic once it inherits from the Generic subclass.
Variadic generics
Type hints also support variadic generics: this feature allows you to declare an arbitrary number of type parameters. To incorporate this feature into your Python code, you'll need to import TypeVarTuple and Unpack the typing_extensions module. TypeVarTuple enables variadic generics by declaring a parameter pack like so:
Ts = TypeVarTuple('Ts')
 Unpack is an operator used to conceptually mark an object as having been unpacked. Let's take a closer look at the syntax:
Note that from Python 3.11 and higher, the Unpack operator can be replaced with the asterisk (*) operator to expand collections.
Such functions can be called as follows:
Now, we can create functions with more complex behavior by combining TypeVar and TypeVarTuple, for example, here is a function that moves the first element of the tuple to the last position:
Here is how this function would work in different cases:

Variadic generics can also be used for classes:
As you can see, Generic base class allows working with an arbitrary number of types (at least one). Note that in this case the Unpack operator can also be replaced with the asterisk (*) operator if your version of Python is 3.11 or higher.
Conclusion
Incorporating type hints into your Python classes and generics can enhance code clarity and promote better maintainability. This can take your experience from coding in Python to the next level since it benefits you as the developer and makes your code more accessible and understandable for fellow programmers who may read your code. And now you're one step closer to it, as you've learned:

how to use Type hints when it comes to inheritance;
how to annotate generic functions and classes using type variables.
How to work with variadic generics and declare parameter packs.
"
239,Type hints and collections,3426,35835,1606,https://hyperskill.org/learn/step/35835,"Introduction
A traditional way to use the type hints tool in Python is to specify the type of a variable when it's created as a typical data type (like int, bool, float, and so on). However, this might be insufficient, especially when we want to define a variable as a collection (such as a list, tuple, dictionary) rather than a single traditional data type. So, learning how to use type hints for collections and self-defined data types and classes is essential.
To make type hints easier to use, we often refer to the typing module. This module is part of Python's standard library and helps us work with type hints and annotations. It provides different classes, functions, and types that we can use to specify the types in our code.
This topic will discuss how to use type hints for collections and self-defined data types. We will also show you how to use the typing module to help with type hints.

Typing module
Typing is a module in Python's standard library that supports type hints and annotations. Type hints allow you to specify the expected types of variables, function arguments, and return values in your code. This enhances code readability and can be used by tools for static type checking, code analysis, and auto-completion.
The typing module provides various classes, functions, and types that you can use to annotate your code. Some of the commonly used constructs from the typing module include:
1. Basic types:
int, str, float, bool: basic built-in types in Python.
List, Tuple, Set, Dict: generic types representing lists, tuples, sets, and dictionaries, respectively.
2. Type aliases:
TypeAlias = ...: you can create your type aliases for better code readability.
3. Union types:
Union[type1, type2, ...]: represents a value that can be of any of the specified types.
4. Optional types:
Optional[type]: equivalent to Union[type, None], indicating that a value can be of the specified type or None.
5. Callable types:
Callable[..., returnType]: represents a callable with specified arguments and return type.
6. Any type:
Any: represents any type, indicating that type checking is not required for that variable.
7. Generics:
TypeVar: defines generic types that can vary in actual type but maintain some typical relationship.
8. Literal types:
Literal[value1, value2, ...]: represents a value that can only be one of the specified literals.
9. Classes for type hinting:
NewType: creates distinct type hints for better type safety.
NamedTuple: allows creating named tuples with annotated field types.
10. Type narrowing:
TypeGuard: lets you annotate the return type of a user-defined type guard function, aiding type narrowing, which helps static type checkers determine more precise types within a program's code flow.

In this example, the Union type is used to indicate that the data parameter can be either a string or a list of integers. Depending on the type used, the function will return different strings: for string input, it would return Processed string: and the string itself; for a list of ints, it would be Processed list: and the sum of elements of the list; and for any other data types, the function would return Unknown data. Note that if a variable of a wrong type is passed to the function, the program will still be executed correctly (and Unknown data will be printed). However, the IDE would print a warning informing that an unexpected type is used.

Type hints for collections
In Python, type hints provide a way to indicate the expected data types of variables, function parameters, and return values. When working with collections such as lists, dictionaries, tuples, and sets, type hints can significantly improve code readability and help catch potential type-related errors early in development. For example, when defining a function that takes a list of integers as an argument, you can use the List type hint from the typing module to indicate this:

In this example, the process_numbers function takes a list of integers as its argument and returns a new list of squared integers. The List[int] type hint clarifies the expected input type, making it clear to developers and tools that the function should be called with a list containing integers.

Type hints for self-defined data types
Python also allows you to create your custom data types using classes. When working with the self-defined data types, type hints become particularly valuable to convey the intended structure of your data and methods. Let's consider a basic example of a Person class:

In this scenario, the Person class has two attributes name and age and the method introduce. The type hints for the __init__ constructor and the introduce method clarifies the expected input and return types. Additionally, the celebrate_birthday function takes a Person object as an argument and returns a modified Person object after incrementing the age. Type hints provide insight into the structure of the custom data type and how it can be used within functions.

Why is it important? While the typing module provides runtime support for type hints; it does not enforce function and variable type annotations, which means IDE and other third-party type checkers could use them but not affect the program execution if a variable of a wrong type is used. Please note that type hints in Python are only informational.

Conclusion
Type hints in Python programming are a great help as they clarify data types of variables, function parameters, and return values. The typing module, available in the standard library, provides various annotation tools, making the code more readable and enabling static type checking. Type hints are handy when working with collections like lists and dictionaries and defining custom data types with classes. By using type hints, developers can create more robust code, promoting better collaboration and reducing the possibility of errors.
"
240,Json module,745,8999,1614,https://hyperskill.org/learn/step/8999,"As you know, JSON is a very common format for storing text-based data. Even though it originally derived from JavaScript, nowadays this format is language-independent and is used in all kinds of situations. Naturally, programming languages have their ways of dealing with JSON, and in this topic, we will see how it is done in Python.

json module
Python has a built-in module for working with the JSON format: json. If we want to use it, we just need to import it at the beginning of the program.
What does it allow us to do? Well, the two main procedures are converting Python data into JSON and the other way around. To better understand the logic behind the conversion, let's take a look at a JSON object:

You can see that there are a lot of similarities between JSON notation and Python data types: we have strings and numbers, a JSON object looks similar to a Python dictionary, an array — to list. This makes conversions between JSON and Python quite easy and intuitive. Here's a full conversion table for encoding Python data to JSON:

Conversion table

Python
JSON

dict
object

list, tuple
array

str
string

int, float
number

True
true

False
false

None
null

 Data types not listed in the table, such as custom classes or, for example, datetime objects cannot be converted to JSON that easily. 

Now let's take a look at specific methods available in the json module and see how the conversion happens.
Encoding to JSON
Generally, encoding to JSON format is called serialization. The json module has two methods for serializing: json.dump() and json.dumps(). The key difference between these two methods is the type we're serializing to: json.dump() writes to a file-like object, and json.dumps() creates a string.
Suppose, we have a dictionary equivalent to the JSON we've seen earlier.

Here's how we can save it to the JSON file movies.json:

As you can see, this method has two required arguments: the data and the file-like object that you can write to. If you run this code, you'll create a JSON file with the data about movies.
Another option is serializing the data into a string using json.dumps(). In this case, the only required argument is the data we want to serialize:

Careful with data types! JSON only supports strings as keys. Basic Python types like integers will get converted to strings automatically but for other types of keys, like tuple, you'll get a TypeError because the .dump() and .dumps() functions cannot convert it to a string.

In addition to the required parameters, both methods have several optional ones. You can check them all out in the official documentation, here we'll only look at the indent parameter. You can see that the string we got in the example above is quite hard to read, compared to the original dictionary. Well, if we specify indent (an integer or a string), we can pretty-print our resulting JSON:

And the resulting string:

Decoding JSON
The opposite procedure is deserialization. Similarly to serialization, the  json module has two methods: json.load() and json.loads(). Here the difference is in the input JSONs: file-like objects or strings.
Let's convert the JSONs we've just created back to Python data types.

You can see that the dictionary that we got as a result of json.load() equals our original dictionary. The same with json.loads():

Remember the issue with non-string keys? Well, if we convert a Python dictionary with non-string keys to JSON and then back to Python object, we will not get the same dictionary.

Summary
In this topic, we've seen how to work with JSON using the built-in Python module json. We can

convert Python objects to JSON using either json.dump() or json.dumps();
convert JSON to Python objects using either json.load() or json.loads().

The conversions are done according to the conversion table and not every Python object can be converted to JSON.
Considering that JSON is a very commonly used data format, it's important to be able to work with it!
"
241,ENUM,2924,29191,1628,https://hyperskill.org/learn/step/29191,"ENUM is a data type in Python that allows you to define a set of related, immutable constant values to give you a more structured and maintainable codebase. It helps make your code more readable, self-documenting, and error-resistant.
Creating enumerations in python
An enumeration, or ENUM, is a special type of data structure that consists of a set of named values, also known as members or enumerators. Python does not have a built-in syntax for them. However, the standard library includes the enum module that provides support for creating sets of related constants via the enum class In Python, you can create an ENUM using the enum module.
To create an ENUM, import the Enum class from the enum module. Here's an example:

Once you've imported the Enum class, you can define your ENUM by creating a new subclass. Each member of the ENUM should be defined as a class attribute with a unique name and an assigned value. For example:

We've defined an ENUM called Color with three members: RED, GREEN, and BLUE. Each member is assigned a unique integer value.
You can also define an ENUM member with an auto-assigned value. In this case, the value will be an integer that starts at 1 and increments by 1 for each subsequent member:

In this example, we've defined the same Color ENUM, but we've used the auto() function to automatically assign integer values to each member.
Once you've defined your ENUM, you can access its members using dot notation:

You can also access the value of an ENUM member using the .value attribute:

That's it! You've successfully created an ENUM in Python using the enum module.
Accessing modes
Each constant is an instance of the Enum class and can be accessed either by its value or name. Here's an example of how to define and access an ENUM:

In this example, we've defined an ENUM called Color with three members: RED, GREEN, and BLUE. Each member has a corresponding integer value.
Now, let's see how we can access these members by their values and names:
# Accessing enum members by value

# Accessing enum members by name

We're accessing enum members by their values in the first set of examples. We're passing the integer value of each member to the Color constructor, which returns the corresponding member.
In the second set of examples, we're accessing enum members by their names. We're using the square bracket notation to access the member with the given name.
Both methods of accessing enum members are reasonable in different situations. Accessing members by value can be useful when you have a variable containing an enum member's integer value. Accessing members by name can be useful when you want to refer to an enum member in a more readable way.
Enumerations are iterable
In Python, enumerations are iterable, meaning you can loop through their members using a for loop or perform other operations that apply to iterable objects.

In this example, we define an enumeration called Color with three members: RED, GREEN, and BLUE. We then loop through all the enumeration members using a for loop and print the name and value of each member.
By using the name and value attributes of each enumeration member, we can get the name and integer value of the color, respectively.
This is just one example of how you can iterate through an enumeration of colors. You can use this approach to perform various operations on each color in the enumeration.
Using enumerations in if and match statements
Enumerations can be used in if and match statements like any other data type. This allows you to write more expressive code that is easier to read and understand.

In this example, we define an enumeration called Color with three members: RED, GREEN, and BLUE. We then set the variable color to Color.RED and use an if statement to check whether color is Color.RED. If it is, we print The color is red. Otherwise, we print The color is not red.
You can also use enumerations in match statements (available from Python 3.10 onwards), which provide a more concise and expressive way of checking the values of an enumeration. Here's an example:

In this example, we define an enumeration called Direction with four members: NORTH, EAST, SOUTH, and WEST. We then define a function called opposite_direction that takes a direction as input and returns its opposite direction.
Inside the function, we use a match statement to check the value of the input direction and return its opposite direction. This provides a more concise and expressive way of checking the values of an enumeration compared to using a series of if-elif statements.
Comparing enumerations
By default, ENUMs in Python allow for two comparison operations: identity and equality. This means that you can compare enum members to see if they are the same object in memory (using is and is not operators), or if they have the same value (using == and != operators).
The identity comparison of enum members is possible because each member is a single instance of its enumeration class, which makes it easy and efficient to compare members using the is and is not operators.

In this example, we have an enum representing different types of animals. The members CAT, DOG, BIRD, and FISH have unique identities. We also have aliases for some of the members: FELINE is an alias for CAT, and CANINE is an alias for DOG. Since aliases are just references to existing members, they share the same identity as the members they reference. Therefore, cat is feline and dog is canine both return True. However, cat is dog, fish is bird, and feline is dog all return False since these are different members with different identities.
The equality operators == and != also work between enumeration members:

In this example, we have an enum representing different colors. We create several members with unique identities: RED, BLUE, GREEN, and YELLOW. We then test the equality of these members using the == and != operators. We see that red == Color.RED returns True since red refers to the RED member, which has the same value and identity as the RED member of the Color enum. Similarly, yellow != blue returns True since yellow refers to the YELLOW member, which has a different value and identity than the BLUE member referred to by blue.
Since ENUM members are assigned a definite value, such as a number, string, or any other object, comparing them directly with other objects using equality operators might be tempting. The outcome of such comparisons may not be as expected since the comparison is performed based on the identity of the objects rather than their values.

Even though the values assigned to the enum members are the same as the integers used for comparison in the examples, the comparisons still result in False. This is because enum members are compared based on their object identity rather than their value. Comparing an enum member to an integer is like comparing two different things with different identities. Therefore, they can never be considered equal.

Using the value attribute, you can compare two members with the same values. It will return True
Additionally, enumerations have a feature that allows membership tests using the in and not in operators.

By default, Python's enum class allows the use of the in and not in operators that can be used to verify the presence of a particular enum member in a given enumeration.
Sorting enumerations
Python's enums do not have built-in support for comparison operators such as >, <, >=, and <=. Due to this limitation, it is not possible to directly sort enum members with the sorted() function. However, sorting enumerations by their member names and values is possible using the key argument in the sorted() function.

In the first example, a lambda function is used to extract the .value attribute of each enumeration member, which allows the input enumeration to be sorted by its member values. Similarly, in the second example, the lambda function extracts the .name attribute of each member to sort the enumeration by its member names.
Best practices and use cases
Here are some best practices and use cases for using ENUMs in Python:
Use ENUM to represent a fixed set of values: ENUM is a great way to represent a selected set of values known at compile-time. This makes your code more self-documenting and error-resistant since the set of valid values is explicitly defined.Use descriptive names for ENUM members: Use descriptive names for ENUM members to make your code more readable and self-explanatory. Avoid using abbreviations or cryptic terms that may be hard to understand later.Use ENUM for constants: Use ENUM to represent constants used throughout your code. This makes it easier to change the value of a constant in the future since you only need to change it in one place.
Conclusion
ENUM is a data type that allows you to define a set of named values in Python.ENUM can help make your code more readable, self-documenting, and less error-prone.Use ENUM to represent constants used throughout your code, making it easier to change the value of a constant in the future.
"
242,Walrus operator,3588,37669,1640,https://hyperskill.org/learn/step/37669,"With the advent of Python 3.8, a new operator, known as the Walrus Operator (:=), made its debut. This operator, formally referred to as the Assignment Expression, provides a compact way to assign values to variables as part of an expression. Through this feature, programmers can write cleaner and more efficient code. This topic will cover the Walrus Operator's syntax, usage, and its potential to streamline code.
Understanding the walrus operator
The Walrus Operator, signified by :=, is a unique feature introduced in Python 3.8. This operator's main purpose is to simplify assignments within expressions, which leads to cleaner and more readable code. It gets its name, the ""Walrus Operator,"" because it looks like the eyes and tusks of a walrus on its side.
The above snippets show how the Walrus Operator lets you execute assignments within the if statement. This shortens the code by one line and maintains a tidy appearance.
Now, let’s compare the Walrus Operator with the traditional = assignment operator. The typical assignment operator works by assigning the value on the right to the variable on the left. For example, x = 5 assigns the value 5 to the variable x. However, the Walrus Operator assigns and returns the assigned value, enabling its use or evaluation right there in the same expression.
In the second example, the Walrus Operator := assigns the value 5 to x, and at the same time returns 5, which is then printed. This characteristic allows for the assignment and utilization of variables in one expression, packing the code without sacrificing clarity.
Practical applications
The Walrus Operator can substantially simplify your code in certain situations by allowing assignments within expressions. This is especially handy in conditions, loops, and other places where you usually need to write separate statements for assignments and conditions. Here, some practical applications of the Walrus Operator in Python programming are explored.
In these examples, the Walrus Operator aids in making the code generous, more readable, and straightforward. It shows how assignments within expressions can simplify typical Python coding patterns, displaying the versatility and practical value of the Walrus Operator for real-world coding scenarios.
Benefits and caveats
The Walrus Operator (:=) brings a fresh twist to Python, targeting code simplification by facilitating assignments within expressions. However, it's vital to comprehend both the advantages and caveats of this operator for efficient use in your programming efforts.
The Walrus Operator contributes to code brevity by enabling assignments within expressions, often trimming the number of lines needed for certain logics. This brevity could lead to a more manageable codebase. Moreover, when judiciously applied, the Walrus Operator can enhance readability by keeping related expressions together, which is beneficial in conditions and loops. By consolidating assignment and evaluation into one expression, the Walrus Operator could also eliminate repetitive operations, possibly resulting in minor efficiency boosts.
Conversely, the Walrus Operator can cloud code if used incorrectly. It can hide assignments within complex expressions, rendering the code less intuitive and potentially trickier to debug. There is a learning curve tied to this operator, especially for Python beginners or those unfamiliar with this syntax. This operator might create an extra hurdle in the learning journey. Moreover, as the Walrus Operator is a feature of Python 3.8 and later versions, it does not work with previous versions. Code intended for compatibility with older versions should avoid this operator. Lastly, the risk of overusing the Walrus Operator may result in overly dense code, possibly causing debugging or maintaining troubles over time.
Conclusion
The Walrus Operator is a key feature in Python 3.8, aiding in code brevity and readability when used wisely. Balancing its use is essential to prevent potential downsides like code obscuring and incompatibility with earlier Python versions. Prudent use of the Walrus Operator will result in more elegant and maintainable code, enhancing the Python programming experience.
"
243,Tokenization,4621,51949,1719,https://hyperskill.org/learn/step/51949,"NLP includes a variety of procedures. Tokenization is one of them. The main task is to split a sequence of characters into units, called tokens. Tokens are usually represented by words, numbers, or punctuation marks. Sometimes, they can be represented by sentences or morphemes (word parts). Tokenization is the first step in text preprocessing. It is a very important procedure; before going to more sophisticated NLP procedures, we need to identify words that can help us interpret the meaning.

Tokenization issues
The major issue is choosing the right token. Let's analyze the example below:

This example is trivial; we use whitespaces to split the sentence into tokens. But, sometimes, the English language displays less obvious cases. What should we do with the apostrophes or a combination of numbers and letters?

What is the most suitable token here? Intuitively, we can say that the first option is what we should go for. Of course, the second option also makes sense as ""we're"" is the contraction for ""we are"". All other options are also theoretically possible.

What if we speak about a city with a complex name, for example, New York or [""New"", ""York""]?

As you can see, choosing the right token may be tricky. During the tokenization process, the following aspects have to be considered:

Capitalization
The language of the text (this includes programming languages, such as Python, where whitespaces and keywords are used for indentation)
Numbers and digits
Special tokens (the tokens that represent something other than text itself). They might indicate the beginning or end of text, a token for a specific task (such as classification), or mask parts of the text for training, among other purposes we will consider below.

The tokenizer granularity
There are 4 main types of tokenization granularity: word, subword, charachter, and byte tokens.

Word tokenization was once popular but faded over the years due to several issues. One of the issues is that the tokenizer is unable to deal with tokens that were not present in the training set. This also makes the vocabulary bloated with words that are very similar in meaning (e.g., classify, classification, classifiable, classifier). This is solved with subword tokenization that has a root token ('class') and suffix tokens ('ify', 'ification', etc), which helps with vocabulary size.

Vocabulary size in tokenization impacts the model's computational requirements, as each token needs its own embedding vector. A smaller vocabulary can still effectively represent language by using subword units, while avoiding the computational overhead of a large vocabulary of whole words.

Subword tokenization breaks down vocabulary into both words and word fragments. This maintains a rich vocabulary while also handling unknown words by decomposing them into known subwords that already exist in the vocabulary. For example, if the word ""uncharacteristically"" isn't in the vocabulary, it can still be represented using subword pieces like ""un"" + ""character"" + ""istic"" + ""ally"".

Character tokenization can handle any new word by using individual letters, but this makes the model's task harder - it must learn to compose letters like ""p-l-a-y"" instead of recognizing ""play"" as a single unit. Additionally, subword tokens are more efficient for context length: in a model with 1,024 token limit, subword tokenization can typically fit 3x more text than character-level tokenization since each subword token usually represents multiple characters.

Some models use byte-level tokenization, processing text as raw unicode bytes without traditional tokenization. While some subword tokenizers include bytes as fallback tokens for unknown characters, they aren't truly tokenization-free since they only use bytes for a subset of characters rather than the entire text.

WordPiece
WordPiece (originally introduced in 2012) is a subword tokenizer that identifies the most common character sequences in a training corpus and combines them to build a vocabulary of subwords that represents the text while maintaining a manageable vocabulary size.

WordPiece works by first initializing the vocabulary with individual characters and then repeatedly merging the most frequently occurring pairs of adjacent tokens. When encoding text, words are split into the longest possible subwords from the vocabulary, with special tokens (usually ##) marking subword pieces that don't start words.

Here, we see how 'uncharacteristically' is split into 6 tokens, with 5 subword tokens. [CLS] is a special token that indicates a classification task. [SEP] is used to separate sentences.

There are 3 more special tokens in WordPiece:

[PAD] - Padding token that is used to make all sequences the same length (a desirable property for training NNs that require fixed length)
[UNK] - Unknown token for words that are not in the model's vocabulary
[MASK] - Masking token that is used for masked language modeling. During training, random tokens in a sentence are replaced with [MASK], and the model learns to predict what word should go in that position.

Byte pair encoding (BPE)
At a high level, byte pair encoding works similar to Wordpiece, but uses a different strategy for merging tokens. BPE is more flexible with unknown words, while WordPiece maintains more semantic units and produces longer subwords.

Here, we see that the new lines, spaces, and tabs are represented by the tokenizer (and this is significant when LLMs work with code). There is a one special token in this model, <|endoftext|>. GPT-4 tokenizer works similarly to GPT-2 tokenizer, but is better at handling code and tends to use fewer tokens for word representation.

Conclusion
As a result, you are now familiar with the following:

Tokenization is a procedure that breaks text into meaningful units (tokens). The process must consider factors like capitalization, language specifics, and special tokens.
There are four main types of tokenization granularity: word, subword, character, and byte tokens. While word tokenization was once common, subword tokenization has become preferred.
Two major subword tokenization approaches are WordPiece (used by BERT) and Byte Pair Encoding (BPE, used by GPT models). WordPiece maintains semantic units and produces longer subwords, while BPE is more flexible with unknown words and is particularly good at handling code due to its preservation of whitespaces and special characters.
"
244,Tokenization implementation,956,10363,1720,https://hyperskill.org/learn/step/10363,"Tokenization helps to identify meaningful units that contribute to understanding the text's content. In this topic, we'll explore various tokenization approaches using the Natural Language Toolkit (NLTK) library.

Tokenization in NLTK

The Natural Language Toolkit (NLTK) provides various tokenization tools through its tokenize module. This module contains several tokenizers, each designed for specific text processing needs. To use a tokenizer, import it directly from the module using:

The table below describes the main tokenizers available.

SyntaxDescriptionword_tokenize()Returns word and punctuation tokens.WordPunctTokenizer()Returns tokens from a string of alphabetic or non-alphabetic characters (like integers, $, @...).regexp_tokenize()Returns tokens using standard regular expressions.TreebankWordTokenizer()Returns the tokens as in the Penn Treebank using regular expressions. sent_tokenize()Returns tokenized sentences.

Word tokenization

Let's take a look at an example. Imagine we have a string of three sentences:

Now, let's have a look at each tokenization method from the table. Don't forget to import all of them in advance.

The result is a list of strings (tokens). The function splits the string into words and punctuation marks. Mind the possessives and the contractions. The tokenizer transforms all 's into separate words. Of course, we understand that cat's could also be recognized as one token.

The next code snippet introduces the WordPunctTokenizer(). This tokenizer is similar to the first one, but the result is a little bit different. All the punctuation marks including dashes and apostrophes are separate tokens. Now, C-3PO, the cat's name, is split into three tokens. In this case, this behavior is not optimal.

The next example shows the results of the TreebankWordTokenizer().

The TreebankWordTokenizer() works almost the same way as the word_tokenize(). Mind full stops – they form a token with the previous word, but the last full stop is a separate token. Word_tokenize(), on the contrary, recognizes full stops as separate tokens in all cases. Moreover, the apostrophe and s are not separated as with WordPunctTokenizer().

Let's now move on to the next method. The regexp_tokenize() function uses regular expressions and accepts two arguments: a string and a pattern for tokens.

The pattern [A-z]+ in the first example above allows us to find all the words or letters, but it leaves aside integers and punctuation. Because of that, all the possessive forms and the cat's name are split. The next pattern improves the search for tokens as the integers are added. It improves the search for the cat's name, but the way isn't optimal. The third pattern with an apostrophe also allows the tokenizer to find possessive forms. The last pattern includes the hyphen, so the name of the cat is recognized without mistakes.

You can see that obtaining tokens with the help of regular expressions can be flexible. We change the pattern in each case; this allows us to get more precise results.

Sentence tokenization

Finally, let's look at the sent_tokenize() function. It splits a string into sentences:

However, sentence tokenization is also a difficult task. A dot, for example, can mark abbreviations or contractions, not the end of a sentence only. Moreover, some dots can indicate both an abbreviation and the end of a sentence. Let's have a look at the examples.

The sent_tokenize() includes a list of typical abbreviations and contractions with dots, so they are not recognized as the end of a sentence. Sometimes, it still provides confusing results. For example, after tokenizing the text_2 above, .) was recognized as the end of the sentence. It is a mistake. The last part in the tokenizer output is 'last year.' but it should belong to the previous sentence.

If you deal with informal texts such as comments splitting them into sentences may be particularly problematic. For example, in text_3, there are lots of periods and no spaces, so two sentences are recognized as one.

Conclusion

To sum up, tokenization is an important procedure for text preprocessing in NLP. In this topic, we have learned:

How to split a text into words with different NLTK modules;
How to split a text into sentences with the sent_tokenize() module.
Of course, there are many other tools for tokenization: spaCy, keras, gensim, HuggingFace, Stanza, and others. It's always a good idea to take a look at their documentation.

Now, it is your time to carry out your tokenization experiments!
"
245,Regexps in programs,1516,14611,1748,https://hyperskill.org/learn/step/14611,"Regular expressions are very versatile. They can be used to automate many tedious text-related tasks, such as input text validation or data collection. In this topic, we will have a look at two examples of simple yet powerful programs that employ regular expressions.
Email validation program
Let's have a look at a basic program that checks whether the text contains email addresses and, if it does, returns them in sequential order:

The program above carries out a rather simple check. It checks if the @ character is preceded and followed by alphanumeric characters, an underscore, and a dot. Mind that \w is equal to [A-Za-z0-9_].
Let's test our program:

The downside is that our program will also match strings like _@._. They obviously cannot be considered email addresses.
Email validation 2.0
If usernames and domain names are too short, it may lead to rather bad scenarios. We can set some restrictions when compiling our pattern to avoid this:

Let's break it down piece by piece:

[\w\.-]{5,} matches alphanumeric characters, underscores, a dot, or a dash that appear at least 5 times;
@ matches the @ sign;
[\w-]+\. matches alphanumeric characters, underscores, or a dash followed by a dot;
\w{2,4} matches alphanumeric characters and underscores that appear 2-4 times.

Here's our final program:

Let's test it:

As you can see, simple restrictions can make our pattern more powerful. You can also make your pattern match more specific strings by, for example, adding the boundary shorthands \b at the beginning and the end of the pattern, as well as lookaround assertions.
Tokenization
As you may already know, text preprocessing plays a crucial role with textual data. Tokenization or splitting text into smaller units (usually words) is the first step in text processing. Text tokenization can go smoother with regular expressions if you don't want to use other special tools.
The most straightforward approach to tokenization is to split a text by whitespaces. Let's see how it works:

After giving it a thorough look, you can spot the elephant in the room — punctuation marks. Let's get rid of them before we split our sentence:

We have not omitted the apostrophe ' in the punctuation mark list. This is quite important as we do not want to split words like Let's, here's, or Mary's into two different tokens and change their meaning.
As you can see, tokenization can be a bit tricky, but regex can help you with it. Of course, there are a lot of ways to tokenize a text depending on the text type you are dealing with. We have presented you with one of the simplest ways to do it.
Conclusion
In this topic, we've seen examples of how regular expressions can help us with string processing. You can experiment further and implement other regular expressions to check whether a string is a valid email address or tokenize more complicated sentences.
To sum up, even simple regular expression patterns can be used to write powerful programs for real-life applications, including textual data extraction and substitution, web scraping, and many other natural language processing tasks.
"
246,Ordering and total order,789,9253,1784,https://hyperskill.org/learn/step/9253,"You've got two arithmetic sequences:

First:
11 12 20 6 9 7 14 1 16 13 19 8 2 4 18 10 17 3 5 15

Second:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

Which one is easier to remember? In which would you find the number 5 faster? It's quite likely that your answer to both questions would be that it's easier to retrieve information from the second sequence. The main reason for that is ordering.

Let's define what ordering means and then see how it works with different types of data.

Total order

If you're familiar with primary school arithmetic, you can easily distinguish the totally ordered numbers. For natural numbers, the smallest number is 1, then come 2, 3, 4, etc. This order has strict rules that we can describe formally.

We say that the sequence has a total order with the relation less or equal when for each \(a\), \(b\), \(c\) from this sequence the following statements are true:

if \(a \leq b\) and \(b \leq a\) then \(a = b\)
if \(a \leq b\) and \(b \leq c\) then \(a \leq c\)
\(a \leq b\) or \(b \leq a\)

You can look at the second sequence above and check if it is possible to apply these rules there.

Apart from numbers, we can put any other types of data in total order, all we need is to define the operation less or equal.

Lexicographical order

The way we compare strings differs from how we compare numbers. The more digits a positive integer has, the greater it is, but that's not true for strings. Their order is similar to the alphabetic one for the same case words.

The particular trait of the alphabetic order appears when we are comparing lowercase and uppercase letters. For example, in ASCII encoding, all Latin-script uppercase letters are less than any lowercase letter, which means that Z < a. Moreover, we can compare any symbols with letters because all of them have the mapping to integer values, and we know how to compare numbers. To compare two strings for the less or equal relation, do it step by step:

Compare each word letter by letter from the first position. When two letters in the same position differ, the order of words matches the order of these letters: cord < core.
When there are no letters left in one of the words, that word is always less than or equal to the other one, so ball < ballet. Note that the empty string is a prefix for any other string, so it's the smallest string due to the lexicographical order.

Chronological order

Can you tell what day was earlier: 1969-06-20 or 1965-03-18? The order of dates is straightforward as we compare them by year, then by month, and finally by day. When we determine the first difference between any two dates, we can identify which date comes earlier.

Almost nothing changes when you add time to date. You compare two timestamps step by step:

by year
by month
by day
by hour
by minute
by second

Just like in real life, the future dates are greater than the current time, and the past is less.

Application of ordering

Let's recall the sequence from the beginning of the topic:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20

The ordering has several applications based on its useful properties, so, looking at this sequence, we can:

compress the information (say, we have elements from 1 to 20)
look for elements faster (it's easy to find elements in it and answer what elements are not present)
analyze the structure of the data (by the glimpse, we can find the minimum and maximum elements in the sequence)

You can find applications for ordering in compression algorithms, search engines, databases, analytics tools, and many other programs.

Conclusion

Now we are familiar with the total order, and in this topic, we have defined:

the formal rules of total order
how to order numbers, strings, dates, and timestamps.
"
247,Sorting a list,914,10059,1799,https://hyperskill.org/learn/step/10059,"After you have learned how to create and perform basic operations with lists, it is time to explore how to put their items in the order you need. There are two similar ways to do this: the method list.sort() and the function sorted(list). They have much in common and take the same arguments, so let's see how they work.
The sorting
Invoking list.sort() as well as sorted(list) sorts the list in the ascending order according to the natural order of stored elements.

Note that the sort() method performs an in-place sorting, changes the original list, and returns None. sorted(list), on the other hand, creates a new sorted list while the original one remains unmodified.

That is why an attempt to use print(numbers.sort()) will lead to the None result while the same attempt with sorted(list) gives you the result you need. This is the important distinction between sorted(list) and list.sort().
The sorted function has one more feature: it works not only with lists but also with other collections, so you can also sort sets, dictionaries, tuples, and so on. The list.sort() method, on the contrary, works only with lists.
To sort a list in the descending order, you need to specify the reverse argument as True (it's False by default).

Both sorted(list) and list.sort() can sort strings according to their lexicographic order (as in a dictionary).
However, if your list has uncomparable types (like strings and integers together), an error will occur both in list.sort() and in sorted(list):
The key
There is one more argument that can be used with both functions. You can pass the key function, this function will be applied to each element in the list, and the list will be sorted depending on the results. For example, you can use key=len to sort words by their length.

You can also use lambda functions as a key. For example, if you need to sort numbers by the remainder of dividing by two,  you can use a lambda function and the % operator. In the example below, 4 is moved to the first place (the remainder is 0), followed by the three other digits with the remainder 1. Note that the relative order of 7, 1, and 5 in the sorted list remains as it was in the initial one.

What is more, you can use custom functions for the value of the key argument. Let's say you have a list of float numbers and you want to sort these numbers by their fractional part. To do so, you can create a function that takes a number as its input and returns the fractional part of this number. The function below performs it by subtracting an integer part from the given number.
The reverse
There is one more way to modify the order of elements in a list; you can reverse them. It can be done with the help of either thelist.reverse() method or by using the reversed() function.
Invoking list.reverse() reverses the order of elements in the list. Just as list.sort(), it operates in place and returns None, so you can't assign the result to another variable, instead, the initial list will be changed.

The function reversed() returns a reverse iterator, by passing which, you can get the elements of the input sequence in the reverse order. To get access to the reversed list, you can write the following:

Pay attention that if you try to print the iterator without using a loop, you will not get the needed result:
Summary
In this topic, we have learned how to sort lists using the function sorted() and the method list.sort(); we've also found out the difference between them and their arguments. Besides, we have learned how to reverse elements in a list with the help of both the function and the method.
To sum up:

list.sort() and list.reverse() work only with list objects; they change the given list and return nothing;
sorted() takes any collection as an argument and creates and returns a new item from the given one;
reversed() can also take any collection as an argument but returns the reversed iterator of the object rather than the modified object itself;
list.sort() and sorted() can take the boolean parameter reverse to change the order of sorting from ascending to descending, as well as the key parameter to specify the sorting function.

For additional information about sorting methods, you can check out the Official Python documentation.
"
248,Bytes basics,624,8061,1904,https://hyperskill.org/learn/step/8061,"As we already know, a str object is a sequence of characters. More than that, these are not just ""some"" characters: these are Unicode characters. Now it's time to introduce bytes, a counterpart of the Python's string. As such, bytes data type was introduced in Python 3, and it has a twofold nature: it represents usual strings, easily understandable by a human reader, in the form that makes them more suitable for processing by the computer.

Functions chr() and ord()
To demonstrate the sophisticated nature of this data type, allow us to start from afar and introduce two Python functions: ord() and chr(). These are inverse functions that serve for converting Unicode characters to their respective code points — and vice versa. More precisely, ord() accepts as an argument a string consisting of a single Unicode character, and returns an integer equal to the code point assigned to this character in the Unicode; chr() in a similar manner allows you to convert an integer to the corresponding Unicode character.

By the way, ord() works behind the scenes when you perform a comparison of two strings! Let's find out more in the next section.
String comparison
In reality, the code compares strings' characters one by one. If the code point of the first character in the first string is bigger than the code point of the first character in the second string, then the first string is bigger than the second one.

If the code points of the first characters are equal, the same comparison is performed between the second characters of each string. This process continues until some respective characters are found not to be equal, or until one (or both) of the strings ends.

As you can see now, there's an easy way of representing string characters as numbers in Python. This is quite important since the computer doesn't know anything about Unicode and letters and symbols used by humans: to store and process information, a computer needs it to be in numeric form. The same applies to the information sent from one computer to another.
Therefore, Python has a special data type whose purpose is to represent strings as a sequence of numbers, and this data type is called bytes. Now we are ready to take a closer look!
Getting familiar with bytes
Any bytesobject is a sequence of integers representing single bytes. Each of these integers has a value between 0 and 255 (including 0 and 255), so there are 256 possible values, which is not arbitrary: each byte consists of 8 bits, and 2^8 is equal to 256. bytes objects, as well as strings, are immutable.
What's so peculiar about bytes? Firstly, when printed, they look like a string in quotes with a prefix b. This prefix is not a part of the actual data stored in the variable: it simply designates a bytes object. All the information contained in our bytes object is printed between quotes.

Secondly, don't be misled by bytes' string-like appearance: they are only printed in the way that makes them look like usual strings, so that we, human readers, could understand more quickly what's being stored inside the object. Deep inside bytes objects are still sequences of integers, as we've stated above.

Such behavior reflects the dual nature of bytes: they contain strings in the numerical form. So, they store data in a form that is suitable for the computer to read, but they are printed in a way that is more convenient for a human.
Why is '1' equal to 49, and '2' to 50? That's where chr() and ord() come in. As you remember, they convert symbols to numbers and vice versa by means of the Unicode table. So, when you create a bytes object for the string '1', an integer returned by the ord() function for the string '1' is actually being stored within the object. And when you print the object, a character returned by the chr() function for this integer is being printed.

But items of the bytes objects are not always printed as single characters. They only do so when their value is within a certain range: if the integer value is somewhere between 32 and 126 or equal to any of these numbers, a corresponding Unicode character will be printed. Otherwise, a hexadecimal escape sequence will be used to represent this integer: it'll usually have the form like '\x01' or '\xdf', (i.e., a backslash followed by 'x' and two other symbols) with the exception of some sequences like \t, \n, that you probably see often even without using bytes.

You must have noticed that in the last example a bytes object was created in a way differing from the ones used before. If you wish to know more about all ways of creating bytes objects, check out the next topic named Creating bytes.
Summary
Python 3.x has immutable bytes data type, used for representing strings as sequences of single bytes;bytes objects consist of integers with values from 0 to 255 (inclusively);characters of usual strings are converted to bytes by means of Unicode table that matches every character with its unique numeric code point;ord() built-in function serves for converting a Unicode character to its respective code point. This function also explains the method of string comparison in Python;chr() built-in function converts an integer, representing a code point in the Unicode table, to the respective character.
"
249,Creating bytes,625,8069,1933,https://hyperskill.org/learn/step/8069,"In general, most operations that you can perform on strings may be also performed on bytes objects. Most probably, though, the only thing you'll actually ever need to do with bytes is to simply create them from objects of other data types and then convert them back. Why do bytes even exist then, you may ask? The thing is, they may be useful in dealing with relatively low-level applications, where binary data is needed. The http and socket modules are good examples: sending and receiving data through sockets is only possible with the bytes data type.
Thus, we're now going to learn how to perform the conversion of data types when it all comes to bytes.

b prefix
The most obvious way to create a bytes object is to write a string with a b prefix. But be careful: this works only for characters that can be encoded by a single byte, i.e., characters whose Unicode code-point lies between 0 and 255 inclusively: ASCII and extended ASCII characters. A string containing characters other than these will lead to a syntax error.
What is more, in bytes literals only ASCII characters are permitted: that is, Latin alphabet, digits, and some basic punctuation characters. Other binary values (extended ASCII, with the Unicode code point between 127 and 255) must be entered into bytes literals using the appropriate escape sequence. Consider the example below:
It doesn't seem very convenient, right? Let's take a look at some more flexible ways of creating bytes.

bytes()
You can still convert such strings into bytes by means of other ways, though. The first of them is bytes() function, whose arguments are the string to be converted and the name of the output encoding.
You can approach the task of creating a bytes object from a different angle, namely, by using integers. If you need only characters whose Unicode code points lie between 0 and 255, the same function bytes() can do the job. It takes a list of integers between 0 and 255 and converts them to a bytes sequence. You don't need to specify the encoding in this case:
However, if you put a single integer (equal to zero or greater) directly as an argument of the function bytes(), you won't get any errors and you'll still create a bytes object. The difference is that it'll be a string of zero bytes, and it'll have the length equal to the specified integer.
In case you want to change the data later, use the mutable counterpart of bytes() — bytearray(). It returns a bytearray object that has most of the methods that the bytes type has.
Apart from this universal way of creating bytes objects, there are also some that are used specifically for strings or integers. More details in the next sections.

encode()
The string method for creating bytes is called encode(). It's basically the same operation as bytes(), but under a different skin. The default encoding is utf-8, but you can specify it, if needed.

Now that we've learned to convert strings to bytes, let's see what we can do with integers.

to_bytes()
As for conversion of any separate integer of every possible value, the integer method to_bytes() can be applied. Two arguments, apart from the integer itself, are required: the number of bytes to be used for representing the integer, and the byteorder, either 'little' or 'big', specifying the order in which the bytes should be printed: from the least significant byte to the most significant one in case of 'little', vice versa for 'big'. If the given integer represents an ASCII character, it will be shown (like in the first example below), and if not, an encoded sequence representing the character will be printed (examples two and three).
Don't forget to put the integer you are converting in parentheses. The absence of parentheses will cause a syntax error.

Alright, now that we've learned how to create bytes, it's high time to learn how to ""undo"" them into more familiar data types!

decode()
There are reverse procedures for converting bytes to strings and integers. For strings, these are str() with an obligatory argument specifying encoding, and method decode() (as with encode(), the default encoding here is utf-8).
Don't forget that this method only works for strings. There's something different for integers.

from_bytes()
This all is a bit more tricky with integers, since the method from_bytes() should be called in a following fashion (only byteorder argument is required):
So, make sure to use int class to call this method.

Summary
Let's sum up what we have learned in the topic:

bytes() can be used both for converting strings and lists of integers to bytes, or creating strings of zero bytes
a byte string can be simply created by means of writing it with b prefix
encode() is for converting strings, to_bytes() serves for converting integers
decode() can be applied for converting bytes to strings
from_bytes() helps you to convert a bytes object to an integer.
"
250,Socket module,699,8670,1936,https://hyperskill.org/learn/step/8670,"In the world where the Internet helps to connect the opposite sides of the Earth, it is important to know how this connection is done. The flow of the data in the network has a direction. To allow for this directed flow, we need a start point A and an end point B, so that they, knowing the locations of each other, could open a connection by means of a certain mechanism called sockets. Although sockets usually operate ""behind the scenes"", hidden from our eyes by browsers and applications, right now we'll learn how they help to provide the connection between different devices within the network.
What is a socket?
Here's a classic real-life analogy to explain what sockets are and how they work. Imagine an information office you want to visit (let it be a metaphor of, say, a website or a process which you establish a connection with). It is situated at a particular address (hostname). When you come there, you see a lot of tables (ports). Some of them are empty, but at the others, there are consultants (server sockets) who are ready to help you with your question. To get the information you want, you (a client socket) need to come to some of such tables, start a conversation (establish a connection), ask your question (send the request) and get an answer (receive the response).
In formal terms, a networking socket is an interface that plays an important part in enabling the connection between two processes exchanging data. Specifically, there is a socket at each end of the connection, so it performs as an endpoint, and it can send the data to the other end and receive the response, if the socket on the other end sends it. Sockets at the opposite ends are not identical in their functions: one of them is a server socket, a listening socket bound to the particular address and waiting for some client socket to connect for data exchange. For the client socket to find the server and successfully connect, the client socket must as well be provided with the address to which the server socket is bound. This address consists of a hostname (IP address or an Internet domain) and a port number.
Now let's move from theory to practice and take a look at socket module in Python!
Creating a client socket
Let's start with an easy one — a client socket. Keep in mind, though, that creating a client socket only makes sense when you already have something to connect to, for example, when you create a server socket and run it yourself or when you simply know the address of some listening socket you need.
To provide the socket with the address to connect to, we should create a tuple containing two elements: the first one is the hostname, the second one is the port. Remember, the hostname is always a string, while the port is an integer. So far, let's take a string '127.0.0.1' as a hostname — this is the address that allows your computer to establish a connection with itself (this address is needed when there is a server running on your computer).
As a port, we can use any number in the range from 0 to 65535. However, usually, only numbers starting from 1024 are chosen, since ports from 0 to 1023 are system ones.
Then we combine these two parts into a single tuple.
The next step is to establish a connection to the given address. This can be done with the help of connect() method of the socket we've created.
Now let's see what we can do with our socket next.
Sending data
If the connection is successful, nothing prevents us from finally sending our data to the server socket. send() method is what we need for that.

An important note: what you send through your socket should be in binary format. So, whatever data you want to submit, make sure you've converted it to bytes data type first.

Note also that you can't send an empty byte string through a socket. It only happens automatically when you close the connection.

Usually we want not only to submit our data, but also to receive the server's response to it, since it may contain valuable data (for example, if you send some inquiry to the server, the server socket sends you back the results of the search). Let's see how this is done!
Receiving data
We can receive the response of the server socket with recv() method. recv() requires a buffer size as an argument — an integer argument specifying the maximum number of bytes to be received at once. The returned response of the server is also always in binary format, so you may want to convert it back to a string.
We can repeat the process of sending-receiving the data if needed. Once we're done, we simply end the connection with close() method.
So, we've gone through the main stages of the socket's life. Let's recall them all once again.
Overview
If you run this code just like that, without creating a server socket first, don't expect it to work. You'll get the ConnectionRefusedError: this means that connection has failed because we tried to connect to the address that no server socket listens to. This is logical since hostname '127.0.0.1' indicates that we connect to our own computer — and there's no server socket running. To fix the error, you should bind a server socket to the same address and run it.
So, as we see, the structure of a client socket is very simple: connect, send the data, receive the answer, end the discussion by closing the socket. The things are a bit more complicated with server sockets, but that's a story for another topic.
with ... as
Sockets, just like file objects, can be used as context managers. In practice, this means that we can simplify the process of ending the connection by using the with keyword. Let's take a look at the same socket we've been working with, but used in this construction:
As you can see, not much has changed but here we can be sure that the connection will be safely closed and no errors will arise!
Summary
Let's go over the main points of the topic:

sockets are endpoints of the connection between two processes
there are server sockets listening to particular ports, and client sockets that initiate the connection and send the data first
a socket needs an address to bind or connect to, and it consists of a hostname and a port number
the data sent through sockets must be bytes
the main steps of the client socket performance involve connection, sending the data, receiving the response and closing the connection
"
251,Flush and file arguments of print,618,8006,1945,https://hyperskill.org/learn/step/8006,"In this topic, we will discuss arguments that can be extremely helpful when working with files. As you know, the print() function takes keyword arguments sep and end. Now it's time to learn that it takes two more: file and flush.

The file
The file argument is in charge of where the function will write given objects to. By default, it is sys.stdout, the standard output stream that prints objects on the screen.
Instead of the default value, you can specify the file parameter with the name of the required file. The file should be opened in advance, and make sure to close it when you are done:

Alternatively, you can set file to sys.stderr, a standard error stream. It is very useful when debugging a small program because you can print out errors using this method:

The flush
The last argument is the bool parameter flush. It can only be used together with specifying the file argument. False by default, if set to True, it forces the stream to be flushed. But what exactly does it mean?
When writing to files, the output is buffered in memory and accumulated until the buffer is full, at which point the buffer gets flushed, so the content is written from the buffer to the file. The thing is, it's just more efficient to flush the buffer fewer times, and the user is less likely to notice if the output is not flushed after each new line. The default size of the buffer depends on the operating system but it is also possible to specify the desired size of the buffer when opening the file (using the keyword argument buffering).
Getting back to our topic, if flush=False, writing to file takes place when the buffer is full (or when the file is being closed even if the buffer is not full yet). And if flush=True, the input is written to the file straight away. Below are two examples to understand the difference.
Without the parameter:

time.sleep(5) makes the program stop for five seconds so that we can notice that the file remains empty till the program is over.
With the flush parameter:

Here, if you open the file before the program is over you will see that some digits are already there.

Note that file and flush, just as sep and end, are keyword arguments. You should explicitly specify them when calling the function.

Print vs Write
You might wonder if there's any difference between the methods file.write() and print() with the file argument. Though they do roughly the same (write a string to a file), there are a few things to keep in mind:
print() renders the given objects, that is, converts them to strings, and there's an opportunity to specify the sep and end arguments or leave the defaults (a space and \n correspondingly), as well as either to flush the stream or not.file.write(), on the contrary, writes the exact string that is given only when the buffer is full. This also implies that it takes only a string as an argument, and if we want to print a number, for example, we should explicitly convert it into a string.
The first one is a bit more flexible and might be helpful when we don't want to think about rendering objects ourselves, while the second one offers a conscious approach due to explicitness.
Conclusion
Arguments of the print() function discussed in this topic provide a very useful opportunity not only to write objects to the system's standard output, but also to make them look like error messages or write them to files. With the help of these arguments, we can do so either straight away or (by default) when the buffer is full, and without rendering the objects ourselves. Keep that in mind when coding further!
"
252,Containers,1578,15082,1993,https://hyperskill.org/learn/step/15082,"The container allows the application to work in almost any environment, providing quick deployments and reproducible builds. Containers allow us to run applications on non-native OS, for example, Linux applications on Windows or macOS.

What are containers?
We call technology the container technology if it allows using the running processes of applications and their dependencies in isolation. Container technology simplifies builds of production-ready applications and provides high-level tools to create a piece of software packed with all dependencies.

The most significant feature of containers is isolation. Various dependencies, libraries, and files of the applications are packed into a container. In this way, the application that works in one place can work in any environment. Different configurations of the same application become available with environment variables.

Multiple containers can run on a machine with the host's operating system isolated in the core. In short, containers can handle any task, despite their small size, and eliminate the need to purchase extra storage space.

Examples of container management software are Docker, Google Kubernetes Engine, Microsoft AKS, AWS Fargate.

What problems do containers solve?
Containers help us overcome such problems as:
Missing libraries, different versions of different applications, or incorrect application dependencies.
Port conflicts between programs running on the same computer.
Overuse of processor and memory-style resources by an application.
The difficulty of installing, starting, stopping, and uninstalling applications.

How do they do it?
To understand how the containers do such tasks, let's dig into their internals.

The three pillars of container technology are namespaces, control groups, and union file systems. Namespaces provide their own view of the underlying Linux system by limiting what containers can see and access. When you run a container, containers create namespaces that the particular container will use and have multiple namespaces that present different information about the operating system. For example, the MNT namespace limits the mounted file systems a container can use, or the USER namespace is used to isolate users in each container.

Control groups are also called cgroups. It is a Linux kernel feature that isolates, prioritizes, and calculates the resource usage (CPU, memory, disk I/O, network, etc.) of a set of processes. Control groups can also impose strict limits on usage, ensure that containers use only the resources they need and, if necessary, set limits on the resources a container can use.

Isolated Union file systems used in containers are stackable. This system helps avoid duplication of data every time you deploy a new container.

What are the advantages of containers?
Containers have many advantages. They also have been preferred by quite a lot of users in recent years. So what are the advantages of containers?

Deploying an existing service with containers takes just a few clicks or commands. On the other hand, you'll probably need to learn how to configure containers properly which takes time and practice.

With the file describing the content of a container, we can start new containers or create more containers with already running applications with just a few commands.

A consistent test environment is provided by following a certain pipeline when using containers.

Thanks to the mass spread of container and cloud technologies, companies can deploy their software almost in any cloud provider with ease.

Conclusion
In summary, containers become more popular every year, because making things lighter and faster. What you will learn in this topic and the upcoming topics will be useful in all areas of software development, as containers are becoming more and more common.
"
253,"Introduction to docker, installation",1691,15850,1994,https://hyperskill.org/learn/step/15850,"After creating a product, you may face certain problems when presenting it to customers. Some elements may differ on other platforms: OS, configs, external libraries. Also, different methods are used to create the whole infrastructure. In this topic, we'll look at Docker, one of the most popular solutions to ease up the process of delivering an application.

What is Docker?

Docker is a technology that provides virtualization with hundreds or even thousands of isolated and independent containers on the same operating system. However, each container has its own operating system, they do not have their own operating system kernel and use the host's one. Docker runs an application with a chosen operating system and version in isolation from other applications. It utilizes the container structure and the images downloaded from the registry, for example, the most famous is Docker Hub. In this case, it eliminates the dependency problems and makes containers with applications self-contained.

Similar to how a virtual machine virtualizes server hardware, containers virtualize a server operating system. Thanks to this operating system, we can install the necessary programs, and run our applications in this container. Docker provides us with simple commands to do it.

Docker architecture

Docker is a system that emerged with the support of the Linux kernel, so it runs on the Linux operating system. So how can Docker be used on both Windows and macOS?

Docker has a client-server architecture. It has a background daemon process and a CLI interface to work with containers. On Linux, both the daemon and CLI can run directly on the host's OS. In Windows and macOS, the Docker CLI runs in the host operating system, and the daemon runs on the virtual machine with the Linux OS because the daemon needs a Linux OS kernel.

The heart of the Docker –the daemon process– works with three types of Docker software components:

Client
Objects
Registry

Now, let's review them one by one.

Client

Docker has the client-server architecture. So the client runs on your own host, and the server side is the host where the Docker daemon runs. The Docker client can communicate with more than one daemon.

Also, the client offers us a command-line interface, allowing us to create, run, and stop application commands.

Registry

The Docker registry contains Docker repositories that can contain more Docker images.

Thanks to the Docker registry, you can store and upload images. For example, Docker Hub is a public registry that anyone can use. In short, images are kept in the Docker Registry.

You can even run your own private registry on this platform. It serves in Docker Hub Cloud, there is also a Private Registry service for those who want to keep the images in their private cloud. 

Objects

You can create new Docker images by combining such objects as:

Image
Container
Network
Volume etc.

We have already mentioned containers, and now we'll talk shortly about images. We'll take a look at the other objects in the upcoming topics.

Each container is an image with a readable/writable layer on top of a bunch of read-only layers. A Docker image is a collection of files and applications that will be installed and launched in containers. You can visit Docker Hub to review Docker image files.

As you can see, there are many images in the Hub. In fact, there is a type of file that describes the contents and descriptions of the built images named Dockerfile. We will refer to this file in the next topics.

Docker pros and cons

So why Docker? Now let's summarize the advantages that docker provides us with.

It makes it easy for you to build scalable data processing systems and conveniently manage platforms for your developers.
There is no need to set up a new environment to use it.
It supports different operating systems, such as Windows, Linux, macOS.
It has a large community. Finding answers to your questions is pretty easy.
It can be integrated with the Docker cloud services.

Now let's summarize the disadvantages of the docker.

To create your images, you need to learn the syntax of Dockerfiles.
To launch a lot of containers, you need to know how to work with the orchestration systems.
It gives a slight overhead relatively to running on the bare OS.
There are some performance issues in non-native environments.

How to install Docker?

Installation on various OSs may differ, so we're providing you with links to official documentation where you can find all the necessary details:

macOS
Windows
Ubuntu
Other

There is an option to try the docker online too. Play with Docker is a site that allows users to run Docker commands.

You can build and run Docker containers and even create clusters in Docker Swarm mode and access a free Linux Virtual Machine in your browser. Thanks to this site, you can try Docker commands without installation.

Conclusion

The most important things to remember about Docker:

It is not a hardware virtualization technology
It uses a layered file structure
It is a container management tool
It has a fairly large ecosystem
It supports multiple platforms

Docker is a technology that provides virtualization with independent containers on the same operating system. In addition, Docker takes the hassle out of running applications in different environments.

Read more on this topic in Bridging the Gap by Understanding DevOps on Hyperskill Blog.
"
254,CSV,1382,13164,2283,https://hyperskill.org/learn/step/13164,"Introduction

It is convenient to store different data in different formats. For example, it is most logical to save the text in a text file like .txt or .docx. But what if the data is in a form of a table with a lot of headers and cells? There are different formats for storing such tabular data. And today we will get acquainted with two of them: the CSV format and the TSV, which is similar to it. Let's start with CSV.

What is CSV

CSV stands for comma-separated values. In fact, a CSV file is a simple text file with numerous lines. Each line of the file is a data entry containing elements separated by a comma. Let's have a look at an example of CSV:

Our file is called cars.csv, we opened it with Libre Office Calc (see picture on the left). The right picture shows the same file opened in Notepad. It contains information about different cars, their models, and the production year.

The first line is a line with column titles separated by commas: Car brand, Car model, and Production year. It's an optional header line, so if you are going to carry out any manipulations with the data, then you need to make sure that the line with the headers is separate from the values. All the other lines (entries) with certain values contain information about cars.

CSV not only stands for comma-separated values and implies a certain standard for tabular data with a comma delimiter, but has another more general meaning. This is an umbrella term. Often CSV denotes data separated by any delimiter. That is, instead of a comma, there can be, for example, spaces, a semicolon, any character that the user wants, and the tabulation inherent in the TSV format can also be such a separator in the CSV file. Thus, these alternative delimiter-separated files are often given a .csv extension despite the use of a non-comma field separator.

After we got acquainted with CSV, let's find out how to work with it.

Working with CSV

To work with a CSV file one just needs to open it. The CSV file format is supported by almost all spreadsheets and database management systems, including LibreOffice Calc, Gnumeric, Emacs, Microsoft Excel, Numbers, SpreadsheetPro, CSVed, KSpread, and Google Sheets. Also, CSV import and export is possible in many engineering packages such as ANSYS and LabVIEW.

For example, that's how a CSV file in Libre Office Calc looks:

Moreover, one can work with a CSV file using programming. For example, in Python one can import either csv or pandas module to open, edit and create tables in the CSV format. In Java one may use CSVReader, and in C Sharp there is a  CsvHelper module. It's also possible to work with CSV files in C++ and PHP and some other programming languages.

So, now we know how to work with CSV files. But what about the other similar TSV format? Let's take a look at it.

What is TSV

TSV is the second most popular delimited file format, which is the reason why it got its name and even its .tsv extension. It stands for tab-separated values. So, TSV also allows you to store tabular data, but it provides another delimiter. Each record in the table is a line of a text file. Each field of the record is separated from the others by a tab character, more precisely a horizontal tab. It is so because the comma is quite common in text data, in the spelling of numbers according to some national standards, in contrast to the tabulation. Thus, it does not need to escape the comma in the middle of the values.

Visually, the TSV file looks exactly the same as the CSV file. So we can open a TSV file with the same spreadsheets and database management systems as CSV.

Why CSV

CSV and TSV files are often used for data interchange between software with different internal file formats. It is especially useful in business tasks. More specifically, one can move data between different vendor implementations of spreadsheets, databases, and data from websites such as banking transactions.

That's why some choose CSV. Moreover, the CSV format has several notable advantages. CSV files:

Provide a straightforward information schema;
Can be viewed and edited even in a text editor;
Are human-readable;
Are simple to create and parse;
Are compact.

On the other hand, there are some disadvantages:

There can be only a single sheet in a CSV file;
They keep only raw data, no macros, and formulas;
No distinction between text and numeric values;
No standard way to represent binary data;
Problems with the distinction between null values and empty strings.

And now you know, what CSV is for and what advantages and disadvantages this format has.

Conclusion

To sum up,

One can store tabular data in CSV and TSV formats;
CSV stands for comma-separated values and TSV means tab-separated values;
These file formats are supported by almost all spreadsheets and database management systems;
CSV also denotes the more general concept of ""delimited data"", where the delimiter can be almost anything.

So, are you up for some challenge? Proceed to the tasks and see how well you understood this topic!
"
255,Working with CSV,1113,11724,2320,https://hyperskill.org/learn/step/11724,"In previous topics, you have learned how to work with a text file. It is a useful skill to master. Right now, imagine that you were hired as a programmer at a well-known company. During your first day, you were asked to save information about every crime in your city. It includes the date, the district, exact time, etc. You are horrified because 100000 crimes have been committed during this month!
It is inconvenient to store this much data as a file with plain text. Your information is going to be very hard to read. Don't get upset! You can use CSV format to save all your information. In this topic, we will discuss what a CSV file is and how to work with it.
What is CSV?
CSV stands for comma-separated values. A CSV file allows you to store your data in a tabular format. In fact, it is a simple text file with numerous lines. Each line of the file is a data entry. Each line contains elements separated by commas. The CSV data can be easily exported to other spreadsheets or databases. Let's have a look at an example of CSV:

Our file is called City_crimes.csv, it can be opened with Microsoft Excel (left picture). The right picture presents the same file opened in Notepad. It contains information about different crimes registered in an imaginary city. The first line is a line with column titles separated by commas: Crime, Time, and District. There are other lines (entries) with certain values that characterize a crime. They are also separated by commas.
If you don't like commas, you can use any other separator instead, but when reading your CSV-file, you need to know in advance which separator is used.
Let's see how we can work with CSV in Python.
Reading CSV
We can read a CSV file like any other text file in Python. Take a look at the code below. We are about to open the City_crimes.csv file from the previous section.
There is nothing extra about reading lines from files, but it may not be very convenient to obtain particular information from the lines. We can use the line.split() and pass a comma as a separator. Now let's have a look at the updated snippet.
We have the resulting data lists. Note that the last element in each list has the \n symbol of a new line, it is recognized as the end of a data entry. Now our results are easy to process, and we can extract any information we need. When you don't need this file anymore, don't forget to close it.
In the following section, we will discuss how to write to CSV files.
Writing to CSV files
As you can guess, the idea of writing to a CSV file doesn't differ from the idea of writing something to any text file. Imagine your colleague brought you a new report in which you saw a crime that isn't stored in your CSV file. So, you decided to append it to the end of the file. What do you do? You create a list in which you write down all the necessary information about the crime, then you join the elements of the list with a comma, write the data into the file. Finally, you need to close the file.
What happens to our file?

As you can see, our data entry is saved at the end of the file.
All ways of working with a CSV file described above are probably familiar to you. However, there's another feature that can be useful: the special CSV library.
CSV library
The CSV library is the main tool for working with CSV files. It is built-in, so you can just import it.
To read data from a file, you should create a reader object. In the example below, the csv.reader returns a reader object that will iterate over lines in the given CSV file.
As you can see, the result is the same as before. Each line returned by the reader is a list of string elements with the data.
 

When we open a CSV file, we need to specify newline=''. It's better to do it this way because if the newline is not mentioned, the older versions of Python will add the line break after the last element.
 
Moving on with our example, let's say your boss asked you to print some of the results: the crime and its time. She also asked to make them readable for other people. Below is an example of how we can improve our code to do that.
What have we changed there? First of all, we added the line counter. If it is equal to 0, it means that we are reading the first line, so we'll print the names of the columns. If it is not 0, then we print all the necessary information by extracting it from the lists with the help of indexing. Don't forget that the indexing of lists starts with 0.
CSV writer
Another object that is widely used in the CSV library is a writer object. As the name suggests, it helps to write information to a file. Let's say that policemen have found some people who had committed those crimes. Now you have to create a new file with their names, age, and height. So it would be:
In this example, we created a new file and then used the file_writer.writerow() method to write new information. The lineterminator parameter is the separator between the data entries. The first data entry contains names of columns, all the others contain the perpetrators. Now we can also have a look at the file we created.

You see, it works well!
DictReader VS DictWriter
Apart from all mentioned above, the CSV library also has two magical classes: csv.DictReader() and csv.DictWriter(). They represent each data entry as a dictionary. The dictionary keys are the names of our columns, and values are corresponding data. As it is a dictionary, you can print particular information using keys. Mind the following code with csv.DictReader().
A similar tool for writing information is the csv.DictWriter(). Let's use our criminals.csv file and write something about criminals again to that file.
First, we created a list of column titles that will be given as an argument to the fieldnames parameter. This list is a sequence of dictionary keys, it identifies the order in which values will be written to the criminals.csv. Then, we stored the titles using the writeheader() and the data using the writerows(). The CSV file will look the same as we have shown in one of the previous sections.
Summary
Working at a well-known company is a tough job but we hope that it will be easier for you as you learned how to deal with CSV files. So far, you know:

that CSV stands for comma-separated value, this file format is used for storing tabular data;
how to read data manually from the file and write information to it;
that Python has the built-in CSV library with useful csv.reader() and csv.writer() methods;
that csv.DictReader() and csv.DictWriter() help you represent data as dictionaries.

Of course, we can't cover all the aspects. If you strive to learn more, read the official documentation and PEP 305. Now let's proceed to the tasks to check your knowledge.
"
256,Real-time interpreter: Shell,633,8133,2370,https://hyperskill.org/learn/step/8133,Error extracting text: The `response.text` quick accessor only works for simple (single-`Part`) text responses. This response is not simple text.Use the `result.parts` accessor or the full `result.candidates[index].content.parts` lookup instead.
257,Experiments with Python shell,646,8238,2371,https://hyperskill.org/learn/step/8238,"You already know how to start the Python shell and run some simple code there. Let's see how to use it for experiments. We will illustrate all of them with IDLE samples.
For instance, if you want to study a new module or library, you can conduct some code experiments in the Python shell to understand how to work with it. You can also implement your functions and classes in the shell and test them before including them in the final script.
Methods, modules, and functions
Imagine you've just heard about the method type() and want to learn more about it. You can simply start the shell and, using your own examples, see how it works:

The same can be done with modules:

The math module contains tools for mathematic calculations. In this example, we have imported it and tested its function that returns the square root of the given value.
This function works so that if we pass a non-numerical value as an argument, e.g. a string, it will return a TypeError.

If we don't want the program to stop executing in such cases, we can alter the method ourselves. That's how we can implement and use our own functions in the shell:

This is a simple modification of the math.sqrt() function that returns None if the passed value was neither an integer nor a float. So, in this experiment, you've found out how to implement your own function in the shell, learned how to use the type() method and got to know the sqrt() function of the math module.
Remember: everything you do in IDLE or command line shell disappears once you close it; you won't be able to use this code afterward. On the other hand, it's good because you definitely won't break anything in the program that you have copied in the shell and work with it there.
Magic? Autocomplete!
The Python shell also has an autocomplete function which is very useful when you're studying new things. In case that you don't remember the exact name of the method you'd like to use or even have no idea how it is called or you want to look up which methods are in the module, type a module name and a dot, then wait for a couple of seconds — the shell will help you with the list of available methods.

The next beautiful thing there is autocomplete for names of functions and variables. Use the TAB key for the shell to offer the function or variable name for you. You just need to type first letters and press TAB. In case of several names, you'll see a list of them:

This won't work if you launch the shell from the command line interpreter.

Summary
The Python shell provides a perfect opportunity both to play around with new modules and to refresh your memory about familiar ones. You can quickly test how methods and functions work, look up which methods an object has or which functions there are in any module. And such a useful option as autocomplete can help you with that!
"
258,Debugging in shell,647,8244,2372,https://hyperskill.org/learn/step/8244,"You've already learned how to start the Python shell and experiment there with modules and functions. But the thing is, the more code you write, the higher chances to get a bug. A bug is an unexpected error in your code that is usually hard to find. The process of finding and fixing bugs is called debugging, and it's another thing the Python shell can be used for.
IDE (Integrated Development Environment) is thought to be better for debugging, and we'll study how to use JetBrains PyCharm for this purpose in another topic. However, IDLE also provides useful tools for debugging, so let's see how it can be done.
Debugging
There may be different reasons to check your program: e.g. you get an exception in your code and don't understand where it comes from, or the code doesn't work as intended. In such cases, it's a good idea to use the shell to find out what's going wrong.
Let's see how the debugger works in action. Say, we have written a function to generate passwords:
It works fine but let's improve it a bit so that it doesn't use confusing characters for a password, such as “0” and “O”  or “1” and “l”:
After these changes our code doesn't work correctly: every password we get contains only those characters.
Using IDLE's debugger will help us find out what's happening inside the function.
Theory
First, import the modules random and string, then copy the function to IDLE and press Enter to see the prompt >>> again. To initialize the debugging mode, click ""Debug"" --> ""Debugger"" from the menu above. You'll see “DEBUG ON” in IDLE, and a new window will appear. Check all checkboxes so that we can investigate all options the IDLE debugger provides.
To start debugging, just call the function from the shell, i.e. type password_generator(4) and press Enter. The debugger window will change: it hasn't executed any code yet but we can see the line of code it has paused at, as well as global variables.
Now, a few words about what can be found in this window.

In area 1, there are a number of buttons. With their help, we can control the process of debugging,

Go runs the program as usual until input is requested or until the program finishes. In our case, there would be no difference with the regular run of the program.
Step serves to go through the code line by line: the most helpful action when debugging. If the line to be executed calls a function, the debugger will go to the first line of the function definition (""stepping into"" the function). If we press this button now, we will find ourselves at the line where the chars variable is defined.
Over is similar to the ""Step"" button, except that if the statement to be executed has a function call in it, the debugger executes the function without showing any details: it ""steps over"" the function, returning the result and pausing again. However, in our example, if we press ""Over"" in the beginning, the result will be the same as with the regular run of the program: debugger will execute the password_generator() function and pause; but this function is the only piece of code we have for debugging right now.
Out is used when we are inside some function's code. It finishes execution of the function as it would do regularly, returns the result, and pauses: we ""step out"" of the function. Instead of clicking ""Step"" repeatedly to jump out of the function, we can simply use ""Out"".
Quit stops the execution of the entire program. This is helpful if we must start debugging again from the beginning of the program.

Area 2 contains checkboxes:

""Stack"" is what we can see in area 3. It shows which line and from where is executed.
""Locals"" (area 4) and ""Globals"" (area 5) contain lists of local and global variables as they change. Remember, local variables are those created inside a function whereas global variables are those created outside of any functions.
""Source"" is helpful when we use some functions or classes from other modules. If it is checked, the module source file will open when we go through lines addressing it, and the corresponding line in the module will be highlighted in gray. In our example, when we reach the line char = random.choice(chars), the file ""random.py"" will open so that we can see what is happening inside the function choice() there.

Practice
Once we understand what's in this window, let's proceed to debug our function.
Press the ""Step"" button several times and carefully look at what is happening in the debugger window. Once you have reached the line where our function initializes the char variable, check the value of this variable. If you see that some line wasn't executed, it means that you need to double-check the line with the if condition:

Ah, that’s it! The condition is wrong, we need to check if it’s NOT in confusing_chars. Sometimes we need to sleep more, sometimes we need a coffee break, otherwise, we can make errors in our code.
After changing this line your function works perfectly!
All glory to the Python shell and debugging! However, you might want to look at this visualization. It might help you to better understand how the code above works.
Conclusion
The debugging process in the Python shell is quite simple and clear: it allows a user to run a code line by line to find errors and fix them.
"
259,Avoiding bad comments,431,6440,2439,https://hyperskill.org/learn/step/6440,"As you already know, a Python feature (beloved by all Python programmers) is its well-readable syntax. However, apart from the syntax itself, there are other important things that contribute to the readability of your program. We assume that you are already familiar with comments and how they help in learning a new language.
In real programs, comments become especially important as the program gets bigger and more complicated. Without them, things may get confusing even for you within a few months after writing the program, not to mention other developers who see your code for the first time. However, there is also a downside of making comments, meaning that more is not necessarily better, and we will discuss it below as well.
When not to write comments?
This may sound strange but sometimes it's better not to write comments at all. Carefully written, they can indeed contribute to the readability of your program, but it doesn't mean you should include them wherever you can. On the contrary, many programmers are convinced that a good piece of code doesn't require any comments in the first place because it is so transparent and accurate. That is what we all should aim at. So, if the code can be made self-explanatory, comments are unnecessary, and it's better to change the code rather than make comments. Let's highlight cases when developers need to comment less.

If a comment explains a variable/function, you can usually delete the comment and explicitly name the variable/method itself. Compare the following lines of code:

Avoid writing obvious comments, like the one below. They make your code redundant and even harder to read. You should always seek to follow the D.R.Y. (don't repeat yourself) principle, not W.E.T. (""wrote everything twice"" or ""wasted everyone's time"" for more cynical ones).

If you see a way to alter your code so that comments would become unnecessary - you should do that.

That is, if you can avoid commenting — you'd better do. Then your code would be clean, wouldn't be overloaded with unnecessary details and wouldn't become more complicated rather than clearer for readers to understand.
How to write good comments?
Now, let's turn to cases when you decide to write a comment. The main thing to remember is that comments should be easily understandable by anyone, be that Future You or some other programmer. Here are some tips on how to achieve it:

Generally, comments should answer the question ""why"" as opposed to ""what"". However, it may be useful for beginners to write comments for themselves explaining what the code does, especially when using a newly learned syntax expression, e.g.:

Make sure that your comments do not contradict the code (that happens more often than you can imagine!). Wrong comments are worse than no comments at all.

Do not forget to update the comments if you modify the code. It will only confuse the reader instead of helping them. In the example below, the variable ""counter"" used to be designated as ""i""; the programmer changed its name in the code but not in the comment.

Following these pieces of advice, you can write code that is clean, organized, easy to understand, and pleasant to read.
Conclusion
When annotating the code, it's important to know where to draw the line. Both over- and undercommented programs can be difficult to understand, which results in wasted and unpleasant time spent working with such pieces of code. So, you should always try to write comments carefully and only when it's necessary.
The simplest way to learn to do so is just by doing it. It's a good idea to start practicing when you only start coding because you will get used to it, and by the time some more complex problems should be solved, you will know how to write comments properly. From now on, try to include simple comments in your code to explain difficult moments that took you a while to understand. It is also useful to get back to review your older programs and see how they (including comments) could be enhanced.
"
260,Recursion basics,410,5984,2441,https://hyperskill.org/learn/step/5984,"In short, recursion in programming is when a function calls itself. It has a case where it terminates and a set of rules to reduce other cases to the first case. A function that can do it is called a recursive function. Sounds a little abstract? Let's try to get the main idea on the example.
Recursive matryoshka
Think of it like a Russian doll, matryoshka. It's a doll, or, more accurately, a set of dolls placed one inside another. You open the first doll, and there's the second, open this one and get the third, and so on until you get to this last doll, which won't open.

If we want to find the smallest doll, we take our big matryoshka and try opening it: if it gives in, we go on and on opening our dolls, until we finally find that tiny one. Recursion works in pretty much the same way, so let's use it as a metaphor to understand more complicated principles.
Imagine that you got a set of dolls like this as a present, and you want not only to find the smallest one but also to count them all. How many dolls do you have? No clue. Let's say we have dolls. As a true recursion enthusiast, you decide to count them recursively. Each time you are optimistic, so you ask yourself a question: ""Is this doll the smallest one?"" You manage to open the doll , but you are not losing hope. ""Oh well, maybe the doll won't open"". Finally, you get to the tiniest doll and exclaim: ""Here is an unopenable doll! This doll is the first!"" Now you understand that the doll that you opened the last was actually the second doll, then the third... And then you can continue till you find . 
Once again: first, you open them one after another, and only when you get to the smallest one you can count them, retracing your steps. If you were a recursive function designed to count the matryoshkas, you would work exactly as described.
Designing a function
Most (if not all) programming languages have recursion (in other words, they allow a function to call itself). It is very convenient to know how to create recursive functions, so let's now create an algorithm to count the dolls. Each recursive function consists of the following steps:

A trivial base case stops the recursion. This is the case we know the result for. For example, if we find a doll we can't open, we take it and proudly state: ""it's our smallest doll!""

A reduction step (one or more, imagine that our doll contains two dolls inside it!) gets us from the current problem to a simpler one. For example, if our doll can be opened, we open it and look at what is inside.

If we are talking about the trivial base of our function, it is just one doll. In other words, if equals , then we can stop thinking and just be happy.
We are now imagining the matryoshkas from the real world, so let's just say the following: if is not equal to , then it is bigger. In this case, we need to try our function on . Just bear in mind that we will need to add this one doll that we opened to the result later.
How to count X dolls:
    If X is 1, the result is 1.
    If X is not 1, see: ""How to count X-1 dolls"" + 1.
But wait, who counts like this? Good question! And here is when we get to our next point: is recursion a good alternative?
Advantages and disadvantages
Many recursive functions can be written another way: we could simply go through all numbers from to and compute the function for each number. For example, we can open the largest doll, say ""One"", throw the doll away, and repeat these steps until we found the last one. This way of computing is called the loop. But which way is more efficient?
It depends on the programming language. As a rule, in Python and Java, loops are more efficient in terms of time and memory. Recursion is slower and ""heavier"" because each call of a function takes additional memory, and recursive functions usually get called many times.
In that case, why recursion? Well, it has one certain advantage over loops: in some cases, it is intuitive. If you are certain that some function uses itself, it is much faster to write 3-4 lines of recursive code than to think how exactly a loop should behave. If you are short on time but don't have to worry about memory consumption, recursion is your choice. 
So, recursion is usually slower and less memory-efficient, but it saves the developers' time.
Let's look at one classic (and more practical, to be perfectly honest) problem that recursion can effectively deal with.
The factorial example
A classic example of recursion is a math function called the factorial.
The factorial of a non-negative integer is equal to the product of all positive integers from to inclusively. Also, by definition, the factorial of is . Let's take a normal number though: for example, the factorial of (written as ) is .
So, we know the factorial of and the factorial of . Also, we could say that the factorial of any number is equal to multiplied by the factorial of . For example:
Do you see what's happening? When writing a function to compute the factorial, we could do it recursively! There is no need to think a lot because the recursive function can be created just using the definition of factorial. We have a trivial case (for or , our function returns ), and the reduction step (if our number , the function returns ). And now try to imagine the factorial function with loops. It isn't that obvious, is it?
Conclusion
Let's summarize what recursion is and when you can use it.

Once again, recursion is a call of a function for itself.

Every recursive function consists of two elements: reduction step and trivial base case.

Use recursion when you're sure your function uses itself and program memory usage and run-time are not your priority.

As you can see, recursion is a pretty simple idea. Enjoy!
"
261,Recursion in Python,585,7665,2442,https://hyperskill.org/learn/step/7665,"You've already learned the theory behind recursion. In this topic, we will put this knowledge to practice by learning how to write recursive functions. To make sure that we are on the same page, let's remind ourselves of the definition of recursion.
Recursion is a method of solving problems by breaking them down into smaller instances. The solutions to those sub-problems are then combined into a bigger solution to the original problem.
Parts of a recursive function
In programming, recursion is achieved when a function calls itself from its code. Sounds simple, doesn't it?
The main function can generally do only two things: either perform a simple task and return a value or call itself with new arguments to divide the problem into smaller chunks. Let's consider an example. Suppose you want to find out the number of people sitting to your left in a long row of seats. You can ask a person to your left how many people are sitting to their left. That person then asks a person to their left, that person asks a new person on the left, and so forth. The process of asking the question is a recursive case (a recursive action). As a result, each person gets the number, adds 1, and passes the message further.
If you're going to use a recursive function in your program, you'll have to terminate it at some point. Otherwise, it may lead to an infinite loop. A condition that stops a recursion is called the base case. In our example, the recursion will end when a person occupying the leftmost seat says, ""no one"".
To summarize, there are two obligatory steps in each recursive function:
A base case that works as a stop sign. It is the smallest problem that can be solved without any further subdivision. It is a condition where a function only outputs a result;
A recursive case (also called a reduction step) is the part where the function calls itself to try and solve a smaller problem.
Constructing a recursive function
Let's construct a recursive function for finding the factorial of an integer number in Python. It looks like this:

This means that we can calculate the factorial of a number by multiplying this number by the factorial of the previous number:

Now, to write a recursive function, we need to define the recursive and the base cases.
As for the recursive case, we need to define a step where we're trying to find the solution to the simpler instances of our problem. With the factorial of \(n\), this would infer multiplying \(n\) by the factorial of \(n-1\):

As for the base case, to prevent our function from calling itself infinitely, we need to set the stop rule or reduce the solution to the smallest possible problem. In our case, the simplest problem is \(0!\)

This is the typical structure of any recursive algorithm. If a problem is reduced to a simple case, solve it. If not, divide it into subproblems and apply the same strategy.
Maximum recursion depth
By now, we've noted that recursion is a function that calls itself. Of course, it tends to occupy the resources of your machine. Like any other function, a recursive function operates with memory, so to prevent it from crashing, Python limits the maximum number of callings — this parameter is called the recursion depth. When it goes beyond the limit, you'll get RecursionError: maximum recursion depth exceeded. This is how you can check the recursion depth:

If we go back to the structure of a recursive function, it means that even if the base case isn't defined, you won't be able to execute your program forever. When the maximum recursion depth is exceeded, you'll get an error.
You can change this parameter manually:

Be careful with this option, as it influences the memory use of your program.
Recursion tracing
Since the concept of recursion may be daunting at first, it is a good idea to visualize the function execution manually or automatically to trace it and have a more clear picture of how it works. Look at the function below:

Here's what it does. The function takes two numbers. In case the first one (x) is less than the second one (y), the function returns x, and the execution stops. This is our base case. Otherwise, the function is called recursively, but at each iteration x is decreased by y until the first condition (x is less than y) is met. Let's visualize it manually step by step:
func(20, 5) -> func(15, 5)
   func(15, 5) -> func(10, 5)
     func(10, 5) -> func(5, 5)
       func(5, 5) -> func(0, 5)
         func(0, 5) -> 0        # this is our base case
       func(5, 5) -> 0          # we're going back since these calls don't return anything useful        
     func(10, 5) -> 0
   func(15, 5) -> 0
func(20, 5) -> 0                # the final answer
You can also try automatic visualization. Just run it!
Recursion vs. Loops
Reading about recursion, you may have noticed that the cases we can solve with recursion are similar to ones solvable with loops. An important thing here is that they have different purposes (loops are designed to repeat a task; recursion is meant to break down a larger task into smaller ones), but recursion and loops are quite similar. Moreover, if we're solving a problem using recursion, we can also solve it with loops. Sometimes it is easier to solve a problem using recursion because the solution is brief and clear, sometimes the performance is crucial, so you may consider a less elegant but more efficient iterative algorithm. At the end of the day, it's really up to you.
To illustrate this idea, let's implement two functions; both will calculate the power. We will use the first one as an iterative implementation:

While the second one is recursive:

As you can see, both functions do the same thing; you can choose the solution depending on which one uses less memory, is faster and clearer. Citing the explanation by Leigh Caldwell on Stack Overflow — Loops may achieve a performance gain for your program. Recursion may achieve a performance gain for your programmer. Choose which is more important in your situation!
Conclusion
Here's what we've learned in this topic:
What recursion is and how to construct a recursive function;
What the notion of the maximum recursion depth is, and why we need it;
How to manually and automatically trace recursive functions for better understanding;
The difference between recursive and iterative implementations, which one to choose, and why.
Summing up, recursion can seem to be mean at first, but it is one of the most important skills in any programmer's toolkit. There are cases where it can be amazingly helpful.
"
262,Recursion in Functional Programming,2786,27671,2443,https://hyperskill.org/learn/step/27671,"One of the guidelines for functional programming is that procedures should have no side effects, which means that we are not allowed to change a variable or modify the value of a parameter that has been passed. Functional programming prefers immutable objects which, once defined, cannot be modified later. In this topic, we will see why recursion is preferred in functional programming and see a scenario where recursion is suitable and another scenario where it is not suitableRecursion in terms of functional programming

When we loop by incrementing a variable, our loop depends on mutation because the variable changes in each iteration as we are reassigning the variable i.If we iterate the elements in a list by using the in keyword, we are getting somewhat closer to functional programming. However, there is still repeated rebinding of the variable i and therefore a change in the program state.

Can we do better? Yes, the following code can be written as:
The map function is a higher-order function that applies another function to each list element. Utilizing a map can transform a list into a new data stream without resorting to explicit loops or mutable state changes. It leads to a more declarative and concise code style, simplifying the implementation, enhancing readability, and reducing the likelihood of introducing errors. The Tower of Hanoi problemTower of Hanoi is a mathematical game that is commonly used as a recursion and optimization problem. There are three towers in the game, and one of the towers contains a stack of disks in decreasing order of size from bottom to top. We must move the disks from the Source tower to the Destination. During the game, a larger disk cannot be put over a smaller disk.

There are three towers as follows: SourceAuxiliary (the tower which is neither source nor destination, but is used for staging the disks)Destination

For \(n = 1\), this is a trivial task: we move the only disk to the destination tower. For \(n = 2\), we can move the small disk to the empty auxiliary rods; by that, we free the large disk and can move it to the destination rod.

For \(n = 3\), this task is complex: for this, we need to figure out when we need to move the largest disk.

First, the largest disk should be the only disk in the source tower to be able to move it. Second, we need an empty tower to stage the largest disk, this is the destination tower. Therefore, the two small disks should be placed on the auxiliary tower in the correct order.

To achieve this, first, we need to move the two smaller disks from the source tower to the auxiliary one. Do you see where we are going? We did this exactly for \(n = 2\) (this is a recursive statement), when we move two smaller disks, the largest one is not an obstacle as any disk can be placed on top of it. After these preparations, we move the largest disk to the destination tower. Hence, we need to achieve the following configuration.  Let's consider the general case now.

To move the largest disk, we need to leave it as the only disk in the rod. We are only allowed to move the largest disk only if the destination is an empty rod.

From these two observations we can infer that \(n -1\) towers should be on the auxiliary tower, the position before moving the largest disk should be as follows:The dotted arrow shows the preparation moves. All the disks except the largest one should be moved to the auxiliary tower. Then we move the largest disk to the destination tower, then we bring the other disks to the Destination tower as shown below.The dotted arrow shows the moving of the smaller disks on top of the largest disk.

Now, these three steps are very important for devising a recursive procedure for the Tower of Hanoi problem. We can now use recursion to recursively call the solution for \(n - 1\) disks. You can try out the game on Math is Fun.

By using the same function to move one and several disks, we can reduce the process of moving \(n\) disk to moving \(1\) disk and \(n -1\) disks. We can directly move one disk, so that's easy. However, using the same trick, we can keep breaking down \(n - 1\) to \(n - 2\), then \(n - 3\), etc, until we're only left with a sequence of moves of a single disk, which is trivial to execute.

That's generally how recursion works: keep breaking the problem down, until you're only left with instances of the base case (in this case, moving a single disk) and instructions on how to assemble multiple instances of the base case to solve more complex ones.We need to follow the tracing from left to right of the tree and move the disks accordingly. Notation in the diagram:Source → (a)Auxiliary → (b)Destination → (c)Recursion is not always suitable, now we will see a bad usage of recursion. Minimum number of moves required to solve a tower of Hanoi problem with n disks is \(2^n - 1\) Bad usage of recursionImmutable objects and recursion are very handy concepts, but they can be extremely inefficient in some cases, as recursions are inefficient for large problems which are non-linear. One such problem is the recursive implementation of the Fibonacci series.A Fibonacci series is a series of numbers where the next element is found by summing up the previous two elements, the first few values are: 0, 1, 1, 2, 3, 5, 8, 13, 21, and so on

Look at the following Fibonacci tree diagram for calculating \(5th\) Fibonacci number. Initially for fib(5)call we go down the tree till we hit a base case. After reaching the base case, we backtrack and calculate the values for each node in the tree. For example, for calculating fib(2) from the tree, we simply add fib(1) and fib(0) to get 1, we already know the value of fib(1) and fib(0) which are set as the base case. Calculating fib(5) requires us to calculate fib(4) and fib(3). This is where the inefficiencies arise, calculating fib(4) also requires us to calculate fib(3). It means that fib(3) will be calculated twice, because these calculations happen in separate branches of the recursion tree. This particular algorithm grows exponentially instead of linearly, because each call of fib() branches off into two more calls and continues on this track. Thus, increasing the size of number heavily increases the time required to complete the calculations. A more efficient implementation using dynamic programming and memoization can be done to improve the time complexity

This is a more efficient solution, as it uses memoization to store the results of previously calculated Fibonacci numbers and reuses them instead of recalculating them. This significantly reduces the time complexity.ConclusionIn this topic, we have seen recursion is preferred in functional programming because we don't need a mutable state while solving a problem as they can produce side effects. Moreover, recursion makes it possible to specify a semantic in simpler terms. We have seen how recursion can be used by avoiding loops and in a more functional way for certain algorithms. Recursion works best for cases when a problem can be divided into sub-problems calculated separately and how the problem is solved is the same as the smaller sub-problems. Recursion is preferred for Tower of Hanoi because it is concise and elegant, whereas it is not preferred for naive Fibonacci series recursion because it recomputes the same value repeatedly, we can improve the naive version with memoization so that the same values are not computed repeatedly.
"
263,Tree,275,5121,2449,https://hyperskill.org/learn/step/5121,"Tree
The first thing that comes to mind is probably a branchy oak in a forest. You aren't too far off: that very image gave name to a specific type of data structure that we are going to look at. In a way, it resembles real trees (both have roots and leaves and a similar structure) and family trees with parents, children, and siblings. Keeping that analogy in mind, let's look closely at what trees are in computer science.
Any tree is a graph, but one with a certain condition: it is a connected graph without cycles. The main property of a tree is that there is only one path between any two nodes (also called vertices) of the graph. If there is at least one cycle in the graph, it means that there are pairs of nodes with more than one path connecting them: in other words, it isn't a tree.
Let's visualize that: the following figures show two graphs. The first is a tree and the second one isn't.

The second graph is not a tree because it contains a \(1-3-6-0\) cycle, so there are two paths from node \(2\) to node \(0\): \(2-3-1-0\) and \(2-3-6-0\).
Important terms and definitions
A tree starts with its topmost node which is called the root node or the root of a tree. For each tree node all nodes directly below it (connected by an edge) are called child nodes or a node's children. In the example above (first figure) node \(2\) is the root of the tree, while nodes \(3\), \(4\), and \(5\) are the root's children. So far quite simple, very much like a family tree.
Let's go over the basic definitions related to trees:

the root node is the topmost node of a tree;
a child is a node directly below a given node, connected by an edge;
a parent is a node directly above a given node, connected by an edge;
a leaf is a node without children;
the depth of a node is the number of edges from the root to this node;
the depth of a tree is the depth of its deepest node;
the height of a node is the number of edges on the longest path from the node to a leaf;
the height of a tree is the height of its root node.

Observe that by definition it follows that the depth of a tree \(=\) the height of that tree. In this and the following graph-related topics, we will use both Node and Vertex as names for points in the graph: treat them as synonyms. In the literature, they are also used interchangeably.
Nodes or edges in the tree may contain information: for example, the number of the vertex or the cost of moving along the edge (the sum of edges from the root to this vertex). The image below shows an example of a tree with numbered nodes:

In this example, node \(0\) is the root of the tree, while nodes \(6\), \(7\), \(8\), \(5\), \(2\), \(9\), and \(10\) are leaves.
Note that if you add an extra edge to the tree, a cycle will be formed, and if you remove any of the edges, the graph will become disconnected.
A tree in which every node has no more than two children is called a binary tree. If the number of nodes in the tree is n, then the depth of the tree is at least \(\lfloor \log_2n \rfloor\), i.e. the greatest integer less than or equal to \(\log_2n\). From this point on, we will discuss specifically binary trees, unless stated otherwise.
Trees in practice

The tree data structure is very common in practice: for example, we have already mentioned family trees. Taxonomy in biology makes use of the same hierarchical structure; if you want to bring it closer to home, you can think about the ""boss-subordinate"" structure in a company, where children stand for subordinates, and the parent is the boss.
Trees are widely used in IT because they allow us to process data considerably faster. Virtually all parsers of different grammars use trees to a varying degree. Also, in many DBMSes, indexes are based on trees for faster data processing.
"
264,ast module,1630,15487,2450,https://hyperskill.org/learn/step/15487,"The ast module is a primary tool from a standard Python library for working with Abstract Syntax Trees (ASTs). AST is a tree representation of the code. They are abstract since they do not employ the actual syntax; they use structure and concept models, instead. ASTs can help you with understanding how Python works.
ASTs are often used in IDEs, custom interpreters, static code analyzers, and other testing tools that automatically find code flaws and errors. AST analysis can help to comprehend why something went wrong, though it is not a standard debugging technique. In this topic, we'll look a little closer at ASTs using the ast module.
Abstract syntax trees
Any code consists of characters. They don't really mean anything for the computer in terms of program execution. It cannot really understand them, so they need to be translated to computer commands. As you know, Python is an interpreted programming language, so it includes the interpreter. The interpreter is a special program that translates the code you've written into the form that a machine can understand. In a nutshell, this is how the Python code turns into the code your computer actually executes:
At first, your code is parsed into pieces called tokens: keywords, operators, delimiters, and so on.Then it constructs an AST — a representation of the Python syntax grammar. AST is a collection of nodes and edges (links) between them. Graphically, an AST of expression = 1 + 2 would look like this. Assign and BinOp are node classes that we'll cover in the next section:After that, the interpreter produces bytecodes that a computer can run.
The ast helpers: parsing
Now, let's switch to the ast module. We will start with utility functions and classes. They are called helpers. We'll only look at some of them. Take a look at the full list in the official documentation if you're interested in details.
The first helper is ast.parse(). It takes the source code and parses it into an AST node:
Keep in mind that the tree is actually a node, a root node, to be specific. You're probably disappointed by the printed value because it doesn't really show anything of importance. Don't worry! Use ast.dump() to print the actual AST:
See? Here it is! Nodes constitute the tree. A tree normally starts with the Module node, which is a root. It has a body attribute that contains every other node and its attributes. In our case, we have the Expr (expression) node with theBinOp (binary operation) node as its value.
Instances of ast.expr and ast.stmt subclasses have two handy attributes lineno and end_lineno that store respectively the first and last line numbers of their corresponding source code (the enumeration starts at 1). Let's assume you have a file called calculations.py with the following code:
You want to analyze it using ast module. Here's how you can check at what line each node is and maybe even use this information later on in your work:
The ast helpers: visiting nodes
If you just need a list without any particular structure, take a look at the ast.walk() helper. It's, in fact, a generator, so you can print the values this way:
It recursively yields children nodes in the tree starting at a given node (included), in no specified order, so it might be useful if you want to modify nodes in place and don’t care about the context.
There are a couple of alternatives to the ast.walk() helper, though. The first one is the ast.NodeVisitor class. It 'scans' the tree and calls a visitor function to every node. You can use it by subclassing it and overriding visit() methods that should have the names of the corresponding node classes (we will discuss them in detail a bit later):
Here we have overridden visit() to only visit BinOp class nodes and print the left operand, the operator, and the right operand. It is helpful if you only need to visit specific nodes, for example.
The second option is ast.NodeTransformer that works similarly, but allows you to modify the visited nodes of the tree. We won't consider it thoroughly now, so you can find more detailed information about the tool in the docs.
The ast helpers: literal_eval()
There's also another helper that you may be interested in. Imagine you have a program that works with user input. User input must be an integer. Even if you've indicated it in the docs, you can't be sure that all potential users will comply with the instructions, so you need a backup. You can use ast.literal_eval() that safely evaluates strings and, if everything's fine, returns the intended type. Just look at the following:
The ast nodes
Alright, helpers are out of the way. Let's now turn to nodes. Each node is a construct that describes a part of the source code. In the ast module, they are divided into classes, and most of them also have attributes that store the most useful information. For instance, the Import(names) class describes the imported parts of your code, and the names attribute stores their names.
Below is a shortlist of the most common node classes with some of their attributes:
literals: Constant(value), List(elts), Set(elts), Dict(keys, values);variables: Name(id), Del;expressions: Expr(value), BinOp(left, op, right), Call(func, args);statements: Assign(targets, value), Raise(exc, cause);imports: Import(names), ImportFrom(module, names);control flow: If(test, body, orelse), For(target, iter, body, orelse), While(test, body, orelse), Break, Continue, Try(body, handlers, orelse, finalbody), ExceptHandler(type, name, body);functions: FunctionDef(name, args, body, returns), Lambda(args, body), Return(value), Yield(value);classes: ClassDef(name, keywords, kwargs, body).
Is anything looking familiar? We hope so! We have already seen Constant, Assign, and BinOp in the very first example and some other nodes later on.
This list isn't exhaustive; you can refer to the official documentation for more detailed information.
The ast nodes: example
It's example time! Imagine someone sent you a pile of scripts to check whether they correspond with PEP 8. You open the first one called my_func.py with the following code:
It is small and easy to check. But there's a lot of them! You decide to do the checking automatically. Of course, there are a lot of conventions to be considered, but let's see how the part responsible for argument names can look like. Suppose you have a function that checks the name, but how to extract the names? ast knows how to do it:
Okay, that looks pretty confusing... but only at first sight. We see that our tree starts with the Module node that has the body attribute containing all other nodes. So, at first, we access the body and, since FunctionDef is the first element, we use the 0 index to access the attributes where the arguments are stored.
function = tree.body[0]
Now, we will take a look at how the FunctionDef is organized. First of all, we, obviously, need the args attribute that also has the args attribute. This last args attribute stores just what we need – the arg node with all function arguments, so we just assemble them in a list and print it:
args = [a.arg for a in function.args.args]

By doing so, we receive a list of argument names and can proceed to check them.
Since it might be tricky to clearly understand what node is where in the tree and why, we strongly recommend using visualization tools, like this one, for example, that make trees more representative and sometimes even let you interact with them. To see how it works, copy the piece of code with the greet() function (or any code you like/have difficulties understanding), paste it in the left part of the webpage, and look at the resulting tree.
Conclusion
In this topic, we've learned several things:
how a computer actually executes the code you write;what ASTs are, how to build them, and what is their purpose;what ast helpers are and how to call them;what ast nodes are, what classes of nodes are there, what attributes they have, and how to use them.
Now you're ready to build and extract information from ASTs. Don't forget about the practical tasks!
"
265,Decrease and conquer,1521,14669,2472,https://hyperskill.org/learn/step/14669,"When you were in elementary school, one of the very first concepts that you were taught in math class was addition. You'll need to remember those classes now in order to get the idea of the decrease-and-conquer algorithm.

Math recap
Let's take a simple math problem of adding four numbers together:
1 + 2 + 3 + 4 = ?
Here, you can start by adding up the first numbers, then add the sum to the next number, and so eventually you'll get the total:
1+ 2 + 3 + 4 = (1 + 2 + 3) + 4 = ((1 + 2) + 3) + 4 = (3 + 3) + 4 = 6 + 4 = 10
This process of reducing a problem to a subproblem and solving it one step at a time is the core concept of the decrease-and-conquer algorithm.
Decrease-and-conquer is an algorithm design paradigm in which a problem is transformed into a smaller subproblem and then that subproblem is solved first. Unlike the case of Divide and conquer algorithms, the reduction process here generates a single subproblem. The transformation is applied either iteratively or recursively until the sub-problem becomes simple enough to be solved directly as a base case. Finally, the solutions of all sub-problems are extended to get a solution to the original problem. Let's consider each of the described steps in more detail.
The steps of the decrease-and-conquer algorithm
Generally, the decrease-and-conquer approach implies the following three steps:

Decrease: reduce a problem to a smaller instance of the same problem.

Conquer: iteratively or recursively solve the sub-problem.

Extend: apply the sub-problem solution to the next sub-problem to get a solution to the original problem.

As shown above, we first reduce the original problem to a smaller sub-problem. Then we move on to the conquer step by solving that single subproblem. Then, we extend that sub-solution to another subproblem in order to obtain a subsolution to that subproblem. This process continues until we have a solution to the original problem.
A simple example: the sum of elements in an array
Let’s see how the decrease-and-conquer-based algorithm can solve the problem of finding the total sum of numbers in an array.
The first step of this algorithm is to decrease the original problem to a smaller subproblem. So, we reduce the problem to subproblem recursion. We slice the array one element at a time and pass the sliced array to the same function, thereby decreasing the problem by a single constant. The base case for this would be the case when the length of the array is one: in this case, the sum of the subarray with one element is simply the value of that element. Then we conquer and extend the sub-solution to the next subproblem by adding one element that is returned by the recursion at a time. An illustration of this algorithm is as follows:

As shown above, given an array of four numbers, the algorithm decreases the problem by slicing the array down to one single element, namely 1. Then, 1 is added to 2, and this sub-total is extended to the next addition (plus 3). The process is continued until the total sum of four numbers is calculated.
Examples of decrease-and-conquer-based algorithms
Decrease-and-conquer-based algorithms are widely applied in many real-world problems. Kahn's algorithm and binary search are just two examples of the algorithm's efficiency in data sorting and searching. As you go further into algorithm topics, you will definitely get to know them.
Conclusion
In this topic, you've learned about the decrease-and-conquer algorithm design paradigm:

The three steps of decrease-and-conquer-based algorithms are: decrease, conquer, and extend.

Unlike the case of divide-and-conquer paradigms, decrease-and-conquer reduction generates one subproblem.

With the decrease-and-conquer-based approach, you can solve a problem either iteratively or recursively.

There are many use cases of decrease-and-conquer-based algorithms, so you may soon find yourself applying such algorithm design, too!
"
266,Insertion sort,269,19086,2480,https://hyperskill.org/learn/step/19086,"As kids, we all used to love card games. Some of us still do. Do you remember, though, how you arranged and sorted the cards in your hand while playing such games? If you are somewhat like me, once you had all the cards in your hands, you would start from the left side and pick them one by one, from left to right. If the selected card is lower than the previous one, you push the previous card to the right to make space for the new card. You continue doing so until the current card is greater or equal to the one on the left. Finally, you insert the selected card in that position.

This is exactly the idea behind insertion sort, a widely used algorithm when it comes to solving the famous sorting problem, which you are already familiar with. In this topic, we will cover in detail the algorithm itself, as well as its advantages and disadvantages, so that you know precisely when to use it and when to look for alternatives instead. So, let's get started!

Algorithm description

Roughly speaking, insertion sort is a simple sorting algorithm that sorts one element at a time. It automatically divides the array into the sorted and the unsorted part, as we will explain below. At each iteration, the algorithm moves an element from the unsorted part to the appropriate position in the sorted one, until it sorts all array elements.

Formally, the algorithm works as follows:

Assume the leftmost element belongs to the sorted part of the array, and all remaining elements are in the unsorted part;
Choose the first element from the unsorted part and insert that element into the sorted list at its proper position;
Repeat step 2, until all elements are sorted.

How to perform insertion at step 2? Compare the selected element with its left neighbor: if it is greater than or equal to it, the element is already in its proper position. Otherwise, move the neighbor one position to the right to make space for the current element. Now, it has a new left neighbor: repeat the same procedure until our element reaches the desired position, i.e. is greater than or equal to the element on its left, and finally, insert it there.

We can notice that after every step, the sorted part literally gets sorted. The fact that at every step we move one unsorted element to the sorted part, guarantees that we will end up with a sorted array after \(n-1\) steps, where \(n\) denotes the number of elements. In other words, it proves that the algorithm works correctly.

Example

Let's forget for a while about the happy times when we used to play cards and not worry about everything else, and remember the exam papers, grades, and all the stuff of that sort. Suppose you are a teaching assistant of Dr. Poulad, a Computer Science professor. Her students have just had an exam, and she has already graded their papers. Now, Dr. Poulad has asked you to arrange them in ascending order, i.e., from the lowest to the highest score.

The array has six elements, the first element's index is 0, and the last element has the index 5. The following image illustrates how the insertion sort algorithm works:

Let's explain in detail the first few steps:

The sorted part includes only a single element with the index 0, since it's the leftmost element in the array. Let's look at the second one (\(23\)). It's greater than the last element in the sorted part, which means we don't move it.

Now, the sorted part includes elements with the indexes 0-1. We consider the element with the index 2 (\(19\)). It's smaller than the last element in the sorted part, hence, we move the last element, namely \(23\), to the right. Still, the new neighbor, \(21\), is greater than our element, therefore, we push \(21\) to the right and insert \(19\) in this position. Now, after moving, it has index 0.

Similarly, we keep applying the steps of the algorithm to the rest of the elements, as shown in the illustration above. At step 6, the unsorted part is empty, which means the whole array is sorted. Now you can be proud of yourself, since you've completed the professor's task!

Seeing a visualization of the insertion sort algorithm might help you get the gist of it. You can skip the lecture mode by clicking X on the top right corner and select INS.

Complexity and other features

Every algorithm has its advantages and shortcomings, and insertion sort is not an exception. Our algorithm works pretty fast with already sorted arrays. It takes \(O(n)\) time, because the elements are already in their proper positions, so we don't need to move anything. In pseudocode language, this means that the inner while cycle will not be executed. Another great advantage of the insertion sort algorithm is its simple implementation and the human-like logic behind it. Also, it is worth mentioning that our algorithm is stable and in-place, meaning that it doesn't require any extra memory. With the insertion sort's features we've mentioned, we can conclude that it is advisable to use this algorithm for arrays that contain few elements or are almost fully sorted. Such examples are sets of data produced by another program, sorted datasets, in which we need to append a few new elements, error log files, etc.

However, quite the opposite happens with the algorithm's efficiency in the average and worst cases. When this happens, insertion sort's time complexity is quadratic, since both while loops will be executed. For example, if the array is in reverse order, we need to compare every pair of elements and make \(\frac{n(n-1)}{2}\) comparisons, which is \(O(n^2)\). Due to its time complexity, it is not recommended to use insertion sort for large datasets. This is why sorting methods in programming languages are based on algorithms other than insertion sort, as we will see in the following topics.

Conclusion

In this topic, we've introduced a new sorting algorithm, namely insertion sort. Here's a summary of what we've learned:

We can implement the algorithm easily by following these steps: divide the array into the sorted and the unsorted part. During each iteration, take the first element from the unsorted part and insert it into the sorted list at its proper position. Iterate this step until all the elements are sorted.

Insertion sort's best-case complexity is \(O(n)\), while in the average and the worst-case scenario, the algorithm takes \(O(n^2)\) time to complete its work.

It's best to use this algorithm for arrays with few elements or almost-sorted datasets.

Avoid using insertion sort for large sets of data.

Now you are perfectly equipped with knowledge and are ready to proceed with the tasks.
"
267,Divide and conquer,144,19087,2489,https://hyperskill.org/learn/step/19087,"Divide and conquer is an algorithm design paradigm, in which we divide a problem into smaller subproblems (often two subproblems) of the same type and then solve each subproblem independently. The division is applied recursively until subproblems become simple enough for us to solve directly using a base case. Finally, the solutions of all sub-problems are combined to get the solution for the original problem. Let's look into the divide and conquer model using a real-life example.
The idea of divide and conquer
Henry is a tomato sauce lover. So, this winter, he has decided to prepare five gallons of sauce for the upcoming year. To do so, he needs to blend \(35 kg\) of tomatoes. However, Henry has a blender machine that can blend a maximum of \(2 kg\) of tomatoes at a time. How can he blend all \(35 kg\) of tomatoes? The solution is obvious: Henry has to take a portion of \(2 kg\) (or less) at a time and blend them. This way, the task will require a minimum of \(18\) batches of blending. Finally, Henry should combine those blended tomatoes to obtain the final result: \(35 kg\) of blended tomatoes.
The divide and conquer algorithm paradigm works in the same way. First, we have to divide our original problem into smaller similar subproblems. We take \(2kg\) from \(35 kg\) of tomatoes in our example, whereas our problem remains the same — to blend them, i.e., the subproblem is similar to the original problem. Next, we solve our subproblems: blend each smaller batch of tomatoes. Finally, we combine each subsolution by mixing all blended tomatoes.
Now imagine, what if Henry had four blender machines? He could have then blended \(4 * 2 = 8kg\) of tomatoes at a time. This idea is known as parallel computing in programming, which can be exploited using the divide and conquer algorithm paradigm.
The steps of a divide-and-conquer-based algorithm
A typical algorithm based on the divide and conquer paradigm consists of three steps:


Divide: split a problem into smaller sub-problems of the same type. Each sub-problem should represent a part of the original problem.


Conquer: recursively solve the sub-problems. If they are simple enough, solve them directly using base case conditions.


Combine: unite the solutions of the sub-problems to get the solution for the original problem.


The following picture shows the steps and their results:

The steps of a divide and conquer algorithm
In the above example, we first divide the original problem into two subproblems. Each subproblem is then divided into new subproblems until they are small enough for us to solve directly. After solving the smallest subproblems, we obtain subsolutions. We combine them to get subsolutions for more complex subproblems. The process continues until we obtain the solution for the original problem. As you can see, the process is recursive by  nature.
A simple example: the sum of elements in an array
Let's consider how we can use the divide and conquer paradigm to calculate the sum of elements in an array \(A=\{1, 4, 2, 8, 3, 1, 6\}\). Note that there's a simpler and more efficient way to solve this problem; here, we apply the paradigm to get a better understanding of how it works. The procedure is the following:


We first define base case solutions. In our case, they are:


The sum of zero elements is \(0\), i.e., the sum of \(\{\}\) is \(0\).


The sum of a one-element array is the element itself. For example, the sum of \(\{5\}\) is \(5\).




Next, we divide our original problem into smaller and similar subproblems. In our example, we first separate \(\{1, 4, 2, 8, 3, 1, 6\}\) into \(\{1, 4, 2, 8\}\) and \(\{3, 1, 6\}\). Now, let's take a look at our original problem and the subproblems:


Original problem: Find the sum of \(\{1, 4, 2, 8, 3, 1, 6\}\).


Subproblem 1: Find the sum of \(\{1, 4, 2, 8\}\).


Subproblem 2: Find the sum of \(\{3, 1, 6\}\).


Take notice that the subproblems are the same as the original problem: finding the sum of an array. The only difference is that the array size is smaller.


Now, let us see how we can solve the subproblems. As the subproblems are similar to the original problem, we can consider the subproblems as an initial problem and repeat step \(2\). At some point, the subproblems will be small enough to be solved by the base solutions, and we will get subsolutions by following step \(1\).


At this point, let us assume that we have solved subproblem \(1\) and subproblem \(2\) and have found subsolutions \(1\) and subsolutions \(2\).


Subsolution \(1\): The sum is \(15\).


Subsolution \(2\): The sum is \(10\).


How can we combine these two solutions to find the original solution? For our example, we have to add subsolution \(1\) and subsolution \(2\). This is the rule of combination we have to follow for combining any two subsolutions. Eventually, we will reach the final solution by combining all subsolutions.


Here is an illustration of the steps mentioned above. In the picture, the blue-bordered arrays indicate problems and subproblems; the black-bordered arrays indicate subsolutions and solutions. The red arrows indicate dividing steps, the yellow arrows indicate conquering steps, and the green arrows indicate combining steps.

Complexity Analysis
We cannot calculate the divide and conquer algorithm's time complexity precisely, since it is an abstract algorithm designing technique. However, we can discuss its performance in terms of space and time. 
Although the recursive nature of the algorithm costs space and time, the similar and smaller subproblems can be processed independently and simultaneously, which allows us to take advantage of multi-thread processors and parallel computing. Moreover, solving problems using some defined base cases can be done within the cache memory. These features of the divide and conquer paradigm make it space-efficient and quite fast to perform.
Conclusion
The divide and conquer algorithm often provides us with a fairly simple solution to a complex problem, since it divides the problem into smaller subproblems. After that, we can combine the solutions of the smaller subproblems to obtain the final solution. There are many widely-used and efficient algorithms based on the divide and conquer paradigm: merge sort, quick sort, and others. If you decide to dive deep into algorithms, you will certainly come across this paradigm in the following topics.
"
268,Merge sort,273,29428,2490,https://hyperskill.org/learn/step/29428,"In today's data-driven world, the ability to organize and process vast amounts of information has become increasingly crucial. Whether it's managing a large database, analyzing customer data, or simply organizing a music playlist, efficient sorting methods play a vital role in our lives. One of the most challenging aspects of handling enormous datasets is sorting them in an organized and timely manner, which calls for an efficient algorithm.
The problem we face is sorting a large collection of data elements in a way that minimizes the time and computational resources required. Traditional sorting methods, such as bubble sort or insertion sort, may not be practical for massive datasets due to their time complexity. This is where a more advanced and efficient sorting algorithm is needed.
Description of the algorithm
Merge sort is a divide-and-conquer algorithm that recursively breaks down the input data into smaller subsets, sorts them, and then merges the sorted subsets to produce the final sorted output.
Imagine you have a deck of cards that you want to sort in ascending order by their face value. To do this as efficiently as possible, let's take advantage of the main features of the merge sort algorithm.

First, what the algorithm would do is to divide the entire deck into smaller parts until each part contains only one card. We'll omit this part to show the process of the merge sort itself.

Next, the algorithm would start merging these smaller parts. To do this, we combine every two sorted parts of the deck into one, also sorted. This process is called merging. This is done in what seems to be the most obvious way: we choose a minimum of two hands, and now this is the first element of the new, merged set of cards. Repeat the procedure for all other cards remaining in your hand.

Next, we continue to sort and merge pairs of adjacent parts until we run out of them.

At the end of this process, we have a fully sorted deck of cards in ascending order.

Implementations
The algorithm can be implemented in many ways. Here's a short description of the most popular ones:

top-down is a recursive implementation that recursively divides the given array into two subarrays until there is only a single-element array remaining; it then merges the results together to produce a sorted subarray of a larger size.
bottom-up is an iterative implementation that first merges pairs of adjacent single-element arrays and produces sorted subarrays of 2 elements, then merges pairs of adjacent arrays of 2 elements producing 4-elements sorted subarrays, then merges pairs of 4 elements, and so on until the whole array is merged (sorted).
in-place: The standard merge sort algorithm requires extra memory to store the sorted subarrays during the merge phase. In-place merge sort eliminates the need for extra memory by using an alternative.
hybrid: This algorithm uses a combination of insertion sort and merge sort. When the sub-array size becomes small enough, the algorithm switches to insertion sort which is faster for small inputs. This can improve the performance of merge sort for small arrays.

These options are not mutually exclusive, and the implementation can incorporate multiple approaches simultaneously.
Top-down merge sort is generally considered more intuitive and easier to grasp, so let's take a look at this closer in terms of pseudocode:

Example
Suppose we have an unsorted five-element array of integers. It takes 5 operations to split the array into single-size subarrays.

Now let's look at the most interesting part. How does merging and sorting work?

In this example, we'll sort the array in ascending order. Here we take the first element of the first array and compare it with the first element of the second array. Which is smaller goes first to the new array.
The same happens with the second half of the array. Omit the merging of single-element arrays and go straight to the final stage

The algorithm uses pointers and constantly shifts them in both arrays depending on the result of the comparison. So at the current step, you can see that 5 is fewer than 7. Therefore, the current element adds to the end of the result array, then the pointer of the first array shifts to the next element.

As you may have guessed, the same principle adds 8. Now we have only 14 left in the first array. The final part of the algorithm checks if anything is left in both arrays and voilà, at the output we have a sorted array.
If you're still somewhat confused, see a Merge Sort visualization.
Algorithm properties
Consider the following properties of Merge sort:

The time complexity is \(O(n \cdot \log n)\), which makes it highly efficient for large arrays of data. The complexity arises from the combination of \(\log n\) levels of divisions and the linear \(O(n)\) time required to merge subarrays at each level. This makes merge sort an efficient and widely used sorting algorithm.
It is a stable sorting algorithm, which means that it maintains the relative order of equal elements in the sorted array. This property is essential in some applications where preserving the order of equal elements is critical.
Merge sort is not an in-place sorting algorithm in the original top-down implementation. It means that it requires additional memory to store the sorted array. This property makes it less suitable for sorting arrays with limited memory or requiring constant updates. We'll also consider in-place implementation by example.

In-place implementation example
We are already familiar with the top-down implementation, which requires additional memory. What if you need to save up some memory? This is when the in-place sort comes in handy. Let's take a look at how it works.

The in-place merge sort algorithm works by maintaining two pointers that traverse the two sorted sub-arrays, and a third pointer that indicates the current position in the output array. At each step, the algorithm compares the elements pointed to by the two sub-array pointers and swaps them if needed to maintain the correct order. This process continues until one of the pointers reaches the end of its sub-array. Once that happens, the remaining elements in the other sub-array are already in their correct positions, and no further action is required. This approach eliminates the need for additional memory to store sorted sub-arrays, making it more memory-efficient.
Note that in each step, the merge sort algorithm works recursively, dividing and merging the parts until the entire deck is sorted. This is different from the insertion sort algorithm, which sorts the elements by repeatedly inserting them into the correct position in the sorted part of the deck.

Conclusion
In this topic, we have explored the merge sort algorithm, which is an efficient, stable, and comparison-based sorting technique. By analyzing its characteristics, we have gained an understanding of its capabilities. To summarize, the key takeaways:

Merge sort follows a divide-and-conquer approach, where the array is recursively divided into halves until each subarray consists of a single element. Then, the subarrays are merged back together in sorted order.
The best-case, average-case, and worst-case time complexity of merge sort is \(O(n \cdot \log n)\), making it a reliable option for sorting datasets of varying sizes.
Merge sort is suitable for large datasets and cases where stability in sorting is required, as it preserves the order of equal elements.
However, it's worth mentioning that merge sort requires additional memory for temporary storage during the merging process, which might not be ideal for memory-constrained systems.

With this knowledge, you are now well-prepared to tackle any challenges involving the merge sort algorithm.
"
269,Date and time formatting,3129,31623,3173,https://hyperskill.org/learn/step/31623,"Date and time formats play a crucial role in programming when dealing with dates and times. They provide a standardized way to represent and manipulate temporal information, ensuring consistency across different systems and programming languages. In this article, you will explore date and time formats, their importance, and some commonly used formats in programming.

A date and time format is a standardized representation of dates and times, allowing computers and software systems to interpret them accurately. It defines the order of the year, month, and day components and the separator characters used to determine them. It may also include specifications for representing the time portion, such as hours, minutes, seconds, and others.

To understand date and time formats, starting with an overview of time zones is essential. A time zone defines the local time of a specific region about a standard, like UTC (Coordinated Universal Time). Let's explore some key definitions that will enhance your understanding of time zones in date and time formatting:

Coordinated Universal Time (UTC) is the standard time reference for numerous computing systems and applications. It is a baseline for comparing and converting times across various time zones.

Local Time refers to the observed time within a specific time zone. It varies depending on the location and the time zone offset from UTC. Determining local time involves applying the corresponding time zone offset.

Time Zone Offset represents the difference in time between a specific time zone and UTC

When formatting dates and times in programming, it's crucial to consider the appropriate time zone for the given context. This ensures consistency, proper localization, and accurate representation of dates and times for different geographical regions and user preferences. But with time zone inclusions, there are potential problems:

Time zones add complexity to date and time calculations and formatting.

Working with time zones becomes more complex when dealing with international applications.

Understanding and accommodating their preferred time zones can be challenging when dealing with user interfaces and displaying dates and times to users.

One widely used datetime format is the ISO 8601 format. It defines an unambiguous representation of dates and times using a combination of numeric values and symbols. The basic ISO 8601 date format is YYYY-MM-DD, where YYYY represents the year, MM means the month, and DD represents the day. For example, ""2023-06-05"" represents June 5, 2023.

ISO 8601 also supports including time information. The extended format also includes the time portion, represented as HH:MM:SS. For example, ""2023-06-05T12:30:45"" means June 5, 2023, at 12:30:45 PM. Formats also allow to include fractional seconds as H:MM:SS.SSS. So ""2023-06-05T12:30:45.102"" will add 102 milliseconds to our time.

Additionally, this format includes a time zone designator or TZD after the time information as +HH:MM or -HH:MM. This information depicts the difference between the local time and UTC. For example, ""2023-06-05T12:30:45+03:30"" represents June 5, 2023, at 12:30:45 PM UTC + 3 hours and 30 minutes.

Another date and time format, RFC 3339, is based on ISO 8601. RFC 3339 format looks like ""YYYY-MM-DDTHH:MM:SSZ"". Its structure is similar to ISO 8601, but it has a few additional differences:

While ISO 8601 allows you to specify time zones, RFC 3339 allows only to use a UTC zone which defines as a letter ""Z.""

RFC 3339 also allows for fractional seconds, but it specifies milliseconds as the maximum precision, while in ISO 8601, you can specify microseconds.

RFC 3339 is specifically used for internet protocols and applications. It fixes issues that can arise with the inclusion of different time zones.

RFC 3339 is a profile of ISO 8601 that provides a more specific and standardized format for representing dates and times in internet-based applications. It introduces stricter rules regarding time zone representation and fractional seconds while aligning with ISO 8601 in many other aspects.

Another popular date and time format is the Unix timestamp. It represents time as the number of seconds that have elapsed since January 1, 1970, at 00:00:00 UTC (Coordinated Universal Time). This format is commonly used in Unix-based systems and programming languages like JavaScript and Python. For example, the Unix timestamp 1685967912 corresponds to June 5, 2023, at 12:25:12 PM UTC.

Programming languages that use UNIX timestamp format include methods that allow you to convert input dates and times. But you can use Timestamp Converter if you want to try to convert the date into a timestamp or vice versa.

In addition to these standard formats, programming languages often provide functions or libraries to parse and format dates and times in various ways.

Date and time formats are important for representing and displaying dates and times and for parsing and manipulating them. When working with user input or data from external sources, programmers must convert date and time strings into native date and time objects in their programming language. This process is called parsing, and it requires matching the date and time string with the appropriate format to ensure accurate conversion.

The choice of date and time format depends on the specific requirements of the application or system. Some designs prioritize ease of understanding for human users, while others focus on efficiency for storage or transmission purposes.

Date and time formats are essential in programming for representing, parsing, and manipulating dates and times. Standard formats like ISO 8601 and Unix timestamp provide widely adopted conventions for consistent date and time representation. Additionally, programming languages offer functions and libraries to handle date and time formatting and parsing. By effectively understanding and utilizing date and time formats, developers can ensure accurate and reliable handling of temporal information in their applications.
"
270,Datetime parsing and formatting,885,9814,3174,https://hyperskill.org/learn/step/9814,Error extracting text: The `response.text` quick accessor only works for simple (single-`Part`) text responses. This response is not simple text.Use the `result.parts` accessor or the full `result.candidates[index].content.parts` lookup instead.
271,Introduction to multiprocessing,3385,35522,3178,https://hyperskill.org/learn/step/35522,"If your Python program runs slower than you expected, multiprocessing can be a solution for you. In this topic, we will explore the fundamentals of multiprocessing in Python, focusing on accelerating CPU-intensive tasks. We will introduce the concept of a process and discuss how to manage it. We will also examine the different process-initiating methods, specifically spawn and fork techniques. Lastly, we will look at inter-process communication tools such as Queue and Pipe.
Multiprocessing process
Python's multiprocessing library is a lifesaver when dealing with tasks that consume a lot of CPU time. The cornerstone of this library is the Process class. Think of a Process as an independent unit of work that runs separately from the main program. Each Process has its own Python interpreter and memory space.

Before diving into the benefits of multiprocessing, let's first look at a code example that performs two different, calculation-heavy tasks without multiprocessing.

This code calculates the sum of squares and the sum of cubes for a list of numbers. It completes the sum of squares before proceeding with the sum of cubes. Remember that the required time would significantly increase for larger or more complex calculations.
The displayed Process ID (PID) is for the main program. In a single-threaded environment like this, all tasks share the same PID, which means they can't run concurrently. This is why multiprocessing can be beneficial. It allows you to perform multiple tasks simultaneously, each with its own PID, making your program more efficient.
The following section will demonstrate how two separate processes can make these calculations faster.
Different methods of starting
Python offers two main strategies when initiating a new process: fork and spawn. These methods differ in creating a new technique and sharing resources, so understanding the nuances can help you pick the right approach for your project.
The fork method creates a new process by duplicating the current process. The parent and child processes continue to execute from the point where the fork was called. This means that the child process inherits the memory state and resources of the parent process.
Since the child process shares the parent's memory, the fork method is generally faster and uses less memory. Moreover, the child process can easily access the parent's variables and state, simplifying inter-process communication. Because the child process inherits the parent's resources, it can sometimes lead to issues like resource locking. 
Here's how you can modify the previous code to use multiprocessing with the fork method:

In the code example above, we use Python's multiprocessing library to create two separate processes: one for calculating the sum of squares (calculate_square) and another for calculating the sum of cubes (calculate_cube).
Each process runs independently and has its Process ID (PID), which we print out during the calculation. This helps you see that two different processes are indeed running the calculations.
The Process class from the multiprocessing library makes it easy to create these separate processes. We define the function each process will run (target) and any arguments it needs (args). After defining the processes, we start with the start() and wait for them to be completed with join().

The default method of starting a process in multiprocessing is fork
The spawn method creates an entirely new Python interpreter for each child process. This ensures that each process is fully independent and starts with a clean state. This is useful to ensure your processes do not share data or state.
Here's how you can modify the previous code to use multiprocessing with the spawn method:


In this modified code, we introduce the set_start_method('spawn') to specify the spawn method for starting new processes. 
We can run both calculations simultaneously by multiprocessing, making the program more efficient. This is especially beneficial for larger numbers or more complex calculations, where the time required would be significantly higher if run sequentially.
So, when to fork and when to spawn? The fork is likely better if you need to share state or data between your processes. However, spawn is your go-to option if you aim for independent processes.
Interprocess communication
Inter-process communication is often a necessary part of multiprocessing. You might need to pass data between processes or even send a signal to let another process know that a task is complete. Two popular ways to handle this in Python's multiprocessing module are through Queue and Pipe.
A Queue is a simple way to send and receive messages between processes. It's a First-In-First-Out (FIFO) data structure, meaning the first item you put in is the first to come out. It's thread-safe and process-safe, making it an excellent choice for most use cases.
Suppose you have a list of numbers and want to calculate the sum using multiple processes.

In this example, a child process calculates the sum of a list of numbers and puts the result into the queue. The parent process then retrieves the sum from the queue and prints it.
While Queue is based on a pipe and some locking mechanisms, Pipe is a lower-level communication method. It can be faster but less safe. Pipes can be used for bidirectional communication between two processes.
Let's say you want to calculate the factorial of a number in a child process and then send the result back to the parent process for further manipulation or output.

In this example, the child process calculates the factorial of a given number. It then sends this result back to the parent process through the Pipe. The parent process receives the result using parent_conn.recv() and prints it out.
When choosing, Queue is generally easier to use and safer, making it suitable for most applications. On the other hand, if you need faster, more direct communication and are willing to handle the safety aspects yourself, Pipe might be the better choice. Selecting between Queue and Pipe should be based on your specific needs for data safety, speed, and the complexity of the data being exchanged. With these examples, you can better assess which tool fits your project requirements.
Conclusion
This topic outlined essential aspects of Python's multiprocessing. The main points to remember are:

Multiprocessing basics: The Process class is foundational for initiating and controlling parallel tasks.
Spawn vs. Fork: Fork enables quick startups by sharing state while Spawn offers process isolation.
Inter-process communication: Queue is user-friendly and safe, whereas Pipe provides faster but less secure data exchange.
"
272,Multiprocessing pool,3539,37224,3183,https://hyperskill.org/learn/step/37224,"The Pool class in Python's multiprocessing module provides a convenient means of managing a pool of worker processes. It comes with built-in methods that offer structured ways to distribute tasks among these processes. In this topic, we will look into the functionality of Pool and its notable methods — map, imap, apply, and apply_async — to harness the power of multiprocessing for efficient task management and execution.

An overview of pool in multiprocessing
The Pool class belongs to the multiprocessing module in Python, providing a convenient avenue for executing parallel tasks. When you start a Pool, you create a set of worker processes that are ready to perform tasks simultaneously. This capability makes it a pivotal tool for effective multiprocessing.

Let's offer a simplified analogy to understand the Pool concept better: Picture a boss with a team of workers. The boss has a to-do list. Instead of tackling all the tasks single-handedly, the boss divides them among the workers, who then carry them out at the same time. In this case, the boss represents the Pool, and the workers symbolize the worker processes.

Moving back to Python, when you establish a Pool, you need to determine the count of worker processes it should oversee. Usually, this count should match the number of cores on your computer, allowing you to fully harness your machine's processing capacity.

The Pool class incorporates various methods like map, imap, apply, and apply_async, each devised for distinctive scenarios of task distribution and execution. These methods aid in effectively distributing tasks to the worker processes and gathering the results once the tasks are done.

Iteration methods: map and imap
The Pool class provides two methods, map and imap, for distributing a function call across various input values and collecting the results. These methods facilitate parallel data processing, which greatly enhances the performance of your program when handling large datasets or tasks that require a lot of computation.

The map method applies a function to every item in a provided iterable, such as a list or tuple, and returns a list of results. With Pool.map, this process happens in parallel, where each worker process deals with a part of the data. The method signature is Pool.map(function, iterable, chunksize=None). The chunksize argument is optional; it helps split the iterable into several chunks that are then sent to worker processes.

In the example above, the square function is applied to each number in the numbers list. Each worker process in the pool calculates a part of the result, which is then gathered into a single list.

The imap method resembles map, but returns an iterator that gives results as soon as they are ready. This is advantageous when processing a flow of data or when you wish to start processing results before all tasks are finished. The method signature is Pool.imap(function, iterable, chunksize=1).

In this example, imap delivers an iterator that yields the square of each number as soon as it is computed. This enables immediate access to the results, in contrast to map, which waits until all computations are finished before returning the results.

Application methods: apply and apply_async
The Pool class offers methods to process a function with arguments in parallel. These methods, apply and apply_async, aid in executing a function with given arguments and manage the distribution of these function calls among the pool of worker processes.

The apply method lets you submit a function and its arguments to a worker process within the pool. The method signature reads Pool.apply(func, args=(), kwds={}). Here, func is the function to be executed, args is a tuple of arguments, and kwds is a dictionary of keyword arguments.

In the code snippet above, the add_numbers function, with its arguments (5, 3), is submitted to a worker process in the pool, which then calculates and returns the result.

The apply_async method works similarly to apply, but operates asynchronously. It returns promptly with an AsyncResult object without waiting for the computation to finish. You can use the get() method on the AsyncResult object to fetch the result once it's ready. The method signature reads Pool.apply_async(func, args=(), kwds={}, callback=None, error_callback=None).

In this example, apply_async submits the add_numbers function to the pool and moves ahead without waiting for the result. Once the AsyncResult object shows the computation is complete, get() fetches the result.

Both apply and apply_async methods aim to distribute individual function calls to the worker processes in the pool. While apply waits for the result, apply_async allows for asynchronous execution, often resulting in more efficient resource usage and increased program responsiveness, as it enables further code to run while waiting for the result.

Practical implications: Real-world use cases of pool in multiprocessing
You can use the Pool class in Python's multiprocessing module when you need parallel processing to improve performance and efficiency.

Data Processing: Speed up the analysis of large datasets, like in data mining or statistical analysis tasks.
Image/Video Processing: Accelerate similar computationally intensive tasks, such as image resizing or video transcoding.
Web Scraping: Fetch and process data from multiple web pages simultaneously to hasten data collection.
Simulation and Modeling: Run simulations in areas like computational physics or financial modeling in parallel.
Machine Learning: Train multiple models at once or fine-tune parameters in parallel.
Network Operations: Monitor multiple network endpoints and perform simultaneous network scans for efficient network management.

Whenever you're dealing with computationally intensive tasks, large datasets, or operations that benefit from concurrent execution, the Pool class can enhance your application's performance and efficiency.

Conclusion
The Pool class found in Python's multiprocessing module makes it simple to distribute and execute tasks efficiently across a pool of worker processes. It offers methods such as map, imap, apply, and apply_async, which simplify parallel processing for a wide range of real-world instances, including data analysis, image processing, and web scraping. By using the Pool class, you can greatly enhance program performance and handle intense computational tasks effectively in a multiprocessing scenario.
"
273,Publishing your project on GitHub,3080,30945,3634,https://hyperskill.org/learn/step/30945,"Your project is complete! Now it's time to consider sharing it with the world, so your friends or potential employers can see it. A portfolio showcasing your projects can increase your chances of landing a new job. A well-crafted portfolio featuring real-world projects helps you stand out and may make employers more likely to choose you. In this section, you'll learn two ways to share your Hyperskill projects on GitHub. You can also find this information in our Hyperskill support pages.

Create the repository
First, you need to create a repository for your future project. A repository is where GitHub stores all the project files. To do this, go to GitHub and sign in to your account. Then click on the ""New"" button in the upper left corner of your Dashboard or give your repo a name, and click ""Create new repository"":

If you choose ""New"", a new page will appear where you can enter all the necessary information: the name of the repository and an optional brief description of the repository:

If you checked ""Add a README file"", chose a license, or added a .gitignore template, the new repo will have each of these in their corresponding files: README.md, LICENSE, and .gitignore. You can learn more about them in the provided links. After clicking ""Create repository"", you'll be redirected to the new repository.

Otherwise, your repository will not have any files and the page will have instructions on how to add files to your new repo:

Great, you now have a repository hosted on GitHub!

Finding your project files
Now it's time to switch to an IDE where you developed your project. Depending on the programming language and IDE, your project files will be in different locations. On the left side of the IDE, in the project panel, you can view the course structure for the project (remember to switch from ""Course"" to ""Project"" view). Let's start with a Python project like Web Calendar:

For Python projects, app.py is the only file you need to add to your repository because this is the file where you wrote your code. It may have other names like main.py or task.py. You can also include requirement.txt which has all the packages needed to run your code. Other files are directly related to the platform and are necessary to check your solutions. They do not belong in your project repository. You can right-click this file and ""Open In Explorer."" In most cases, the project exists in the task folder within the project directory: ~/PycharmProjects/ProjectName/ProjectName/task/ or %USERPROFILE%/PycharmProjects/ProjectName/ProjectName/task/ on Windows OS.

If you are working in IntelliJ IDEA or WebStorm for Java/Kotlin/Scala projects, you will find project files in the src folder. In Android Studio, they can be found within src/main/. Again, you can view them in Explorer/Finder. In general, the path will be as follows: ~/[IdeaProjects|WebstromProjects]/ProjectName/ProjectName/task/src/ProjectName or %USERPROFILE%/[IdeaProjects|WebstromProjects]/ProjectName/ProjectName/task/src/ProjectName. Let's take a look at Maze Runner (Kotlin), for example:

Here, you can also add configuration files: build.gradle as well as settings.gradle. Now that you know where your project files are, there are several ways to publish them on GitHub. You can either add the files using the GitHub web interface, command line, built-in IDE tools, or even GitHub Desktop. It's up to you. We will cover posting via the IDE as well as the GitHub web interface on this topic.

Publishing Hyperskill Projects to GitHub via IDE
JetBrains IDEs integrate Git functionality by providing a built-in version control system (VCS) interface. You can clone repositories, manage branches, commit changes, resolve conflicts, and push updates directly from the IDE. This greatly streamlines development workflows without needing external Git tools or command-line usage. This means you can post your projects directly to GitHub, among other things.

As soon as you complete all stages, you will find a ""Post project to GitHub"" link on the check panel:

Alternatively, you can use the VCS tab in your IDE:

You'll see a standard IDEA dialog suggesting posting to GitHub:

You will be able to select the files you want to add to your repository in the next dialog. Remember, only your project files and settings/dependencies (Python requirements and Gradle configuration) are necessary:

Adding files via the GitHub web interface
Time to go back to the page of the first repository. The process of adding files via the web interface is quite intuitive. Click on the ""Add file"" button and select ""Upload files"":

You will see the following page:

Go to the directory you discovered in the previous section and drag the necessary file to this window, or select ""choose your files"" and select the file. It is a good practice to fill in the commit information according to the Conventional Commits specification and add some description about the files you add. After you are done, click the ""Commit changes"" button. GitHub will add your file to the repository!

To verify everything is working as expected, you can do the following:
Post project to GitHub;
Clone it locally;
Check that the solution can be run.

Great job, now you're all set! Your colleagues and future employers can now see all the amazing projects you've been doing.

Conclusion
Congratulations on completing your project! You now know how to publish it on GitHub. There are several ways to do this, including using the Integrated Development Environment (IDE), the web interface, the console application, or GitHub Desktop. Regardless of the method you select, your project is now visible to the world.

As you enhance your portfolio, adding diverse projects will significantly increase its impact. By including a variety of projects, you can strengthen and enrich your portfolio's breadth. This not only sharpens your skills but also helps create a well-rounded portfolio that will impress both friends and potential employers. Happy coding
"
